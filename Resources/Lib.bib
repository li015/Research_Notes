@inproceedings{13thEastAsiaPacific2013,
  title = {13th {{East Asia-Pacific Conference}} on {{Structural Engineering}} and {{Construction}}, {{EASEC}} 2013},
  booktitle = {Proceedings of the 13th {{East Asia-Pacific Conference}} on {{Structural Engineering}} and {{Construction}}, {{EASEC}} 2013},
  date = {2013},
  abstract = {The proceedings contain 311 papers. The special focus in this conference is on Structural Engineering and Construction. The topics include: Wind-vehicle-bridge interaction; an integrated deterioration method for predicting long-term performance of bridge components; evaluation of tsunami force acting on bridge girders; friction damper in traditional buildings in Indonesia; seismic performance of fixed-movable-fixed supported folded cantilever shear structure; development of a passive variable friction damper with displacement-dependent damping force characteristics; expansion joint seismic damage evaluation on curved bridges equipped with friction pendulum systems; sloped rolling-type isolation devices for seismic protection of equipment and facilities; a probabilistic approach for damage detection utilizing incomplete modal data; wave propagation analysis of cracked levy plate; development of a relative displacement sensor for structural health monitoring; monitoring of traffic axle loads in orthotropic steel deck structures; an in-situ experiment of F-bent double decked freeway bridge; the development of web-based integrating management information system in construction lab; quality management from QA to TQM in the Hong Kong construction industry; diagnostics of steel roof structures of sport stadiums; numerical study on shear strength degradation after flexural yielding of RC member subjected to cyclic loading; a proposal for compressive design strength of stainless steel plates; repaired chromosome in genetic algorithm for steel structure optimization; analysis of piled raft foundations in clayey soils using finite element and analytical methods; optimization on footing layout design for residential house with piles foundation; presenting a new approach based on inertia forces to control the vibration of structures; mitigation measures for expansion joint effects on seismic performance of bridge structures; seismic response of curved grillage girder viaducts with base isolation system in cold region; response of base-isolated buildings subject to near-fault ground motion considering seismic pounding; active solar systems for energy efficient facade structures; application of smart sensors for bridge vibration measurement under low temperature environment; proposal of bridge management system using cloud computing for local government; enhancing worker onsite safety management using RFID technology in construction; 2D barcode-based properties breakdown reporting and maintaining management system; enhancing visual unit bath setup implementation using BIM approach; panel zone in the flange plate connection to box column; structural performance of continuity connection for decked bulb tee girder; assessment for seismic performance of headed bar anchoring in internal beam-column joints; shear behaviour of composite slab reinforced with steel fibre concrete topping; a new model for concrete in compression considering the growth of the damage zone; shear capacity of reinforced high-strength concrete beams without web reinforcement; deformation-based approach for determination of the efficiency of the confinement in R/C members; assessment method of seismic performance for corroded reinforced concrete buildings; influence of beam flange thickness on seismic performance of flange plate connections; dynamic response evaluation on curved twin I-girder bridge using vehicle-bridge coupled vibration analysis; study on simplification of girder structure in suspension bridge; full-scale experimental verification of semi-active control on cable -MR damper system; vibration of thermo-elastically damped imperfect ring gyro; multi-period evaluation model for the satisfaction degree in property management; dynamic loading tests carried out after repair works of the Yodogawa bridge; non-destructive tests applied during repair works of the Yodogawa bridge; fatigue strength of longitudinal welded joints with steel corrugated plates; the mechanical properties of hybrid fibre reinforced composite concrete; ductility and strength of reinforced concrete beams intrinsically reinforced with polypropylene fibres; evaluation on prediction error of corrosion initiation time depending on number of concrete cores; shear capacity of RC beams containing corroded longitudinal bars; restraining of chloride induced corrosion in RC structures using ion exchange resin; numerical analysis of influencing factors on corrosion-induced concrete cracking with RBSM; seismic evaluation of RC columns considering equivalency of circular and square cross-sections; seismic damage prediction of water supply system with PML index; strength evaluation for a corroded damaged steel girder end considering its collapse mechanism; dynamic response of structures loaded by outside blasts; exploring critical conflict issues between public owners and contractors during construction phase; structure of risk transfer in Indonesian public road projects; building stakeholder relationships in biomass energy industry in rural China; load-carrying capacities of isolated tower scaffolds used in construction; glue-laminated composite sandwich beams for structural engineering and construction; comparative study of the interlocking block and clay brick masonry building; a study of structural material quantities of high-rise residential buildings; investigation of mechanical properties of a new type of acid resistant concrete; on the development of high volume volcanic mud mortar and concrete; seismic evaluation of an existing overpass steel bridge by time history analysis for its retrofit design; smart FRP systems with embedded FBG for structural monitoring and retrofitting; close-range stereo registration for concrete crack monitoring; a BIM-based framework for selection of cost-effective green building design; a prospect game theory model for bidding price decision; cutting pattern generation for reinforcement bars using intensive search algorithm; influence of boundary condition to push-out test of headed stud shear connector; fundamental study on experiments for torque shear test to evaluate bonding strength of steel-concrete joint; an investigation on the effect of cement and silica fume on properties of self-compacting concrete; development of a sliding bearing system for seismic isolation in vertical direction; effect of base isolation on seismic fragility of aboveground LNG storage tanks; reliability estimation of recycled aggregate concrete structure subjected to carbonation; verification of self-healing mechanism in OPC incorporating carbonate; observation of recycled aggregate structure using X-ray CT; biaxial flexural fatigue responses of circular concrete plates; effects of near-field earthquakes on elevated cylindrical water tanks; redundancy of continuous two-girder steel-concrete composite highway bridges; parametric modelling for modular prefabricated bridges; optimal structural configurations for tall buildings; size effect on shear capacity of reinforced concrete beams strengthened by FRP U-shape jacket; column test of concrete-filled steel tubes with reinforced lattice angle; evaluation of structural performance of precast modular pier cap; evaluating the effects of period of structures on soil-structure interaction; dynamical behaviour of steel towers by numerical simulation; analysis on seismic performance of energy dissipation subsidiary piers considering foundation effects; damage identification of a belt-conveyor support structure using local vibration modes; indirect measurement of bridge frequencies by a hand-drawn cart; basic study on damage localization of steel bridges based on the changes of modal amplitude; energy-based damping estimation of steel bridges and its applicability to damage detection; patch loading - stability analysis with exact in-plane stress functions; housing for poverty stricken masses; compressive-to-tensile strength ratio of buckling-restrained braces using steel-and-mortar planks; numerical simulation of welding deformation and residual stress by FEM with shell elements; finite element simulation of crack welding with contact pressure effect; development of GFRP and UHF composite girders; experimental investigation of masonry calcareous walls repaired and strengthened by C-FRP; out-of-plane loading tests on masonry walls strengthened with restraining axial elongation; shaking table testing of a multi-storey post-tensioned timber building; sloshing effect and mitigation solution of floating oil storage tank; track vibrations during accelerating and decelerating phases of high-speed rails; study on vibration induced by the shaking tables array in large scale civil lab; seismic performance of steel bridge piers with corrosion damages; shear strength of dry joints in precast concrete modules; experimental study on shear-slipping behavior of PBL joint connection between concrete and UFC hybrid girder; strengthening of deficient RC columns by steel angles and battens under axial load and investigating mechanical performances of double lap composite joint with stepwise patch.}
}

@inproceedings{13thEastAsiaPacific2013a,
  title = {13th {{East Asia-Pacific Conference}} on {{Structural Engineering}} and {{Construction}}, {{EASEC}} 2013},
  booktitle = {Proceedings of the 13th {{East Asia-Pacific Conference}} on {{Structural Engineering}} and {{Construction}}, {{EASEC}} 2013},
  date = {2013},
  abstract = {The proceedings contain 311 papers. The special focus in this conference is on Structural Engineering and Construction. The topics include: Wind-vehicle-bridge interaction; an integrated deterioration method for predicting long-term performance of bridge components; evaluation of tsunami force acting on bridge girders; friction damper in traditional buildings in Indonesia; seismic performance of fixed-movable-fixed supported folded cantilever shear structure; development of a passive variable friction damper with displacement-dependent damping force characteristics; expansion joint seismic damage evaluation on curved bridges equipped with friction pendulum systems; sloped rolling-type isolation devices for seismic protection of equipment and facilities; a probabilistic approach for damage detection utilizing incomplete modal data; wave propagation analysis of cracked levy plate; development of a relative displacement sensor for structural health monitoring; monitoring of traffic axle loads in orthotropic steel deck structures; an in-situ experiment of F-bent double decked freeway bridge; the development of web-based integrating management information system in construction lab; quality management from QA to TQM in the Hong Kong construction industry; diagnostics of steel roof structures of sport stadiums; numerical study on shear strength degradation after flexural yielding of RC member subjected to cyclic loading; a proposal for compressive design strength of stainless steel plates; repaired chromosome in genetic algorithm for steel structure optimization; analysis of piled raft foundations in clayey soils using finite element and analytical methods; optimization on footing layout design for residential house with piles foundation; presenting a new approach based on inertia forces to control the vibration of structures; mitigation measures for expansion joint effects on seismic performance of bridge structures; seismic response of curved grillage girder viaducts with base isolation system in cold region; response of base-isolated buildings subject to near-fault ground motion considering seismic pounding; active solar systems for energy efficient facade structures; application of smart sensors for bridge vibration measurement under low temperature environment; proposal of bridge management system using cloud computing for local government; enhancing worker onsite safety management using RFID technology in construction; 2D barcode-based properties breakdown reporting and maintaining management system; enhancing visual unit bath setup implementation using BIM approach; panel zone in the flange plate connection to box column; structural performance of continuity connection for decked bulb tee girder; assessment for seismic performance of headed bar anchoring in internal beam-column joints; shear behaviour of composite slab reinforced with steel fibre concrete topping; a new model for concrete in compression considering the growth of the damage zone; shear capacity of reinforced high-strength concrete beams without web reinforcement; deformation-based approach for determination of the efficiency of the confinement in R/C members; assessment method of seismic performance for corroded reinforced concrete buildings; influence of beam flange thickness on seismic performance of flange plate connections; dynamic response evaluation on curved twin I-girder bridge using vehicle-bridge coupled vibration analysis; study on simplification of girder structure in suspension bridge; full-scale experimental verification of semi-active control on cable -MR damper system; vibration of thermo-elastically damped imperfect ring gyro; multi-period evaluation model for the satisfaction degree in property management; dynamic loading tests carried out after repair works of the Yodogawa bridge; non-destructive tests applied during repair works of the Yodogawa bridge; fatigue strength of longitudinal welded joints with steel corrugated plates; the mechanical properties of hybrid fibre reinforced composite concrete; ductility and strength of reinforced concrete beams intrinsically reinforced with polypropylene fibres; evaluation on prediction error of corrosion initiation time depending on number of concrete cores; shear capacity of RC beams containing corroded longitudinal bars; restraining of chloride induced corrosion in RC structures using ion exchange resin; numerical analysis of influencing factors on corrosion-induced concrete cracking with RBSM; seismic evaluation of RC columns considering equivalency of circular and square cross-sections; seismic damage prediction of water supply system with PML index; strength evaluation for a corroded damaged steel girder end considering its collapse mechanism; dynamic response of structures loaded by outside blasts; exploring critical conflict issues between public owners and contractors during construction phase; structure of risk transfer in Indonesian public road projects; building stakeholder relationships in biomass energy industry in rural China; load-carrying capacities of isolated tower scaffolds used in construction; glue-laminated composite sandwich beams for structural engineering and construction; comparative study of the interlocking block and clay brick masonry building; a study of structural material quantities of high-rise residential buildings; investigation of mechanical properties of a new type of acid resistant concrete; on the development of high volume volcanic mud mortar and concrete; seismic evaluation of an existing overpass steel bridge by time history analysis for its retrofit design; smart FRP systems with embedded FBG for structural monitoring and retrofitting; close-range stereo registration for concrete crack monitoring; a BIM-based framework for selection of cost-effective green building design; a prospect game theory model for bidding price decision; cutting pattern generation for reinforcement bars using intensive search algorithm; influence of boundary condition to push-out test of headed stud shear connector; fundamental study on experiments for torque shear test to evaluate bonding strength of steel-concrete joint; an investigation on the effect of cement and silica fume on properties of self-compacting concrete; development of a sliding bearing system for seismic isolation in vertical direction; effect of base isolation on seismic fragility of aboveground LNG storage tanks; reliability estimation of recycled aggregate concrete structure subjected to carbonation; verification of self-healing mechanism in OPC incorporating carbonate; observation of recycled aggregate structure using X-ray CT; biaxial flexural fatigue responses of circular concrete plates; effects of near-field earthquakes on elevated cylindrical water tanks; redundancy of continuous two-girder steel-concrete composite highway bridges; parametric modelling for modular prefabricated bridges; optimal structural configurations for tall buildings; size effect on shear capacity of reinforced concrete beams strengthened by FRP U-shape jacket; column test of concrete-filled steel tubes with reinforced lattice angle; evaluation of structural performance of precast modular pier cap; evaluating the effects of period of structures on soil-structure interaction; dynamical behaviour of steel towers by numerical simulation; analysis on seismic performance of energy dissipation subsidiary piers considering foundation effects; damage identification of a belt-conveyor support structure using local vibration modes; indirect measurement of bridge frequencies by a hand-drawn cart; basic study on damage localization of steel bridges based on the changes of modal amplitude; energy-based damping estimation of steel bridges and its applicability to damage detection; patch loading - stability analysis with exact in-plane stress functions; housing for poverty stricken masses; compressive-to-tensile strength ratio of buckling-restrained braces using steel-and-mortar planks; numerical simulation of welding deformation and residual stress by FEM with shell elements; finite element simulation of crack welding with contact pressure effect; development of GFRP and UHF composite girders; experimental investigation of masonry calcareous walls repaired and strengthened by C-FRP; out-of-plane loading tests on masonry walls strengthened with restraining axial elongation; shaking table testing of a multi-storey post-tensioned timber building; sloshing effect and mitigation solution of floating oil storage tank; track vibrations during accelerating and decelerating phases of high-speed rails; study on vibration induced by the shaking tables array in large scale civil lab; seismic performance of steel bridge piers with corrosion damages; shear strength of dry joints in precast concrete modules; experimental study on shear-slipping behavior of PBL joint connection between concrete and UFC hybrid girder; strengthening of deficient RC columns by steel angles and battens under axial load and investigating mechanical performances of double lap composite joint with stepwise patch.}
}

@inproceedings{13thIAPRInternational2013,
  title = {13th {{IAPR International Conference}} on {{Machine Vision Applications}}, {{MVA}} 2013},
  booktitle = {Proceedings of the 13th {{IAPR International Conference}} on {{Machine Vision Applications}}, {{MVA}} 2013},
  date = {2013},
  abstract = {The proceedings contain 115 papers. The special focus in this conference is on Machine Vision Applications. The topics include: Multi spatio-temporal co-occurrence measures for human action classification; intelligent human detection based on depth information; calibration of the projector with fixed pattern and large distortion lens in a structured light system; experimental evaluation of stereo-based person tracking in real environment; a real-time ica-based activity recognition in video sequences; a framework unifying the development of image analysis algorithms and associated user interfaces; learning-based human fall detection using rgb-d cameras; detection method of scallop and asteroid from seabed video; comparing investigation of images and 3d mesh model for categorizing electric appliance components; bog: An extension of hog by interpreting it as bag of features; an object-driven online segmentation system for mobile robots; enhanced photometric stereo with multispectral images; multimodal stereo vision using mutual information with adaptive windowing; video-based head tracking for high-performance games; global binary patterns: A novel shape descriptor; automatic sharp feature extraction from point clouds with optimal neighborhood size; body pose based pedestrian tracking in a particle filtering framework; segmentation of human instances using grab-cut and active shape model feedback; scene change detection and topological map construction using omnidirectional image sequences; small target detection combining foreground and background manifolds; latent spatio-temporal models for action localization and recognition in nursing home surveillance video; detection and decomposition of foreground target from image sequence; the local-threshold 2d-tophat cell segmentation for the two-photon confocal microscope image; big trajectory data analysis for clustering and anomaly detection.},
  isbn = {978-4-901122-13-9}
}

@inproceedings{13thIAPRInternational2013a,
  title = {13th {{IAPR International Conference}} on {{Machine Vision Applications}}, {{MVA}} 2013},
  booktitle = {Proceedings of the 13th {{IAPR International Conference}} on {{Machine Vision Applications}}, {{MVA}} 2013},
  date = {2013},
  abstract = {The proceedings contain 115 papers. The special focus in this conference is on Machine Vision Applications. The topics include: Multi spatio-temporal co-occurrence measures for human action classification; intelligent human detection based on depth information; calibration of the projector with fixed pattern and large distortion lens in a structured light system; experimental evaluation of stereo-based person tracking in real environment; a real-time ica-based activity recognition in video sequences; a framework unifying the development of image analysis algorithms and associated user interfaces; learning-based human fall detection using rgb-d cameras; detection method of scallop and asteroid from seabed video; comparing investigation of images and 3d mesh model for categorizing electric appliance components; bog: An extension of hog by interpreting it as bag of features; an object-driven online segmentation system for mobile robots; enhanced photometric stereo with multispectral images; multimodal stereo vision using mutual information with adaptive windowing; video-based head tracking for high-performance games; global binary patterns: A novel shape descriptor; automatic sharp feature extraction from point clouds with optimal neighborhood size; body pose based pedestrian tracking in a particle filtering framework; segmentation of human instances using grab-cut and active shape model feedback; scene change detection and topological map construction using omnidirectional image sequences; small target detection combining foreground and background manifolds; latent spatio-temporal models for action localization and recognition in nursing home surveillance video; detection and decomposition of foreground target from image sequence; the local-threshold 2d-tophat cell segmentation for the two-photon confocal microscope image; big trajectory data analysis for clustering and anomaly detection.},
  isbn = {978-4-901122-13-9}
}

@inproceedings{2012IEEEApplied2012,
  title = {2012 {{IEEE Applied Imagery Pattern Recognition Workshop}}, {{AIPR}} 2012},
  booktitle = {Proceedings - {{Applied Imagery Pattern Recognition Workshop}}},
  date = {2012},
  abstract = {The proceedings contain 35 papers. The topics discussed include: future image frame generation using artificial neural network with selected features; unsupervised land cover classification in multispectral imagery with sparse representations on learned dictionaries; distributed adaptive spectral and spatial sensor fusion for super-resolution classification; centralized multi-scale singular value decomposition for feature construction in LIDAR image classification problems; contextual video clip classification; generation of future image frames using adaptive network based fuzzy inference system on spatiotemporal framework; obtaining accurate change detection results from high-resolution satellite sensors; simulating vision through time: hierarchical, sparse models of visual cortex for motion imagery; and video track screening using syntactic activity-based methods.},
  isbn = {978-1-4673-4558-3}
}

@inproceedings{2012IEEEApplied2012a,
  title = {2012 {{IEEE Applied Imagery Pattern Recognition Workshop}}, {{AIPR}} 2012},
  booktitle = {Proceedings - {{Applied Imagery Pattern Recognition Workshop}}},
  date = {2012},
  abstract = {The proceedings contain 35 papers. The topics discussed include: future image frame generation using artificial neural network with selected features; unsupervised land cover classification in multispectral imagery with sparse representations on learned dictionaries; distributed adaptive spectral and spatial sensor fusion for super-resolution classification; centralized multi-scale singular value decomposition for feature construction in LIDAR image classification problems; contextual video clip classification; generation of future image frames using adaptive network based fuzzy inference system on spatiotemporal framework; obtaining accurate change detection results from high-resolution satellite sensors; simulating vision through time: hierarchical, sparse models of visual cortex for motion imagery; and video track screening using syntactic activity-based methods.},
  isbn = {978-1-4673-4558-3}
}

@book{25thInternationalSymposium2020,
  title = {25th {{International Symposium}} on {{Methodologies}} for {{Intelligent Systems}}, {{ISMIS}} 2020},
  date = {2020},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {12117 LNAI},
  abstract = {The proceedings contain 44 papers. The special focus in this conference is on Methodologies for Intelligent Systems. The topics include: A Deep Learning Approach to Fake News Detection; satirical News Detection with Semantic Feature Extraction and Game-Theoretic Rough Sets; comparing State-of-the-Art Neural Network Ensemble Methods in Soccer Predictions; static Music Emotion Recognition Using Recurrent Neural Networks; saliency Detection in Hyperspectral Images Using Autoencoder-Based Data Reconstruction; mesoscale Anisotropically-Connected Learning; empirical Comparison of Graph Embeddings for Trust-Based Collaborative Filtering; neural Spike Sorting Using Unsupervised Adversarial Learning; poriferal Vision: Classifying Benthic Sponge Spicules to Assess Historical Impacts of Marine Climate Change; the Construction of Action Rules to Raise Artwork Prices; Experimental Evaluation of GAN-Based One-Class Anomaly Detection on Office Monitoring; ranking Speech Features for Their Usage in Singing Emotion Classification; leveraging Machine Learning in IoT to Predict the Trustworthiness of Mobile Crowd Sensing Data; a Hierarchical-Based Web-Platform for Crowdsourcing Distinguishable Image Patches; performing Arithmetic Using a Neural Network Trained on Digit Permutation Pairs; CatIO - A Framework for Model-Based Diagnosis of Cyber-Physical Systems; data Publishing: Availability of Data Under Security Policies; matrix Factorization Based Heuristics Learning for Solving Constraint Satisfaction Problems; explaining Object Motion Using Answer Set Programming; The GraphBRAIN System for Knowledge Graph Management and Advanced Fruition; metric-Guided Multi-task Learning; mining Exceptional Mediation Models; multivariate Predictive Clustering Trees for Classification; comparison of Machine Learning Methods to Detect Anomalies in the Activity of Dairy Cows; clustering Algorithm Consistency in Fixed Dimensional Spaces; estimating the Importance of Relational Features by Using Gradient Boosting.},
  isbn = {978-3-030-59490-9}
}

@book{25thInternationalSymposium2020a,
  title = {25th {{International Symposium}} on {{Methodologies}} for {{Intelligent Systems}}, {{ISMIS}} 2020},
  date = {2020},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {12117 LNAI},
  abstract = {The proceedings contain 44 papers. The special focus in this conference is on Methodologies for Intelligent Systems. The topics include: A Deep Learning Approach to Fake News Detection; satirical News Detection with Semantic Feature Extraction and Game-Theoretic Rough Sets; comparing State-of-the-Art Neural Network Ensemble Methods in Soccer Predictions; static Music Emotion Recognition Using Recurrent Neural Networks; saliency Detection in Hyperspectral Images Using Autoencoder-Based Data Reconstruction; mesoscale Anisotropically-Connected Learning; empirical Comparison of Graph Embeddings for Trust-Based Collaborative Filtering; neural Spike Sorting Using Unsupervised Adversarial Learning; poriferal Vision: Classifying Benthic Sponge Spicules to Assess Historical Impacts of Marine Climate Change; the Construction of Action Rules to Raise Artwork Prices; Experimental Evaluation of GAN-Based One-Class Anomaly Detection on Office Monitoring; ranking Speech Features for Their Usage in Singing Emotion Classification; leveraging Machine Learning in IoT to Predict the Trustworthiness of Mobile Crowd Sensing Data; a Hierarchical-Based Web-Platform for Crowdsourcing Distinguishable Image Patches; performing Arithmetic Using a Neural Network Trained on Digit Permutation Pairs; CatIO - A Framework for Model-Based Diagnosis of Cyber-Physical Systems; data Publishing: Availability of Data Under Security Policies; matrix Factorization Based Heuristics Learning for Solving Constraint Satisfaction Problems; explaining Object Motion Using Answer Set Programming; The GraphBRAIN System for Knowledge Graph Management and Advanced Fruition; metric-Guided Multi-task Learning; mining Exceptional Mediation Models; multivariate Predictive Clustering Trees for Classification; comparison of Machine Learning Methods to Detect Anomalies in the Activity of Dairy Cows; clustering Algorithm Consistency in Fixed Dimensional Spaces; estimating the Importance of Relational Features by Using Gradient Boosting.},
  isbn = {978-3-030-59490-9}
}

@inproceedings{3rdInternationalConference2019,
  title = {3rd {{International Conference}} on {{Building Information Modelling}} in {{Design}}, {{Construction}} and {{Operations}}, {{BIM}} 2019},
  booktitle = {{{WIT Transactions}} on the {{Built Environment}}},
  date = {2019},
  volume = {192},
  abstract = {The proceedings contain 28 papers. The special focus in this conference is on Building Information Modelling in Design, Construction and Operations. The topics include: Computational bim for green retrofitting of the existing building envelope; bim-based lca throughout the design process: A dynamic approach; parametric modelling in construction: Investigating the quality of rule-based checking; bim-based analysis of spatial properties in building layouts; necessity of monitoring vital bim information for optimized design process management; lessons learned from the 2022 world cup final stadium, Qatar; revolutionizing the future of the construction industry: Strategizing and redefining challenges; model of information sharing and exchange in a building information modelling supply chain; evolution within the maturity concept of bim; integrated factory modelling: Using bim to disrupt the interface between manufacturing and construction in factory planning; bim methodology applied to architectural heritage preservation: Case study of the medina and dungeons of tetuÁn, morocco; information modelling and management in historical contexts: An italian case study; study on the establishment of a maintenance mode for a bim-based landscape project; 4d bim-oriented digital project construction management for the aec industry; 5d bim: Tools and methods for digital project construction management; strategies and outcomes of bim education: Italian experiences; structural pre-analysis through implementing revit structures and robot to develop and compare engineered timber structural families; development of model checking rules for validation and content checking; exploring bim intelligence further with itwo; bim objects library for information exchange in public works: The use of proprietary and open formats.},
  isbn = {978-1-78466-361-2}
}

@inproceedings{3rdInternationalConference2019a,
  title = {3rd {{International Conference}} on {{Building Information Modelling}} in {{Design}}, {{Construction}} and {{Operations}}, {{BIM}} 2019},
  booktitle = {{{WIT Transactions}} on the {{Built Environment}}},
  date = {2019},
  volume = {192},
  abstract = {The proceedings contain 28 papers. The special focus in this conference is on Building Information Modelling in Design, Construction and Operations. The topics include: Computational bim for green retrofitting of the existing building envelope; bim-based lca throughout the design process: A dynamic approach; parametric modelling in construction: Investigating the quality of rule-based checking; bim-based analysis of spatial properties in building layouts; necessity of monitoring vital bim information for optimized design process management; lessons learned from the 2022 world cup final stadium, Qatar; revolutionizing the future of the construction industry: Strategizing and redefining challenges; model of information sharing and exchange in a building information modelling supply chain; evolution within the maturity concept of bim; integrated factory modelling: Using bim to disrupt the interface between manufacturing and construction in factory planning; bim methodology applied to architectural heritage preservation: Case study of the medina and dungeons of tetuÁn, morocco; information modelling and management in historical contexts: An italian case study; study on the establishment of a maintenance mode for a bim-based landscape project; 4d bim-oriented digital project construction management for the aec industry; 5d bim: Tools and methods for digital project construction management; strategies and outcomes of bim education: Italian experiences; structural pre-analysis through implementing revit structures and robot to develop and compare engineered timber structural families; development of model checking rules for validation and content checking; exploring bim intelligence further with itwo; bim objects library for information exchange in public works: The use of proprietary and open formats.},
  isbn = {978-1-78466-361-2}
}

@book{4thInternationalConference2014,
  title = {4th {{International Conference}} on {{Intelligent Structure}} and {{Vibration Control}}, {{ISVC}} 2014},
  date = {2014},
  journaltitle = {Applied Mechanics and Materials},
  volume = {539},
  abstract = {The proceedings contain 199 papers. The special focus in this conference is on Advanced Intelligent Structure, Bio-inspired Smart Materials and Structures, Materials for energy storage, Active Materials, Mechanics and Behavior, Vibration and Control, Modeling, Simulation, Control and Applications, Fuzzy System and Fuzzy Control, Management Information Systems. The topics include: Research on dynamic model of rotors with bearing misalignment; research on the structure design of double eccentric coaxial spherical robot; vibration control on shells through theoretical and numerical analysis; study on the NC machining theory and simulation of hypoid gear; design of gear parameters visual system based on LISP; study of rhino and fastship in calculation of ship hydrostatic; part design and analysis of cycloid installation systems; drawing threaded programs with AutoCAD secondary development; design and implementation of DDFS based on CORDIC in FPGA; design and implementation of detection system based on IC; design and implementation of portable intelligent LCF measuring instrument; design of digital filter based on numerical simulation; multi-channel SSVEP pattern recognition based on MUSIC; diagnostic analysis of ignition system fault of polaris engine; design of reliable serial port transmission mechanism based on zigbee; improved statistical algorithm in digital terrain; electromagnetic spider web application in earthquake prediction; tracking target identification model based on multiple algorithms; comparison of gas chromatography and liquid chromatogram detecting pesticide residue; fingerprint identification scheme based on distribution density; GPU parallel computing algorithm in target tracking of space; image processing algorithm based on solitary wave; research of speech recognition based on neural network; research on improvement algorithm of image edge detection; research on recognition technology of 2-dimensional barcode; study on the iris recognition technology based on 2D-Gabor filter; precise measurement of temperature based on self-correcting technique; design of quantum communication broadband amplifier based on photoelectric diode; application and research of land changes based on GIS and RS; design of high precision temperature sensor based on platinum resistance; design of wireless multi-channel responder system; research on database design based on wireless sensor network; study of computer key technologies and mobile technology; reader management and coordination component based on RFID; research on position detection substation in personnel location system; optimization on NoC mapping based on improved ant colony algorithm; research of network management platform based on BS structure; design of computer information network security system; design and realization of security network database; research on network platform of information management and security; research on stream cipher model based on chaos theory; design of ARP intrusion detection system; research on intrusion detection method of web service composition; community medical management system based on SOA; evolution model of technology innovation cooperation network of software enterprise; research on multimedia integrated management system; research on code separation technology in B/S framework; design of 3D digital earth resource mapping system; station models research based on IFS models; earthquake emergency command system based on virtual technology; cyclic structure in regenerating codes; study of new materials of mobile communication devices; the design of web user interface based on dynamic re-components; research on intelligent information search based on Web; design of information management system based on WEB; behavior analysis in e-commerce; architecture and technique on internet of things; lifetime estimation for web game based on Weibull distribution; research on web intelligent information extraction method; BP neural network based animation production prediction; nonlinear analysis of mixed signal test based on graphic program design; sensor node design and building of multimedia network in smart home; model design of mathematical physics in multi-media source term; design and manufacture of light string electric piano; design on AC/DC converter based on DSP56000 processor; GPIB communication design of programmable instrument; research on CGI in embedded system; research of development of embedded systems; research on automobile electronic technology; study of automation control sports training system; research on local control system of hydropower station spillway; research on the design of laptop temperature control system; study of optical polishing machine based on intelligent control technology; study on intelligent self-adaptive control system; research on swimming pool water treatment based on embedded system; research on automatic cleaning robot based on machine vision; design of sintering machine lubrication system based on PLC; prediction of coal and gas outburst by BP neural network; research on intelligent power management system based on CAN bus; thermal neutron utilization factor calculation by Monte Carlo; pressurized water reactor control rods worth calibration calculation by MCNP; direct damage-based seismic design method of RC frame structures; study on green construction of building engineering; study on energy saving of local building material; study of urban storm intensity; a trust-based method in construction industry; flotation research of a fluorite ore; study on a lead-zinc-fluorite-barite symbiotic ore; design of mining boundary for Yinjng limestone; adsorption of dye from aqueous solution by palm leaves; low carbon technology assessment and planning; simulation of environmental pollution improvement; dynamic vehicle scheduling with time windows model and optimization; performance prediction using fuzzy mapping and artificial neural network; fuzzy comprehension evaluation of sunny sports activity using entropy weight; research of sport computer integrated management system; analysis of new materials in competitive sports; behavior based on product concept learning; improving product appearance based on industry design; research on digital industrial design system; internet industry cluster design based on PDE mathematical model; industry research under automated control and GA based intelligent curriculum arrangement system.},
  isbn = {978-3-03835-050-7}
}

@book{4thInternationalConference2014a,
  title = {4th {{International Conference}} on {{Civil Engineering}}, {{Architecture}} and {{Building Materials}}, {{CEABM}} 2014},
  date = {2014},
  journaltitle = {Applied Mechanics and Materials},
  volume = {587--589},
  abstract = {The proceedings contain 459 papers. The special focus in this conference is on Structural Engineering, Monitoring and Control of Structures, Structural Rehabilitation, Retrofitting and Strengthening, Reliability and Durability of Structures. The topics include: Analysis on determining factors of regional construction land carbon emissions; based on the land resources reuse under the condition of projects benefit analysis; paradigm analysis and guidance of island commercial settlements - a case study of work-living settlements in zhoushan island; building sustainable communities in China - status and outlook; analysis of landscape space meta-structure in regional settlement; applications of GIS in regional planning; attractiveness of the area in the context of individual housing; fuzzy evaluation method of sustainable development of mining area; residential differentiation research in Guangzhou; the initial study of evaluation system in hot-summer and warm-winter region; management of the investment potential of sustainable development of the city; a survey on development of energy service industry in Zhejiang China; study on urban sustainable development based on system dynamics; the measure index system and evaluation research of new-type urbanization; from disordering center competition to space cooperation; a solar-powered in-vehicle semiconductor refrigeration system; mechanical and thermal properties of liquefied corn bran-based epoxy resins; study on cost of green building based on the life cycle theory; the solar energy-air source heat pump was applied to the hot water system; insulation design for non-heated stairwells of residences in severe cold zones; application of BIM technology on energy efficiency building design; photovoltaic architectural shadow and a case analysis; review on phase change material storage in solar energy application; automated calculation of solar electricity systems in Russia as an example of the Moscow region; the research of test on load-bearing capacity of the new energy-saving panels; energy saving renovation of existing buildings on campus sunshade design; the agglomeration effect of Chinese wind power industry and empirical study; a field study on thermal comfort of traditional metal processing factories; air age equation parameterized by ventilation grouped time; medical space oriented color psychology perception model; numerical research on indoor wind environment of green building; the indoor greening design practices; the determination and analysis of volatile organic compounds in public buildings; reduce haze and improve urban and rural construction; noise influence and prevention treatment of residential buildings near highway; rural community environmental health evaluation empirical study; PCBs in soils around an old electric transformer factory in North China; condition of road infrastructure related with regional development; application of natural zeolites for aquatic and air medium purification; numerical simulation of dissolved oxygen transfer in an aerated pond; development of network pressure-superposed secondary water purification; removal of geosmin by powered activated carbon as an emergency method; information technologies in view of complex solution of waste water problems; discussion of treatment of wastewater and sludge from viscose industry; application and development of artificial floating island technology; a review of research development of ventilated double-skin facade; green building development features in China; diffusion model of atmospheric fine particles PM2.5 under the direction of the wind; optimization and selection of automatic monitoring indicators in beer manufacturing; research of antibiotics pollution in soil environments and theirs biological degradation; study on plant-microbial remediation of antibiotic and heavy metal contaminated soil; the exploration of public participation mechanism in ecological civilization construction; the summarized study of heavy metal pollution in the city soil; marine environment impact analysis and countermeasures on sea water utilization project; simulation of final cover systems in mitigating landfill gas migration; the analysis of the characteristics and the research status of the recycled concrete; a southern highway asphalt pavement analysis and treatment of water damage; study on the bearing capacity test for the saline soil soft ground; the study on a new composite road panel structure; study of static mechanical properties of Aeolian sand; the different pavement structure combination shear stress analyze; acoustic models for dense- and open-graded asphalt pavement; research on evaluation method of asphalt pavement crack treatment; time-domain simulation of high-speed railway track irregularity; evaluation segregation of SMA-13 asphalt pavement by compactness; precast pavement smoothness control method; effect of reinforcing the base of pavement with steel geogrid; experimental study on the reinforcement treatment of saline soil subgrade; key construction technology of porous concrete permeable base; newly-constructed cement concrete pavement crack renovation technique; case study on composite bridge pier construction method; research on maintenance and repair technology of the continuous welded railway in plateau permafrost region; review on nanomodified asphalt; specific study of airport pavement asphalt mixture; study on factors for determination of highway subgrade height; study on the effect of WMA additive to the asphalt technical properties; the application of discrete element method on asphalt mixture; the influence of coarse and fine ratio on ATB asphalt mixture performance; study on water stability improvement of granite asphalt mixture; the fatigue test of railway rail fastener assemblies; research on numerical simulation of roadway deformation under the influence of mining; study on low temperature performance of SBS modified asphalt and its mixture; mechanical properties of wood and timber bridge evaluation; study on the vehicle load of highway bridge based on measured data; application of stress-free status control method in bridge construction control; research status of FRP-concrete composite beam/bridge deck systems; on the development and innovation of modern suspension bridge in China; the application of pushover method in complex bridge seismic design; research on skew coefficient for stresses of skewly supported three-span continuous box girders; design of an experimental prestressed arch pedestrian bridge made of UHPC; dynamic analysis and test validation for continuous girder bridge; impact response spectrum for design of ship-bridge collisions; optimization of cable force of extradosed bridges; practical calculation of cable-stayed arch bridge lateral stability; reliability analysis of half-through concrete-filled steel tubular arch bridge; study on the durability of coastal area bridge; design of an experimental tensegrity pedestrian bridge; transverse ribs affect the stability of steel-concrete composite box beams; simulation analysis on construction of Liangjiang great bridge; research on CWR design on steel-concrete composite beam bridge in alpine region; a new decision support methodology for subway operation management; evaluation model of road network vulnerability and its genetic algorithm solution; the integrated berth and quay crane scheduling problem in container terminals; traffic demand model to study urban agglomeration transportation system; a method of bike sharing demand forecasting; on urban transportation planning in an information society; on urban transportation planning in an information society; study on the bike path width considering the electric bike; adaptive reliable shortest path in discrete stochastic networks; freight vehicles regulatory assistance system based on internet of things; research of cluster supply chain network for its optimal control by SOA technology; research on supply chain network system based on industrial cluster; study on the index system of urban rail transit and bus network integration; optimizing supply and demand in coal logistics networks; research on traffic flow characteristics of urban expressway; analysis of the impact of fog on expressway vehicle speed; traffic speed time series short term forecasting using aggregated model; study of dynamic adjustment to the freeway entrance ramp based on VISSIM; design of a warning system for pedestrians and non-motorized vehicles; research on the calculation model of signal intersection delay; research on applications of grid technology in railway information service; a survey on awareness of traffic signs among youth in Qatar; power quality problems and their monitoring of urban rail transit; security design in Tianjin city expressway entrances and exits; the research on urban rail transit ticket pricing based on system dynamics; an analysis on common overload traffic disease and treatment; Nash equilibrium analysis based on a generalized travel cost; impact analysis of different bus lane layout form to traffic efficiency; application study of green building based on BIM technology; on equilibrium for abstract economies in GFC-spaces; improved global harmony search algorithm for numerical optimization; study on the fitting methods of the polyworks software; the stability analysis for a kind of functional differential equations and analysis on non-center cloud storage architecture of gluster.},
  isbn = {978-3-03835-167-2}
}

@book{4thInternationalConference2014b,
  title = {4th {{International Conference}} on {{Civil Engineering}}, {{Architecture}} and {{Building Materials}}, {{CEABM}} 2014},
  date = {2014},
  journaltitle = {Applied Mechanics and Materials},
  volume = {587--589},
  abstract = {The proceedings contain 459 papers. The special focus in this conference is on Structural Engineering, Monitoring and Control of Structures, Structural Rehabilitation, Retrofitting and Strengthening, Reliability and Durability of Structures. The topics include: Analysis on determining factors of regional construction land carbon emissions; based on the land resources reuse under the condition of projects benefit analysis; paradigm analysis and guidance of island commercial settlements - a case study of work-living settlements in zhoushan island; building sustainable communities in China - status and outlook; analysis of landscape space meta-structure in regional settlement; applications of GIS in regional planning; attractiveness of the area in the context of individual housing; fuzzy evaluation method of sustainable development of mining area; residential differentiation research in Guangzhou; the initial study of evaluation system in hot-summer and warm-winter region; management of the investment potential of sustainable development of the city; a survey on development of energy service industry in Zhejiang China; study on urban sustainable development based on system dynamics; the measure index system and evaluation research of new-type urbanization; from disordering center competition to space cooperation; a solar-powered in-vehicle semiconductor refrigeration system; mechanical and thermal properties of liquefied corn bran-based epoxy resins; study on cost of green building based on the life cycle theory; the solar energy-air source heat pump was applied to the hot water system; insulation design for non-heated stairwells of residences in severe cold zones; application of BIM technology on energy efficiency building design; photovoltaic architectural shadow and a case analysis; review on phase change material storage in solar energy application; automated calculation of solar electricity systems in Russia as an example of the Moscow region; the research of test on load-bearing capacity of the new energy-saving panels; energy saving renovation of existing buildings on campus sunshade design; the agglomeration effect of Chinese wind power industry and empirical study; a field study on thermal comfort of traditional metal processing factories; air age equation parameterized by ventilation grouped time; medical space oriented color psychology perception model; numerical research on indoor wind environment of green building; the indoor greening design practices; the determination and analysis of volatile organic compounds in public buildings; reduce haze and improve urban and rural construction; noise influence and prevention treatment of residential buildings near highway; rural community environmental health evaluation empirical study; PCBs in soils around an old electric transformer factory in North China; condition of road infrastructure related with regional development; application of natural zeolites for aquatic and air medium purification; numerical simulation of dissolved oxygen transfer in an aerated pond; development of network pressure-superposed secondary water purification; removal of geosmin by powered activated carbon as an emergency method; information technologies in view of complex solution of waste water problems; discussion of treatment of wastewater and sludge from viscose industry; application and development of artificial floating island technology; a review of research development of ventilated double-skin facade; green building development features in China; diffusion model of atmospheric fine particles PM2.5 under the direction of the wind; optimization and selection of automatic monitoring indicators in beer manufacturing; research of antibiotics pollution in soil environments and theirs biological degradation; study on plant-microbial remediation of antibiotic and heavy metal contaminated soil; the exploration of public participation mechanism in ecological civilization construction; the summarized study of heavy metal pollution in the city soil; marine environment impact analysis and countermeasures on sea water utilization project; simulation of final cover systems in mitigating landfill gas migration; the analysis of the characteristics and the research status of the recycled concrete; a southern highway asphalt pavement analysis and treatment of water damage; study on the bearing capacity test for the saline soil soft ground; the study on a new composite road panel structure; study of static mechanical properties of Aeolian sand; the different pavement structure combination shear stress analyze; acoustic models for dense- and open-graded asphalt pavement; research on evaluation method of asphalt pavement crack treatment; time-domain simulation of high-speed railway track irregularity; evaluation segregation of SMA-13 asphalt pavement by compactness; precast pavement smoothness control method; effect of reinforcing the base of pavement with steel geogrid; experimental study on the reinforcement treatment of saline soil subgrade; key construction technology of porous concrete permeable base; newly-constructed cement concrete pavement crack renovation technique; case study on composite bridge pier construction method; research on maintenance and repair technology of the continuous welded railway in plateau permafrost region; review on nanomodified asphalt; specific study of airport pavement asphalt mixture; study on factors for determination of highway subgrade height; study on the effect of WMA additive to the asphalt technical properties; the application of discrete element method on asphalt mixture; the influence of coarse and fine ratio on ATB asphalt mixture performance; study on water stability improvement of granite asphalt mixture; the fatigue test of railway rail fastener assemblies; research on numerical simulation of roadway deformation under the influence of mining; study on low temperature performance of SBS modified asphalt and its mixture; mechanical properties of wood and timber bridge evaluation; study on the vehicle load of highway bridge based on measured data; application of stress-free status control method in bridge construction control; research status of FRP-concrete composite beam/bridge deck systems; on the development and innovation of modern suspension bridge in China; the application of pushover method in complex bridge seismic design; research on skew coefficient for stresses of skewly supported three-span continuous box girders; design of an experimental prestressed arch pedestrian bridge made of UHPC; dynamic analysis and test validation for continuous girder bridge; impact response spectrum for design of ship-bridge collisions; optimization of cable force of extradosed bridges; practical calculation of cable-stayed arch bridge lateral stability; reliability analysis of half-through concrete-filled steel tubular arch bridge; study on the durability of coastal area bridge; design of an experimental tensegrity pedestrian bridge; transverse ribs affect the stability of steel-concrete composite box beams; simulation analysis on construction of Liangjiang great bridge; research on CWR design on steel-concrete composite beam bridge in alpine region; a new decision support methodology for subway operation management; evaluation model of road network vulnerability and its genetic algorithm solution; the integrated berth and quay crane scheduling problem in container terminals; traffic demand model to study urban agglomeration transportation system; a method of bike sharing demand forecasting; on urban transportation planning in an information society; on urban transportation planning in an information society; study on the bike path width considering the electric bike; adaptive reliable shortest path in discrete stochastic networks; freight vehicles regulatory assistance system based on internet of things; research of cluster supply chain network for its optimal control by SOA technology; research on supply chain network system based on industrial cluster; study on the index system of urban rail transit and bus network integration; optimizing supply and demand in coal logistics networks; research on traffic flow characteristics of urban expressway; analysis of the impact of fog on expressway vehicle speed; traffic speed time series short term forecasting using aggregated model; study of dynamic adjustment to the freeway entrance ramp based on VISSIM; design of a warning system for pedestrians and non-motorized vehicles; research on the calculation model of signal intersection delay; research on applications of grid technology in railway information service; a survey on awareness of traffic signs among youth in Qatar; power quality problems and their monitoring of urban rail transit; security design in Tianjin city expressway entrances and exits; the research on urban rail transit ticket pricing based on system dynamics; an analysis on common overload traffic disease and treatment; Nash equilibrium analysis based on a generalized travel cost; impact analysis of different bus lane layout form to traffic efficiency; application study of green building based on BIM technology; on equilibrium for abstract economies in GFC-spaces; improved global harmony search algorithm for numerical optimization; study on the fitting methods of the polyworks software; the stability analysis for a kind of functional differential equations and analysis on non-center cloud storage architecture of gluster.},
  isbn = {978-3-03835-167-2}
}

@book{4thInternationalConference2014c,
  title = {4th {{International Conference}} on {{Intelligent Structure}} and {{Vibration Control}}, {{ISVC}} 2014},
  date = {2014},
  journaltitle = {Applied Mechanics and Materials},
  volume = {539},
  abstract = {The proceedings contain 199 papers. The special focus in this conference is on Advanced Intelligent Structure, Bio-inspired Smart Materials and Structures, Materials for energy storage, Active Materials, Mechanics and Behavior, Vibration and Control, Modeling, Simulation, Control and Applications, Fuzzy System and Fuzzy Control, Management Information Systems. The topics include: Research on dynamic model of rotors with bearing misalignment; research on the structure design of double eccentric coaxial spherical robot; vibration control on shells through theoretical and numerical analysis; study on the NC machining theory and simulation of hypoid gear; design of gear parameters visual system based on LISP; study of rhino and fastship in calculation of ship hydrostatic; part design and analysis of cycloid installation systems; drawing threaded programs with AutoCAD secondary development; design and implementation of DDFS based on CORDIC in FPGA; design and implementation of detection system based on IC; design and implementation of portable intelligent LCF measuring instrument; design of digital filter based on numerical simulation; multi-channel SSVEP pattern recognition based on MUSIC; diagnostic analysis of ignition system fault of polaris engine; design of reliable serial port transmission mechanism based on zigbee; improved statistical algorithm in digital terrain; electromagnetic spider web application in earthquake prediction; tracking target identification model based on multiple algorithms; comparison of gas chromatography and liquid chromatogram detecting pesticide residue; fingerprint identification scheme based on distribution density; GPU parallel computing algorithm in target tracking of space; image processing algorithm based on solitary wave; research of speech recognition based on neural network; research on improvement algorithm of image edge detection; research on recognition technology of 2-dimensional barcode; study on the iris recognition technology based on 2D-Gabor filter; precise measurement of temperature based on self-correcting technique; design of quantum communication broadband amplifier based on photoelectric diode; application and research of land changes based on GIS and RS; design of high precision temperature sensor based on platinum resistance; design of wireless multi-channel responder system; research on database design based on wireless sensor network; study of computer key technologies and mobile technology; reader management and coordination component based on RFID; research on position detection substation in personnel location system; optimization on NoC mapping based on improved ant colony algorithm; research of network management platform based on BS structure; design of computer information network security system; design and realization of security network database; research on network platform of information management and security; research on stream cipher model based on chaos theory; design of ARP intrusion detection system; research on intrusion detection method of web service composition; community medical management system based on SOA; evolution model of technology innovation cooperation network of software enterprise; research on multimedia integrated management system; research on code separation technology in B/S framework; design of 3D digital earth resource mapping system; station models research based on IFS models; earthquake emergency command system based on virtual technology; cyclic structure in regenerating codes; study of new materials of mobile communication devices; the design of web user interface based on dynamic re-components; research on intelligent information search based on Web; design of information management system based on WEB; behavior analysis in e-commerce; architecture and technique on internet of things; lifetime estimation for web game based on Weibull distribution; research on web intelligent information extraction method; BP neural network based animation production prediction; nonlinear analysis of mixed signal test based on graphic program design; sensor node design and building of multimedia network in smart home; model design of mathematical physics in multi-media source term; design and manufacture of light string electric piano; design on AC/DC converter based on DSP56000 processor; GPIB communication design of programmable instrument; research on CGI in embedded system; research of development of embedded systems; research on automobile electronic technology; study of automation control sports training system; research on local control system of hydropower station spillway; research on the design of laptop temperature control system; study of optical polishing machine based on intelligent control technology; study on intelligent self-adaptive control system; research on swimming pool water treatment based on embedded system; research on automatic cleaning robot based on machine vision; design of sintering machine lubrication system based on PLC; prediction of coal and gas outburst by BP neural network; research on intelligent power management system based on CAN bus; thermal neutron utilization factor calculation by Monte Carlo; pressurized water reactor control rods worth calibration calculation by MCNP; direct damage-based seismic design method of RC frame structures; study on green construction of building engineering; study on energy saving of local building material; study of urban storm intensity; a trust-based method in construction industry; flotation research of a fluorite ore; study on a lead-zinc-fluorite-barite symbiotic ore; design of mining boundary for Yinjng limestone; adsorption of dye from aqueous solution by palm leaves; low carbon technology assessment and planning; simulation of environmental pollution improvement; dynamic vehicle scheduling with time windows model and optimization; performance prediction using fuzzy mapping and artificial neural network; fuzzy comprehension evaluation of sunny sports activity using entropy weight; research of sport computer integrated management system; analysis of new materials in competitive sports; behavior based on product concept learning; improving product appearance based on industry design; research on digital industrial design system; internet industry cluster design based on PDE mathematical model; industry research under automated control and GA based intelligent curriculum arrangement system.},
  isbn = {978-3-03835-050-7}
}

@book{5thInternationalConference2021,
  title = {5th {{International Conference}} on {{Cognitive Systems}} and {{Signal Processing}}, {{ICCSIP}} 2020},
  date = {2021},
  journaltitle = {Communications in Computer and Information Science},
  volume = {1397 CCIS},
  abstract = {The proceedings contain 59 papers. The special focus in this conference is on Cognitive Systems and Signal Processing. The topics include: Application of Broad Learning System for Image Classification Based on Deep Features; emotion Recognition Based on Graph Neural Networks; a Light-Weight Stereo Matching Network with Color Guidance Refinement; overview of Monocular Depth Estimation Based on Deep Learning; Non-contact Physiological Parameters Detection Based on MTCNN and EVM; texture Classification of a Miniature Whisker Sensor with Varied Contact Pose; the Realtime Indoor Localization Unmanned Aerial Vehicle; semantic-Based Road Segmentation for High-Definition Map Construction; transformer Region Proposal for Object Detection; a Feature Fusion Based Object Tracking Algorithm; Detection and Reconstruction of Transparent Objects with Infrared Projection-Based RGB-D Cameras; a Simulation-to-Real Autonomous Driving System Based on End-to-End Learning; Underwater SLAM Based on Forward-Looking Sonar; robust Visual Odometry Using Semantic Information in Complex Dynamic Scenes; A Multi-sensor Data Fusion Method Based on Improved XGBoost Model for AGV Localization; Multi UAV Target Tracking Based on the Vision and Communication Information; an Accurate Positioning Method for Robotic Manipulation Based on Vision and Tactile Sensors; l1-Norm and Trace Lasso Based Locality Correlation Projection; episodic Training for Domain Generalization Using Latent Domains; A Novel Attitude Estimation Algorithm Based on EKF-LSTM Fusion Model; METAHACI: Meta-learning for Human Activity Classification from IMU Data; preface; Quantized Separable Residual Network for Facial Expression Recognition on FPGA; fusing Knowledge and Experience with Graph Convolutional Network for Cross-task Learning in Visual Cognitive Development; factored Trace Lasso Based Linear Regression Methods: Optimizations and Applications.},
  isbn = {9789811623356}
}

@book{5thInternationalConference2021a,
  title = {5th {{International Conference}} on {{Cognitive Systems}} and {{Signal Processing}}, {{ICCSIP}} 2020},
  date = {2021},
  journaltitle = {Communications in Computer and Information Science},
  volume = {1397 CCIS},
  abstract = {The proceedings contain 59 papers. The special focus in this conference is on Cognitive Systems and Signal Processing. The topics include: Application of Broad Learning System for Image Classification Based on Deep Features; emotion Recognition Based on Graph Neural Networks; a Light-Weight Stereo Matching Network with Color Guidance Refinement; overview of Monocular Depth Estimation Based on Deep Learning; Non-contact Physiological Parameters Detection Based on MTCNN and EVM; texture Classification of a Miniature Whisker Sensor with Varied Contact Pose; the Realtime Indoor Localization Unmanned Aerial Vehicle; semantic-Based Road Segmentation for High-Definition Map Construction; transformer Region Proposal for Object Detection; a Feature Fusion Based Object Tracking Algorithm; Detection and Reconstruction of Transparent Objects with Infrared Projection-Based RGB-D Cameras; a Simulation-to-Real Autonomous Driving System Based on End-to-End Learning; Underwater SLAM Based on Forward-Looking Sonar; robust Visual Odometry Using Semantic Information in Complex Dynamic Scenes; A Multi-sensor Data Fusion Method Based on Improved XGBoost Model for AGV Localization; Multi UAV Target Tracking Based on the Vision and Communication Information; an Accurate Positioning Method for Robotic Manipulation Based on Vision and Tactile Sensors; l1-Norm and Trace Lasso Based Locality Correlation Projection; episodic Training for Domain Generalization Using Latent Domains; A Novel Attitude Estimation Algorithm Based on EKF-LSTM Fusion Model; METAHACI: Meta-learning for Human Activity Classification from IMU Data; preface; Quantized Separable Residual Network for Facial Expression Recognition on FPGA; fusing Knowledge and Experience with~Graph Convolutional Network for~Cross-task Learning in Visual Cognitive Development; factored Trace Lasso Based Linear Regression Methods: Optimizations and Applications.},
  isbn = {9789811623356}
}

@book{7thInternationalConference2021,
  title = {7th {{International Conference}} on {{Life System Modeling}} and {{Simulation}}, {{LSMS}} 2021, and the 7th {{International Conference}} on {{Intelligent Computing}} for {{Sustainable Energy}} and {{Environment}}, {{ICSEE}} 2021},
  date = {2021},
  journaltitle = {Communications in Computer and Information Science},
  volume = {1469 CCIS},
  abstract = {The proceedings contain 159 papers. The special focus in this conference is on Life System Modeling and Simulation. The topics include: Housing Assignment Optimization of Warehouse Breeding; Automobile Rim Weld Detection Using the Improved YOLO Algorithm; A Novel Algorithm YOLOv4-Mini to Detection Automobile Rim Weld; detection Method of Automobile Rim Weld Based on Machine Vision; event-Triggered Output Feedback Predictive Control of Networked Control Systems Against Denial-of-Service Attacks; Compression of YOLOv3-spp Model Based on Channel and Layer Pruning; A Chinese Dish Detector with Modified YOLO v3; UJN-Traffic: A Benchmark Dataset for Performance Evaluation of Traffic Element Classification; online Adaptive Strategy for Traffic-Light Timing Based on Congestion Pressure; Object Detection of Basketball Robot Based on MobileNet-SSD; UJN-Land: A Large-Scale High-Resolution Parcel of Land of Multi-temporal Dataset with CNN Based Semantic Segmentation Analysis; an End-to-End Feature-Complementing Method for Building Classification with Residual Network; optimal-Performance-Supervised Vibration Control for Nonlinear Discrete-Time System with Delayed Input Under Sinusoidal Disturbance; A Novel PID Control for MIMO Systems in the DPLS Framework with Gaussian Process Model; an Enhanced Discrete Human Learning Optimization for Permutation Flow Shop Scheduling Problem; key Technology for Service Sharing Platform Based on Big Data; A Novel YOLO Based Safety Helmet Detection in Intelligent Construction Platform; hierarchical Finite-Horizon Optimal Control for Stackelberg Games via Integral Reinforcement Learning; Activity Recognition Through Micro-Doppler Image Based on Improved Faster R-CNN; prediction of Landslide Risk Based on Modified Generalized Regression Neural Network Algorithm; Detection of Overlapping and Small-Scale Targets in Indoor Environment Based on Improved Faster-RCNN.},
  isbn = {9789811672125}
}

@book{7thInternationalConference2021a,
  title = {7th {{International Conference}} on {{Life System Modeling}} and {{Simulation}}, {{LSMS}} 2021, and the 7th {{International Conference}} on {{Intelligent Computing}} for {{Sustainable Energy}} and {{Environment}}, {{ICSEE}} 2021},
  date = {2021},
  journaltitle = {Communications in Computer and Information Science},
  volume = {1469 CCIS},
  abstract = {The proceedings contain 159 papers. The special focus in this conference is on Life System Modeling and Simulation. The topics include: Housing Assignment Optimization of Warehouse Breeding; Automobile Rim Weld Detection Using the Improved YOLO Algorithm; A Novel Algorithm YOLOv4-Mini to Detection Automobile Rim Weld; detection Method of Automobile Rim Weld Based on Machine Vision; event-Triggered Output Feedback Predictive Control of Networked Control Systems Against Denial-of-Service Attacks; Compression of YOLOv3-spp Model Based on Channel and Layer Pruning; A Chinese Dish Detector with Modified YOLO v3; UJN-Traffic: A Benchmark Dataset for Performance Evaluation of Traffic Element Classification; online Adaptive Strategy for Traffic-Light Timing Based on Congestion Pressure; Object Detection of Basketball Robot Based on MobileNet-SSD; UJN-Land: A Large-Scale High-Resolution Parcel of Land of Multi-temporal Dataset with CNN Based Semantic Segmentation Analysis; an End-to-End Feature-Complementing Method for Building Classification with Residual Network; optimal-Performance-Supervised Vibration Control for Nonlinear Discrete-Time System with Delayed Input Under Sinusoidal Disturbance; A Novel PID Control for MIMO Systems in the DPLS Framework with Gaussian Process Model; an Enhanced Discrete Human Learning Optimization for Permutation Flow Shop Scheduling Problem; key Technology for Service Sharing Platform Based on Big Data; A Novel YOLO Based Safety Helmet Detection in Intelligent Construction Platform; hierarchical Finite-Horizon Optimal Control for Stackelberg Games via Integral Reinforcement Learning; Activity Recognition Through Micro-Doppler Image Based on Improved Faster R-CNN; prediction of Landslide Risk Based on Modified Generalized Regression Neural Network Algorithm; Detection of Overlapping and Small-Scale Targets in Indoor Environment Based on Improved Faster-RCNN.},
  isbn = {9789811672125}
}

@book{8thMexicanConference2016,
  title = {8th {{Mexican Conference}} on {{Pattern Recognition}}, {{MCPR}} 2016},
  date = {2016},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {9703},
  abstract = {The proceedings contain 34 papers. The special focus in this conference is on Computer Vision and Image Analysis. The topics include: Text detection in digital images captured with low resolution under nonuniform illumination conditions; rotation invariant local shape descriptors for classification of archaeological 3D models; feature extraction as ellipse of wild-life images; application to defect detection in automated visual inspection systems; training a multilayered perceptron to compute the euler number of a 2-D binary image; edge detection in time variant scenarios based on a novel perceptual method and a gestalt spiking cortical model; an effective image de-noising alternative approach based on third generation neural networks; toward the labeled segmentation of natural images using rough-set rules; dynamic object detection and representation for mobile robot application; saliency detection based on heuristic rules; order tracking by square-root cubature kalman filter with constraints; contour detection at range images using sparse normal detector; an optimization approach to the TWPVD method for digital image steganography; real time gesture recognition with heuristic-based classification; simultaneous encryption and compression of digital images based on secure-jpeg encoding; automatic tuning of the pulse-coupled neural network using differential evolution for image segmentation; efficient counting of the number of independent sets on polygonal trees; SMOTE-D a deterministic version of SMOTE; automatic construction of radial-basis function networks through an adaptive partition algorithm; feature selection using genetic algorithms for hand posture recognition and activity recognition in meetings with one and two kinect sensors.},
  isbn = {978-3-319-39392-6},
  pagetotal = {1-357}
}

@book{8thMexicanConference2016a,
  title = {8th {{Mexican Conference}} on {{Pattern Recognition}}, {{MCPR}} 2016},
  date = {2016},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {9703},
  abstract = {The proceedings contain 34 papers. The special focus in this conference is on Computer Vision and Image Analysis. The topics include: Text detection in digital images captured with low resolution under nonuniform illumination conditions; rotation invariant local shape descriptors for classification of archaeological 3D models; feature extraction as ellipse of wild-life images; application to defect detection in automated visual inspection systems; training a multilayered perceptron to compute the euler number of a 2-D binary image; edge detection in time variant scenarios based on a novel perceptual method and a gestalt spiking cortical model; an effective image de-noising alternative approach based on third generation neural networks; toward the labeled segmentation of natural images using rough-set rules; dynamic object detection and representation for mobile robot application; saliency detection based on heuristic rules; order tracking by square-root cubature kalman filter with constraints; contour detection at range images using sparse normal detector; an optimization approach to the TWPVD method for digital image steganography; real time gesture recognition with heuristic-based classification; simultaneous encryption and compression of digital images based on secure-jpeg encoding; automatic tuning of the pulse-coupled neural network using differential evolution for image segmentation; efficient counting of the number of independent sets on polygonal trees; SMOTE-D a deterministic version of SMOTE; automatic construction of radial-basis function networks through an adaptive partition algorithm; feature selection using genetic algorithms for hand posture recognition and activity recognition in meetings with one and two kinect sensors.},
  isbn = {978-3-319-39392-6},
  pagetotal = {1-357}
}

@article{aagaardDevelopingFabricationWorkflow2020,
  title = {Developing a Fabrication Workflow for Irregular Sawlogs},
  author = {Aagaard, A.K. and Larsen, N.M.},
  date = {2020},
  journaltitle = {International Journal of Architectural Computing},
  volume = {18},
  number = {3},
  pages = {270--283},
  doi = {10.1177/1478077120906736},
  abstract = {In this article, we suggest using contemporary manufacturing technologies to integrate material properties with architectural design tools, revealing new possibilities for the use of wood in architecture. Through an investigative approach, material capacities and fabrication methods are explored and combined towards establishing new workflows and architectural expressions, where material, fabrication and result are closely interlinked. The experimentation revolves around discarded, crooked oak logs, doomed to be used as firewood due to their irregularity. This project treats their diverging shapes differently by offering unique processing to each log informed by its particularities. We suggest here a way to use the natural forms and properties of sawlogs to generate new structures and spatial conditions. In this article, we discuss the scope of this approach and provide an example of a workflow for handling the discrete shapes of natural sawlogs in a system that involve the collection of material, scanning/digitisation, handling of a stockpile, computer analysis, design and robotic manufacturing. The creation of this specific method comes from a combination of investigation of wood as a material, review of existing research in the field, studies of the production lines in the current wood industry and experimentation through our in-house laboratory facilities. As such, the workflow features several solutions for handling the complex and different shapes and data of natural wood logs in a highly digitised machining and fabrication environment. This up-cycling of discarded wood supply establishes a non-standard workflow that utilises non-standard material stock and leads to a critical articulation of today’s linear material economy. The project becomes part of an ambition to reach sustainable development goals and technological innovation in global and resource-intensive architecture and building industry.}
}

@article{aagaardDevelopingFabricationWorkflow2020a,
  title = {Developing a Fabrication Workflow for Irregular Sawlogs},
  author = {Aagaard, A.K. and Larsen, N.M.},
  date = {2020},
  journaltitle = {International Journal of Architectural Computing},
  volume = {18},
  number = {3},
  pages = {270--283},
  doi = {10.1177/1478077120906736},
  abstract = {In this article, we suggest using contemporary manufacturing technologies to integrate material properties with architectural design tools, revealing new possibilities for the use of wood in architecture. Through an investigative approach, material capacities and fabrication methods are explored and combined towards establishing new workflows and architectural expressions, where material, fabrication and result are closely interlinked. The experimentation revolves around discarded, crooked oak logs, doomed to be used as firewood due to their irregularity. This project treats their diverging shapes differently by offering unique processing to each log informed by its particularities. We suggest here a way to use the natural forms and properties of sawlogs to generate new structures and spatial conditions. In this article, we discuss the scope of this approach and provide an example of a workflow for handling the discrete shapes of natural sawlogs in a system that involve the collection of material, scanning/digitisation, handling of a stockpile, computer analysis, design and robotic manufacturing. The creation of this specific method comes from a combination of investigation of wood as a material, review of existing research in the field, studies of the production lines in the current wood industry and experimentation through our in-house laboratory facilities. As such, the workflow features several solutions for handling the complex and different shapes and data of natural wood logs in a highly digitised machining and fabrication environment. This up-cycling of discarded wood supply establishes a non-standard workflow that utilises non-standard material stock and leads to a critical articulation of today’s linear material economy. The project becomes part of an ambition to reach sustainable development goals and technological innovation in global and resource-intensive architecture and building industry.}
}

@inproceedings{abergerBuildingInformationModeling2018,
  title = {Building Information Modeling in Timber Construction - {{A}} Solution for Planning Process, Design Phases and the Unification of Scope of Works},
  booktitle = {{{WCTE}} 2018 - {{World Conference}} on {{Timber Engineering}}},
  author = {Aberger, E. and Koppelhuber, J. and Heck, D.},
  date = {2018},
  abstract = {The advancements of recently developed timber products and their application in construction demand standardization and unification of planning processes, design solutions and construction management. Within the planning sector and the timber industry, the call for an early integration of specific information referring to timber construction aspects increases constantly. To this end, implementing methods of an integral planning process such as Building Information Modeling (BIM) seems to be a feasible solution. The existing planning equipment and design tools, the data on building components and processing technologies offer great possibilities for the large-scale implementation of BIM in the timber industry. Today's planning methodology commonly used in construction is based on formal concepts with the successive integration of designers and experts following the construction sequences from general into detail. This traditional approach dictates the methods of today's construction design. However, the probability of information loss through a step by step planning phase is extremely high as the degree of information within a building's construction increases significantly. To be able to investigate the requirements and constraints for an integrated planning process in timber construction, an expert survey was conducted in 2016. According to the experts' opinions, the integration of consistent data and information workflow in the planning process enables a traceable and transparent planning process, precise cost estimation and increasing planning quality. Among others, these arguments are confirmed by the majority of existing surveys as well as direct expert consultancies. Following the expert survey, timber construction systems with a high percentage of prefabrication are considered to be ideal for the vast implementation of building information modeling and management. The identified criterion and surveyed fundamentals of industrialized serial building systems can be transferred into general planning management methods. Additionally, the applicability was analysed in order to determine the potentials to generate appropriate design systems for timber construction.}
}

@inproceedings{abergerBuildingInformationModeling2018a,
  title = {Building Information Modeling in Timber Construction - {{A}} Solution for Planning Process, Design Phases and the Unification of Scope of Works},
  booktitle = {{{WCTE}} 2018 - {{World Conference}} on {{Timber Engineering}}},
  author = {Aberger, E. and Koppelhuber, J. and Heck, D.},
  date = {2018},
  abstract = {The advancements of recently developed timber products and their application in construction demand standardization and unification of planning processes, design solutions and construction management. Within the planning sector and the timber industry, the call for an early integration of specific information referring to timber construction aspects increases constantly. To this end, implementing methods of an integral planning process such as Building Information Modeling (BIM) seems to be a feasible solution. The existing planning equipment and design tools, the data on building components and processing technologies offer great possibilities for the large-scale implementation of BIM in the timber industry. Today's planning methodology commonly used in construction is based on formal concepts with the successive integration of designers and experts following the construction sequences from general into detail. This traditional approach dictates the methods of today's construction design. However, the probability of information loss through a step by step planning phase is extremely high as the degree of information within a building's construction increases significantly. To be able to investigate the requirements and constraints for an integrated planning process in timber construction, an expert survey was conducted in 2016. According to the experts' opinions, the integration of consistent data and information workflow in the planning process enables a traceable and transparent planning process, precise cost estimation and increasing planning quality. Among others, these arguments are confirmed by the majority of existing surveys as well as direct expert consultancies. Following the expert survey, timber construction systems with a high percentage of prefabrication are considered to be ideal for the vast implementation of building information modeling and management. The identified criterion and surveyed fundamentals of industrialized serial building systems can be transferred into general planning management methods. Additionally, the applicability was analysed in order to determine the potentials to generate appropriate design systems for timber construction.}
}

@inproceedings{abiriRealtimeBrainMachine2017,
  title = {Real-Time Brain Machine Interaction via Social Robot Gesture Control},
  booktitle = {{{ASME}} 2017 {{Dynamic Systems}} and {{Control Conference}}, {{DSCC}} 2017},
  author = {Abiri, R. and Borhani, S. and Zhao, X. and Jiang, Y.},
  date = {2017},
  volume = {1},
  doi = {10.1115/DSCC2017-5128},
  abstract = {Brain-Machine Interaction (BMI) system motivates interesting and promising results in forward/feedback control consistent with human intention. It holds great promise for advancements in patient care and applications to neurorehabilitation. Here, we propose a novel neurofeedbackbased BCI robotic platform using a personalized social robot in order to assist patients having cognitive deficits through bilateral rehabilitation and mental training. For initial testing of the platform, electroencephalography (EEG) brainwaves of a human user were collected in real time during tasks of imaginary movements. First, the brainwaves associated with imagined body kinematics parameters were decoded to control a cursor on a computer screen in training protocol. Then, the experienced subject was able to interact with a social robot via our real-time BMI robotic platform. Corresponding to subject's imagery performance, he/she received specific gesture movements and eye color changes as neural-based feedback from the robot. This hands-free neurofeedback interaction not only can be used for mind control of a social robot's movements, but also sets the stage for application to enhancing and recovering mental abilities such as attention via training in humans by providing real-time neurofeedback from a social robot.},
  isbn = {978-0-7918-5827-1}
}

@inproceedings{abiriRealtimeBrainMachine2017a,
  title = {Real-Time Brain Machine Interaction via Social Robot Gesture Control},
  booktitle = {{{ASME}} 2017 {{Dynamic Systems}} and {{Control Conference}}, {{DSCC}} 2017},
  author = {Abiri, R. and Borhani, S. and Zhao, X. and Jiang, Y.},
  date = {2017},
  volume = {1},
  doi = {10.1115/DSCC2017-5128},
  abstract = {Brain-Machine Interaction (BMI) system motivates interesting and promising results in forward/feedback control consistent with human intention. It holds great promise for advancements in patient care and applications to neurorehabilitation. Here, we propose a novel neurofeedbackbased BCI robotic platform using a personalized social robot in order to assist patients having cognitive deficits through bilateral rehabilitation and mental training. For initial testing of the platform, electroencephalography (EEG) brainwaves of a human user were collected in real time during tasks of imaginary movements. First, the brainwaves associated with imagined body kinematics parameters were decoded to control a cursor on a computer screen in training protocol. Then, the experienced subject was able to interact with a social robot via our real-time BMI robotic platform. Corresponding to subject's imagery performance, he/she received specific gesture movements and eye color changes as neural-based feedback from the robot. This hands-free neurofeedback interaction not only can be used for mind control of a social robot's movements, but also sets the stage for application to enhancing and recovering mental abilities such as attention via training in humans by providing real-time neurofeedback from a social robot.},
  isbn = {978-0-7918-5827-1}
}

@article{abourizkRoleSimulationConstruction2010,
  title = {Role of {{Simulation}} in {{Construction Engineering}} and {{Management}}},
  author = {AbouRizk, Simaan},
  date = {2010-10},
  journaltitle = {Journal of Construction Engineering and Management},
  shortjournal = {J. Constr. Eng. Manage.},
  volume = {136},
  number = {10},
  pages = {1140--1153},
  issn = {0733-9364, 1943-7862},
  doi = {10.1061/(ASCE)CO.1943-7862.0000220},
  url = {https://ascelibrary.org/doi/10.1061/%28ASCE%29CO.1943-7862.0000220},
  urldate = {2023-09-19},
  langid = {english}
}

@article{adamczykWearableSensingUnderstanding2023,
  title = {Wearable Sensing for Understanding and Influencing Human Movement in Ecological Contexts},
  author = {Adamczyk, Peter Gabriel and Harper, Sara E. and Reiter, Alex J. and Roembke, Rebecca A. and Wang, Yisen and Nichols, Kieran M. and Thelen, Darryl G.},
  date = {2023-12},
  journaltitle = {Current Opinion in Biomedical Engineering},
  shortjournal = {Current Opinion in Biomedical Engineering},
  volume = {28},
  pages = {100492},
  issn = {24684511},
  doi = {10.1016/j.cobme.2023.100492},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S246845112300048X},
  urldate = {2023-11-12},
  langid = {english},
  file = {D:\Lib\wearable sensing.pdf}
}

@inproceedings{adibaIntentionsharedUserinterfaceAutodiscrimination2015,
  title = {Intention-Shared User-Interface by the Auto-Discrimination of Gaze Object '{{See}} What i See'},
  booktitle = {2014 {{International Symposium}} on {{Micro-NanoMechatronics}} and {{Human Science}}, {{MHS}} 2014},
  author = {Adiba, A. I. and Tanaka, N. and Miyake, J.},
  date = {2015},
  doi = {10.1109/MHS.2014.7006122},
  abstract = {A social robot, which is used in a human living environment, is gathering a massive attract from not only robot researchers but also the general people. Because the users of a social robot normally differ from the specialist of robotics, the robot is required to be controlled by an intuitive user-interface. An eye-gaze point is a good signal representing human-intention with interest as compared with other human behavior, such as indication by fingers or hand, gesture, voice, etc. Within this concept, a robot has successfully found human-intention even in experimental environment, human and robot has different point/angle view to the object.},
  isbn = {978-1-4799-6679-0}
}

@inproceedings{adibaIntentionsharedUserinterfaceAutodiscrimination2015a,
  title = {Intention-Shared User-Interface by the Auto-Discrimination of Gaze Object '{{See}} What i See'},
  booktitle = {2014 {{International Symposium}} on {{Micro-NanoMechatronics}} and {{Human Science}}, {{MHS}} 2014},
  author = {Adiba, A.I. and Tanaka, N. and Miyake, J.},
  date = {2015},
  doi = {10.1109/MHS.2014.7006122},
  abstract = {A social robot, which is used in a human living environment, is gathering a massive attract from not only robot researchers but also the general people. Because the users of a social robot normally differ from the specialist of robotics, the robot is required to be controlled by an intuitive user-interface. An eye-gaze point is a good signal representing human-intention with interest as compared with other human behavior, such as indication by fingers or hand, gesture, voice, etc. Within this concept, a robot has successfully found human-intention even in experimental environment, human and robot has different point/angle view to the object.},
  isbn = {978-1-4799-6679-0}
}

@inproceedings{Admoni201449,
  title = {Deliberate Delays during Robot-to-Human Handovers Improve Compliance with Gaze Communication},
  author = {Admoni, H. and Dragan, A. and Srinivasa, S.S. and Scassellati, B.},
  date = {2014},
  series = {{{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  pages = {49--56},
  doi = {10.1145/2559636.2559682}
}

@article{aggarwalHumanActivityAnalysis2011,
  title = {Human Activity Analysis: {{A}} Review},
  author = {Aggarwal, J. K. and Ryoo, M. S.},
  date = {2011},
  journaltitle = {ACM Computing Surveys},
  volume = {43},
  number = {3},
  issn = {03600300},
  doi = {10.1145/1922649.1922653},
  abstract = {Human activity recognition is an important area of computer vision research. Its applications include surveillance systems, patient monitoring systems, and a variety of systems that involve interactions between persons and electronic devices such as human-computer interfaces. Most of these applications require an automated recognition of high-level activities, composed of multiple simple (or atomic) actions of persons. This article provides a detailed overview of various state-of-the-art research papers on human activity recognition. We discuss both the methodologies developed for simple human actions and those for high-level activities. An approach-based taxonomy is chosen that compares the advantages and limitations of each approach. Recognition methodologies for an analysis of the simple actions of a single person are first presented in the article. Space-time volume approaches and sequential approaches that represent and recognize activities directly from input images are discussed. Next, hierarchical recognition methodologies for high-level activities are presented and compared. Statistical approaches, syntactic approaches, and description-based approaches for hierarchical recognition are discussed in the article. In addition, we further discuss the papers on the recognition of human-object interactions and group activities. Public datasets designed for the evaluation of the recognition methodologies are illustrated in our article as well, comparing the methodologies' performances. This review will provide the impetus for future research in more productive areas. © 2011 ACM.},
  keywords = {Activity analysis,Computer vision,Event detection,Human activity recognition,Video recognition}
}

@article{aggarwalHumanActivityAnalysis2011a,
  title = {Human Activity Analysis: {{A}} Review},
  author = {Aggarwal, J. K. and Ryoo, M. S.},
  date = {2011},
  journaltitle = {ACM Computing Surveys},
  volume = {43},
  number = {3},
  issn = {03600300},
  doi = {10.1145/1922649.1922653},
  abstract = {Human activity recognition is an important area of computer vision research. Its applications include surveillance systems, patient monitoring systems, and a variety of systems that involve interactions between persons and electronic devices such as human-computer interfaces. Most of these applications require an automated recognition of high-level activities, composed of multiple simple (or atomic) actions of persons. This article provides a detailed overview of various state-of-the-art research papers on human activity recognition. We discuss both the methodologies developed for simple human actions and those for high-level activities. An approach-based taxonomy is chosen that compares the advantages and limitations of each approach. Recognition methodologies for an analysis of the simple actions of a single person are first presented in the article. Space-time volume approaches and sequential approaches that represent and recognize activities directly from input images are discussed. Next, hierarchical recognition methodologies for high-level activities are presented and compared. Statistical approaches, syntactic approaches, and description-based approaches for hierarchical recognition are discussed in the article. In addition, we further discuss the papers on the recognition of human-object interactions and group activities. Public datasets designed for the evaluation of the recognition methodologies are illustrated in our article as well, comparing the methodologies' performances. This review will provide the impetus for future research in more productive areas. © 2011 ACM.},
  keywords = {Activity analysis,Computer vision,Event detection,Human activity recognition,Video recognition},
  file = {C:\Users\leemar\Zotero\storage\MUS7F7GW\1922649.1922653.pdf}
}

@article{aggarwalHumanActivityAnalysis2011b,
  title = {Human Activity Analysis: {{A}} Review},
  shorttitle = {Human Activity Analysis},
  author = {Aggarwal, J.K. and Ryoo, M.S.},
  date = {2011-04},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {43},
  number = {3},
  pages = {1--43},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/1922649.1922653},
  url = {https://dl.acm.org/doi/10.1145/1922649.1922653},
  urldate = {2023-03-22},
  abstract = {Human activity recognition is an important area of computer vision research. Its applications include surveillance systems, patient monitoring systems, and a variety of systems that involve interactions between persons and electronic devices such as human-computer interfaces. Most of these applications require an automated recognition of high-level activities, composed of multiple simple (or atomic) actions of persons. This article provides a detailed overview of various state-of-the-art research papers on human activity recognition. We discuss both the methodologies developed for simple human actions and those for high-level activities. An approach-based taxonomy is chosen that compares the advantages and limitations of each approach.             Recognition methodologies for an analysis of the simple actions of a single person are first presented in the article. Space-time volume approaches and sequential approaches that represent and recognize activities directly from input images are discussed. Next, hierarchical recognition methodologies for high-level activities are presented and compared. Statistical approaches, syntactic approaches, and description-based approaches for hierarchical recognition are discussed in the article. In addition, we further discuss the papers on the recognition of human-object interactions and group activities. Public datasets designed for the evaluation of the recognition methodologies are illustrated in our article as well, comparing the methodologies' performances. This review will provide the impetus for future research in more productive areas.},
  langid = {english}
}

@article{agusti-juanEnvironmentalDesignGuidelines2017,
  title = {Environmental Design Guidelines for Digital Fabrication},
  author = {Agustí-Juan, I. and Habert, G.},
  date = {2017},
  journaltitle = {Journal of Cleaner Production},
  volume = {142},
  pages = {2780--2791},
  doi = {10.1016/j.jclepro.2016.10.190},
  abstract = {Digital fabrication represents an innovative technology with the potential of expanding the boundaries of architecture. The potential to fabricate elements directly from design information is transforming many design and production disciplines. In particular, 3D printing has become the key of modern product development. As the use of additive manufacturing grows, research into large-scale processes is beginning to reveal potential applications in construction. The combined methods of computational design and robotic fabrication have the well-demonstrated potential to create formal and structural advances in architecture. However, their potential contribution to the improvement of sustainability in construction must be evaluated. In this study, we identified environmental guidelines to be considered during the design of digitally fabricated architecture. The key parameters were extracted from the Life Cycle Assessment (LCA) of three case studies. The environmental assessment performed indicated that the relative sustainability of the projects depended primarily on the building material production. Specifically, the impact of digital fabrication processes was negligible compared to the materials manufacturing process. Furthermore, the study highlighted the opportunities of integrating additional functions in structural elements with digital fabrication to reduce the overall environmental impact of these multi-functional elements. Finally, the analysis proved the potential of digital fabrication to reduce the amount of highly industrialized materials in a project, which are associated with high environmental impacts.}
}

@article{agusti-juanEnvironmentalDesignGuidelines2017a,
  title = {Environmental Design Guidelines for Digital Fabrication},
  author = {Agustí-Juan, I. and Habert, G.},
  date = {2017},
  journaltitle = {Journal of Cleaner Production},
  volume = {142},
  pages = {2780--2791},
  doi = {10.1016/j.jclepro.2016.10.190},
  abstract = {Digital fabrication represents an innovative technology with the potential of expanding the boundaries of architecture. The potential to fabricate elements directly from design information is transforming many design and production disciplines. In particular, 3D printing has become the key of modern product development. As the use of additive manufacturing grows, research into large-scale processes is beginning to reveal potential applications in construction. The combined methods of computational design and robotic fabrication have the well-demonstrated potential to create formal and structural advances in architecture. However, their potential contribution to the improvement of sustainability in construction must be evaluated. In this study, we identified environmental guidelines to be considered during the design of digitally fabricated architecture. The key parameters were extracted from the Life Cycle Assessment (LCA) of three case studies. The environmental assessment performed indicated that the relative sustainability of the projects depended primarily on the building material production. Specifically, the impact of digital fabrication processes was negligible compared to the materials manufacturing process. Furthermore, the study highlighted the opportunities of integrating additional functions in structural elements with digital fabrication to reduce the overall environmental impact of these multi-functional elements. Finally, the analysis proved the potential of digital fabrication to reduce the amount of highly industrialized materials in a project, which are associated with high environmental impacts.}
}

@article{ajayiLifeCycleEnvironmental2015,
  title = {Life Cycle Environmental Performance of Material Specification: A {{BIM-enhanced}} Comparative Assessment},
  author = {Ajayi, S.O. and Oyedele, L.O. and Ceranic, B. and Gallanagh, M. and Kadiri, K.O.},
  date = {2015},
  journaltitle = {International Journal of Sustainable Building Technology and Urban Development},
  volume = {6},
  number = {1},
  pages = {14--24},
  doi = {10.1080/2093761X.2015.1006708},
  abstract = {This study aims to evaluate the extent to which building material specification affects life cycle environmental performance, using a building information modelling (BIM)-enhanced life cycle assessment (LCA) methodology. A combination of the BIM-based design and analysis tool Revit Architecture, the energy simulation tool Green Building Studio (GBS) and the LCA tool ATHENA Impact Estimator were used for the assessment. The LCA was carried out on a life case study of a 2100~m2 two-floor primary-school building, as well as a variability analysis, by varying the material specification in terms of whole building materials. The life cycle performance of the buildings was primarily evaluated in terms of its global warming potential (GWP) and health impact. The findings of the study show that irrespective of the materials used, buildings that are based on renewable energy perform better than those based on fossil fuels over their life cycle. In terms of building materials, both environmental and health preferences of buildings congruently range from timber, brick/block and steel to insulated concrete formwork (ICF), in descending order. The study suggests that as buildings become more energy efficient during operational stages, serious attention needs to be given to their embodied impact. The study lays out a methodological framework that could be adopted by industry practitioners in evaluating life cycle environmental impact of different BIM-modelled material options at the building conception stage. This has the tendency to ensure that the highest proportion of life cycle environmentally beneficial material combinations are selected during specification and construction.}
}

@article{ajayiLifeCycleEnvironmental2015a,
  title = {Life Cycle Environmental Performance of Material Specification: A {{BIM-enhanced}} Comparative Assessment},
  author = {Ajayi, S.O. and Oyedele, L.O. and Ceranic, B. and Gallanagh, M. and Kadiri, K.O.},
  date = {2015},
  journaltitle = {International Journal of Sustainable Building Technology and Urban Development},
  volume = {6},
  number = {1},
  pages = {14--24},
  doi = {10.1080/2093761X.2015.1006708},
  abstract = {This study aims to evaluate the extent to which building material specification affects life cycle environmental performance, using a building information modelling (BIM)-enhanced life cycle assessment (LCA) methodology. A combination of the BIM-based design and analysis tool Revit Architecture, the energy simulation tool Green Building Studio (GBS) and the LCA tool ATHENA Impact Estimator were used for the assessment. The LCA was carried out on a life case study of a 2100~m2 two-floor primary-school building, as well as a variability analysis, by varying the material specification in terms of whole building materials. The life cycle performance of the buildings was primarily evaluated in terms of its global warming potential (GWP) and health impact. The findings of the study show that irrespective of the materials used, buildings that are based on renewable energy perform better than those based on fossil fuels over their life cycle. In terms of building materials, both environmental and health preferences of buildings congruently range from timber, brick/block and steel to insulated concrete formwork (ICF), in descending order. The study suggests that as buildings become more energy efficient during operational stages, serious attention needs to be given to their embodied impact. The study lays out a methodological framework that could be adopted by industry practitioners in evaluating life cycle environmental impact of different BIM-modelled material options at the building conception stage. This has the tendency to ensure that the highest proportion of life cycle environmentally beneficial material combinations are selected during specification and construction.}
}

@article{aksoyLearningSemanticsObject2011,
  title = {Learning the Semantics of Object–Action Relations by Observation},
  author = {Aksoy, Eren Erdal and Abramov, Alexey and Dörr, Johannes and Ning, Kejun and Dellen, Babette and Wörgötter, Florentin},
  date = {2011-09},
  journaltitle = {The International Journal of Robotics Research},
  shortjournal = {The International Journal of Robotics Research},
  volume = {30},
  number = {10},
  pages = {1229--1249},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364911410459},
  url = {http://journals.sagepub.com/doi/10.1177/0278364911410459},
  urldate = {2023-03-23},
  abstract = {Recognizing manipulations performed by a human and the transfer and execution of this by a robot is a difficult problem. We address this in the current study by introducing a novel representation of the relations between objects at decisive time points during a manipulation. Thereby, we encode the essential changes in a visual scenery in a condensed way such that a robot can recognize and learn a manipulation without prior object knowledge. To achieve this we continuously track image segments in the video and construct a dynamic graph sequence. Topological transitions of those graphs occur whenever a spatial relation between some segments has changed in a discontinuous way and these moments are stored in a transition matrix called the semantic event chain (SEC). We demonstrate that these time points are highly descriptive for distinguishing between different manipulations. Employing simple sub-string search algorithms, SECs can be compared and type-similar manipulations can be recognized with high confidence. As the approach is generic, statistical learning can be used to find the archetypal SEC of a given manipulation class. The performance of the algorithm is demonstrated on a set of real videos showing hands manipulating various objects and performing different actions. In experiments with a robotic arm, we show that the SEC can be learned by observing human manipulations, transferred to a new scenario, and then reproduced by the machine.},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\U8DT9SXJ\Aksoy et al. - 2011 - Learning the semantics of object–action relations .pdf}
}

@article{al-qaderiTwolevelSpeakerIdentification2021,
  title = {A Two-Level Speaker Identification System via Fusion of Heterogeneous Classifiers and Complementary Feature Cooperation},
  author = {Al-Qaderi, M. and Lahamer, E. and Rad, A.},
  date = {2021},
  journaltitle = {Sensors},
  volume = {21},
  number = {15},
  doi = {10.3390/s21155097},
  abstract = {We present a new architecture to address the challenges of speaker identification that arise in interaction of humans with social robots. Though deep learning systems have led to impressive performance in many speech applications, limited speech data at training stage and short utterances with background noise at test stage present challenges and are still open problems as no optimum solution has been reported to date. The proposed design employs a generative model namely the Gaussian mixture model (GMM) and a discriminative model—support vector machine (SVM) classifiers as well as prosodic features and short-term spectral features to concurrently classify a speaker’s gender and his/her identity. The proposed architecture works in a semi-sequential manner consisting of two stages: the first classifier exploits the prosodic features to determine the speaker’s gender which in turn is used with the short-term spectral features as inputs to the second classifier system in order to identify the speaker. The second classifier system employs two types of short-term spectral features; namely mel-frequency cepstral coefficients (MFCC) and gammatone frequency cepstral coefficients (GFCC) as well as gender information as inputs to two different classifiers (GMM and GMM supervector-based SVM) which in total leads to construction of four classifiers. The outputs from the second stage classifiers; namely GMM-MFCC maximum likelihood classifier (MLC), GMM-GFCC MLC, GMM-MFCC supervector SVM, and GMM-GFCC supervector SVM are fused at score level by the weighted Borda count approach. The weight factors are computed on the fly via Mamdani fuzzy inference system that its inputs are the signal to noise ratio and the length of utterance. Experimental evaluations suggest that the proposed architecture and the fusion framework are promising and can improve the recognition performance of the system in challenging environments where the signal-to-noise ratio is low, and the length of utterance is short; such scenarios often arise in social robot interactions with humans.}
}

@article{al-qaderiTwolevelSpeakerIdentification2021a,
  title = {A Two-Level Speaker Identification System via Fusion of Heterogeneous Classifiers and Complementary Feature Cooperation},
  author = {Al-Qaderi, M. and Lahamer, E. and Rad, A.},
  date = {2021},
  journaltitle = {Sensors},
  volume = {21},
  number = {15},
  doi = {10.3390/s21155097},
  abstract = {We present a new architecture to address the challenges of speaker identification that arise in interaction of humans with social robots. Though deep learning systems have led to impressive performance in many speech applications, limited speech data at training stage and short utterances with background noise at test stage present challenges and are still open problems as no optimum solution has been reported to date. The proposed design employs a generative model namely the Gaussian mixture model (GMM) and a discriminative model—support vector machine (SVM) classifiers as well as prosodic features and short-term spectral features to concurrently classify a speaker’s gender and his/her identity. The proposed architecture works in a semi-sequential manner consisting of two stages: the first classifier exploits the prosodic features to determine the speaker’s gender which in turn is used with the short-term spectral features as inputs to the second classifier system in order to identify the speaker. The second classifier system employs two types of short-term spectral features; namely mel-frequency cepstral coefficients (MFCC) and gammatone frequency cepstral coefficients (GFCC) as well as gender information as inputs to two different classifiers (GMM and GMM supervector-based SVM) which in total leads to construction of four classifiers. The outputs from the second stage classifiers; namely GMM-MFCC maximum likelihood classifier (MLC), GMM-GFCC MLC, GMM-MFCC supervector SVM, and GMM-GFCC supervector SVM are fused at score level by the weighted Borda count approach. The weight factors are computed on the fly via Mamdani fuzzy inference system that its inputs are the signal to noise ratio and the length of utterance. Experimental evaluations suggest that the proposed architecture and the fusion framework are promising and can improve the recognition performance of the system in challenging environments where the signal-to-noise ratio is low, and the length of utterance is short; such scenarios often arise in social robot interactions with humans.}
}

@inproceedings{al-yacoubEffectiveHumanRobotCollaboration2020,
  title = {Effective {{Human-Robot Collaboration}} through {{Wearable Sensors}}},
  booktitle = {{{IEEE International Conference}} on {{Emerging Technologies}} and {{Factory Automation}}, {{ETFA}}},
  author = {Al-Yacoub, A. and Buerkle, A. and Flanagan, M. and Ferreira, P. and Hubbard, E.-M. and Lohse, N.},
  date = {2020},
  volume = {2020-Septe},
  pages = {651--658},
  doi = {10.1109/ETFA46521.2020.9212100},
  abstract = {With the developments of collaborative robots in manufacturing, physical interactions between humans and robots represent a vital role in performing tasks collaboratively. Most conducted studies focused on robot motion planning and control during the execution of a task. However, for effective task distribution and allocation, human physical and psychological status are essential. In this research, a hardware setup and support software for a set of wearable sensors and a data acquisition framework, are developed. This can be used to develop more efficient Human-Robot collaboration strategies. The developed framework is intended to recognise the human mental state and physical activities. Subsequently, a robot could effectively and naturally perform the given task with the human. Besides, the collected data through the developed hardware enables online classification of human intentions and activities; therefore, robots can actively adapt to ensure the safety of the human while delivering the required task.},
  isbn = {978-1-72818-956-7},
  file = {D:\Lib\Effective_Human-Robot_Collaboration_Through_Wearable_Sensors.pdf}
}

@inproceedings{al-yacoubEffectiveHumanRobotCollaboration2020a,
  title = {Effective {{Human-Robot Collaboration}} through {{Wearable Sensors}}},
  booktitle = {{{IEEE International Conference}} on {{Emerging Technologies}} and {{Factory Automation}}, {{ETFA}}},
  author = {Al-Yacoub, A. and Buerkle, A. and Flanagan, M. and Ferreira, P. and Hubbard, E.-M. and Lohse, N.},
  date = {2020},
  volume = {2020-Septe},
  pages = {651--658},
  doi = {10.1109/ETFA46521.2020.9212100},
  abstract = {With the developments of collaborative robots in manufacturing, physical interactions between humans and robots represent a vital role in performing tasks collaboratively. Most conducted studies focused on robot motion planning and control during the execution of a task. However, for effective task distribution and allocation, human physical and psychological status are essential. In this research, a hardware setup and support software for a set of wearable sensors and a data acquisition framework, are developed. This can be used to develop more efficient Human-Robot collaboration strategies. The developed framework is intended to recognise the human mental state and physical activities. Subsequently, a robot could effectively and naturally perform the given task with the human. Besides, the collected data through the developed hardware enables online classification of human intentions and activities; therefore, robots can actively adapt to ensure the safety of the human while delivering the required task.},
  isbn = {978-1-72818-956-7}
}

@article{aleksanderFASTFLEXIBLEPARALLEL1983,
  title = {{{FAST}}, {{FLEXIBLE PARALLEL VISION FOR ROBOTS}}.},
  author = {Aleksander, Igor and Stoneham, T.John and Wilkie, Bruce V.},
  date = {1983},
  journaltitle = {Dev Rob},
  pages = {133--140},
  abstract = {The paper initially addresses the prospect for the solution of the problems of automatic, computer-based pattern vision for robots. It surveys known methods in the light of opportunities offered by Silicon Chip technology. It then discusses some of the design decisions made in the creation of WISARD, a fast pattern recognition computer built at Brunel University. Its structure has been optimized for Silicon Chip implementation.}
}

@article{aleksanderFASTFLEXIBLEPARALLEL1983a,
  title = {{{FAST}}, {{FLEXIBLE PARALLEL VISION FOR ROBOTS}}.},
  author = {Aleksander, Igor and Stoneham, T.John and Wilkie, Bruce V.},
  date = {1983},
  journaltitle = {Dev Rob},
  pages = {133--140},
  abstract = {The paper initially addresses the prospect for the solution of the problems of automatic, computer-based pattern vision for robots. It surveys known methods in the light of opportunities offered by Silicon Chip technology. It then discusses some of the design decisions made in the creation of WISARD, a fast pattern recognition computer built at Brunel University. Its structure has been optimized for Silicon Chip implementation.}
}

@inproceedings{alzubiAutomatedMonitoringConstruction2021,
  title = {Automated {{Monitoring}} for {{Construction Productivity Recognition}}},
  booktitle = {2021 3rd {{International Sustainability}} and {{Resilience Conference}}: {{Climate Change}}},
  author = {Alzubi, K. M. and Alaloul, W. S. and Salaheen, M. A. and Qureshi, A. H. and Musarat, M. A. and Baarimah, A. O.},
  date = {2021},
  pages = {489--494},
  doi = {10.1109/IEEECONF53624.2021.9668172},
  abstract = {Comparing to other sectors, the construction sector suffers from low productivity, and it is not improving over time due to the unique nature of construction projects. It is believed that construction productivity cannot be improved without efficient monitoring and measuring, and this is crucial for project success. There are many limitations for the traditional construction productivity monitoring practices like time and cost consuming and error-prone. Although a lot of studies have been implemented to eliminate these limitations, a gap still exists in the automated monitoring of construction productivity. This study proposes an automated monitoring model for indoor productivity recognition in construction projects. The model will provide an instant evaluation of the project productivity which will enhance the optimum utilization of the project resources. The proposed model will be developed by first generating a baseline for the activities state which will be represented as baseline state model. Then the as-built model will be generated. Preliminary experimentation was performed on selected images where the number of tiles and bricks was obtained. The experimentation was performed using Open-Source Computer Vision Library (OpenCV). Preliminary results depict that by using the proposed model the automated monitoring of productivity is achievable. Although, there is a need of dedicated efforts for improvement and development of technique for more effective and efficient results.},
  isbn = {978-1-66541-632-0}
}

@inproceedings{alzubiAutomatedMonitoringConstruction2021a,
  title = {Automated {{Monitoring}} for {{Construction Productivity Recognition}}},
  booktitle = {2021 3rd {{International Sustainability}} and {{Resilience Conference}}: {{Climate Change}}},
  author = {Alzubi, K.M. and Alaloul, W.S. and Salaheen, M.A. and Qureshi, A.H. and Musarat, M.A. and Baarimah, A.O.},
  date = {2021},
  pages = {489--494},
  doi = {10.1109/IEEECONF53624.2021.9668172},
  abstract = {Comparing to other sectors, the construction sector suffers from low productivity, and it is not improving over time due to the unique nature of construction projects. It is believed that construction productivity cannot be improved without efficient monitoring and measuring, and this is crucial for project success. There are many limitations for the traditional construction productivity monitoring practices like time and cost consuming and error-prone. Although a lot of studies have been implemented to eliminate these limitations, a gap still exists in the automated monitoring of construction productivity. This study proposes an automated monitoring model for indoor productivity recognition in construction projects. The model will provide an instant evaluation of the project productivity which will enhance the optimum utilization of the project resources. The proposed model will be developed by first generating a baseline for the activities state which will be represented as baseline state model. Then the as-built model will be generated. Preliminary experimentation was performed on selected images where the number of tiles and bricks was obtained. The experimentation was performed using Open-Source Computer Vision Library (OpenCV). Preliminary results depict that by using the proposed model the automated monitoring of productivity is achievable. Although, there is a need of dedicated efforts for improvement and development of technique for more effective and efficient results.},
  isbn = {978-1-66541-632-0}
}

@article{aminMixedperceptionApproachSafe2020,
  title = {A Mixed-Perception Approach for Safe Human–Robot Collaboration in Industrial Automation},
  author = {Amin, F. M. and Rezayati, M. and family=Venn, given=H. W., prefix=van de, useprefix=false and Karimpour, H.},
  date = {2020},
  journaltitle = {Sensors (Switzerland)},
  volume = {20},
  number = {21},
  pages = {1--20},
  doi = {10.3390/s20216347},
  abstract = {Digital-enabled manufacturing systems require a high level of automation for fast and low-cost production but should also present flexibility and adaptiveness to varying and dynamic conditions in their environment, including the presence of human beings; however, this presence of workers in the shared workspace with robots decreases the productivity, as the robot is not aware about the human position and intention, which leads to concerns about human safety. This issue is addressed in this work by designing a reliable safety monitoring system for collaborative robots (cobots). The main idea here is to significantly enhance safety using a combination of recognition of human actions using visual perception and at the same time interpreting physical human–robot contact by tactile perception. Two datasets containing contact and vision data are collected by using different volunteers. The action recognition system classifies human actions using the skeleton representation of the latter when entering the shared workspace and the contact detection system distinguishes between intentional and incidental interactions if physical contact between human and cobot takes place. Two different deep learning networks are used for human action recognition and contact detection, which in combination, are expected to lead to the enhancement of human safety and an increase in the level of cobot perception about human intentions. The results show a promising path for future AI-driven solutions in safe and productive human–robot collaboration (HRC) in industrial automation.}
}

@article{aminMixedperceptionApproachSafe2020a,
  title = {A Mixed-Perception Approach for Safe Human–Robot Collaboration in Industrial Automation},
  author = {Amin, F.M. and Rezayati, M. and family=Venn, given=H.W., prefix=van de, useprefix=true and Karimpour, H.},
  date = {2020},
  journaltitle = {Sensors (Switzerland)},
  volume = {20},
  number = {21},
  pages = {1--20},
  doi = {10.3390/s20216347},
  abstract = {Digital-enabled manufacturing systems require a high level of automation for fast and low-cost production but should also present flexibility and adaptiveness to varying and dynamic conditions in their environment, including the presence of human beings; however, this presence of workers in the shared workspace with robots decreases the productivity, as the robot is not aware about the human position and intention, which leads to concerns about human safety. This issue is addressed in this work by designing a reliable safety monitoring system for collaborative robots (cobots). The main idea here is to significantly enhance safety using a combination of recognition of human actions using visual perception and at the same time interpreting physical human–robot contact by tactile perception. Two datasets containing contact and vision data are collected by using different volunteers. The action recognition system classifies human actions using the skeleton representation of the latter when entering the shared workspace and the contact detection system distinguishes between intentional and incidental interactions if physical contact between human and cobot takes place. Two different deep learning networks are used for human action recognition and contact detection, which in combination, are expected to lead to the enhancement of human safety and an increase in the level of cobot perception about human intentions. The results show a promising path for future AI-driven solutions in safe and productive human–robot collaboration (HRC) in industrial automation.}
}

@inproceedings{amtsbergIHRCARbasedInterface2021,
  title = {{{iHRC}}: {{An AR-based}} Interface for Intuitive, Interactive and Coordinated Task Sharing between Humans and Robots in Building Construction},
  booktitle = {Proceedings of the 38th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} ({{ISARC}})},
  author = {Amtsberg, Felix and Yang, Xiliu and Skoury, Lior and Wagner, Hans-Jakob and Menges, Achim},
  date = {2021-11},
  issn = {24135844},
  doi = {10.22260/ISARC2021/0006},
  url = {http://www.iaarc.org/publications/2021_proceedings_of_the_38th_isarc/ihrc-an_ar_based_interface_for_intuitive_interactive_and_coordinated_task_sharing_between_humans_and_robots_in_building_construction.html},
  abstract = {The research presented in this paper introduces a novel method for Augmented Reality informed human-machine collaboration in the context of timber prefabrication. The concept is based on the craftsman controlled instructive interaction between a High Level of Automation (robotic) fabrication setup and a human co-worker. It argues that by enabling the craftsmen to coordinate or take over specific process parts, a significant increase in flexibility and robustness of automated workflows becomes feasible. This is highly relevant within the project-based construction industry where efficient and flexible production of one-off components is predominant. A novel approach to integrate human and robotic co-workers in a joint fabrication setup that we call “Instructive Human Robot Collaboration” is introduced. With Vizor, a computational framework was developed for this purpose. It provides an intuitive interface between human and robotic fabrication units via a mixed reality head-mounted display (HMD). Finally, the proposed method is tested with an initial case study in which a 14-Axis fabrication setup is connected with human craft. The HMD gives a craftsman without any knowledge in robot programming direct control over the fabrication setup and extends its individual skill set. Fabrication tasks can be shared freely and between human and robotic units, enabling a dynamically adaptive workflow.},
  isbn = {978-952-69524-1-3}
}

@inproceedings{amtsbergIHRCARbasedInterface2021a,
  title = {{{iHRC}}: {{An AR-based}} Interface for Intuitive, Interactive and Coordinated Task Sharing between Humans and Robots in Building Construction},
  booktitle = {Proceedings of the 38th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} ({{ISARC}})},
  author = {Amtsberg, Felix and Yang, Xiliu and Skoury, Lior and Wagner, Hans-Jakob and Menges, Achim},
  date = {2021-11-02},
  issn = {24135844},
  doi = {10.22260/ISARC2021/0006},
  url = {http://www.iaarc.org/publications/2021_proceedings_of_the_38th_isarc/ihrc-an_ar_based_interface_for_intuitive_interactive_and_coordinated_task_sharing_between_humans_and_robots_in_building_construction.html},
  abstract = {The research presented in this paper introduces a novel method for Augmented Reality informed human-machine collaboration in the context of timber prefabrication. The concept is based on the craftsman controlled instructive interaction between a High Level of Automation (robotic) fabrication setup and a human co-worker. It argues that by enabling the craftsmen to coordinate or take over specific process parts, a significant increase in flexibility and robustness of automated workflows becomes feasible. This is highly relevant within the project-based construction industry where efficient and flexible production of one-off components is predominant. A novel approach to integrate human and robotic co-workers in a joint fabrication setup that we call “Instructive Human Robot Collaboration” is introduced. With Vizor, a computational framework was developed for this purpose. It provides an intuitive interface between human and robotic fabrication units via a mixed reality head-mounted display (HMD). Finally, the proposed method is tested with an initial case study in which a 14-Axis fabrication setup is connected with human craft. The HMD gives a craftsman without any knowledge in robot programming direct control over the fabrication setup and extends its individual skill set. Fabrication tasks can be shared freely and between human and robotic units, enabling a dynamically adaptive workflow.},
  isbn = {978-952-69524-1-3}
}

@inproceedings{amtsbergIHRCARbasedInterface2021b,
  title = {{{iHRC}}: {{An AR-based}} Interface for Intuitive, Interactive and Coordinated Task Sharing between Humans and Robots in Building Construction},
  shorttitle = {{{iHRC}}},
  author = {Amtsberg, Felix and Yang, Xiliu and Skoury, Lior and Wagner, Hans-Jakob and Menges, Achim},
  date = {2021-11-02},
  location = {{Dubai, UAE}},
  doi = {10.22260/ISARC2021/0006},
  url = {http://www.iaarc.org/publications/2021_proceedings_of_the_38th_isarc/ihrc-an_ar_based_interface_for_intuitive_interactive_and_coordinated_task_sharing_between_humans_and_robots_in_building_construction.html},
  urldate = {2023-03-15},
  abstract = {The research presented in this paper introduces a novel method for Augmented Reality informed human-machine collaboration in the context of timber prefabrication. The concept is based on the craftsman controlled instructive interaction between a High Level of Automation (robotic) fabrication setup and a human co-worker. It argues that by enabling the craftsmen to coordinate or take over specific process parts, a significant increase in flexibility and robustness of automated workflows becomes feasible. This is highly relevant within the project-based construction industry where efficient and flexible production of one-off components is predominant.},
  eventtitle = {38th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  langid = {english},
  file = {/Volumes/WIP/library/004 ISARC 2021 Paper 141.pdf}
}

@inproceedings{andrewsComparisonLaserScanning2013,
  title = {A Comparison of Laser Scanning and Structure from Motion as Applied to the Great Barn at {{Harmondsworth}}, {{UK}}},
  booktitle = {International {{Archives}} of the {{Photogrammetry}}, {{Remote Sensing}} and {{Spatial Information Sciences}} - {{ISPRS Archives}}},
  author = {Andrews, D.P. and Bedford, J. and Bryan, P.G.},
  date = {2013},
  volume = {40},
  pages = {31--36},
  abstract = {The great barn at Harmondsworth near London Heathrow airport, United Kingdom (UK), was built in 1426-7 for the Bishop of Winchester. At 58 metres long and 11.4 metres wide, it is one of the largest ever known to have been built in the UK, and the largest intact medieval timber-framed barn in England. The barn is built almost entirely of oak, although the walls rest on a low masonry sill-wall. Internally the space is divided into a central 'nave' with a lower aisle to each side, and is divided along its length into 12 bays. There are three doorways on the east side. For an entirely timber-framed barn, the fabric is exceptionally well preserved. Even the external weatherboarding may be partly original. Following years of neglect, however, there are a number of on-going structural and conservation problems, so in 2011 the barn was bought by English Heritage in order to allow these needs to be addressed. English Heritage is the government agency responsible for the historic sites and buildings in the care of the state of England and is also the UK government's lead advisor on the built heritage. As one of the first steps in the conservation process the English Heritage Geospatial Imaging and Imaging \& Visualisation teams undertook a four-day campaign of survey data collection. This took the form of laser scanning of the interior and exterior of the barn plus the acquisition of photography of the exterior elevations to be used with structure from motion (SFM) software. A comparison of the results of these complimentary yet potentially competing technologies will be given, as well as an evaluation of when they can be successfully used together. This paper will describe the procedures and problems involved with collecting the survey data and its subsequent analysis. The laser scanning was undertaken using a FARO Focus 3D phase based instrument. Approximately 60 scans were acquired in order to provide as comprehensive as possible coverage given the site circumstances. A repeat visit following the clearance of artefacts and with the benefit of access equipment was required to obtain complete coverage, especially for the top surfaces of the timber frame elements. Initial results from the laser scanning were extremely promising, with some historical events (e.g. a major fire at one end of the structure) dramatically shown in the intensity data. Comprehensive photographic coverage of the exterior of the barn including the roof was obtained using a Nikon D3X mounted on both a 6m telescopic pole and a conventional tripod. A repeat visit was required to address some exposure problems in shadow areas. A unified control network for both sets of data was obtained through the use of a total station theodolite (TST) with reflectorless electromagnetic distance measurement (REDM), incorporating a closed traverse as well as the acquisition of scanner and photo-grammetric targets. The control network therefore permits the direct comparison of the results from both survey methods (allowing for systematic errors). A point cloud generated from the photography, using Agisoft Photoscan structure from motion software, was compared with the registered laser scan points with a view to determining any systematic differences, although these were to a large extent ameliorated by the use of the dense control network. The resultant data also has potential downstream use within English Heritage for improving our understanding of Building Information Modelling (BIM) as applied to heritage structures rather than new build, and thereby contributing to the formulation of elements of a BIM strategy for English Heritage. There are also a number of hand-measured survey drawings of the barn in existence. A quantitative as well as a qualitative comparison was made with drawings generated from the laser scan data. In general the later drawings were more metrically accurate but exhibited less understanding of the construction techniques employed. A discussion of the reasons for this is also presented.},
  issue = {5W2}
}

@inproceedings{andrewsComparisonLaserScanning2013a,
  title = {A Comparison of Laser Scanning and Structure from Motion as Applied to the Great Barn at {{Harmondsworth}}, {{UK}}},
  booktitle = {International {{Archives}} of the {{Photogrammetry}}, {{Remote Sensing}} and {{Spatial Information Sciences}} - {{ISPRS Archives}}},
  author = {Andrews, D.P. and Bedford, J. and Bryan, P.G.},
  date = {2013},
  volume = {40},
  pages = {31--36},
  abstract = {The great barn at Harmondsworth near London Heathrow airport, United Kingdom (UK), was built in 1426-7 for the Bishop of Winchester. At 58 metres long and 11.4 metres wide, it is one of the largest ever known to have been built in the UK, and the largest intact medieval timber-framed barn in England. The barn is built almost entirely of oak, although the walls rest on a low masonry sill-wall. Internally the space is divided into a central 'nave' with a lower aisle to each side, and is divided along its length into 12 bays. There are three doorways on the east side. For an entirely timber-framed barn, the fabric is exceptionally well preserved. Even the external weatherboarding may be partly original. Following years of neglect, however, there are a number of on-going structural and conservation problems, so in 2011 the barn was bought by English Heritage in order to allow these needs to be addressed. English Heritage is the government agency responsible for the historic sites and buildings in the care of the state of England and is also the UK government's lead advisor on the built heritage. As one of the first steps in the conservation process the English Heritage Geospatial Imaging and Imaging \& Visualisation teams undertook a four-day campaign of survey data collection. This took the form of laser scanning of the interior and exterior of the barn plus the acquisition of photography of the exterior elevations to be used with structure from motion (SFM) software. A comparison of the results of these complimentary yet potentially competing technologies will be given, as well as an evaluation of when they can be successfully used together. This paper will describe the procedures and problems involved with collecting the survey data and its subsequent analysis. The laser scanning was undertaken using a FARO Focus 3D phase based instrument. Approximately 60 scans were acquired in order to provide as comprehensive as possible coverage given the site circumstances. A repeat visit following the clearance of artefacts and with the benefit of access equipment was required to obtain complete coverage, especially for the top surfaces of the timber frame elements. Initial results from the laser scanning were extremely promising, with some historical events (e.g. a major fire at one end of the structure) dramatically shown in the intensity data. Comprehensive photographic coverage of the exterior of the barn including the roof was obtained using a Nikon D3X mounted on both a 6m telescopic pole and a conventional tripod. A repeat visit was required to address some exposure problems in shadow areas. A unified control network for both sets of data was obtained through the use of a total station theodolite (TST) with reflectorless electromagnetic distance measurement (REDM), incorporating a closed traverse as well as the acquisition of scanner and photo-grammetric targets. The control network therefore permits the direct comparison of the results from both survey methods (allowing for systematic errors). A point cloud generated from the photography, using Agisoft Photoscan structure from motion software, was compared with the registered laser scan points with a view to determining any systematic differences, although these were to a large extent ameliorated by the use of the dense control network. The resultant data also has potential downstream use within English Heritage for improving our understanding of Building Information Modelling (BIM) as applied to heritage structures rather than new build, and thereby contributing to the formulation of elements of a BIM strategy for English Heritage. There are also a number of hand-measured survey drawings of the barn in existence. A quantitative as well as a qualitative comparison was made with drawings generated from the laser scan data. In general the later drawings were more metrically accurate but exhibited less understanding of the construction techniques employed. A discussion of the reasons for this is also presented.},
  issue = {5W2}
}

@inproceedings{andrilukaMonocular3DPose2010,
  title = {Monocular {{3D}} Pose Estimation and Tracking by Detection},
  booktitle = {2010 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Andriluka, Mykhaylo and Roth, Stefan and Schiele, Bernt},
  date = {2010-06},
  pages = {623--630},
  publisher = {{IEEE}},
  location = {{San Francisco, CA, USA}},
  doi = {10.1109/CVPR.2010.5540156},
  url = {http://ieeexplore.ieee.org/document/5540156/},
  urldate = {2023-03-15},
  abstract = {Automatic recovery of 3D human pose from monocular image sequences is a challenging and important research topic with numerous applications. Although current methods are able to recover 3D pose for a single person in controlled environments, they are severely challenged by realworld scenarios, such as crowded street scenes. To address this problem, we propose a three-stage process building on a number of recent advances. The first stage obtains an initial estimate of the 2D articulation and viewpoint of the person from single frames. The second stage allows early data association across frames based on tracking-by-detection. These two stages successfully accumulate the available 2D image evidence into robust estimates of 2D limb positions over short image sequences (= tracklets). The third and final stage uses those tracklet-based estimates as robust image observations to reliably recover 3D pose. We demonstrate state-of-the-art performance on the HumanEva II benchmark, and also show the applicability of our approach to articulated 3D tracking in realistic street conditions.},
  eventtitle = {2010 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4244-6984-0},
  langid = {english},
  file = {/Volumes/WIP/library/cvpr10andriluka.pdf}
}

@article{anumbaOntologybasedInformationKnowledge2008,
  title = {Ontology-Based Information and Knowledge Management in Construction},
  author = {Anumba, Chimay J. and Issa, Raja R. A. and Pan, Jiayi and Mutis, Ivan},
  date = {2008-07},
  journaltitle = {Construction Innovation},
  volume = {8},
  number = {3},
  pages = {218--239},
  issn = {14770857},
  doi = {10.1108/14714170810888976},
  abstract = {There is an increasing recognition of the value of effective information and knowledge management (KM) in the construction project delivery process. Many architecture, engineering and construction (AEC) organisations have invested heavily in information technology and KM systems that help in this regard. While these have been largely successful in supporting intra-organisational business processes, interoperability problems still persist at the project organisation level due to the heterogeneity of the systems used by the different organisations involved. Ontologies are seen as an important means of addressing these problems. The purpose of this paper is to explore the role of ontologies in the construction project delivery process, particularly with respect to information and KM. A detailed technical review of the fundamental concepts and related work has been undertaken, with examples and case studies of ontology-based information and KM presented to illustrate the key concepts. The specific issues and technical difficulties in the design and construction context are highlighted, and the approaches adopted in two ontology-based applications for the AEC sector are presented. The paper concludes that there is considerable merit in ontology-based approaches to information and KM, but that significant technical challenges remain. Middleware applications, such as semantic web-based information management system, are contributing in this regard but more needs to be done particularly on integrating or merging ontologies. The value of the paper lies in the detailed exploration of ontology-based information and KM within a design and construction context, and the use of appropriate examples and applications to illustrate the key issues. © 2008, Emerald Group Publishing Limited},
  keywords = {Construction industry,Data structures,Generation and dissemination of information,Knowledge management,Semantics}
}

@article{anumbaOntologybasedInformationKnowledge2008a,
  title = {Ontology-Based Information and Knowledge Management in Construction},
  author = {Anumba, Chimay J. and Issa, Raja R.A. and Pan, Jiayi and Mutis, Ivan},
  date = {2008-07-11},
  journaltitle = {Construction Innovation},
  volume = {8},
  number = {3},
  pages = {218--239},
  issn = {14770857},
  doi = {10.1108/14714170810888976},
  abstract = {There is an increasing recognition of the value of effective information and knowledge management (KM) in the construction project delivery process. Many architecture, engineering and construction (AEC) organisations have invested heavily in information technology and KM systems that help in this regard. While these have been largely successful in supporting intra-organisational business processes, interoperability problems still persist at the project organisation level due to the heterogeneity of the systems used by the different organisations involved. Ontologies are seen as an important means of addressing these problems. The purpose of this paper is to explore the role of ontologies in the construction project delivery process, particularly with respect to information and KM. A detailed technical review of the fundamental concepts and related work has been undertaken, with examples and case studies of ontology-based information and KM presented to illustrate the key concepts. The specific issues and technical difficulties in the design and construction context are highlighted, and the approaches adopted in two ontology-based applications for the AEC sector are presented. The paper concludes that there is considerable merit in ontology-based approaches to information and KM, but that significant technical challenges remain. Middleware applications, such as semantic web-based information management system, are contributing in this regard but more needs to be done particularly on integrating or merging ontologies. The value of the paper lies in the detailed exploration of ontology-based information and KM within a design and construction context, and the use of appropriate examples and applications to illustrate the key issues. © 2008, Emerald Group Publishing Limited},
  keywords = {★,Construction industry,Data structures,Generation and dissemination of information,Knowledge management,Semantics},
  file = {C:\Users\leemar\Zotero\storage\5MHF9NVP\10-1108_14714170810888976.pdf}
}

@inproceedings{aokiTeleoperationMethodIllusion2021,
  title = {Teleoperation Method by Illusion of Human Intention and Time},
  booktitle = {2021 30th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}}, {{RO-MAN}} 2021},
  author = {Aoki, J. and Yamashina, R. and Kurazume, R.},
  date = {2021},
  pages = {482--487},
  doi = {10.1109/RO-MAN50785.2021.9515457},
  abstract = {Shared control, in which teleoperation and autonomous control are combined to move the robot, is expected to improve the efficiency of the user teleoperation problem. However, a problem exists whereby the user acceptance decreases owing to the conflict of intention between the teleoperation and autonomous control. In this study, we address this problem by providing an illusion to humans. We propose a teleoperation method named the 'Illusory Control' that can achieve both mobility efficiency and user acceptance by implementing a cyber-physical system that controls a robot in real space through robot operations in virtual space. Illusory Control has two functions: the 'Illusion of Intention, ' which provides the illusion that the robot is operating according to human intention, and 'Illusion of Time, ' which provides the illusion of time to fill the gap by changing human behavior when the robot positions in the virtual space and real space diverge. Preliminary teleoperation experiments with subjects demonstrated that the system improves the operational efficiency and acceptance of the system compared to conventional teleoperation methods, namely direct teleoperation and shared control.},
  isbn = {978-1-66540-492-1}
}

@inproceedings{aokiTeleoperationMethodIllusion2021a,
  title = {Teleoperation Method by Illusion of Human Intention and Time},
  booktitle = {2021 30th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}}, {{RO-MAN}} 2021},
  author = {Aoki, J. and Yamashina, R. and Kurazume, R.},
  date = {2021},
  pages = {482--487},
  doi = {10.1109/RO-MAN50785.2021.9515457},
  abstract = {Shared control, in which teleoperation and autonomous control are combined to move the robot, is expected to improve the efficiency of the user teleoperation problem. However, a problem exists whereby the user acceptance decreases owing to the conflict of intention between the teleoperation and autonomous control. In this study, we address this problem by providing an illusion to humans. We propose a teleoperation method named the 'Illusory Control' that can achieve both mobility efficiency and user acceptance by implementing a cyber-physical system that controls a robot in real space through robot operations in virtual space. Illusory Control has two functions: the 'Illusion of Intention, ' which provides the illusion that the robot is operating according to human intention, and 'Illusion of Time, ' which provides the illusion of time to fill the gap by changing human behavior when the robot positions in the virtual space and real space diverge. Preliminary teleoperation experiments with subjects demonstrated that the system improves the operational efficiency and acceptance of the system compared to conventional teleoperation methods, namely direct teleoperation and shared control.},
  isbn = {978-1-66540-492-1}
}

@article{arashpourSceneUnderstandingConstruction2021,
  title = {Scene Understanding in Construction and Buildings Using Image Processing Methods: {{A}} Comprehensive Review and a Case Study},
  author = {Arashpour, M. and Ngo, T. and Li, H.},
  date = {2021},
  journaltitle = {Journal of Building Engineering},
  volume = {33},
  doi = {10.1016/j.jobe.2020.101672},
  abstract = {Acquiring photos and videos has become a new norm in construction and building projects. However, imagery data is not utilized effectively due to the shortage of required skillsets in the industry and nonfamiliarity with classic image processing methods. Computer vision research in the context of construction and building has heavily focused on the interface between machine learning, and object tracking and activity recognition. Although positive results have been reported, namely improved productivity, safety and quality, implementations in the industry will not be immediate. Furthermore, algorithms such as convolutional neural networks (CNN), residual neural networks (ResNet) and recurrent neural networks (RNN) usually need to undergo extensive transfer learning in order to capture project-specific information in civil infrastructure engineering. This paper revisits classic image processing methods that can capture clues of site scenes with capability of high-level reasoning and inference. The work contributes to the body of knowledge by reviewing color, geometry and feature-based diagnostics in project environments.}
}

@article{arashpourSceneUnderstandingConstruction2021a,
  title = {Scene Understanding in Construction and Buildings Using Image Processing Methods: {{A}} Comprehensive Review and a Case Study},
  author = {Arashpour, M. and Ngo, T. and Li, H.},
  date = {2021},
  journaltitle = {Journal of Building Engineering},
  volume = {33},
  doi = {10.1016/j.jobe.2020.101672},
  abstract = {Acquiring photos and videos has become a new norm in construction and building projects. However, imagery data is not utilized effectively due to the shortage of required skillsets in the industry and nonfamiliarity with classic image processing methods. Computer vision research in the context of construction and building has heavily focused on the interface between machine learning, and object tracking and activity recognition. Although positive results have been reported, namely improved productivity, safety and quality, implementations in the industry will not be immediate. Furthermore, algorithms such as convolutional neural networks (CNN), residual neural networks (ResNet) and recurrent neural networks (RNN) usually need to undergo extensive transfer learning in order to capture project-specific information in civil infrastructure engineering. This paper revisits classic image processing methods that can capture clues of site scenes with capability of high-level reasoning and inference. The work contributes to the body of knowledge by reviewing color, geometry and feature-based diagnostics in project environments.}
}

@article{arbuluRh1FullsizeHumanoid2009,
  title = {The {{Rh-1}} Full-Size Humanoid Robot: {{Design}}, Walking Pattern Generation and Control},
  author = {Arbulú, M. and Kaynov, D. and Cabas, L. and Balaguer, C.},
  date = {2009},
  journaltitle = {Applied Bionics and Biomechanics},
  volume = {6},
  number = {3-4},
  pages = {301--344},
  doi = {10.1080/11762320903123575},
  abstract = {This paper is an overview of the humanoid robot Rh-1, the second phase of the Rh project, which was launched by the Robotics Lab at the Carlos III University of Madrid in 2002. The robot mechanical design includes the specifications development in order to construct a platform, which is capable of stable biped walking. At first, the robots' weights were calculated in order to obtain the inverse dynamics and to select the actuators. After that, mechanical specifications were introduced in order to verify the robot's structural behaviour with different experimental gaits. In addition, an important aspect is the joints design when their axes are crossed, which is called 'Joints of Rectangular Axes' (JRA). The problem with these joints is obtaining two or more degrees of freedom (DOF) in small space. The construction of a humanoid robot also includes the design of hardware and software architectures. The main advantage of the proposed hardware and software architectures is the use of standardised solutions frequently used in the automation industry and commercially available hardware components. It provides scalability, modularity and application of standardised interfaces and brings the design of the complex control system of the humanoid robot out of a closed laboratory to industry. Stable walking is the most essential ability for the humanoid robot. The three dimensional Linear Inverted Pendulum Model (3D-LIPM) and the Cart-table models had been used in order to achieve natural and dynamic biped walking. Humanoid dynamics is widely simplified by concentrating its mass in the centre of gravity (COG) and moving it following the natural inverted pendulum laws (3D-LIPM) or by controlling the cart motion (Cart-table model). An offline-calculated motion pattern does not guarantee the walking stability of the humanoid robot. Control architecture for the dynamic humanoid robot walking was developed, which is able to make online modifications of the motion patterns in order to adjust it to the continuously changing environment. Experimental results concerning biped locomotion of the Rh-1 humanoid robot are presented and discussed. © 2009 Taylor \& Francis.}
}

@article{arbuluRh1FullsizeHumanoid2009a,
  title = {The {{Rh-1}} Full-Size Humanoid Robot: {{Design}}, Walking Pattern Generation and Control},
  author = {Arbulú, M. and Kaynov, D. and Cabas, L. and Balaguer, C.},
  date = {2009},
  journaltitle = {Applied Bionics and Biomechanics},
  volume = {6},
  number = {3-4},
  pages = {301--344},
  doi = {10.1080/11762320903123575},
  abstract = {This paper is an overview of the humanoid robot Rh-1, the second phase of the Rh project, which was launched by the Robotics Lab at the Carlos III University of Madrid in 2002. The robot mechanical design includes the specifications development in order to construct a platform, which is capable of stable biped walking. At first, the robots' weights were calculated in order to obtain the inverse dynamics and to select the actuators. After that, mechanical specifications were introduced in order to verify the robot's structural behaviour with different experimental gaits. In addition, an important aspect is the joints design when their axes are crossed, which is called 'Joints of Rectangular Axes' (JRA). The problem with these joints is obtaining two or more degrees of freedom (DOF) in small space. The construction of a humanoid robot also includes the design of hardware and software architectures. The main advantage of the proposed hardware and software architectures is the use of standardised solutions frequently used in the automation industry and commercially available hardware components. It provides scalability, modularity and application of standardised interfaces and brings the design of the complex control system of the humanoid robot out of a closed laboratory to industry. Stable walking is the most essential ability for the humanoid robot. The three dimensional Linear Inverted Pendulum Model (3D-LIPM) and the Cart-table models had been used in order to achieve natural and dynamic biped walking. Humanoid dynamics is widely simplified by concentrating its mass in the centre of gravity (COG) and moving it following the natural inverted pendulum laws (3D-LIPM) or by controlling the cart motion (Cart-table model). An offline-calculated motion pattern does not guarantee the walking stability of the humanoid robot. Control architecture for the dynamic humanoid robot walking was developed, which is able to make online modifications of the motion patterns in order to adjust it to the continuously changing environment. Experimental results concerning biped locomotion of the Rh-1 humanoid robot are presented and discussed. © 2009 Taylor \& Francis.}
}

@article{Argall2009469,
  title = {A Survey of Robot Learning from Demonstration},
  author = {Argall, B.D. and Chernova, S. and Veloso, M. and Browning, B.},
  date = {2009},
  journaltitle = {Robotics and Autonomous Systems},
  volume = {57},
  number = {5},
  pages = {469--483},
  doi = {10.1016/j.robot.2008.10.024}
}

@article{aristizabalModularHardwareArchitecture2021,
  title = {Modular Hardware Architecture for the Development of Underwater Vehicles Based on Systems Engineering},
  author = {Aristizábal, L.M. and Zuluaga, C.A. and Rúa, S. and Vásquez, R.E.},
  date = {2021},
  journaltitle = {Journal of Marine Science and Engineering},
  volume = {9},
  number = {5},
  doi = {10.3390/jmse9050516},
  abstract = {This paper addresses the development of a modular hardware architecture for the design/ construction/operation of a remotely operated vehicle (ROV), based on systems engineering. The Vee model is first presented as a sequential process that emphasizes the validation processes with stakeholders and verification plans in the development and production stages of the ROV’s life cycle. The conceptual design process starts with the mapping of user requirements to engineering specifications, using the House of Quality (HoQ), a quality function deployment tool that allows executing a functional-division-based hardware design process that facilitates the integration of components and subsystems, as desired for modular architectures. Then, the functional division and hardware architectures are described, and their connection is made through the proposed system architecture that sets the foundation for the definition of a physical architecture, as it involves flows that connect abstract functions with a real context. Development and production stages are exemplified through the design, construction, and integration of some hardware components needed for the remotely operated vehicle Pionero500, and the operational stage briefly describes the first sea trials conducted for the ROV. Systems engineering has shown to be a very useful tool for the development of marine vehicles and marine engineering projects that require modular architectures.}
}

@article{aristizabalModularHardwareArchitecture2021a,
  title = {Modular Hardware Architecture for the Development of Underwater Vehicles Based on Systems Engineering},
  author = {Aristizábal, L.M. and Zuluaga, C.A. and Rúa, S. and Vásquez, R.E.},
  date = {2021},
  journaltitle = {Journal of Marine Science and Engineering},
  volume = {9},
  number = {5},
  doi = {10.3390/jmse9050516},
  abstract = {This paper addresses the development of a modular hardware architecture for the design/ construction/operation of a remotely operated vehicle (ROV), based on systems engineering. The Vee model is first presented as a sequential process that emphasizes the validation processes with stakeholders and verification plans in the development and production stages of the ROV’s life cycle. The conceptual design process starts with the mapping of user requirements to engineering specifications, using the House of Quality (HoQ), a quality function deployment tool that allows executing a functional-division-based hardware design process that facilitates the integration of components and subsystems, as desired for modular architectures. Then, the functional division and hardware architectures are described, and their connection is made through the proposed system architecture that sets the foundation for the definition of a physical architecture, as it involves flows that connect abstract functions with a real context. Development and production stages are exemplified through the design, construction, and integration of some hardware components needed for the remotely operated vehicle Pionero500, and the operational stage briefly describes the first sea trials conducted for the ROV. Systems engineering has shown to be a very useful tool for the development of marine vehicles and marine engineering projects that require modular architectures.}
}

@article{arroukCADbasedUnifiedGraphical2016,
  title = {{{CAD-based}} Unified Graphical Methodology for Solving the Main Problems Related to Geometric and Kinematic Analysis of Planar Parallel Robotic Manipulators},
  author = {Arrouk, K.A. and Bouzgarrou, B.C. and Gogu, G.},
  date = {2016},
  journaltitle = {Robotics and Computer-Integrated Manufacturing},
  volume = {37},
  pages = {302--321},
  doi = {10.1016/j.rcim.2015.03.009},
  abstract = {CAD environments provide powerful tools for graphical programming and geometric feature handling. This paper explores this potential for robotics applications by presenting a set of several original approaches for solving the main problems related to geometric and kinematic analysis of planar parallel robotic manipulators (PPRMs). These approaches rely on the use of CAD-based graphical programming enabling rapid resolution and geometric interpretation of the 3D total workspace characteristics. The novelty of the proposed approach resides in the association of an original, unique and natural 3D graphical representation of the end-effector poses and the use of geometric feature handling and graphical solver capabilities within a CAD environment, for determining the 3D total operational workspace as well as solving the forward kinematic problem (FKP) of PPRMs. The approach consists in considering the mobile platform separately attached to each limb that we disconnect from the rest of the mechanism. The geometric construction of the spaces reachable by the end-effector is performed by using Boolean intersections of the vertex volumes, respectively the vertex surfaces, relative to each limb for 3D total workspace determination, respectively for FKP resolution. By combining in the same 3D graphical environment several geometric entities associated to the PPRM, such as workspace volume, singularity surface, and the different solutions of the FKP, this approach allows designers, in a user-friendly way, to generate the singularity-free trajectories connecting different assembly modes. The approach presented in this paper is mostly useful for the architectures of 3-DOF parallel robotic manipulators for which an algebraic closed form solution does not exist for the forward kinematic model and the singularity-free trajectory planning between assembly modes is not a trivial task. It is applied for several PPRMs such as: 3-RPR, 3-RRR, 3-PPR, 3-RRP, 3-PRP, 3-PRR, 3-RRR, and 3-RPR.}
}

@article{arroukCADbasedUnifiedGraphical2016a,
  title = {{{CAD-based}} Unified Graphical Methodology for Solving the Main Problems Related to Geometric and Kinematic Analysis of Planar Parallel Robotic Manipulators},
  author = {Arrouk, K.A. and Bouzgarrou, B.C. and Gogu, G.},
  date = {2016},
  journaltitle = {Robotics and Computer-Integrated Manufacturing},
  volume = {37},
  pages = {302--321},
  doi = {10.1016/j.rcim.2015.03.009},
  abstract = {CAD environments provide powerful tools for graphical programming and geometric feature handling. This paper explores this potential for robotics applications by presenting a set of several original approaches for solving the main problems related to geometric and kinematic analysis of planar parallel robotic manipulators (PPRMs). These approaches rely on the use of CAD-based graphical programming enabling rapid resolution and geometric interpretation of the 3D total workspace characteristics. The novelty of the proposed approach resides in the association of an original, unique and natural 3D graphical representation of the end-effector poses and the use of geometric feature handling and graphical solver capabilities within a CAD environment, for determining the 3D total operational workspace as well as solving the forward kinematic problem (FKP) of PPRMs. The approach consists in considering the mobile platform separately attached to each limb that we disconnect from the rest of the mechanism. The geometric construction of the spaces reachable by the end-effector is performed by using Boolean intersections of the vertex volumes, respectively the vertex surfaces, relative to each limb for 3D total workspace determination, respectively for FKP resolution. By combining in the same 3D graphical environment several geometric entities associated to the PPRM, such as workspace volume, singularity surface, and the different solutions of the FKP, this approach allows designers, in a user-friendly way, to generate the singularity-free trajectories connecting different assembly modes. The approach presented in this paper is mostly useful for the architectures of 3-DOF parallel robotic manipulators for which an algebraic closed form solution does not exist for the forward kinematic model and the singularity-free trajectory planning between assembly modes is not a trivial task. It is applied for several PPRMs such as: 3-RPR, 3-RRR, 3-PPR, 3-RRP, 3-PRP, 3-PRR, 3-RRR, and 3-RPR.}
}

@article{awaisIntentionBasedComparative2020,
  title = {Intention Based Comparative Analysis of Human-Robot Interaction},
  author = {Awais, Muhammad and Saeed, Muhammad Yahya and Malik, Muhammad Sheraz Arshad and Younas, Muhammad and Asif, Sohail Rao Iqbal},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {205821--205835},
  issn = {21693536},
  doi = {10.1109/ACCESS.2020.3035201},
  abstract = {Human-robot interaction is inevitable due to the increase of the autonomous intelligent machines in the human vicinity. The autonomous machines should synchronize with the interacting human. The key factor for synchronized Human-Robot Interaction (HRI) is a human intention. The interacting machine must have the clue about the intention of the interacting human for a useful interaction. In this review paper, recently proposed intention-based approaches for human-robot interaction are discussed. The approaches are categorized concerning different aspects, e.g., application area, specialized and generalized estimation techniques, etc. The review categorized the recently proposed approaches into five categories. The categorization is mainly based on the application areas of the intention recognition approaches. The type of approaches includes general and application-specific approaches. The application areas include synchronized physical human-assistance, human-synchronized vehicles, etc. The vehicles are synchronized with the driver and the pedestrian. The study highlighted the currently active as well as the dormant areas of the intention-based human-robot interaction and indicated new directions.},
  keywords = {Intention based bionics,Intention based safe vehicles,Intention based teleoperation,Intention recognition}
}

@article{awaisIntentionBasedComparative2020a,
  title = {Intention Based Comparative Analysis of Human-Robot Interaction},
  author = {Awais, Muhammad and Saeed, Muhammad Yahya and Malik, Muhammad Sheraz Arshad and Younas, Muhammad and Asif, Sohail Rao Iqbal},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {205821--205835},
  issn = {21693536},
  doi = {10.1109/ACCESS.2020.3035201},
  abstract = {Human-robot interaction is inevitable due to the increase of the autonomous intelligent machines in the human vicinity. The autonomous machines should synchronize with the interacting human. The key factor for synchronized Human-Robot Interaction (HRI) is a human intention. The interacting machine must have the clue about the intention of the interacting human for a useful interaction. In this review paper, recently proposed intention-based approaches for human-robot interaction are discussed. The approaches are categorized concerning different aspects, e.g., application area, specialized and generalized estimation techniques, etc. The review categorized the recently proposed approaches into five categories. The categorization is mainly based on the application areas of the intention recognition approaches. The type of approaches includes general and application-specific approaches. The application areas include synchronized physical human-assistance, human-synchronized vehicles, etc. The vehicles are synchronized with the driver and the pedestrian. The study highlighted the currently active as well as the dormant areas of the intention-based human-robot interaction and indicated new directions.},
  keywords = {Intention based bionics,Intention based safe vehicles,Intention based teleoperation,Intention recognition},
  file = {C:\Users\leemar\Zotero\storage\LCZCK7ZB\Intention_Based_Comparative_Analysis_of_Human-Robot_Interaction.pdf}
}

@inproceedings{awaisRuleBasedIntention2012,
  title = {Rule Based Intention Generalization through Human-Robot Interaction},
  booktitle = {7th {{German Conference}} on {{Robotics}}, {{ROBOTIK}} 2012},
  author = {Awais, M. and Henrich, D.},
  date = {2012},
  pages = {199--204},
  abstract = {Humans have the capability of concept generalization. They can generalize an operation specific to an object on different objects present in the scene. In this paper we introduce a novel approach of rule based human intention generalization. The generalization is performed through Human-Robot Interaction (HRI) by inducing the rules online. The online rule induction corresponds to the performed human action on a known object with known characteristics. The novel generalization of an induced rule is performed based on the acceptance, rejection or correction by the human in response to the robot reaction while HRI. A novel method of conflict resolution is also proposed for the generalized rules. The experiments performed for the rule based intention generalization and online rule induction include teaching the robot of a specialized human intention. The robot tries to generalize the taught human intention by applying the actions on the related objects. The robot generalizes the human intention while HRI, based on acceptance, rejection or correction by the human. The intention generalization is performed by embedding the generalized rule into the probabilistic finite state machine. A finite state machine represents a human intention.}
}

@inproceedings{awaisRuleBasedIntention2012a,
  title = {Rule Based Intention Generalization through Human-Robot Interaction},
  booktitle = {7th {{German Conference}} on {{Robotics}}, {{ROBOTIK}} 2012},
  author = {Awais, M. and Henrich, D.},
  date = {2012},
  pages = {199--204},
  abstract = {Humans have the capability of concept generalization. They can generalize an operation specific to an object on different objects present in the scene. In this paper we introduce a novel approach of rule based human intention generalization. The generalization is performed through Human-Robot Interaction (HRI) by inducing the rules online. The online rule induction corresponds to the performed human action on a known object with known characteristics. The novel generalization of an induced rule is performed based on the acceptance, rejection or correction by the human in response to the robot reaction while HRI. A novel method of conflict resolution is also proposed for the generalized rules. The experiments performed for the rule based intention generalization and online rule induction include teaching the robot of a specialized human intention. The robot tries to generalize the taught human intention by applying the actions on the related objects. The robot generalizes the human intention while HRI, based on acceptance, rejection or correction by the human. The intention generalization is performed by embedding the generalized rule into the probabilistic finite state machine. A finite state machine represents a human intention.}
}

@article{azarConstructionEquipmentIdentification2016,
  title = {Construction {{Equipment Identification Using Marker-Based Recognition}} and an {{Active Zoom Camera}}},
  author = {Azar, E. R.},
  date = {2016},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {30},
  number = {3},
  doi = {10.1061/(ASCE)CP.1943-5487.0000507},
  abstract = {Control systems have proven to be beneficial in improving the productivity of earthmoving operations. A main component of these systems is the monitoring module. Computer vision algorithms are among the new methods that have been tested for real-time monitoring of earthwork activities. These methods, however, were able to detect only intraclass equipment and failed to identify individual machines, which is a key disadvantage compared to radio-based devices, namely global positioning systems (GPS). To address this issue, a pipeline framework, consisting of several computer vision algorithms, has been developed to identify individual machines. In this framework, an object detection method is used to locate construction equipment. If a detection view of a target is obtained, the camera zooms on the candidate to identify visual markers attached on the machine. The architecture of this system is optimized by employing time-consuming processes only for the most probable candidates. This system was evaluated using several real-time videos, and demonstrated promising performance in identifying excavators and dump trucks, with 89 and 84\% identification rates and 64.6 and 77.1\% recall rates, respectively. In addition, applying the marker-based verification step proved to be effective in rejecting false alarms as the precision was 100\% in both test cases.}
}

@article{azarConstructionEquipmentIdentification2016a,
  title = {Construction {{Equipment Identification Using Marker-Based Recognition}} and an {{Active Zoom Camera}}},
  author = {Azar, E.R.},
  date = {2016},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {30},
  number = {3},
  doi = {10.1061/(ASCE)CP.1943-5487.0000507},
  abstract = {Control systems have proven to be beneficial in improving the productivity of earthmoving operations. A main component of these systems is the monitoring module. Computer vision algorithms are among the new methods that have been tested for real-time monitoring of earthwork activities. These methods, however, were able to detect only intraclass equipment and failed to identify individual machines, which is a key disadvantage compared to radio-based devices, namely global positioning systems (GPS). To address this issue, a pipeline framework, consisting of several computer vision algorithms, has been developed to identify individual machines. In this framework, an object detection method is used to locate construction equipment. If a detection view of a target is obtained, the camera zooms on the candidate to identify visual markers attached on the machine. The architecture of this system is optimized by employing time-consuming processes only for the most probable candidates. This system was evaluated using several real-time videos, and demonstrated promising performance in identifying excavators and dump trucks, with 89 and 84\% identification rates and 64.6 and 77.1\% recall rates, respectively. In addition, applying the marker-based verification step proved to be effective in rejecting false alarms as the precision was 100\% in both test cases.}
}

@inproceedings{azarVisionbasedRecognitionDirt2012,
  title = {Vision-Based Recognition of Dirt Loading Cycles in Construction Sites},
  booktitle = {Construction {{Research Congress}} 2012: {{Construction Challenges}} in a {{Flat World}}, {{Proceedings}} of the 2012 {{Construction Research Congress}}},
  author = {Azar, E. Rezazadeh and McCabe, B.},
  date = {2012},
  pages = {1042--1051},
  doi = {10.1061/9780784412329.105},
  abstract = {Automated control of production lines in different segments of manufacturing has been advanced due to emergence of sensing devices and the repetitive character of the processes. The construction industry, however, still suffers from inefficiencies in real-time control of activities due to the manual practice of monitoring, and the fragmented and temporary nature of construction projects. Several sensing technologies including computer vision-based systems have been introduced to address this issue on construction sites. Earthmoving projects are one of the most suitable areas to employ vision-based techniques to extract productivity data because it is possible to select clear sightlines and earthmoving equipment are relatively easy to recognize. In addition to challenges of developing efficient object detection and tracking algorithms, activity recognition based on collected data from detection and tracking engines is yet to be tackled. In this paper, a logical framework is introduced that combines object recognition, tracking, and rational events to recognize dirt loading to a dump truck by a hydraulic excavators, and measure the working cycles and idle times of the earthmoving plants. This logical algorithm showed promising performance in which the variations were caused by deficiencies of recognition and tracking engines rather than the activity recognition algorithm. © 2012 ASCE.},
  isbn = {978-0-7844-1232-9}
}

@article{baeVariableAdmittanceControl2020,
  title = {Variable {{Admittance Control}} with {{Virtual Stiffness Guidance}} for {{Human-Robot Collaboration}}},
  author = {Bae, J. and Kim, K. and Huh, J. and Hong, D.},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {117335--117346},
  doi = {10.1109/ACCESS.2020.3004872},
  abstract = {Human-robot collaboration (HRC) is a promising solution for expanding the use of robotic systems in unstructured environments and complex processes in various industries. In this paper, a novel variable admittance control (VAC) with virtual stiffness guidance (VSG) is proposed to improve the performance of HRC. The proposed VAC prevents unnecessary changes of the damping parameter by classifying the human intentions in the low-velocity region, which results in smooth movement. Additionally, the VAC with VSG makes the robot actively assist an operator using a virtual spring. Under the proposed VSG scheme, the equilibrium position of the virtual spring can be adjusted by the operator during a task. The proposed control strategies are implemented in a four-degree-of-freedom hydraulic manipulator referred to as HydCobot. Two experimental tasks for evaluating the accuracy, effort, and elapsed time are conducted to validate the effectiveness of the proposed methods. The results indicate that the proposed methods effectively enhance the performance of HRC.}
}

@article{baeVariableAdmittanceControl2020a,
  title = {Variable {{Admittance Control}} with {{Virtual Stiffness Guidance}} for {{Human-Robot Collaboration}}},
  author = {Bae, J. and Kim, K. and Huh, J. and Hong, D.},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {117335--117346},
  doi = {10.1109/ACCESS.2020.3004872},
  abstract = {Human-robot collaboration (HRC) is a promising solution for expanding the use of robotic systems in unstructured environments and complex processes in various industries. In this paper, a novel variable admittance control (VAC) with virtual stiffness guidance (VSG) is proposed to improve the performance of HRC. The proposed VAC prevents unnecessary changes of the damping parameter by classifying the human intentions in the low-velocity region, which results in smooth movement. Additionally, the VAC with VSG makes the robot actively assist an operator using a virtual spring. Under the proposed VSG scheme, the equilibrium position of the virtual spring can be adjusted by the operator during a task. The proposed control strategies are implemented in a four-degree-of-freedom hydraulic manipulator referred to as HydCobot. Two experimental tasks for evaluating the accuracy, effort, and elapsed time are conducted to validate the effectiveness of the proposed methods. The results indicate that the proposed methods effectively enhance the performance of HRC.}
}

@article{baiModularDesignTeleoperated2017,
  title = {Modular Design of a Teleoperated Robotic Control System for Laparoscopic Minimally Invasive Surgery Based on {{ROS}} \&amp; {{RT-Middleware}}},
  author = {Bai, W. and Cao, Q. and Wang, P. and Chen, P. and Leng, C. and Pan, T.},
  date = {2017},
  journaltitle = {Industrial Robot},
  volume = {44},
  number = {5},
  pages = {596--608},
  doi = {10.1108/IR-12-2016-0351},
  abstract = {Purpose - Robotic systems for laparoscopic minimally invasive surgery (MIS) always end up with highly sophisticated mechanisms and control schemes - making it a long and hard development process with a steep price. This paper aims to propose and realize a new, efficient and convenient strategy for building effective control systems for surgical and even other complex robotic systems. Design/methodology/approach - A novel method that takes advantage of the modularization concept by integrating two middleware technologies (robot operating system and robotic technology middleware) into a common architecture based on the strengths of both was designed and developed. Findings - Tests of the developed control system showed very low time-delay between the master and slave sides; good movement representation on the slave manipulator; and high positional and operational accuracy. Moreover, the new development strategy trial came with much higher efficiency and lower costs. Research limitations/implications - This method results in a modularized and distributed control system that is amenable to collaboratively develop; convenient to modify and update; componentized and easy to extend; mutually independent among subsystems; and practicable to be running and communicating across multiple operating systems. However, experiments show that surgical training and updates of the robotic system are still required to achieve better proficiency for completing complex minimally invasive surgical operations with the proposed and developed system. Originality/value - This research proposed and developed a novel modularization design method and a novel architecture for building a distributed teleoperation control system for laparoscopic MIS.}
}

@article{baiModularDesignTeleoperated2017a,
  title = {Modular Design of a Teleoperated Robotic Control System for Laparoscopic Minimally Invasive Surgery Based on {{ROS}} \&amp; {{RT-Middleware}}},
  author = {Bai, W. and Cao, Q. and Wang, P. and Chen, P. and Leng, C. and Pan, T.},
  date = {2017},
  journaltitle = {Industrial Robot},
  volume = {44},
  number = {5},
  pages = {596--608},
  doi = {10.1108/IR-12-2016-0351},
  abstract = {Purpose - Robotic systems for laparoscopic minimally invasive surgery (MIS) always end up with highly sophisticated mechanisms and control schemes - making it a long and hard development process with a steep price. This paper aims to propose and realize a new, efficient and convenient strategy for building effective control systems for surgical and even other complex robotic systems. Design/methodology/approach - A novel method that takes advantage of the modularization concept by integrating two middleware technologies (robot operating system and robotic technology middleware) into a common architecture based on the strengths of both was designed and developed. Findings - Tests of the developed control system showed very low time-delay between the master and slave sides; good movement representation on the slave manipulator; and high positional and operational accuracy. Moreover, the new development strategy trial came with much higher efficiency and lower costs. Research limitations/implications - This method results in a modularized and distributed control system that is amenable to collaboratively develop; convenient to modify and update; componentized and easy to extend; mutually independent among subsystems; and practicable to be running and communicating across multiple operating systems. However, experiments show that surgical training and updates of the robotic system are still required to achieve better proficiency for completing complex minimally invasive surgical operations with the proposed and developed system. Originality/value - This research proposed and developed a novel modularization design method and a novel architecture for building a distributed teleoperation control system for laparoscopic MIS.}
}

@article{baltruschWhatHumanHuman2022,
  title = {What about the Human in Human Robot Collaboration?: {{A}} Literature Review on {{HRC}}’s Effects on Aspects of Job Quality},
  shorttitle = {What about the Human in Human Robot Collaboration?},
  author = {Baltrusch, S. J. and Krause, F. and De Vries, A. W. and Van Dijk, W. and De Looze, M. P.},
  date = {2022-05-04},
  journaltitle = {Ergonomics},
  shortjournal = {Ergonomics},
  volume = {65},
  number = {5},
  pages = {719--740},
  issn = {0014-0139, 1366-5847},
  doi = {10.1080/00140139.2021.1984585},
  url = {https://www.tandfonline.com/doi/full/10.1080/00140139.2021.1984585},
  urldate = {2023-08-18},
  langid = {english}
}

@misc{banks2005discrete,
  title = {Discrete-Event System Simulationfourth Edition},
  author = {Banks, Jerry and CARSON II, John S and Barry, L and others},
  date = {2005},
  organization = {{Pearson}}
}

@article{bar-sinaiPedagogicalProtocolIterative2020,
  title = {A Pedagogical Protocol for Iterative Robotic Fabrication on Remote Grounds},
  author = {Bar-Sinai, K.L. and Shaked, T. and Sprecher, A.},
  date = {2020},
  journaltitle = {Archnet-IJAR},
  volume = {14},
  number = {3},
  pages = {453--468},
  doi = {10.1108/ARCH-09-2019-0214},
  abstract = {Purpose: The purpose of the paper is to advance remote robotic fabrication through an iterative and pedagogical protocol for shaping architectural grounds. Advancements in autonomous robotic tools enable to reach increasingly larger scales of architectural and landscape construction and operate in remote and inaccessible sites. In parallel, the relation of architecture to its environment is significantly reconsidered, as the building industry's contribution to the environmental stress increases. In response, new practices emerge, addressing the reshaping and modulation of environments using digital tools. The context of extra-terrestrial architecture provides a ground for exploring these issues, as future practice in this domain relies on the use of remote autonomous means for repurposing local matter. As a result, the novelty in robotic construction laboratories is tied to innovation in architectural pedagogy. Design/methodology/approach: This paper puts forth a pedagogical protocol and iterative framework for digital groundscaping using robotic tools. The framework is demonstrated through an intensive workshop led by the authors. To situate the discussion, digital groundscaping is linked to several conditions that characterize practice and relate to pedagogy. These conditions include the experimental dimension of knowledge in digital fabrication, the convergence of knowledge as part of the blur between the fields of architecture and landscape architecture and the bridging of heterogeneous knowledge sets (virtual and physical), which robotic fabrication on natural terrains entails. Findings: The outcomes of the workshop indicate that iterative processes can assist in applying autonomous design protocols on remote grounds. The protocols were assessed in light of the roles of technological tools, design iterations and material agency in the robotic fabrication. Originality/value: The paper concludes with observations linking the iterative protocol to new avenues in architectural pedagogy as means of advancing the capacity to digitally design, modulate and transform natural grounds.}
}

@article{bar-sinaiPedagogicalProtocolIterative2020a,
  title = {A Pedagogical Protocol for Iterative Robotic Fabrication on Remote Grounds},
  author = {Bar-Sinai, K.L. and Shaked, T. and Sprecher, A.},
  date = {2020},
  journaltitle = {Archnet-IJAR},
  volume = {14},
  number = {3},
  pages = {453--468},
  doi = {10.1108/ARCH-09-2019-0214},
  abstract = {Purpose: The purpose of the paper is to advance remote robotic fabrication through an iterative and pedagogical protocol for shaping architectural grounds. Advancements in autonomous robotic tools enable to reach increasingly larger scales of architectural and landscape construction and operate in remote and inaccessible sites. In parallel, the relation of architecture to its environment is significantly reconsidered, as the building industry's contribution to the environmental stress increases. In response, new practices emerge, addressing the reshaping and modulation of environments using digital tools. The context of extra-terrestrial architecture provides a ground for exploring these issues, as future practice in this domain relies on the use of remote autonomous means for repurposing local matter. As a result, the novelty in robotic construction laboratories is tied to innovation in architectural pedagogy. Design/methodology/approach: This paper puts forth a pedagogical protocol and iterative framework for digital groundscaping using robotic tools. The framework is demonstrated through an intensive workshop led by the authors. To situate the discussion, digital groundscaping is linked to several conditions that characterize practice and relate to pedagogy. These conditions include the experimental dimension of knowledge in digital fabrication, the convergence of knowledge as part of the blur between the fields of architecture and landscape architecture and the bridging of heterogeneous knowledge sets (virtual and physical), which robotic fabrication on natural terrains entails. Findings: The outcomes of the workshop indicate that iterative processes can assist in applying autonomous design protocols on remote grounds. The protocols were assessed in light of the roles of technological tools, design iterations and material agency in the robotic fabrication. Originality/value: The paper concludes with observations linking the iterative protocol to new avenues in architectural pedagogy as means of advancing the capacity to digitally design, modulate and transform natural grounds.}
}

@article{bar-sinaiRoboticToolsNative2021,
  title = {Robotic Tools, Native Matter: Workflow and Methods for Geomaterial Reconstitution Using Additive Manufacturing},
  author = {Bar-Sinai, K. L. and Shaked, T. and Sprecher, A.},
  date = {2021},
  journaltitle = {Architectural Science Review},
  issn = {17589622},
  doi = {10.1080/00038628.2021.1898324},
  abstract = {Recent advancements in on-site robotic construction allow a direct modulation of native soil into architecture. To date, this was mainly explored for extra-terrestrial construction. To promote geomaterial reconstitution in architecture, the paper presents a workflow and methods for additive manufacturing, explored using desert soil and a robotic tool. The workflow provides the steps for linking site, material, design, and fabrication, including the robotic setup, simulation, and technical analysis. The paper explores three methods: continuous, discrete, and a method termed here multimode additive. These methods are demonstrated through experiments detailing their design and fabrication processes, and the paper concludes with their comparative analysis. The research expands additive manufacturing with earthen materials, and the outcomes indicate a potential for combining computational design, robotic fabrication, and manual assembly. The paper also clarifies and expands existing terminology regarding part-to-whole relationships in on-site robotic fabrication, promoting resource-conscious, site-tailored additive manufacturing in architecture.},
  keywords = {additive manufacturing,Computational design,earthen construction materials,geomaterial reconstitution,multimode robotic production,robotic fabrication}
}

@article{bar-sinaiRoboticToolsNative2021a,
  title = {Robotic Tools, Native Matter: Workflow and Methods for Geomaterial Reconstitution Using Additive Manufacturing},
  author = {Bar-Sinai, K.L. and Shaked, T. and Sprecher, A.},
  date = {2021},
  journaltitle = {Architectural Science Review},
  doi = {10.1080/00038628.2021.1898324},
  abstract = {Recent advancements in on-site robotic construction allow a direct modulation of native soil into architecture. To date, this was mainly explored for extra-terrestrial construction. To promote geomaterial reconstitution in architecture, the paper presents a workflow and methods for additive manufacturing, explored using desert soil and a robotic tool. The workflow provides the steps for linking site, material, design, and fabrication, including the robotic setup, simulation, and technical analysis. The paper explores three methods: continuous, discrete, and a method termed here multimode additive. These methods are demonstrated through experiments detailing their design and fabrication processes, and the paper concludes with their comparative analysis. The research expands additive manufacturing with earthen materials, and the outcomes indicate a potential for combining computational design, robotic fabrication, and manual assembly. The paper also clarifies and expands existing terminology regarding part-to-whole relationships in on-site robotic fabrication, promoting resource-conscious, site-tailored additive manufacturing in architecture.}
}

@article{barContextualProcessingVisual2002,
  title = {Contextual Processing of Visual Objects in the Brain},
  author = {Bar, M. and Aminoff, E.},
  date = {2002},
  journaltitle = {Journal of Vision},
  volume = {2},
  number = {7},
  doi = {10.1167/2.7.410},
  abstract = {Objects that share the same context tend to appear together in our environment. Is this frequent co-occurrence manifested in the organization of their representation in the brain? Given how little is known about the neuronal analysis of context, the first step in addressing this question is to define the cortical network involved. To elicit maximal contextual activation, we first identified for each of the 40 contexts in the experiment a "key object" that is most commonly associated with that specific context (e.g., a flower for a garden, a hardhat for a construction site). In addition, we identified another set of objects that are not associated with any specific context (e.g., a rope). Average reaction time for recognizing the objects in both sets was equal. We then used fMRI to scan six subjects while they were engaged in recognizing those individual objects (3T magnet; TR=2sec; 33 slices, 3mm each). The cortical activation elicited by highly contextual objects ("key objects") was compared with the cortical activation elicited by "non-contextual" objects. The resulting differential activation concentrated in the temporal cortex, primarily in the collateral sulcus and extended into the parahippocampal gyrus. This focus, which was exceptional in its extent, significance, and consistency across subjects, is suggested to play a central role in the representation and processing of context. What is the specific function associated with this focused activity? One possible explanation is that it reflects the co-activation of multiple objects that share the same context, triggered by the recognition of a "key object." Such contextual representations may include information about typical members of each context as well as the typical spatial relations between those objects (schema or "context frames"). Alternatively, this activation may be a manifestation of semantic and abstract information associated with the specific contexts. We will contrast these accounts.}
}

@article{barContextualProcessingVisual2002a,
  title = {Contextual Processing of Visual Objects in the Brain},
  author = {Bar, M. and Aminoff, E.},
  date = {2002},
  journaltitle = {Journal of Vision},
  volume = {2},
  number = {7},
  doi = {10.1167/2.7.410},
  abstract = {Objects that share the same context tend to appear together in our environment. Is this frequent co-occurrence manifested in the organization of their representation in the brain? Given how little is known about the neuronal analysis of context, the first step in addressing this question is to define the cortical network involved. To elicit maximal contextual activation, we first identified for each of the 40 contexts in the experiment a "key object" that is most commonly associated with that specific context (e.g., a flower for a garden, a hardhat for a construction site). In addition, we identified another set of objects that are not associated with any specific context (e.g., a rope). Average reaction time for recognizing the objects in both sets was equal. We then used fMRI to scan six subjects while they were engaged in recognizing those individual objects (3T magnet; TR=2sec; 33 slices, 3mm each). The cortical activation elicited by highly contextual objects ("key objects") was compared with the cortical activation elicited by "non-contextual" objects. The resulting differential activation concentrated in the temporal cortex, primarily in the collateral sulcus and extended into the parahippocampal gyrus. This focus, which was exceptional in its extent, significance, and consistency across subjects, is suggested to play a central role in the representation and processing of context. What is the specific function associated with this focused activity? One possible explanation is that it reflects the co-activation of multiple objects that share the same context, triggered by the recognition of a "key object." Such contextual representations may include information about typical members of each context as well as the typical spatial relations between those objects (schema or "context frames"). Alternatively, this activation may be a manifestation of semantic and abstract information associated with the specific contexts. We will contrast these accounts.}
}

@book{barrileRealtimeUpdateRoad2019,
  title = {Real-Time Update of the Road Cadastre in {{GIS}} Environment from a {{MMS}} Rudimentary System},
  author = {Barrile, V. and Leonardi, G. and Fotia, A. and Bilotta, G. and Ielo, G.},
  date = {2019},
  journaltitle = {Smart Innovation, Systems and Technologies},
  volume = {101},
  doi = {10.1007/978-3-319-92102-0_26},
  abstract = {The local authorities that are responsible for the management of road infrastructures must have by law a Road Cadastre by realizing one from scratch or updating the existing one. The Italian road network is spread over 160,000 km of state and provincial roads, so in the face of an efficient solution in terms of costs/performance, a rapid timetable is required for the data acquisition and the construction of the system. The elements of the territory represented in the GIS for the management of the Road Cadastre, on the one hand are characterized by the high mutability that affects both their position and the attributes necessary for classification; on the other hand, the integration of the GIS is only possible through a process of continuous and constant updating of the database. This note, taking up the experimental activities presented in [1] concerning the preparation of an MMS for automatic driving, uses only some of the equipment appropriately predisposed (GPS - GIS), integrating them with two low cost cameras. This in order to test a rudimentary MMS for the updating of the Road Cadastre that through the realization and implementation of suitable software allows to obtain appreciable and interesting results in terms of identification acquisition and transposition in real time on GIS system of elements of the territory for the management of the Road Cadastre. In fact, the proposed system allows real-time recognition (via computer vision) of road artefacts (drains, grids) and vertical signs, as well as the subsequent geo-referencing of acquired frames and automatic transposition in GIS environment (thanks to a dedicated software for updating of the Road Cadastre).},
  isbn = {978-3-319-92101-3},
  pagetotal = {240-247}
}

@book{barrileRealtimeUpdateRoad2019a,
  title = {Real-Time Update of the Road Cadastre in {{GIS}} Environment from a {{MMS}} Rudimentary System},
  author = {Barrile, V. and Leonardi, G. and Fotia, A. and Bilotta, G. and Ielo, G.},
  date = {2019},
  journaltitle = {Smart Innovation, Systems and Technologies},
  volume = {101},
  doi = {10.1007/978-3-319-92102-0_26},
  abstract = {The local authorities that are responsible for the management of road infrastructures must have by law a Road Cadastre by realizing one from scratch or updating the existing one. The Italian road network is spread over 160,000 km of state and provincial roads, so in the face of an efficient solution in terms of costs/performance, a rapid timetable is required for the data acquisition and the construction of the system. The elements of the territory represented in the GIS for the management of the Road Cadastre, on the one hand are characterized by the high mutability that affects both their position and the attributes necessary for classification; on the other hand, the integration of the GIS is only possible through a process of continuous and constant updating of the database. This note, taking up the experimental activities presented in [1] concerning the preparation of an MMS for automatic driving, uses only some of the equipment appropriately predisposed (GPS - GIS), integrating them with two low cost cameras. This in order to test a rudimentary MMS for the updating of the Road Cadastre that through the realization and implementation of suitable software allows to obtain appreciable and interesting results in terms of identification acquisition and transposition in real time on GIS system of elements of the territory for the management of the Road Cadastre. In fact, the proposed system allows real-time recognition (via computer vision) of road artefacts (drains, grids) and vertical signs, as well as the subsequent geo-referencing of acquired frames and automatic transposition in GIS environment (thanks to a dedicated software for updating of the Road Cadastre).},
  isbn = {978-3-319-92101-3},
  pagetotal = {240-247}
}

@book{bassierImplementationScantoBIMFEM2016,
  title = {Implementation of Scan-to-{{BIM}} and {{FEM}} for the Documentation and Analysis of Heritage Timber Roof Structures},
  author = {Bassier, M. and Hadjidemetriou, G. and Vergauwen, M. and Van Roy, N. and Verstrynge, E.},
  date = {2016},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {10058 LNCS},
  doi = {10.1007/978-3-319-48496-9_7},
  abstract = {Current heritage analysis applications and documentation techniques for timber roof structures rely on manual measurements to provide the spatial data. Major simplifications are made to document these structures efficiently. However, these simplified geometric models provide less reliable results. Therefore, the need exists for more realistic models. Additionally, the exchangeability of information between varying parties is paramount. Hence, the construction elements should be defined in a Building Information Model (BIM). This allows users to reuse the model, allowing the distribution of information throughout the project. The goal of our research is to create a realistic BIM model of a complex heritage roof structure employing dense point clouds. The comparison of our complex geometric model to a traditional wire-frame model proves that our approach provides more reliable results in terms of geometry and structural behaviour. Our work covers the acquisition, the modelling and the structural analysis of timber roof structures.},
  isbn = {978-3-319-48495-2},
  pagetotal = {79-90},
  file = {C:\Users\leemar\Zotero\storage\AG5WCBMH\Implementation-of-scantoBIM-and-FEM-for-the-documentation-and-analysis-of-heritage-timber-roof-structuresLecture-Notes-in-Computer-Science-including-subseries-Lecture-Notes-in-Artificial-Intelligence-and-Le.pdf}
}

@book{bassierImplementationScantoBIMFEM2016a,
  title = {Implementation of Scan-to-{{BIM}} and {{FEM}} for the Documentation and Analysis of Heritage Timber Roof Structures},
  author = {Bassier, M. and Hadjidemetriou, G. and Vergauwen, M. and Van Roy, N. and Verstrynge, E.},
  date = {2016},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {10058 LNCS},
  doi = {10.1007/978-3-319-48496-9_7},
  abstract = {Current heritage analysis applications and documentation techniques for timber roof structures rely on manual measurements to provide the spatial data. Major simplifications are made to document these structures efficiently. However, these simplified geometric models provide less reliable results. Therefore, the need exists for more realistic models. Additionally, the exchangeability of information between varying parties is paramount. Hence, the construction elements should be defined in a Building Information Model (BIM). This allows users to reuse the model, allowing the distribution of information throughout the project. The goal of our research is to create a realistic BIM model of a complex heritage roof structure employing dense point clouds. The comparison of our complex geometric model to a traditional wire-frame model proves that our approach provides more reliable results in terms of geometry and structural behaviour. Our work covers the acquisition, the modelling and the structural analysis of timber roof structures.},
  isbn = {978-3-319-48495-2},
  pagetotal = {79-90},
  file = {C:\Users\leemar\Zotero\storage\IQUABBR4\Implementation-of-scantoBIM-and-FEM-for-the-documentation-and-analysis-of-heritage-timber-roof-structuresLecture-Notes-in-Computer-Science-including-subseries-Lecture-Notes-in-Artificial-Intelligence-and-Le.pdf}
}

@article{bedkowskiTerrestrial3DData2014,
  title = {Towards Terrestrial {{3D}} Data Registration Improved by Parallel Programming and Evaluated with Geodetic Precision},
  author = {Bȩdkowski, J. and Majek, K. and Musialik, P. and Adamek, A. and Andrzejewski, D. and Czekaj, D.},
  date = {2014},
  journaltitle = {Automation in Construction},
  volume = {47},
  pages = {78--91},
  doi = {10.1016/j.autcon.2014.07.013},
  abstract = {In this paper a quantitative and qualitative evaluation of proposed ICP-based data registration algorithm, improved by parallel programming in CUDA (compute unified device architecture), is shown. The algorithm was tested on data collected with a 3D terrestrial laser scanner Z + F Imager 5010 mounted on the mobile platform PIONNER 3AT. Parallel implementation enables data registration on-line, even using a laptop with a standard hardware configuration (graphic card NVIDIA GeForce 6XX/7XX series). Robustness is assured by the use of CUDA-enhanced fast NNS (nearest neighbor search) applied for ICP (iterative closest point) with SVD (singular value decomposition) solver. The evaluation is based on the reference ground truth data registered with geodetic precision. The geodetic approach extends our previous work and gives an accurate benchmark for the algorithm. The data were collected in an urban area under a demolition scenario in a real environment. We compared four registration strategies concerning data preprocessing, such as subsampling and vegetation removal. The result is the analysis of measured performance and the accuracy of the geometric maps. The system provides accurate metric maps on-line and can be used in several applications such as mobile robotics for construction area modelling or spatial design support. It is a core component for our future work on mobile mapping systems. © 2014 Elsevier B.V.}
}

@article{bedkowskiTerrestrial3DData2014a,
  title = {Towards Terrestrial {{3D}} Data Registration Improved by Parallel Programming and Evaluated with Geodetic Precision},
  author = {Bȩdkowski, J. and Majek, K. and Musialik, P. and Adamek, A. and Andrzejewski, D. and Czekaj, D.},
  date = {2014},
  journaltitle = {Automation in Construction},
  volume = {47},
  pages = {78--91},
  doi = {10.1016/j.autcon.2014.07.013},
  abstract = {In this paper a quantitative and qualitative evaluation of proposed ICP-based data registration algorithm, improved by parallel programming in CUDA (compute unified device architecture), is shown. The algorithm was tested on data collected with a 3D terrestrial laser scanner Z + F Imager 5010 mounted on the mobile platform PIONNER 3AT. Parallel implementation enables data registration on-line, even using a laptop with a standard hardware configuration (graphic card NVIDIA GeForce 6XX/7XX series). Robustness is assured by the use of CUDA-enhanced fast NNS (nearest neighbor search) applied for ICP (iterative closest point) with SVD (singular value decomposition) solver. The evaluation is based on the reference ground truth data registered with geodetic precision. The geodetic approach extends our previous work and gives an accurate benchmark for the algorithm. The data were collected in an urban area under a demolition scenario in a real environment. We compared four registration strategies concerning data preprocessing, such as subsampling and vegetation removal. The result is the analysis of measured performance and the accuracy of the geometric maps. The system provides accurate metric maps on-line and can be used in several applications such as mobile robotics for construction area modelling or spatial design support. It is a core component for our future work on mobile mapping systems. © 2014 Elsevier B.V.}
}

@inproceedings{BenAmor20142831,
  title = {Interaction Primitives for Human-Robot Cooperation Tasks},
  author = {Ben Amor, H. and Neumann, G. and Kamthe, S. and Kroemer, O. and Peters, J.},
  date = {2014},
  series = {Proceedings - {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  pages = {2831--2837},
  doi = {10.1109/ICRA.2014.6907265},
  art_number = {6907265}
}

@book{bentoSeismicAssessmentPombalino2016,
  title = {Seismic Assessment of Pombalino {{Buildings}}},
  author = {Bento, R. and Falcão, A.P. and Catulo, R. and Milosevic, J.},
  date = {2016},
  journaltitle = {Lecture Notes in Civil Engineering},
  volume = {1},
  doi = {10.1007/978-3-319-39492-3_14},
  abstract = {Portuguese Pombalino masonry buildings were built mainly in Lisbon after the 1755s Lisbon Earthquake. These buildings are characterized by a mixed timber-masonry structure, known as the gaiola pombalina (cage), and were built aiming to withstand the horizontal seismic loads. The cage is composed of timber floors and improved mixed timber-masonry shear walls (“frontal” walls). It was arguably the first case in history of an entire town built with the purpose of providing seismic resistance to its buildings. In this paper, a description of the Pombalino buildings is presented, GIS mapping tool was developed to identify the main features of Pombalino buildings in Lisbon downtown area and the results of the seismic assessment of existing building are briefly discussed. A three-dimensional model was developed in Tremuri program based on the equivalent frame model approach. The building was modelled using non-linear beams for masonry panels. The “frontal” walls were modelled by a macro-element model developed and calibrated according to an experimental campaign. The seismic assessment of the global response of the building was determined through non-linear static (pushover) analyses. Due to the fact that building does not fulfil the safety requirements for the ultimate limit state, a strengthening solution was proposed in order to improve the seismic behavior of the building.},
  pagetotal = {171-181},
  file = {C:\Users\leemar\Zotero\storage\6QHCZELM\Seismic-assessment-of-pombalino-BuildingsLecture-Notes-in-Civil-Engineering.pdf}
}

@book{bentoSeismicAssessmentPombalino2016a,
  title = {Seismic Assessment of Pombalino {{Buildings}}},
  author = {Bento, R. and Falcão, A.P. and Catulo, R. and Milosevic, J.},
  date = {2016},
  journaltitle = {Lecture Notes in Civil Engineering},
  volume = {1},
  doi = {10.1007/978-3-319-39492-3_14},
  abstract = {Portuguese Pombalino masonry buildings were built mainly in Lisbon after the 1755s Lisbon Earthquake. These buildings are characterized by a mixed timber-masonry structure, known as the gaiola pombalina (cage), and were built aiming to withstand the horizontal seismic loads. The cage is composed of timber floors and improved mixed timber-masonry shear walls (“frontal” walls). It was arguably the first case in history of an entire town built with the purpose of providing seismic resistance to its buildings. In this paper, a description of the Pombalino buildings is presented, GIS mapping tool was developed to identify the main features of Pombalino buildings in Lisbon downtown area and the results of the seismic assessment of existing building are briefly discussed. A three-dimensional model was developed in Tremuri program based on the equivalent frame model approach. The building was modelled using non-linear beams for masonry panels. The “frontal” walls were modelled by a macro-element model developed and calibrated according to an experimental campaign. The seismic assessment of the global response of the building was determined through non-linear static (pushover) analyses. Due to the fact that building does not fulfil the safety requirements for the ultimate limit state, a strengthening solution was proposed in order to improve the seismic behavior of the building.},
  pagetotal = {171-181},
  file = {C:\Users\leemar\Zotero\storage\QJBKEWFM\Seismic-assessment-of-pombalino-BuildingsLecture-Notes-in-Civil-Engineering.pdf}
}

@article{bernardetIqrToolConstruction2010,
  title = {Iqr: {{A}} Tool for the Construction of Multi-Level Simulations of Brain and Behaviour},
  author = {Bernardet, U. and Verschure, P.F.M.J.},
  date = {2010},
  journaltitle = {Neuroinformatics},
  volume = {8},
  number = {2},
  pages = {113--134},
  doi = {10.1007/s12021-010-9069-7},
  abstract = {The brain is the most complex system we know of. Despite the wealth of data available in neuroscience, our understanding of this system is still very limited. Here we argue that an essential component in our arsenal of methods to advance our understanding of the brain is the construction of artificial brain-like systems. In this way we can encompass the multi-level organisation of the brain and its role in the context of the complete embodied real-world and real-time perceiving and behaving system. Hence, on the one hand, we must be able to develop and validate theories of brains as closing the loop between perception and action, and on the other hand as interacting with the real world. Evidence is growing that one of the sources of the computational power of neuronal systems lies in the massive and specific connectivity, rather than the complexity of single elements. To meet these challenges - multiple levels of organisation, sophisticated connectivity, and the interaction of neuronal models with the real-world - we have developed a multi-level neuronal simulation environment, iqr. This framework deals with these requirements by directly transforming them into the core elements of the simulation environment itself. iqr provides a means to design complex neuronal models graphically, and to visualise and analyse their properties on-line. In iqr connectivity is defined in a flexible, yet compact way, and simulations run at a high speed, which allows the control of real-world devices - robots in the broader sense - in real-time. The architecture of iqr is modular, providing the possibility to write new neuron, and synapse types, and custom interfaces to other hardware systems. The code of iqr is publicly accessible under the GNU General Public License (GPL). iqr has been in use since 1996 and has been the core tool for a large number of studies ranging from detailed models of neuronal systems like the cerebral cortex, and the cerebellum, to robot based models of perception, cognition and action to large-scale real-world systems. In addition, iqr has been widely used over many years to introduce students to neuronal simulation and neuromorphic control. In this paper we outline the conceptual and methodological background of iqr and its design philosophy. Thereafter we present iqr's main features and computational properties. Finally, we describe a number of projects using iqr, singling out how iqr is used for building a "synthetic insect".}
}

@article{bernardetIqrToolConstruction2010a,
  title = {Iqr: {{A}} Tool for the Construction of Multi-Level Simulations of Brain and Behaviour},
  author = {Bernardet, U. and Verschure, P.F.M.J.},
  date = {2010},
  journaltitle = {Neuroinformatics},
  volume = {8},
  number = {2},
  pages = {113--134},
  doi = {10.1007/s12021-010-9069-7},
  abstract = {The brain is the most complex system we know of. Despite the wealth of data available in neuroscience, our understanding of this system is still very limited. Here we argue that an essential component in our arsenal of methods to advance our understanding of the brain is the construction of artificial brain-like systems. In this way we can encompass the multi-level organisation of the brain and its role in the context of the complete embodied real-world and real-time perceiving and behaving system. Hence, on the one hand, we must be able to develop and validate theories of brains as closing the loop between perception and action, and on the other hand as interacting with the real world. Evidence is growing that one of the sources of the computational power of neuronal systems lies in the massive and specific connectivity, rather than the complexity of single elements. To meet these challenges - multiple levels of organisation, sophisticated connectivity, and the interaction of neuronal models with the real-world - we have developed a multi-level neuronal simulation environment, iqr. This framework deals with these requirements by directly transforming them into the core elements of the simulation environment itself. iqr provides a means to design complex neuronal models graphically, and to visualise and analyse their properties on-line. In iqr connectivity is defined in a flexible, yet compact way, and simulations run at a high speed, which allows the control of real-world devices - robots in the broader sense - in real-time. The architecture of iqr is modular, providing the possibility to write new neuron, and synapse types, and custom interfaces to other hardware systems. The code of iqr is publicly accessible under the GNU General Public License (GPL). iqr has been in use since 1996 and has been the core tool for a large number of studies ranging from detailed models of neuronal systems like the cerebral cortex, and the cerebellum, to robot based models of perception, cognition and action to large-scale real-world systems. In addition, iqr has been widely used over many years to introduce students to neuronal simulation and neuromorphic control. In this paper we outline the conceptual and methodological background of iqr and its design philosophy. Thereafter we present iqr's main features and computational properties. Finally, we describe a number of projects using iqr, singling out how iqr is used for building a "synthetic insect".}
}

@article{bernsteinDistractionsDisruptionsTechnical2020,
  title = {The {{Distractions}} of {{Disruptions}}: {{Technical Supply}} in an {{Era}} of {{Social Demand}}},
  author = {Bernstein, P.},
  date = {2020},
  journaltitle = {Architectural Design},
  volume = {90},
  number = {2},
  pages = {82--87},
  doi = {10.1002/ad.2550},
  abstract = {Architect and Associate Dean at the Yale School of Architecture, Phil Bernstein sees a tsunami of change brewing for the architectural profession, conditioned by artificial intelligence, big data, the ubiquitous cloud and robotics. Yet the delivery and procurement of buildings is often inhibited by pre-digital structures of the construction industry. He argues that architects need to rethink their processes from first principles.}
}

@article{bernsteinDistractionsDisruptionsTechnical2020a,
  title = {The {{Distractions}} of {{Disruptions}}: {{Technical Supply}} in an {{Era}} of {{Social Demand}}},
  author = {Bernstein, P.},
  date = {2020},
  journaltitle = {Architectural Design},
  volume = {90},
  number = {2},
  pages = {82--87},
  doi = {10.1002/ad.2550},
  abstract = {Architect and Associate Dean at the Yale School of Architecture, Phil Bernstein sees a tsunami of change brewing for the architectural profession, conditioned by artificial intelligence, big data, the ubiquitous cloud and robotics. Yet the delivery and procurement of buildings is often inhibited by pre-digital structures of the construction industry. He argues that architects need to rethink their processes from first principles.}
}

@article{betancur-vasquezOpenSourceOpen2021,
  title = {Open Source and Open Hardware Mobile Robot for Developing Applications in Education and Research},
  author = {Betancur-Vásquez, D. and Mejia-Herrera, M. and Botero-Valencia, J.S.},
  date = {2021},
  journaltitle = {HardwareX},
  volume = {10},
  doi = {10.1016/j.ohx.2021.e00217},
  abstract = {Nowadays, additive manufacturing, rapid prototyping and assembly modules represent a market that has invaded the entire world, especially in developing countries where traditional manufacturing is more restricted. In robotics, it is pertinent to think that modular construction is essential, due to the complexity of geometry in each of the pieces and their manufacture. Taking into account the globalization of information and the worldwide reproduction of databases, facilitating access to CAD files to be reproduced in 3D printing promotes the easy construction of archived mechanical designs. A robotic architecture becomes a complex assembly by having multiple operating systems. The sensorics, mechanics, electronics and programming that it requires for navigation, collaboration, development, operation and even industrial manufacturing means that more and more elaborate embedded systems are used. In this work, a mobile robotics architecture was developed with a sensory system that allows free movement and navigation in closed loop inverse kinematics. This kind of robot uses navigation algorithms to take a trajectory in collaborative closed environments, that is, closed industrial environments where obstacles are normally immovable and corridors to move narrow, in addition to having mobile obstacles like humans.}
}

@article{betancur-vasquezOpenSourceOpen2021a,
  title = {Open Source and Open Hardware Mobile Robot for Developing Applications in Education and Research},
  author = {Betancur-Vásquez, D. and Mejia-Herrera, M. and Botero-Valencia, J.S.},
  date = {2021},
  journaltitle = {HardwareX},
  volume = {10},
  doi = {10.1016/j.ohx.2021.e00217},
  abstract = {Nowadays, additive manufacturing, rapid prototyping and assembly modules represent a market that has invaded the entire world, especially in developing countries where traditional manufacturing is more restricted. In robotics, it is pertinent to think that modular construction is essential, due to the complexity of geometry in each of the pieces and their manufacture. Taking into account the globalization of information and the worldwide reproduction of databases, facilitating access to CAD files to be reproduced in 3D printing promotes the easy construction of archived mechanical designs. A robotic architecture becomes a complex assembly by having multiple operating systems. The sensorics, mechanics, electronics and programming that it requires for navigation, collaboration, development, operation and even industrial manufacturing means that more and more elaborate embedded systems are used. In this work, a mobile robotics architecture was developed with a sensory system that allows free movement and navigation in closed loop inverse kinematics. This kind of robot uses navigation algorithms to take a trajectory in collaborative closed environments, that is, closed industrial environments where obstacles are normally immovable and corridors to move narrow, in addition to having mobile obstacles like humans.}
}

@article{bhokareSMARTCONSTRUCTIONSCHEDULING2022,
  title = {{{SMART CONSTRUCTION SCHEDULING MONITORING USING YOLOV3-BASED ACTIVITY DETECTION AND CLASSIFICATION}}},
  author = {Bhokare, S. and Goyal, L. and Ren, R. and Zhang, J.},
  date = {2022},
  journaltitle = {Journal of Information Technology in Construction},
  volume = {27},
  pages = {240--252},
  doi = {10.36680/j.itcon.2022.012},
  abstract = {SUMMARY: Increasing efficiency and adhering to a schedule are prominent issues faced by many construction projects. Identifying areas where productivity is low would automatically be a helpful tool for managers. This research aims to analyze and compare the efficiency and accuracy of different computer-vision based activity recognition algorithms that are used on construction sites. The authors then propose a method which involves the use of YOLOv3 to perform activity recognition on construction sites and compare the accuracy of our method to existing algorithms. The algorithms for comparison are selected on the basis that: (1) they incorporate various state-of-the-art activity recognition techniques, such as bounding-box predictions and skeleton-models; and (2) they are relatively recent implementations. The authors trained the model using a data-base consisting of 4 activities with frames from 20 videos for each. The dataset was created by extracting frames from the videos and labelling the activities that are taking place in each video. The authors then use the aforementioned activity classification method to propose a smart schedule monitoring system that automatically updates start and finish times of individual activity conducted in a construction project based on the activities that are detected. This computer-vision based approach to provide automatic and real-time updates to the construction schedule is expected to improve worker productivity and shorten construction project timelines.}
}

@article{bhokareSMARTCONSTRUCTIONSCHEDULING2022a,
  title = {{{SMART CONSTRUCTION SCHEDULING MONITORING USING YOLOV3-BASED ACTIVITY DETECTION AND CLASSIFICATION}}},
  author = {Bhokare, S. and Goyal, L. and Ren, R. and Zhang, J.},
  date = {2022},
  journaltitle = {Journal of Information Technology in Construction},
  volume = {27},
  pages = {240--252},
  doi = {10.36680/j.itcon.2022.012},
  abstract = {SUMMARY: Increasing efficiency and adhering to a schedule are prominent issues faced by many construction projects. Identifying areas where productivity is low would automatically be a helpful tool for managers. This research aims to analyze and compare the efficiency and accuracy of different computer-vision based activity recognition algorithms that are used on construction sites. The authors then propose a method which involves the use of YOLOv3 to perform activity recognition on construction sites and compare the accuracy of our method to existing algorithms. The algorithms for comparison are selected on the basis that: (1) they incorporate various state-of-the-art activity recognition techniques, such as bounding-box predictions and skeleton-models; and (2) they are relatively recent implementations. The authors trained the model using a data-base consisting of 4 activities with frames from 20 videos for each. The dataset was created by extracting frames from the videos and labelling the activities that are taking place in each video. The authors then use the aforementioned activity classification method to propose a smart schedule monitoring system that automatically updates start and finish times of individual activity conducted in a construction project based on the activities that are detected. This computer-vision based approach to provide automatic and real-time updates to the construction schedule is expected to improve worker productivity and shorten construction project timelines.}
}

@article{bianconiAutomatedDesignModeling2019,
  title = {Automated Design and Modeling for Mass-Customized Housing. {{A}} Web-Based Design Space Catalog for Timber Structures},
  author = {Bianconi, F. and Filippucci, M. and Buffi, A.},
  date = {2019},
  journaltitle = {Automation in Construction},
  volume = {103},
  pages = {13--25},
  doi = {10.1016/j.autcon.2019.03.002},
  abstract = {The research proposes a model for mass-customized housing in the emerging context of Industry 4.0 promoted by the European Union as a mean for technological and industrial innovation. With the aim to develop a cross-laminated timber (CLT) model for the Architecture, Engineering, and Construction (AEC) industry, the study deepens the possibility of using generative models and evolutionary principles to inform the customization process in the early stage of design. By trying to bring the latest innovation in the field of computer science and information technology to customers who typically are not proficient with algorithmic design and computation, the research builds up an intuitive interface that allows customers to explore different design solutions. Related to the scale of a single-family house, this model is intended to be used as a decision support system for the design of residential and emergency homes in central Italy.},
  file = {C:\Users\leemar\Zotero\storage\MMHIPAJL\Automated-design-and-modeling-for-masscustomized-housing-A-webbased-design-space-catalog-for-timber-structuresAutomation-in-Construction.pdf}
}

@article{bianconiAutomatedDesignModeling2019a,
  title = {Automated Design and Modeling for Mass-Customized Housing. {{A}} Web-Based Design Space Catalog for Timber Structures},
  author = {Bianconi, F. and Filippucci, M. and Buffi, A.},
  date = {2019},
  journaltitle = {Automation in Construction},
  volume = {103},
  pages = {13--25},
  doi = {10.1016/j.autcon.2019.03.002},
  abstract = {The research proposes a model for mass-customized housing in the emerging context of Industry 4.0 promoted by the European Union as a mean for technological and industrial innovation. With the aim to develop a cross-laminated timber (CLT) model for the Architecture, Engineering, and Construction (AEC) industry, the study deepens the possibility of using generative models and evolutionary principles to inform the customization process in the early stage of design. By trying to bring the latest innovation in the field of computer science and information technology to customers who typically are not proficient with algorithmic design and computation, the research builds up an intuitive interface that allows customers to explore different design solutions. Related to the scale of a single-family house, this model is intended to be used as a decision support system for the design of residential and emergency homes in central Italy.},
  file = {C:\Users\leemar\Zotero\storage\KUMAUTJZ\Automated-design-and-modeling-for-masscustomized-housing-A-webbased-design-space-catalog-for-timber-structuresAutomation-in-Construction.pdf}
}

@book{biggsNonhumanIntentionMeaningmaking2019,
  title = {Non-Human Intention and Meaning-Making: {{An}} Ecological Theory},
  author = {Biggs, M. A. R.},
  date = {2019},
  journaltitle = {Intelligent Systems, Control and Automation: Science and Engineering},
  volume = {94},
  doi = {10.1007/978-3-319-97550-4_12},
  abstract = {Social robots have the potential to problematize many attributes that have previously been considered, in philosophical discourse, to be unique to human beings. Thus, if one construes the explicit programming of robots as constituting specific objectives and the overall design and structure of AI as having aims, in the sense of embedded directives, one might conclude that social robots are motivated to fulfil these objectives, and therefore act intentionally towards fulfilling those goals. The purpose of this paper is to consider the impact of this description of social robotics on traditional notions of intention and meaning-making, and, in particular, to link meaning-making to a social ecology that is being impacted by the presence of social robots. To the extent that intelligent non-human agents are occupying our world alongside us, this paper suggests that there is no benefit in differentiating them from human agents because they are actively changing the context that we share with them, and therefore influencing our meaning-making like any other agent. This is not suggested as some kind of Turing Test, in which we can no longer differentiate between humans and robots, but rather to observe that the argument in which human agency is defined in terms of free will, motivation, and intention can equally be used as a description of the agency of social robots. Furthermore, all of this occurs within a shared context in which the actions of the human impinge upon the non-human, and vice versa, thereby problematising Anscombe’s classic account of intention.},
  pagetotal = {195-204}
}

@book{biggsNonhumanIntentionMeaningmaking2019a,
  title = {Non-Human Intention and Meaning-Making: {{An}} Ecological Theory},
  author = {Biggs, M.A.R.},
  date = {2019},
  journaltitle = {Intelligent Systems, Control and Automation: Science and Engineering},
  volume = {94},
  doi = {10.1007/978-3-319-97550-4_12},
  abstract = {Social robots have the potential to problematize many attributes that have previously been considered, in philosophical discourse, to be unique to human beings. Thus, if one construes the explicit programming of robots as constituting specific objectives and the overall design and structure of AI as having aims, in the sense of embedded directives, one might conclude that social robots are motivated to fulfil these objectives, and therefore act intentionally towards fulfilling those goals. The purpose of this paper is to consider the impact of this description of social robotics on traditional notions of intention and meaning-making, and, in particular, to link meaning-making to a social ecology that is being impacted by the presence of social robots. To the extent that intelligent non-human agents are occupying our world alongside us, this paper suggests that there is no benefit in differentiating them from human agents because they are actively changing the context that we share with them, and therefore influencing our meaning-making like any other agent. This is not suggested as some kind of Turing Test, in which we can no longer differentiate between humans and robots, but rather to observe that the argument in which human agency is defined in terms of free will, motivation, and intention can equally be used as a description of the agency of social robots. Furthermore, all of this occurs within a shared context in which the actions of the human impinge upon the non-human, and vice versa, thereby problematising Anscombe’s classic account of intention.},
  pagetotal = {195-204}
}

@inproceedings{biParametricModelingCost2018,
  title = {Parametric Modeling and Cost Management of {{Chinese Ancient Buildings}} Based on {{BIM}}},
  booktitle = {Conference {{Proceedings}} of the 6th {{International Symposium}} on {{Project Management}}, {{ISPM}} 2018},
  author = {Bi, J. and Li, J.},
  date = {2018},
  pages = {1116--1122},
  abstract = {Unlike the reinforced concrete structure, the timber structure of Chinese Ancient Buildings, which has diverse types of components, is rather complex. Thus, the modeling of Chinese Ancient Buildings is difficult, which leads to the facts that the cost management for Chinese Ancient Buildings preservation project still depends on manual calculation. As a representative Building Information Modeling software, Revit has powerful spatial modeling ability. Therefore, the paper attempt to use Revit assisted by Dynamo to build the Parametric Model of Chinese Ancient Buildings and introduce a way of the cost management for Chinese Ancient Buildings preservation project based on the model.},
  isbn = {978-1-921712-66-1}
}

@inproceedings{biParametricModelingCost2018a,
  title = {Parametric Modeling and Cost Management of {{Chinese Ancient Buildings}} Based on {{BIM}}},
  booktitle = {Conference {{Proceedings}} of the 6th {{International Symposium}} on {{Project Management}}, {{ISPM}} 2018},
  author = {Bi, J. and Li, J.},
  date = {2018},
  pages = {1116--1122},
  abstract = {Unlike the reinforced concrete structure, the timber structure of Chinese Ancient Buildings, which has diverse types of components, is rather complex. Thus, the modeling of Chinese Ancient Buildings is difficult, which leads to the facts that the cost management for Chinese Ancient Buildings preservation project still depends on manual calculation. As a representative Building Information Modeling software, Revit has powerful spatial modeling ability. Therefore, the paper attempt to use Revit assisted by Dynamo to build the Parametric Model of Chinese Ancient Buildings and introduce a way of the cost management for Chinese Ancient Buildings preservation project based on the model.},
  isbn = {978-1-921712-66-1}
}

@article{bonwetschRoboticAssemblyProcesses2012,
  title = {Robotic {{Assembly Processes}} as a {{Driver}} in {{Architectural Design}}},
  author = {Bonwetsch, T.},
  date = {2012},
  journaltitle = {Nexus Network Journal},
  volume = {14},
  number = {3},
  pages = {483--494},
  doi = {10.1007/s00004-012-0119-3},
  abstract = {Over the last couple of years industrial robots have increasingly gained the interest of architects and designers. Robotics in architecture and construction has mainly been looked at from an engineering perspective during the latter half of the twentieth century, with the main purpose of automating the building process. Today the focus has turned towards realizing non-standardized designs and developing custom fabrication processes. However, the specific characteristics of the robot, which distinguish it from common computer numerically controlled machines, are often overlooked. Industrial robots are universal fabrication machines that lend themselves especially well to assembly tasks. Applied to architecture this resolves to the ability to control and manipulate the building process. As such, applying industrial robots emphasizes construction as an integral part of architectural design. Moreover, designing and manipulating robotic assembly processes can become a driver in architectural design. The potential of such an approach is discussed on the basis of several design experiments that illustrate that by applying such methods, form is not derived from computation or geometry, but from a physical process. © 2012 Kim Williams Books, Turin.}
}

@article{bonwetschRoboticAssemblyProcesses2012a,
  title = {Robotic {{Assembly Processes}} as a {{Driver}} in {{Architectural Design}}},
  author = {Bonwetsch, T.},
  date = {2012},
  journaltitle = {Nexus Network Journal},
  volume = {14},
  number = {3},
  pages = {483--494},
  doi = {10.1007/s00004-012-0119-3},
  abstract = {Over the last couple of years industrial robots have increasingly gained the interest of architects and designers. Robotics in architecture and construction has mainly been looked at from an engineering perspective during the latter half of the twentieth century, with the main purpose of automating the building process. Today the focus has turned towards realizing non-standardized designs and developing custom fabrication processes. However, the specific characteristics of the robot, which distinguish it from common computer numerically controlled machines, are often overlooked. Industrial robots are universal fabrication machines that lend themselves especially well to assembly tasks. Applied to architecture this resolves to the ability to control and manipulate the building process. As such, applying industrial robots emphasizes construction as an integral part of architectural design. Moreover, designing and manipulating robotic assembly processes can become a driver in architectural design. The potential of such an approach is discussed on the basis of several design experiments that illustrate that by applying such methods, form is not derived from computation or geometry, but from a physical process. © 2012 Kim Williams Books, Turin.}
}

@article{boxerbaumDesignSimulationFabrication2012,
  title = {Design, Simulation, Fabrication and Testing of a Bio-Inspired Amphibious Robot with Multiple Modes of Mobility},
  author = {Boxerbaum, A.S. and Klein, M.A. and Kline, J.E. and Burgess, S.C. and Quinn, R.D. and Harkins, R. and Vaidyanathan, R.},
  date = {2012},
  journaltitle = {Journal of Robotics and Mechatronics},
  volume = {24},
  number = {4},
  pages = {629--641},
  doi = {10.20965/jrm.2012.p0629},
  abstract = {Surf-zone environments represent an extreme challenges to robot operation. A robot that autonomously navigates rocky terrain, constantly changing underwater currents, hard-packed moist sand and loose dry sand characterizing this environment, would have significant utility in a range of defence and civilian missions. The study of animal locomotion mechanisms can elucidate specific movement principles that can be applied to address these demands. In this work, we report on the design and optimization of a biologically inspired amphibious robot for deployment and operation in an ocean beach environment. We specifically report a new design fusing a range of insectinspired passive mechanisms with active autonomous control architectures to seamlessly adapt to and traverse a range of challenging substrates both in and out of the water, and the design and construction of SeaDog, a proof-of-concept amphibious robot built for navigating rocky or sandy beaches and turbulent surf zones. The robot incorporates a layered hull and chassis design that is integrated into a waterproof Explorer Case in order to provide a large, protected payload in an easy-to-carry package. It employs a rugged drivetrain with four wheel-legs and a unique tail design and actuation strategy to aid in climbing, swimming and stabilization. Several modes of terrestrial and aquatic locomotion are suggested and tested versus range of mobility metrics, including data obtained in simulation and hardware testing. A waterproofing strategy is also tested and discussed, providing a foundation for future generations of amphibious mobile robots.}
}

@article{boxerbaumDesignSimulationFabrication2012a,
  title = {Design, Simulation, Fabrication and Testing of a Bio-Inspired Amphibious Robot with Multiple Modes of Mobility},
  author = {Boxerbaum, A.S. and Klein, M.A. and Kline, J.E. and Burgess, S.C. and Quinn, R.D. and Harkins, R. and Vaidyanathan, R.},
  date = {2012},
  journaltitle = {Journal of Robotics and Mechatronics},
  volume = {24},
  number = {4},
  pages = {629--641},
  doi = {10.20965/jrm.2012.p0629},
  abstract = {Surf-zone environments represent an extreme challenges to robot operation. A robot that autonomously navigates rocky terrain, constantly changing underwater currents, hard-packed moist sand and loose dry sand characterizing this environment, would have significant utility in a range of defence and civilian missions. The study of animal locomotion mechanisms can elucidate specific movement principles that can be applied to address these demands. In this work, we report on the design and optimization of a biologically inspired amphibious robot for deployment and operation in an ocean beach environment. We specifically report a new design fusing a range of insectinspired passive mechanisms with active autonomous control architectures to seamlessly adapt to and traverse a range of challenging substrates both in and out of the water, and the design and construction of SeaDog, a proof-of-concept amphibious robot built for navigating rocky or sandy beaches and turbulent surf zones. The robot incorporates a layered hull and chassis design that is integrated into a waterproof Explorer Case in order to provide a large, protected payload in an easy-to-carry package. It employs a rugged drivetrain with four wheel-legs and a unique tail design and actuation strategy to aid in climbing, swimming and stabilization. Several modes of terrestrial and aquatic locomotion are suggested and tested versus range of mobility metrics, including data obtained in simulation and hardware testing. A waterproofing strategy is also tested and discussed, providing a foundation for future generations of amphibious mobile robots.}
}

@inproceedings{breitDigitalSimulationLean2010,
  title = {Digital Simulation in Lean Project Development},
  booktitle = {Challenging {{Lean Construction Thinking}}: {{What Do We Think}} and {{What Do We Know}}? - 18th {{Annual Conference}} of the {{International Group}} for {{Lean Construction}}, {{IGLC}} 18},
  author = {Breit, M. and Häubi, F. and Arnold, N.},
  date = {2010},
  pages = {622--632},
  abstract = {Skilled use of information technology such as Building Information Modeling (BIM) (Eastman et al., 2008) managed by Lean Construction principles (Koskela 1992; Koskela 2000) can have a significant positive impacts on the construction industry (e.g. Khanzode et al, 2005, 2008). In an ongoing research program "Individual parametric Façade Modules with integrated de-central building services technology" we analyzed the digital information flow possibilities of today' s BIM application on residential housing projects with timber facades and derived the following questions: How can we integrate engineering, manufacturing and construction knowledge in the early design and planning phases of the project development to increase the value for the customer and reduce variability for the construc tion process "And how can we use the simulation capabilities of BIM methods and technology to improve overall building performance" We identified the bidding process as one of the areas with the highest potential to gain additional value for the customer a nd to improve upstream flow variability for fabrication and constructi on. This is done through impr oving the value stream by introducing and integrating knowledge of the do wnstream trades earlier than currently done in practice. We use an adapted "Functional Design and Bidding" methodology to achieve this. In order to change the information exchange from the current predominant drawing centred approach to a model-based paradigm, we developed a new module called Process oriented Product Model Interface (PPMI), which serves as an interface for integrating people, processes and information systems (Dave et al. 2008). Using BIM enhanced model checking and simulation methods enables the purchaser to compare offers and their construction alternatives in terms of architectural design quality, building performances e.g. energy consumption, usability, comfort, flexibility of use, feasibility, impact on schedule, construction and life cycle costs.}
}

@inproceedings{breitDigitalSimulationLean2010a,
  title = {Digital Simulation in Lean Project Development},
  booktitle = {Challenging {{Lean Construction Thinking}}: {{What Do We Think}} and {{What Do We Know}}? - 18th {{Annual Conference}} of the {{International Group}} for {{Lean Construction}}, {{IGLC}} 18},
  author = {Breit, M. and Häubi, F. and Arnold, N.},
  date = {2010},
  pages = {622--632},
  abstract = {Skilled use of information technology such as Building Information Modeling (BIM) (Eastman et al., 2008) managed by Lean Construction principles (Koskela 1992; Koskela 2000) can have a significant positive impacts on the construction industry (e.g. Khanzode et al, 2005, 2008). In an ongoing research program "Individual parametric Façade Modules with integrated de-central building services technology" we analyzed the digital information flow possibilities of today' s BIM application on residential housing projects with timber facades and derived the following questions: How can we integrate engineering, manufacturing and construction knowledge in the early design and planning phases of the project development to increase the value for the customer and reduce variability for the construc tion process "And how can we use the simulation capabilities of BIM methods and technology to improve overall building performance" We identified the bidding process as one of the areas with the highest potential to gain additional value for the customer a nd to improve upstream flow variability for fabrication and constructi on. This is done through impr oving the value stream by introducing and integrating knowledge of the do wnstream trades earlier than currently done in practice. We use an adapted "Functional Design and Bidding" methodology to achieve this. In order to change the information exchange from the current predominant drawing centred approach to a model-based paradigm, we developed a new module called Process oriented Product Model Interface (PPMI), which serves as an interface for integrating people, processes and information systems (Dave et al. 2008). Using BIM enhanced model checking and simulation methods enables the purchaser to compare offers and their construction alternatives in terms of architectural design quality, building performances e.g. energy consumption, usability, comfort, flexibility of use, feasibility, impact on schedule, construction and life cycle costs.}
}

@article{brissiReviewInteractionsRobotic2021,
  title = {A Review on the Interactions of Robotic Systems and Lean Principles in Offsite Construction},
  author = {Brissi, Sara Gusmao and Chong, Oscar Wong and Debs, Luciana and Zhang, Jiansong},
  date = {2021},
  journaltitle = {Engineering, Construction and Architectural Management},
  issn = {09699988},
  doi = {10.1108/ECAM-10-2020-0809},
  abstract = {Purpose: The purpose is two-fold: (1) to explore the interactions of robotic systems and lean construction in the context of offsite construction (OC) that were addressed in the literature published between 2008 and 2019 and (2) to identify the gaps in such interactions while discussing how addressing those gaps can benefit not only OC but the architecture, engineering and construction (AEC) industry as a whole. Design/methodology/approach: First, a systematic literature review (SLR) identified journal papers addressing the interactions of automation and lean in OC. Then, the researchers focused the analysis on the under-researched subtopic of robotic systems. The focused analysis includes discussing the interactions identified in the SLR through a matrix of interactions and utilizing literature beyond the previously identified articles for future research directions on robotic systems and lean construction in OC. Findings: The study found 35 journal papers that addressed automation and lean in the context of OC. Most of the identified literature focused on interactions of BIM and lean construction, while only nine focused on the interactions of robotic systems and lean construction. Identified literature related to robotic systems mainly addressed robots and automated equipment. Additional interactions were identified in the realm of wearable devices, unmanned aerial vehicles/automated guided vehicles and digital fabrication/computer numerical control (CNC) machines. Originality/value: This is one of the first studies dedicated to exploring the interactions of robotic systems and lean construction in OC. Also, it proposes a categorization for construction automation and a matrix of interactions between construction automation and lean construction.},
  keywords = {Construction automation,Lean construction,Offsite construction,Robotic systems,Systematic literature review}
}

@book{britainSustainableCommunitiesPeople2005,
  title = {Sustainable {{Communities}}: {{People}}, {{Places}} and {{Prosperity}}: A {{Five Year Plan}}},
  author = {Britain, Great},
  date = {2005},
  publisher = {{Stationery Office Limited}}
}

@article{broquereAttentionalApproachHuman2014,
  title = {An {{Attentional Approach}} to {{Human}}–{{Robot Interactive Manipulation}}},
  author = {Broquère, X. and Finzi, A. and Mainprice, J. and Rossi, S. and Sidobre, D. and Staffa, M.},
  date = {2014},
  journaltitle = {International Journal of Social Robotics},
  volume = {6},
  number = {4},
  pages = {533--553},
  doi = {10.1007/s12369-014-0236-0},
  abstract = {Human robot collaborative work requires interactive manipulation and object handover. During the execution of such tasks, the robot should monitor manipulation cues to assess the human intentions and quickly determine the appropriate execution strategies. In this paper, we present a control architecture that combines a supervisory attentional system with a human aware manipulation planner to support effective and safe collaborative manipulation. After detailing the approach, we present experimental results describing the system at work with different manipulation tasks (give, receive, pick, and place).}
}

@article{broquereAttentionalApproachHuman2014a,
  title = {An {{Attentional Approach}} to {{Human}}–{{Robot Interactive Manipulation}}},
  author = {Broquère, X. and Finzi, A. and Mainprice, J. and Rossi, S. and Sidobre, D. and Staffa, M.},
  date = {2014},
  journaltitle = {International Journal of Social Robotics},
  volume = {6},
  number = {4},
  pages = {533--553},
  doi = {10.1007/s12369-014-0236-0},
  abstract = {Human robot collaborative work requires interactive manipulation and object handover. During the execution of such tasks, the robot should monitor manipulation cues to assess the human intentions and quickly determine the appropriate execution strategies. In this paper, we present a control architecture that combines a supervisory attentional system with a human aware manipulation planner to support effective and safe collaborative manipulation. After detailing the approach, we present experimental results describing the system at work with different manipulation tasks (give, receive, pick, and place).}
}

@article{brorstromPlansSituatedActions2021,
  title = {Plans and Situated Actions in Urban Renewal Projects: {{The}} Role of Governance Devices in Realizing Projects},
  author = {Brorström, S. and Styhre, A.},
  date = {2021},
  journaltitle = {Environment and Planning C: Politics and Space},
  volume = {39},
  number = {3},
  pages = {646--663},
  doi = {10.1177/2399654420941856},
  abstract = {Municipalities and city administrations have the jurisdiction to determine the use of land and real estate, but must collaborate with various actors, including real estate developers, construction companies, and financial institutions, to realize stated goals. When implementing initiatives such as urban renewal projects, plans and situated actions may be loosely coupled during the early stages, when visions of the future are being articulated; over time, however, the information needed to calculate whether illiquid assets are attractive investment objects must be introduced. As such information is generated, the gap between plans and situated actions closes, having material effects under favourable conditions. This article presents an empirical study of an urban renewal project in a metropolitan area that initially gained external recognition via a prize awarded for visionary planning work. The project eventually encountered considerable difficulties, as a shortage of accurate information hampered production activities. The study underlines the importance of robust governance practices and accompanying governance devices in effectively transforming illiquid assets into, for example, housing.}
}

@article{brorstromPlansSituatedActions2021a,
  title = {Plans and Situated Actions in Urban Renewal Projects: {{The}} Role of Governance Devices in Realizing Projects},
  author = {Brorström, S. and Styhre, A.},
  date = {2021},
  journaltitle = {Environment and Planning C: Politics and Space},
  volume = {39},
  number = {3},
  pages = {646--663},
  doi = {10.1177/2399654420941856},
  abstract = {Municipalities and city administrations have the jurisdiction to determine the use of land and real estate, but must collaborate with various actors, including real estate developers, construction companies, and financial institutions, to realize stated goals. When implementing initiatives such as urban renewal projects, plans and situated actions may be loosely coupled during the early stages, when visions of the future are being articulated; over time, however, the information needed to calculate whether illiquid assets are attractive investment objects must be introduced. As such information is generated, the gap between plans and situated actions closes, having material effects under favourable conditions. This article presents an empirical study of an urban renewal project in a metropolitan area that initially gained external recognition via a prize awarded for visionary planning work. The project eventually encountered considerable difficulties, as a shortage of accurate information hampered production activities. The study underlines the importance of robust governance practices and accompanying governance devices in effectively transforming illiquid assets into, for example, housing.}
}

@article{brosqueHumanRobotCollaborationConstruction2020,
  title = {Human-{{Robot Collaboration}} in {{Construction}}: {{Opportunities}} and {{Challenges}}},
  author = {Brosque, Cynthia and Galbally, Elena and Khatib, Oussama and Fischer, Martin},
  date = {2020},
  journaltitle = {HORA 2020 - 2nd International Congress on Human-Computer Interaction, Optimization and Robotic Applications, Proceedings},
  doi = {10.1109/HORA49412.2020.9152888},
  abstract = {The last decade of robotic advances in manipulation, sensing, and computing is starting to enable the use of robots in unstructured environments, such as construction, to assist in hazardous, repetitive, and strenuous manual tasks. The construction field poses considerable technical challenges that have led to complex setups and programming as well as unsafe robots that are not suited for human-robot collaboration. Human-robot collaboration through haptic interfaces, utilized in other fields, could help integrate the workers' expertise with the robots' accuracy, safety, repeatability, and speed, but have not yet been widely applied to the construction industry. By using the SAI robotic simulation environment and human-safe compliant robots, this paper introduces a method to study the potential of haptics for five construction tasks: drywall installation, painting, bolting, welding, and pouring concrete.},
  isbn = {9781728193526}
}

@article{brosqueHumanRobotCollaborationConstruction2020a,
  title = {Human-{{Robot Collaboration}} in {{Construction}}: {{Opportunities}} and {{Challenges}}},
  author = {Brosque, Cynthia and Galbally, Elena and Khatib, Oussama and Fischer, Martin},
  date = {2020},
  journaltitle = {HORA 2020 - 2nd International Congress on Human-Computer Interaction, Optimization and Robotic Applications, Proceedings},
  doi = {10.1109/HORA49412.2020.9152888},
  abstract = {The last decade of robotic advances in manipulation, sensing, and computing is starting to enable the use of robots in unstructured environments, such as construction, to assist in hazardous, repetitive, and strenuous manual tasks. The construction field poses considerable technical challenges that have led to complex setups and programming as well as unsafe robots that are not suited for human-robot collaboration. Human-robot collaboration through haptic interfaces, utilized in other fields, could help integrate the workers' expertise with the robots' accuracy, safety, repeatability, and speed, but have not yet been widely applied to the construction industry. By using the SAI robotic simulation environment and human-safe compliant robots, this paper introduces a method to study the potential of haptics for five construction tasks: drywall installation, painting, bolting, welding, and pouring concrete.},
  isbn = {9781728193526},
  file = {C:\Users\leemar\Zotero\storage\LWL9H7KN\Human-Robot_Collaboration_in_Construction_Opportunities_and_Challenges-2.pdf}
}

@inproceedings{brosqueHumanRobotCollaborationConstruction2020b,
  title = {Human-{{Robot Collaboration}} in {{Construction}}: {{Opportunities}} and {{Challenges}}},
  shorttitle = {Human-{{Robot Collaboration}} in {{Construction}}},
  booktitle = {2020 {{International Congress}} on {{Human-Computer Interaction}}, {{Optimization}} and {{Robotic Applications}} ({{HORA}})},
  author = {Brosque, Cynthia and Galbally, Elena and Khatib, Oussama and Fischer, Martin},
  date = {2020-06},
  pages = {1--8},
  publisher = {{IEEE}},
  location = {{Ankara, Turkey}},
  doi = {10.1109/HORA49412.2020.9152888},
  url = {https://ieeexplore.ieee.org/document/9152888/},
  urldate = {2023-03-20},
  eventtitle = {2020 {{International Congress}} on {{Human-Computer Interaction}}, {{Optimization}} and {{Robotic Applications}} ({{HORA}})},
  isbn = {978-1-72819-352-6}
}

@article{brozPlanningHumanRobotInteraction2013,
  title = {Planning for {{Human-Robot Interaction}} in {{Socially Situated Tasks}}: {{The Impact}} of {{Representing Time}} and {{Intention}}},
  author = {Broz, F. and Nourbakhsh, I. and Simmons, R.},
  date = {2013},
  journaltitle = {International Journal of Social Robotics},
  volume = {5},
  number = {2},
  pages = {193--214},
  doi = {10.1007/s12369-013-0185-z},
  abstract = {This article presents the results of a study on the effects of representing time and intention in models of socially situated tasks on the quality of policies for robot behavior. The ability to reason about how others' observable actions relate to their unobservable intentions is an important part of interpreting and responding to social behavior. It is also often necessary to observe the timing of actions in order to disambiguate others' intentions. Therefore, our proposed approach is to model these interactions as time-indexed partially observable Markov decision processes (POMDPs). The intentions of humans are represented as hidden state in the POMDP models, and the time-dependence of actions by both humans and the robot are explicitly modelled. Our hypothesis is that planning for these interactions with a model that represents time dependent action outcomes and uncertainty about others' intentions will achieve better results than simpler models that make fixed assumptions about people's intentionality or abstract away time-dependent effects. A driving interaction governed by social conventions and involving ambiguity in the other driver's intent was used as the scenario with which to test this hypothesis. A robot car controlled by policies from time-dependent POMDP models or by policies from two less expressive model variants performed this interaction in a driving simulator with human drivers. The time-dependent POMDP policies achieved better results than those of the models without explicit time representation or human intention as hidden state, both according to the reward obtained and to people's subjective impressions of how socially appropriate and natural the robot's behavior was. These results demonstrate both the relative superiority of these representation choices and the effectiveness of this approach to planning for socially situated tasks. © 2013 Springer Science+Business Media Dordrecht.}
}

@article{brozPlanningHumanRobotInteraction2013a,
  title = {Planning for {{Human-Robot Interaction}} in {{Socially Situated Tasks}}: {{The Impact}} of {{Representing Time}} and {{Intention}}},
  author = {Broz, F. and Nourbakhsh, I. and Simmons, R.},
  date = {2013},
  journaltitle = {International Journal of Social Robotics},
  volume = {5},
  number = {2},
  pages = {193--214},
  doi = {10.1007/s12369-013-0185-z},
  abstract = {This article presents the results of a study on the effects of representing time and intention in models of socially situated tasks on the quality of policies for robot behavior. The ability to reason about how others' observable actions relate to their unobservable intentions is an important part of interpreting and responding to social behavior. It is also often necessary to observe the timing of actions in order to disambiguate others' intentions. Therefore, our proposed approach is to model these interactions as time-indexed partially observable Markov decision processes (POMDPs). The intentions of humans are represented as hidden state in the POMDP models, and the time-dependence of actions by both humans and the robot are explicitly modelled. Our hypothesis is that planning for these interactions with a model that represents time dependent action outcomes and uncertainty about others' intentions will achieve better results than simpler models that make fixed assumptions about people's intentionality or abstract away time-dependent effects. A driving interaction governed by social conventions and involving ambiguity in the other driver's intent was used as the scenario with which to test this hypothesis. A robot car controlled by policies from time-dependent POMDP models or by policies from two less expressive model variants performed this interaction in a driving simulator with human drivers. The time-dependent POMDP policies achieved better results than those of the models without explicit time representation or human intention as hidden state, both according to the reward obtained and to people's subjective impressions of how socially appropriate and natural the robot's behavior was. These results demonstrate both the relative superiority of these representation choices and the effectiveness of this approach to planning for socially situated tasks. © 2013 Springer Science+Business Media Dordrecht.}
}

@article{bruzzoneNovelParallelRobot2006,
  entrysubtype = {magazine},
  title = {A Novel Parallel Robot for Current Microassembly Applications},
  author = {Bruzzone, L. and Molfino, R.M.},
  date = {2006},
  journaltitle = {Assembly Automation},
  volume = {26},
  number = {4},
  pages = {299--306},
  doi = {10.1108/01445150610705218},
  abstract = {Purpose - Aims to discuss how a Cartesian parallel robot with flexure revolute joints can effectively perform miniaturized assembly tasks. Design/methodology/approach - The results of the test and validation phase of a Cartesian parallel robot designed for miniaturized assembly are shown. The workspace volume is a cube with 30mm side and the target accuracy is 1 μm. Each of the three robot legs has a prismatic-planar architecture, with a cog-free linear motor and a planar joint realized using ten superelastic flexure revolute joints. Flexure joints are adopted in order to avoid stick-slip phenomena and reach high positioning accuracy; their patented construction is relatively low-cost and allows a quick replacement in case of fatigue failure. Findings - The tests on the prototype are very encouraging: the measured positioning accuracy of the linear motors is ±0.5 μm; on the other hand, the effects of unwanted rotations of flexure joints d hysteresis of the superelastic material are not negligible and must be properly compensated for in order to fully exploit the potential performance of the machine. Practical implications - The introduction of this robotic architecture can fulfil the needs of a wide range of industrial miniaturized assembly applications, thanks to its accurate positioning in a relatively large workspace. The cost of the machine is low thanks to its extreme modularity. Originality/value - The combination of Cartesian parallel kinematics, cog-free linear motors and superelastic flexure revolute joints allows one to obtain very good positioning performance. © Emerald Group Publishing Limited.}
}

@article{bruzzoneNovelParallelRobot2006a,
  entrysubtype = {magazine},
  title = {A Novel Parallel Robot for Current Microassembly Applications},
  author = {Bruzzone, L. and Molfino, R.M.},
  date = {2006},
  journaltitle = {Assembly Automation},
  volume = {26},
  number = {4},
  pages = {299--306},
  doi = {10.1108/01445150610705218},
  abstract = {Purpose - Aims to discuss how a Cartesian parallel robot with flexure revolute joints can effectively perform miniaturized assembly tasks. Design/methodology/approach - The results of the test and validation phase of a Cartesian parallel robot designed for miniaturized assembly are shown. The workspace volume is a cube with 30mm side and the target accuracy is 1 μm. Each of the three robot legs has a prismatic-planar architecture, with a cog-free linear motor and a planar joint realized using ten superelastic flexure revolute joints. Flexure joints are adopted in order to avoid stick-slip phenomena and reach high positioning accuracy; their patented construction is relatively low-cost and allows a quick replacement in case of fatigue failure. Findings - The tests on the prototype are very encouraging: the measured positioning accuracy of the linear motors is ±0.5 μm; on the other hand, the effects of unwanted rotations of flexure joints d hysteresis of the superelastic material are not negligible and must be properly compensated for in order to fully exploit the potential performance of the machine. Practical implications - The introduction of this robotic architecture can fulfil the needs of a wide range of industrial miniaturized assembly applications, thanks to its accurate positioning in a relatively large workspace. The cost of the machine is low thanks to its extreme modularity. Originality/value - The combination of Cartesian parallel kinematics, cog-free linear motors and superelastic flexure revolute joints allows one to obtain very good positioning performance. © Emerald Group Publishing Limited.}
}

@inproceedings{Brys20153352,
  title = {Reinforcement Learning from Demonstration through Shaping},
  author = {Brys, T. and Harutyunyan, A. and Suay, H.B. and Chernova, S. and Taylor, M.E. and Nowé, A.},
  date = {2015},
  series = {{{IJCAI International Joint Conference}} on {{Artificial Intelligence}}},
  volume = {2015-January},
  pages = {3352--3358}
}

@article{buhamdanDevelopingBIMSimulationBased2021,
  title = {Developing a {{BIM}} and {{Simulation-Based Hazard Assessment}} and {{Visualization Framework}} for {{CLT Construction Design}}},
  author = {Buhamdan, S. and Duncheva, T. and Alwisy, A.},
  date = {2021},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {147},
  number = {3},
  doi = {10.1061/(ASCE)CO.1943-7862.0002000},
  abstract = {One emerging trend in sustainable medium-density construction is the use of mass timber products such as cross laminated timber (CLT), which is a novel approach that involves numerous connectors. Researchers have not previously investigated the potential health impacts of different connectors. This paper proposes a framework to correlate the specification of CLT connectors to the potential risk of exposure to hand arm vibration syndrome (HAVS). We also propose an innovative adaptation of the Location-Based Management System flow line by adding a health risk dimension. The usefulness of the proposed framework is tested using a cutting-edge case study building, the tallest timber building in Scotland. The contribution of this research is a novel appreciation of the impact on installers' Health \& Safety based on the specified type of CLT connectors. With the methodology outlined in this paper, a HAVS variable can be added to design analysis to increase social sustainability in the built environment alongside other sustainability pillars. The findings are relevant to structural engineers, architects, key industry stakeholders, and researchers in the built environment.},
  file = {C:\Users\leemar\Zotero\storage\TV75VVPE\Developing-a-BIM-and-SimulationBased-Hazard-Assessment-and-Visualization-Framework-for-CLT-Construction-DesignJournal-of-Construction-Engineering-and-Management.pdf}
}

@article{buhamdanDevelopingBIMSimulationBased2021a,
  title = {Developing a {{BIM}} and {{Simulation-Based Hazard Assessment}} and {{Visualization Framework}} for {{CLT Construction Design}}},
  author = {Buhamdan, S. and Duncheva, T. and Alwisy, A.},
  date = {2021},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {147},
  number = {3},
  doi = {10.1061/(ASCE)CO.1943-7862.0002000},
  abstract = {One emerging trend in sustainable medium-density construction is the use of mass timber products such as cross laminated timber (CLT), which is a novel approach that involves numerous connectors. Researchers have not previously investigated the potential health impacts of different connectors. This paper proposes a framework to correlate the specification of CLT connectors to the potential risk of exposure to hand arm vibration syndrome (HAVS). We also propose an innovative adaptation of the Location-Based Management System flow line by adding a health risk dimension. The usefulness of the proposed framework is tested using a cutting-edge case study building, the tallest timber building in Scotland. The contribution of this research is a novel appreciation of the impact on installers' Health \& Safety based on the specified type of CLT connectors. With the methodology outlined in this paper, a HAVS variable can be added to design analysis to increase social sustainability in the built environment alongside other sustainability pillars. The findings are relevant to structural engineers, architects, key industry stakeholders, and researchers in the built environment.},
  file = {C:\Users\leemar\Zotero\storage\HN5PYVLM\Developing-a-BIM-and-SimulationBased-Hazard-Assessment-and-Visualization-Framework-for-CLT-Construction-DesignJournal-of-Construction-Engineering-and-Management.pdf}
}

@book{burgessCompactCities2002,
  title = {Compact {{Cities}}},
  editor = {Burgess, Rod and Jenks, Mike},
  date = {2002-09-11},
  edition = {0},
  publisher = {{Routledge}},
  doi = {10.4324/9780203478622},
  url = {https://www.taylorfrancis.com/books/9781135803902},
  urldate = {2023-09-17},
  isbn = {978-1-135-80390-2},
  langid = {english}
}

@inproceedings{cacaceSupervisedHandguidanceHuman2021,
  title = {Supervised Hand-Guidance during Human Robot Collaborative Task Execution: {{A}} Case Study},
  booktitle = {{{CEUR Workshop Proceedings}}},
  author = {Cacace, J. and Caccavale, R. and Finzi, A.},
  date = {2021},
  volume = {2806},
  pages = {1--6},
  abstract = {We present and discuss a human-robot collaboration system suitable for supervising the execution of structured manipulation tasks in industrial assembly scenarios. As a case study, we consider the application domain proposed in the context of the project (PON R\& I 2014-2020) ICOSAF (Integrated collaborative systems for Smart Factory) in which a human operator physically interacts with a collaborative robot (Cobot) to perform multiple item insertion tasks in a shared workspace. The proposed system combines hierarchical task orchestration and human intention recognition during human-robot interaction through hand-guidance. We provide an overview of the system discussing an initial experimental evaluation.}
}

@inproceedings{cacaceSupervisedHandguidanceHuman2021a,
  title = {Supervised Hand-Guidance during Human Robot Collaborative Task Execution: {{A}} Case Study},
  booktitle = {{{CEUR Workshop Proceedings}}},
  author = {Cacace, J. and Caccavale, R. and Finzi, A.},
  date = {2021},
  volume = {2806},
  pages = {1--6},
  abstract = {We present and discuss a human-robot collaboration system suitable for supervising the execution of structured manipulation tasks in industrial assembly scenarios. As a case study, we consider the application domain proposed in the context of the project (PON R\& I 2014-2020) ICOSAF (Integrated collaborative systems for Smart Factory) in which a human operator physically interacts with a collaborative robot (Cobot) to perform multiple item insertion tasks in a shared workspace. The proposed system combines hierarchical task orchestration and human intention recognition during human-robot interaction through hand-guidance. We provide an overview of the system discussing an initial experimental evaluation.}
}

@article{caiTwostepLongShortterm2019,
  title = {Two-Step Long Short-Term Memory Method for Identifying Construction Activities through Positional and Attentional Cues},
  author = {Cai, Jiannan and Zhang, Yuxi and Cai, Hubo},
  date = {2019},
  journaltitle = {Automation in Construction},
  volume = {106},
  pages = {102886},
  publisher = {{Elsevier}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2019.102886},
  url = {https://doi.org/10.1016/j.autcon.2019.102886},
  abstract = {Recognizing construction activities and involved working groups is critical to enhancing construction safety and improving productivity. Most existing studies use videos that only contain one activity with involved entities and rely solely on the spatial-temporal relationship among entities. However, in practice, many workers and machines co-exist and collaborate to accomplish different activities, and not all of them are relevant to the same activity, even though they are spatially close. This paper presents a two-step classification approach – working group identification followed by activity recognition, leveraging both positional and attentional cues, to recognize complex interactions and their involved entities from videos that contain different activities with multiple entities. The spatial and attentional states of individual entities are represented numerically, and the corresponding positional and attentional cues between two entities are computed. Long short-term memory (LSTM) networks are designed to (1) classify whether two entities belong to the same group, and (2) recognize the activities they are involved in. The newly created method is validated using two sets of construction videos. Identifying working groups before recognizing ongoing activities enables the exclusion of group-irrelevant entities and thus, improves the performance. Moreover, by leveraging both positional and attentional cues, the accuracy increases from 85\% to 95\% compared with cases using positional cues alone.},
  issue = {June},
  keywords = {Attentional cues,Construction group activity recognition,Long short-term memory (LSTM),Positional cues,Working group identification}
}

@article{caiTwostepLongShortterm2019a,
  title = {Two-Step Long Short-Term Memory Method for Identifying Construction Activities through Positional and Attentional Cues},
  author = {Cai, Jiannan and Zhang, Yuxi and Cai, Hubo},
  date = {2019},
  journaltitle = {Automation in Construction},
  volume = {106},
  pages = {102886},
  publisher = {{Elsevier}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2019.102886},
  url = {https://doi.org/10.1016/j.autcon.2019.102886},
  abstract = {Recognizing construction activities and involved working groups is critical to enhancing construction safety and improving productivity. Most existing studies use videos that only contain one activity with involved entities and rely solely on the spatial-temporal relationship among entities. However, in practice, many workers and machines co-exist and collaborate to accomplish different activities, and not all of them are relevant to the same activity, even though they are spatially close. This paper presents a two-step classification approach – working group identification followed by activity recognition, leveraging both positional and attentional cues, to recognize complex interactions and their involved entities from videos that contain different activities with multiple entities. The spatial and attentional states of individual entities are represented numerically, and the corresponding positional and attentional cues between two entities are computed. Long short-term memory (LSTM) networks are designed to (1) classify whether two entities belong to the same group, and (2) recognize the activities they are involved in. The newly created method is validated using two sets of construction videos. Identifying working groups before recognizing ongoing activities enables the exclusion of group-irrelevant entities and thus, improves the performance. Moreover, by leveraging both positional and attentional cues, the accuracy increases from 85\% to 95\% compared with cases using positional cues alone.},
  issue = {June},
  keywords = {Attentional cues,Construction group activity recognition,Long short-term memory (LSTM),Positional cues,Working group identification},
  file = {C:\Users\leemar\Zotero\storage\JMDXLGJM\1-s2.0-S0926580519302316-main.pdf}
}

@inproceedings{Cakmak2011489,
  title = {Using Spatial and Temporal Contrast for Fluent Robot-Human Hand-Overs},
  author = {Cakmak, M. and Srinivasa, S.S. and Kyung Lee, M. and Kiesler, S. and Forlizzi, J.},
  date = {2011},
  series = {{{HRI}} 2011 - {{Proceedings}} of the 6th {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  pages = {489--496},
  doi = {10.1145/1957656.1957823}
}

@article{callensFrameworkRecognitionPrediction2020,
  title = {A {{Framework}} for {{Recognition}} and {{Prediction}} of {{Human Motions}} in {{Human-Robot Collaboration Using Probabilistic Motion Models}}},
  author = {Callens, Thomas and family=Have, given=Tuur, prefix=van der, useprefix=true and Rossom, Sam Van and De Schutter, Joris and Aertbelien, Erwin},
  date = {2020-10},
  journaltitle = {IEEE Robotics and Automation Letters},
  shortjournal = {IEEE Robot. Autom. Lett.},
  volume = {5},
  number = {4},
  pages = {5151--5158},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2020.3005892},
  url = {https://ieeexplore.ieee.org/document/9130153/},
  urldate = {2023-03-22},
  file = {C:\Users\leemar\Zotero\storage\6S8XQR79\Callens et al. - 2020 - A Framework for Recognition and Prediction of Huma.pdf}
}

@article{cangelliArchitectureDemandNew2018,
  title = {Architecture on Demand. {{New}} Scenarios for the Design Project and the Construction Industry | {{Architettura}} on Demand. {{Nuovi}} Scenari per Il Progetto e l'industria Delle Costruzioni},
  author = {Cangelli, E. and Conteduca, M.},
  date = {2018},
  journaltitle = {TECHNE},
  volume = {16},
  pages = {96--104},
  doi = {10.13128/Techne-23036},
  abstract = {The paper examines how the relationship between the project and the matter is changing under the impact of digitalization and the productive and economical emerging paradigms, both in terms of process and product. The evolutionary path of the relationship between industrialization and architecture allow us to draw a picture which, starting from the first experience of standardizing prefabrication, lead to results increasingly oriented towards the personalization of realizations (Industrial Mass Customization). The essay proposes a critical reading of most recent and advanced technological innovations, focusing on the applications of 3d printing additive technology to the architecture and to the new scenarios of research opened for the project and the construction industry.}
}

@article{cangelliArchitectureDemandNew2018a,
  title = {Architecture on Demand. {{New}} Scenarios for the Design Project and the Construction Industry | {{Architettura}} on Demand. {{Nuovi}} Scenari per Il Progetto e l'industria Delle Costruzioni},
  author = {Cangelli, E. and Conteduca, M.},
  date = {2018},
  journaltitle = {TECHNE},
  volume = {16},
  pages = {96--104},
  doi = {10.13128/Techne-23036},
  abstract = {The paper examines how the relationship between the project and the matter is changing under the impact of digitalization and the productive and economical emerging paradigms, both in terms of process and product. The evolutionary path of the relationship between industrialization and architecture allow us to draw a picture which, starting from the first experience of standardizing prefabrication, lead to results increasingly oriented towards the personalization of realizations (Industrial Mass Customization). The essay proposes a critical reading of most recent and advanced technological innovations, focusing on the applications of 3d printing additive technology to the architecture and to the new scenarios of research opened for the project and the construction industry.}
}

@incollection{casalinoAllowingRealCollaboration2021,
  title = {Allowing a {{Real Collaboration Between Humans}} and {{Robots}}},
  booktitle = {{{SpringerBriefs}} in {{Applied Sciences}} and {{Technology}}},
  author = {Casalino, Andrea},
  date = {2021},
  pages = {139--148},
  doi = {10.1007/978-3-030-62476-7_13},
  url = {http://link.springer.com/10.1007/978-3-030-62476-7_13},
  abstract = {Robotics researchers are spending many efforts in developing methodologies and techniques that allow robots to work side by side with humans, with the aim of improving the manufacturing processes. Such a level of interaction does not require just the safe coexistence in a common space, which is something completely achieved by the current state of the art. In scenarios like co-assemblies, humans and robots have to execute alternating tasks, with the aim of realizing a set of possible finite products. This requires the robots to adapt, synchronize and actively cooperate with the humans. This work will show that this goal can be reached by providing the cobots with three main abilities: recognizing the human behaviour, predicting the human actions and optimally planning the robotic ones.}
}

@article{Chan2017,
  title = {Object Proposal Algorithms in the Wild: {{Are}} They Generalizable to Robot Perception?},
  author = {Chan, D. and Riek, L.D.},
  date = {2017},
  journaltitle = {Review-literature and Arts of The Americas},
  shortjournal = {Review}
}

@inproceedings{Chan20174152,
  title = {Faster Robot Perception Using Salient Depth Partitioning},
  author = {Chan, D.M. and Taylor, A. and Riek, L.D.},
  date = {2017},
  series = {{{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  volume = {2017-September},
  pages = {4152--4158},
  doi = {10.1109/IROS.2017.8206275},
  art_number = {8206275}
}

@article{chanBridgingGapSustainable2019,
  title = {Bridging the Gap between Sustainable Housing and Affordable Housing: {{The}} Required Critical Success Criteria ({{CSC}})},
  shorttitle = {Bridging the Gap between Sustainable Housing and Affordable Housing},
  author = {Chan, Albert P.C. and Adabre, Michael Atafo},
  date = {2019-03},
  journaltitle = {Building and Environment},
  shortjournal = {Building and Environment},
  volume = {151},
  pages = {112--125},
  issn = {03601323},
  doi = {10.1016/j.buildenv.2019.01.029},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0360132319300356},
  urldate = {2023-09-19},
  langid = {english}
}

@inproceedings{charalambousHumanautomationCollaborationManufacturing2013,
  title = {Human-Automation Collaboration in Manufacturing: Identifying Key Implementation Factors},
  booktitle = {Proceedings of the {{International Conference}} on {{Ergonomics}} \& {{Human Factors}}},
  author = {Charalambous, George and Fletcher, Sarah and Webb, Philip},
  date = {2013},
  pages = {59}
}

@article{charlesYourNewColleague2015,
  title = {Your New Colleague Is a Robot. {{Is}} That Ok?},
  author = {Charles, Rebecca and Charalambous, George and Fletcher, Sarah R},
  date = {2015},
  publisher = {{CRC Press: Taylor and Francis Group}}
}

@article{chaturvediIntelligentArchitecture2008,
  title = {Intelligent Architecture},
  author = {Chaturvedi, S.},
  date = {2008},
  journaltitle = {Journal of the Institution of Engineers (India): Architectural Engineering Division},
  volume = {89},
  pages = {27--32},
  abstract = {Successful building design relics on an inter-disciplinary approach between building engineering, as well as architecture. An intelligent building is a dynamic and responsive architecture that provides every occupant productive, cost effective and environmentally approved conditions. Some significant technologies for an intelligent building are new materials, embedded sensors technology, nanotechnology, information technology and communications, photovoltaic, robotics, refined design, construction and facilities. Today people are living in the midst of an emerging new iconography paradigm, that of the digital image. Through the presented paper, attention is drawn towards requirement for the involvement of people with different backgrounds (eg engineers, sociologist, pedagogues, and artists) who are able to merge their competencies and perspectives in a creative way for this present call and study the core requirements of intelligent architecture.},
  issue = {APRIL}
}

@article{chaturvediIntelligentArchitecture2008a,
  title = {Intelligent Architecture},
  author = {Chaturvedi, S.},
  date = {2008},
  journaltitle = {Journal of the Institution of Engineers (India): Architectural Engineering Division},
  volume = {89},
  pages = {27--32},
  abstract = {Successful building design relics on an inter-disciplinary approach between building engineering, as well as architecture. An intelligent building is a dynamic and responsive architecture that provides every occupant productive, cost effective and environmentally approved conditions. Some significant technologies for an intelligent building are new materials, embedded sensors technology, nanotechnology, information technology and communications, photovoltaic, robotics, refined design, construction and facilities. Today people are living in the midst of an emerging new iconography paradigm, that of the digital image. Through the presented paper, attention is drawn towards requirement for the involvement of people with different backgrounds (eg engineers, sociologist, pedagogues, and artists) who are able to merge their competencies and perspectives in a creative way for this present call and study the core requirements of intelligent architecture.},
  issue = {APRIL}
}

@article{chengActivityAnalysisConstruction2017,
  title = {Activity Analysis of Construction Equipment Using Audio Signals and Support Vector Machines},
  author = {Cheng, C.-F. and Rashidi, A. and Davenport, M. A. and Anderson, D. V.},
  date = {2017},
  journaltitle = {Automation in Construction},
  volume = {81},
  pages = {240--253},
  doi = {10.1016/j.autcon.2017.06.005},
  abstract = {In the construction industry, especially for civil infrastructure projects, a large portion of overall project expenses are allocated towards various costs associated with heavy equipment. As a result, continuous tracking and monitoring of tasks performed by construction heavy equipment is vital for project managers and jobsite personnel. The current approaches for automated construction equipment monitoring include both location and action tracking methods. Current construction equipment action recognition and tracking methods can be divided into two major categories: 1) using active sensors such as accelerometers and gyroscopes and 2) implementing computer vision algorithms to extract information by processing images and videos. While both categories have their own advantages, the limitations of each mean that the industry still suffers from the lack of an efficient and automatic solution for the construction equipment activity analysis problem. In this paper we propose an innovative audio-based system for activity analysis (and tracking) of construction heavy equipment. Such equipment usually generates distinct sound patterns while performing certain tasks, and hence audio signal processing could be an alternative solution for solving the activity analysis problem within construction jobsites. The proposed system consists of multiple steps including filtering the audio signals, converting them into time-frequency representations, classifying these representations using machine learning techniques (e.g., a support vector machine), and window filtering the output of the classifier to differentiating between different patterns of activities. The proposed audio-based system has been implemented and evaluated using multiple case studies from several construction jobsites and the results demonstrate the potential capabilities of the system in accurately recognizing various actions of construction heavy equipment.}
}

@article{chengActivityAnalysisConstruction2017a,
  title = {Activity Analysis of Construction Equipment Using Audio Signals and Support Vector Machines},
  author = {Cheng, C.-F. and Rashidi, A. and Davenport, M.A. and Anderson, D.V.},
  date = {2017},
  journaltitle = {Automation in Construction},
  volume = {81},
  pages = {240--253},
  doi = {10.1016/j.autcon.2017.06.005},
  abstract = {In the construction industry, especially for civil infrastructure projects, a large portion of overall project expenses are allocated towards various costs associated with heavy equipment. As a result, continuous tracking and monitoring of tasks performed by construction heavy equipment is vital for project managers and jobsite personnel. The current approaches for automated construction equipment monitoring include both location and action tracking methods. Current construction equipment action recognition and tracking methods can be divided into two major categories: 1) using active sensors such as accelerometers and gyroscopes and 2) implementing computer vision algorithms to extract information by processing images and videos. While both categories have their own advantages, the limitations of each mean that the industry still suffers from the lack of an efficient and automatic solution for the construction equipment activity analysis problem. In this paper we propose an innovative audio-based system for activity analysis (and tracking) of construction heavy equipment. Such equipment usually generates distinct sound patterns while performing certain tasks, and hence audio signal processing could be an alternative solution for solving the activity analysis problem within construction jobsites. The proposed system consists of multiple steps including filtering the audio signals, converting them into time-frequency representations, classifying these representations using machine learning techniques (e.g., a support vector machine), and window filtering the output of the classifier to differentiating between different patterns of activities. The proposed audio-based system has been implemented and evaluated using multiple case studies from several construction jobsites and the results demonstrate the potential capabilities of the system in accurately recognizing various actions of construction heavy equipment.}
}

@inproceedings{chengAudioSignalProcessing2016,
  title = {Audio Signal Processing for Activity Recognition of Construction Heavy Equipment},
  booktitle = {{{ISARC}} 2016 - 33rd {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  author = {Cheng, C.-F. and Rashidi, A. and Davenport, M. A. and Anderson, D.},
  date = {2016},
  pages = {642--650},
  abstract = {Action recognition and tracking of construction heavy equipment is the first step for benchmarking and analyzing the performance of individual machines and evaluating the productivity of a jobsite as a whole. Aside from direct observations, the current approaches for automatically recognizing and tracking various actions of construction heavy equipment includes: 1) using active sensors such as RFID tags, GPS and accelerometers or 2) computer vision-based activity analysis (processing images or videos). In this paper, we present a novel audio-based approach for activity recognition of construction heavy equipment. Construction machines often produce distinct sound patterns while performing certain activities and it is possible to extract useful information by recording and processing those audio files at construction jobsites. The proposed audiobased framework begins with recording generated sound patterns of construction equipment using commercially available audio recorders. The recorded signal is then fed into a signal enhancement algorithm to reduce background noise commonly found at construction jobsites. The modified audio signal is then converted into a time-frequency representation using the Short-Time Fourier Transform (STFT). A Support Vector Machine (SVM) is then trained to differentiate between the acoustic patterns of the various activities of each machine. The processed audio signal is then finally divided and classified into various activities using a window filtering approach and by setting proper thresholds. We implemented the presented audio-based system at several jobsites as case studies and the results illustrate the efficiency of the system in automatically recognizing various actions of construction heavy equipment.}
}

@inproceedings{chengAudioSignalProcessing2016a,
  title = {Audio Signal Processing for Activity Recognition of Construction Heavy Equipment},
  booktitle = {{{ISARC}} 2016 - 33rd {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  author = {Cheng, C.-F. and Rashidi, A. and Davenport, M.A. and Anderson, D.},
  date = {2016},
  pages = {642--650},
  abstract = {Action recognition and tracking of construction heavy equipment is the first step for benchmarking and analyzing the performance of individual machines and evaluating the productivity of a jobsite as a whole. Aside from direct observations, the current approaches for automatically recognizing and tracking various actions of construction heavy equipment includes: 1) using active sensors such as RFID tags, GPS and accelerometers or 2) computer vision-based activity analysis (processing images or videos). In this paper, we present a novel audio-based approach for activity recognition of construction heavy equipment. Construction machines often produce distinct sound patterns while performing certain activities and it is possible to extract useful information by recording and processing those audio files at construction jobsites. The proposed audiobased framework begins with recording generated sound patterns of construction equipment using commercially available audio recorders. The recorded signal is then fed into a signal enhancement algorithm to reduce background noise commonly found at construction jobsites. The modified audio signal is then converted into a time-frequency representation using the Short-Time Fourier Transform (STFT). A Support Vector Machine (SVM) is then trained to differentiate between the acoustic patterns of the various activities of each machine. The processed audio signal is then finally divided and classified into various activities using a window filtering approach and by setting proper thresholds. We implemented the presented audio-based system at several jobsites as case studies and the results illustrate the efficiency of the system in automatically recognizing various actions of construction heavy equipment.}
}

@article{chengAutomatedTasklevelActivity2013,
  title = {Automated Task-Level Activity Analysis through Fusion of Real Time Location Sensors and Worker's Thoracic Posture Data},
  author = {Cheng, Tao and Teizer, Jochen and Migliaccio, Giovanni C. and Gatti, Umberto C.},
  date = {2013},
  journaltitle = {Automation in Construction},
  volume = {29},
  pages = {24--39},
  publisher = {{Elsevier B.V.}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2012.08.003},
  url = {http://dx.doi.org/10.1016/j.autcon.2012.08.003},
  abstract = {Knowledge of workforce productivity and activity is crucial for determining whether a construction project can be accomplished on time and within budget. Significant work has been done on improving and assessing productivity and activity at task, project, or industry levels. Task level productivity and activity analysis are used extensively within the construction industry for various purposes, including cost estimating, claim evaluation, and day-to-day project management. The assessment is mostly performed through visual observations and after-the-fact analyses even though previous studies show automatic translation of operations data into productivity information and provide spatial information of resources for specific construction operations. An original approach is presented that automatically assesses labor activity. Using data fusion of spatio-temporal and workers' thoracic posture data, a framework was developed for identifying and understanding the worker's activity type over time. This information is used to perform automatic work sampling that is expected to facilitate real-time productivity assessment. © 2012 Elsevier B.V. All rights reserved.},
  keywords = {Activity and task analysis,Construction worker,Data fusion,Health,Location tracking,Productivity,Safety,Sensors,Thoracic posture data,Workforce}
}

@article{chengAutomatedTasklevelActivity2013a,
  title = {Automated Task-Level Activity Analysis through Fusion of Real Time Location Sensors and Worker's Thoracic Posture Data},
  author = {Cheng, Tao and Teizer, Jochen and Migliaccio, Giovanni C. and Gatti, Umberto C.},
  date = {2013},
  journaltitle = {Automation in Construction},
  volume = {29},
  pages = {24--39},
  publisher = {{Elsevier B.V.}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2012.08.003},
  url = {http://dx.doi.org/10.1016/j.autcon.2012.08.003},
  abstract = {Knowledge of workforce productivity and activity is crucial for determining whether a construction project can be accomplished on time and within budget. Significant work has been done on improving and assessing productivity and activity at task, project, or industry levels. Task level productivity and activity analysis are used extensively within the construction industry for various purposes, including cost estimating, claim evaluation, and day-to-day project management. The assessment is mostly performed through visual observations and after-the-fact analyses even though previous studies show automatic translation of operations data into productivity information and provide spatial information of resources for specific construction operations. An original approach is presented that automatically assesses labor activity. Using data fusion of spatio-temporal and workers' thoracic posture data, a framework was developed for identifying and understanding the worker's activity type over time. This information is used to perform automatic work sampling that is expected to facilitate real-time productivity assessment. © 2012 Elsevier B.V. All rights reserved.},
  keywords = {Activity and task analysis,Construction worker,Data fusion,Health,Location tracking,Productivity,Safety,Sensors,Thoracic posture data,Workforce},
  file = {C:\Users\leemar\Zotero\storage\WL8LS9PX\1-s2.0-S0926580512001446-main.pdf}
}

@article{chengBioinspiredDesignAssembly2021,
  title = {Bioinspired Design and Assembly of a Multilayer Cage-Shaped Sensor Capable of Multistage Load Bearing and Collapse Prevention},
  author = {Cheng, X. and Liu, Z. and Jin, T. and Zhang, F. and Zhang, H. and Zhang, Y.},
  date = {2021},
  journaltitle = {Nanotechnology},
  volume = {32},
  number = {15},
  doi = {10.1088/1361-6528/abd581},
  abstract = {Flexible bioinspired mesostructures and electronic devices have recently attracted intense attention because of their widespread application in microelectromechanical systems (MEMS), reconfigurable electronics, health-monitoring systems, etc. Among various geometric constructions, 3D flexible bioinspired architectures are of particular interest, since they can provide new functions and capabilities, compared to their 2D counterparts. However, 3D electronic device systems usually undergo complicated mechanical loading in practical operation, resulting in complex deformation modes and elusive failure mechanisms. The development of mechanically robust flexible 3D electronics that can undergo extreme compression without irreversible collapse or fracture remains a challenge. Here, inspired by the multilayer mesostructure of Enhydra lutris fur, we introduce the design and assembly of multilayer cage architectures capable of multistage load bearing and collapse prevention under large out-of-plane compression. Combined in situ experiments and mechanical modeling show that the multistage mechanical responses of the developed bionic architectures can be fine-tuned by tailoring the microstructural geometries. The integration of functional layers of gold and piezoelectric polymer allows the development of a flexible multifunctional sensor that can simultaneously achieve the dynamic sensing of compressive forces and temperatures. The demonstrated capabilities and performances of fast response speed, tunable measurement range, excellent flexibility, and reliability suggest potential uses in MEMS, robotics and biointegrated electronics.}
}

@article{chengBioinspiredDesignAssembly2021a,
  title = {Bioinspired Design and Assembly of a Multilayer Cage-Shaped Sensor Capable of Multistage Load Bearing and Collapse Prevention},
  author = {Cheng, X. and Liu, Z. and Jin, T. and Zhang, F. and Zhang, H. and Zhang, Y.},
  date = {2021},
  journaltitle = {Nanotechnology},
  volume = {32},
  number = {15},
  doi = {10.1088/1361-6528/abd581},
  abstract = {Flexible bioinspired mesostructures and electronic devices have recently attracted intense attention because of their widespread application in microelectromechanical systems (MEMS), reconfigurable electronics, health-monitoring systems, etc. Among various geometric constructions, 3D flexible bioinspired architectures are of particular interest, since they can provide new functions and capabilities, compared to their 2D counterparts. However, 3D electronic device systems usually undergo complicated mechanical loading in practical operation, resulting in complex deformation modes and elusive failure mechanisms. The development of mechanically robust flexible 3D electronics that can undergo extreme compression without irreversible collapse or fracture remains a challenge. Here, inspired by the multilayer mesostructure of Enhydra lutris fur, we introduce the design and assembly of multilayer cage architectures capable of multistage load bearing and collapse prevention under large out-of-plane compression. Combined in situ experiments and mechanical modeling show that the multistage mechanical responses of the developed bionic architectures can be fine-tuned by tailoring the microstructural geometries. The integration of functional layers of gold and piezoelectric polymer allows the development of a flexible multifunctional sensor that can simultaneously achieve the dynamic sensing of compressive forces and temperatures. The demonstrated capabilities and performances of fast response speed, tunable measurement range, excellent flexibility, and reliability suggest potential uses in MEMS, robotics and biointegrated electronics.}
}

@inproceedings{chengHumanrobotInteractionMethod2021,
  title = {Human-Robot {{Interaction Method Combining Human Pose Estimation}} and {{Motion Intention Recognition}}},
  booktitle = {2021 {{IEEE}} 24th {{International Conference}} on {{Computer Supported Cooperative Work}} in {{Design}} ({{CSCWD}})},
  author = {Cheng, Yalin and Yi, Pengfei and Liu, Rui and Dong, Jing and Zhou, Dongsheng and Zhang, Qiang},
  date = {2021-05-05},
  pages = {958--963},
  publisher = {{IEEE}},
  doi = {10.1109/CSCWD49262.2021.9437772},
  url = {https://ieeexplore.ieee.org/document/9437772/},
  isbn = {978-1-72816-597-4},
  file = {C:\Users\leemar\Zotero\storage\S3U9SNCD\Human-robot_Interaction_Method_Combining_Human_Pose_Estimation_and_Motion_Intention_Recognition.pdf}
}

@inproceedings{chengHumanrobotInteractionMethod2021a,
  title = {Human-Robot {{Interaction Method Combining Human Pose Estimation}} and {{Motion Intention Recognition}}},
  booktitle = {Proceedings of the 2021 {{IEEE}} 24th {{International Conference}} on {{Computer Supported Cooperative Work}} in {{Design}}, {{CSCWD}} 2021},
  author = {Cheng, Yalin and Yi, Pengfei and Liu, Rui and Dong, Jing and Zhou, Dongsheng and Zhang, Qiang},
  date = {2021-05-05},
  pages = {958--963},
  publisher = {{IEEE}},
  doi = {10.1109/CSCWD49262.2021.9437772},
  url = {https://ieeexplore.ieee.org/document/9437772/},
  abstract = {Although human pose estimation technology based on RGB images is becoming more and more mature, most of the current mainstream methods rely on depth camera to obtain human joints information. These interaction frameworks are affected by the infrared detection distance so that they cannot well adapt to the interaction scene of different distance. Therefore, the purpose of this paper is to build a modular interactive framework based on RGB images, which aims to alleviate the problem of high dependence on depth camera and low adaptability to distance in the current human-robot interaction (HRI) framework based on human body by using advanced human pose estimation technology. To enhance the adaptability of the HRI framework to different distances, we adopt optical cameras instead of depth cameras as acquisition equipment. Firstly, the human joints information is extracted by a human pose estimation network. Then, a joints sequence filter is designed in the intermediate stage to reduce the influence of unreasonable skeletons on the interaction results. Finally, a human intention recognition model is built to recognize the human intention from reasonable joints information, and drive the robot to respond according to the predicted intention. The experimental results show that our interactive framework is more robust in the distance than the framework based on depth camera and is able to achieve effective interaction under different distances, illuminations, costumes, customers, and scenes.},
  isbn = {978-1-72816-597-4},
  keywords = {★,human pose estimation,human-robot interaction,intention recognition}
}

@inproceedings{chengHumanrobotInteractionMethod2021b,
  title = {Human-Robot {{Interaction Method Combining Human Pose Estimation}} and {{Motion Intention Recognition}}},
  booktitle = {2021 {{IEEE}} 24th {{International Conference}} on {{Computer Supported Cooperative Work}} in {{Design}} ({{CSCWD}})},
  author = {Cheng, Yalin and Yi, Pengfei and Liu, Rui and Dong, Jing and Zhou, Dongsheng and Zhang, Qiang},
  date = {2021-05-05},
  pages = {958--963},
  publisher = {{IEEE}},
  location = {{Dalian, China}},
  doi = {10.1109/CSCWD49262.2021.9437772},
  url = {https://ieeexplore.ieee.org/document/9437772/},
  urldate = {2023-03-20},
  eventtitle = {2021 {{IEEE}} 24th {{International Conference}} on {{Computer Supported Cooperative Work}} in {{Design}} ({{CSCWD}})},
  isbn = {978-1-72816-597-4}
}

@article{chenResearchModelingYingxian2017,
  title = {Research on the Modeling of {{Yingxian}} Wooden Tower Based on Revit and Revit {{API}}},
  author = {Chen, Q. and Wang, Y. and Wang, Y. and Li, M.},
  date = {2017},
  journaltitle = {Xi'an Jianzhu Keji Daxue Xuebao/Journal of Xi'an University of Architecture and Technology},
  volume = {49},
  number = {3},
  doi = {10.15986/j.1006-7930.2017.03.009},
  abstract = {In recent years, Building Information Modeling (BIM) technology was created and boomed because of its ability to integrate the modeling analysis of architecture, structure, facility, construction and management. However, BIM has not been commonly used in creating models of historic timber architecture. The present work used REVIT to create the models of Yingxian wooden tower, on the base of family. Details like Jieji,Taijie,Huagong,Nidaogong,Ludou,Gezimen,Goulan,Wuyan,Zhuzi,Liangfu,Chuan,Dougong were created and clear and systematic model information was established. Based on.NET platform and REVIT API, the method of creating DouGong by parameterization come up, reducing the difficulty of the work. As for the frame system model exported from REVIT, an equivalent member system model was used to replace the Dougong structure and a finite element analytical model was established. Finally, the overall mechanical properties of Yingxian Wooden Tower under earthquake and wind action was analyzed by SAP2000.The paper will work for the application of BIM in modeling and the structure analysis.}
}

@article{chenResearchModelingYingxian2017a,
  title = {Research on the Modeling of {{Yingxian}} Wooden Tower Based on Revit and Revit {{API}}},
  author = {Chen, Q. and Wang, Y. and Wang, Y. and Li, M.},
  date = {2017},
  journaltitle = {Xi'an Jianzhu Keji Daxue Xuebao/Journal of Xi'an University of Architecture and Technology},
  volume = {49},
  number = {3},
  doi = {10.15986/j.1006-7930.2017.03.009},
  abstract = {In recent years, Building Information Modeling (BIM) technology was created and boomed because of its ability to integrate the modeling analysis of architecture, structure, facility, construction and management. However, BIM has not been commonly used in creating models of historic timber architecture. The present work used REVIT to create the models of Yingxian wooden tower, on the base of family. Details like Jieji,Taijie,Huagong,Nidaogong,Ludou,Gezimen,Goulan,Wuyan,Zhuzi,Liangfu,Chuan,Dougong were created and clear and systematic model information was established. Based on.NET platform and REVIT API, the method of creating DouGong by parameterization come up, reducing the difficulty of the work. As for the frame system model exported from REVIT, an equivalent member system model was used to replace the Dougong structure and a finite element analytical model was established. Finally, the overall mechanical properties of Yingxian Wooden Tower under earthquake and wind action was analyzed by SAP2000.The paper will work for the application of BIM in modeling and the structure analysis.}
}

@article{chenThreeLayerWeightedFuzzy2018,
  title = {Three-{{Layer Weighted Fuzzy Support Vector Regression}} for {{Emotional Intention Understanding}} in {{Human}}–{{Robot Interaction}}},
  author = {Chen, Luefeng and Zhou, Mengtian and Wu, Min and She, Jinhua and Liu, Zhentao and Dong, Fangyan and Hirota, Kaoru},
  date = {2018-10},
  journaltitle = {IEEE Transactions on Fuzzy Systems},
  volume = {26},
  number = {5},
  pages = {2524--2538},
  issn = {1063-6706},
  doi = {10.1109/TFUZZ.2018.2809691},
  url = {https://ieeexplore.ieee.org/document/8302926/},
  abstract = {A three-layer weighted fuzzy support vector regression (TLWFSVR) model is proposed for understanding human intention, and it is based on the emotion-identification information in human-robot interaction. The TLWFSVR model consists of three layers, including adjusted weighted kernel fuzzy c-means for data clustering, fuzzy support vector regressions (FSVR) for information understanding, and weighted fusion for intention understanding. It aims to guarantee the quick convergence and satisfactory performance of the local FSVR via adjusting the weights of each feature in each cluster, in such a way that importance of different emotion-identification information is represented. Moreover, smooth human-oriented interaction can be obtained by endowing robot with human intention understanding capability. Experimental results show that the proposed TLWFSVR model obtains higher intention understanding accuracy and less computational time than that of two-layer fuzzy support vector regression, support vector regression, and back propagation neural network (BPNN), respectively. Additionally, the preliminary application experiments are performed in the developing human-robot interaction system, called emotional social robot system, where 12 volunteers and 2 mobile robots experience a scenario of 'drinking at a bar.' Application results indicate that the bartender robot is able to understand customers' order intentions.}
}

@article{chenThreeLayerWeightedFuzzy2018a,
  title = {Three-{{Layer Weighted Fuzzy Support Vector Regression}} for {{Emotional Intention Understanding}} in {{Human}}–{{Robot Interaction}}},
  author = {Chen, Luefeng and Zhou, Mengtian and Wu, Min and She, Jinhua and Liu, Zhentao and Dong, Fangyan and Hirota, Kaoru},
  date = {2018-10},
  journaltitle = {IEEE Transactions on Fuzzy Systems},
  volume = {26},
  number = {5},
  pages = {2524--2538},
  issn = {1063-6706},
  doi = {10.1109/TFUZZ.2018.2809691},
  url = {https://ieeexplore.ieee.org/document/8302926/},
  abstract = {A three-layer weighted fuzzy support vector regression (TLWFSVR) model is proposed for understanding human intention, and it is based on the emotion-identification information in human-robot interaction. The TLWFSVR model consists of three layers, including adjusted weighted kernel fuzzy c-means for data clustering, fuzzy support vector regressions (FSVR) for information understanding, and weighted fusion for intention understanding. It aims to guarantee the quick convergence and satisfactory performance of the local FSVR via adjusting the weights of each feature in each cluster, in such a way that importance of different emotion-identification information is represented. Moreover, smooth human-oriented interaction can be obtained by endowing robot with human intention understanding capability. Experimental results show that the proposed TLWFSVR model obtains higher intention understanding accuracy and less computational time than that of two-layer fuzzy support vector regression, support vector regression, and back propagation neural network (BPNN), respectively. Additionally, the preliminary application experiments are performed in the developing human-robot interaction system, called emotional social robot system, where 12 volunteers and 2 mobile robots experience a scenario of 'drinking at a bar.' Application results indicate that the bartender robot is able to understand customers' order intentions.}
}

@article{chenThreeLayerWeightedFuzzy2018b,
  title = {Three-{{Layer Weighted Fuzzy Support Vector Regression}} for {{Emotional Intention Understanding}} in {{Human}}–{{Robot Interaction}}},
  author = {Chen, Luefeng and Zhou, Mengtian and Wu, Min and She, Jinhua and Liu, Zhentao and Dong, Fangyan and Hirota, Kaoru},
  date = {2018-10},
  journaltitle = {IEEE Transactions on Fuzzy Systems},
  shortjournal = {IEEE Trans. Fuzzy Syst.},
  volume = {26},
  number = {5},
  pages = {2524--2538},
  issn = {1063-6706, 1941-0034},
  doi = {10.1109/TFUZZ.2018.2809691},
  url = {https://ieeexplore.ieee.org/document/8302926/},
  urldate = {2023-03-20}
}

@article{chenThreeLayerWeightedFuzzy2021,
  title = {Three-{{Layer Weighted Fuzzy Support Vector Regressions}} for {{Emotional Intention Understanding}}},
  author = {Chen, Luefeng and Wu, Min and Pedrycz, Witold and Hirota, Kaoru},
  date = {2021},
  journaltitle = {Studies in Computational Intelligence},
  volume = {926},
  number = {5},
  pages = {133--159},
  publisher = {{IEEE}},
  issn = {18609503},
  doi = {10.1007/978-3-030-61577-2_9},
  abstract = {A three-layer weighted fuzzy support vector regression (TLWFSVR) model is proposed for understanding human intention, and it is based on the emotion-identification information in human-robot interaction. TLWFSVR model consists of three layers, including adjusted weighted kernel fuzzy c-means (AWKFCM) for data clustering, fuzzy support vector regressions (FSVR) for information understanding, and weighted fusion for intention understanding.}
}

@article{chenThreeLayerWeightedFuzzy2021a,
  title = {Three-{{Layer Weighted Fuzzy Support Vector Regressions}} for {{Emotional Intention Understanding}}},
  author = {Chen, Luefeng and Wu, Min and Pedrycz, Witold and Hirota, Kaoru},
  date = {2021},
  journaltitle = {Studies in Computational Intelligence},
  volume = {926},
  number = {5},
  pages = {133--159},
  publisher = {{IEEE}},
  issn = {18609503},
  doi = {10.1007/978-3-030-61577-2_9},
  abstract = {A three-layer weighted fuzzy support vector regression (TLWFSVR)~model is proposed for understanding human intention, and it is based on the emotion-identification information in human-robot interaction. TLWFSVR model consists of three layers, including adjusted weighted kernel fuzzy c-means (AWKFCM) for data clustering, fuzzy support vector regressions (FSVR)~for information understanding, and weighted fusion for intention understanding.},
  keywords = {★},
  file = {C:\Users\leemar\Zotero\storage\NQFYDE9S\Three-Layer_Weighted_Fuzzy_Support_Vector_Regression_for_Emotional_Intention_Understanding_in_HumanRobot_Interaction.pdf}
}

@article{chenTrackingCompletionParts2020,
  title = {Tracking the Completion of Parts into Whole Objects: {{Retinotopic}} Activation in Response to Illusory Figures in the Lateral Occipital Complex},
  author = {Chen, S. and Weidner, R. and Zeng, H. and Fink, G. R. and Müller, H. J. and Conci, M.},
  date = {2020},
  journaltitle = {NeuroImage},
  volume = {207},
  doi = {10.1016/j.neuroimage.2019.116426},
  abstract = {Illusory figures demonstrate the visual system's ability to integrate separate parts into coherent, whole objects. The present study was performed to track the neuronal object construction process in human observers, by incrementally manipulating the grouping strength within a given configuration until the emergence of a whole-object representation. Two tasks were employed: First, in the spatial localization task, object completion could facilitate performance and was task-relevant, whereas it was irrelevant in the second, luminance discrimination task. Concurrent functional magnetic resonance imaging (fMRI) used spatial localizers to locate brain regions representing task-critical illusory-figure parts to investigate whether the step-wise object construction process would modulate neural activity in these localized brain regions. The results revealed that both V1 and the lateral occipital complex (LOC, with sub-regions LO1 and LO2) were involved in Kanizsa figure processing. However, completion-specific activations were found predominantly in LOC, where neural activity exhibited a modulation in accord with the configuration's grouping strength, whether or not the configuration was relevant to performing the task at hand. Moreover, right LOC activations were confined to LO2 and responded primarily to surface and shape completions, whereas left LOC exhibited activations in both LO1 and LO2 and was related to encoding shape structures with more detail. Together, these results demonstrate that various grouping properties within a visual scene are integrated automatically in LOC, with sub-regions located in different hemispheres specializing in the component sub-processes that render completed objects.}
}

@article{chenTrackingCompletionParts2020a,
  title = {Tracking the Completion of Parts into Whole Objects: {{Retinotopic}} Activation in Response to Illusory Figures in the Lateral Occipital Complex},
  author = {Chen, S. and Weidner, R. and Zeng, H. and Fink, G.R. and Müller, H.J. and Conci, M.},
  date = {2020},
  journaltitle = {NeuroImage},
  volume = {207},
  doi = {10.1016/j.neuroimage.2019.116426},
  abstract = {Illusory figures demonstrate the visual system's ability to integrate separate parts into coherent, whole objects. The present study was performed to track the neuronal object construction process in human observers, by incrementally manipulating the grouping strength within a given configuration until the emergence of a whole-object representation. Two tasks were employed: First, in the spatial localization task, object completion could facilitate performance and was task-relevant, whereas it was irrelevant in the second, luminance discrimination task. Concurrent functional magnetic resonance imaging (fMRI) used spatial localizers to locate brain regions representing task-critical illusory-figure parts to investigate whether the step-wise object construction process would modulate neural activity in these localized brain regions. The results revealed that both V1 and the lateral occipital complex (LOC, with sub-regions LO1 and LO2) were involved in Kanizsa figure processing. However, completion-specific activations were found predominantly in LOC, where neural activity exhibited a modulation in accord with the configuration's grouping strength, whether or not the configuration was relevant to performing the task at hand. Moreover, right LOC activations were confined to LO2 and responded primarily to surface and shape completions, whereas left LOC exhibited activations in both LO1 and LO2 and was related to encoding shape structures with more detail. Together, these results demonstrate that various grouping properties within a visual scene are integrated automatically in LOC, with sub-regions located in different hemispheres specializing in the component sub-processes that render completed objects.}
}

@inproceedings{chenVisionBasedExcavatorActivity2019,
  title = {Vision-{{Based Excavator Activity Recognition}} and {{Productivity Analysis}} in {{Construction}}},
  booktitle = {Computing in {{Civil Engineering}} 2019: {{Data}}, {{Sensing}}, and {{Analytics}} - {{Selected Papers}} from the {{ASCE International Conference}} on {{Computing}} in {{Civil Engineering}} 2019},
  author = {Chen, C. and Zhu, Z. and Hammad, A. and Ahmed, W.},
  date = {2019},
  pages = {241--248},
  abstract = {Equipment activity recognition plays an important role in automating the analysis of onsite construction productivity, considering that human observation is always labor-intensive and time-consuming. Recently, several methods have been proposed to recognize the activity of construction equipment from videos. However, one of their common issues is the failure to conduct the recognition in a long video for classifying a sequence of equipment activities. This paper proposes a novel equipment recognition method with the support of a three-dimensional (3D) convolutional neural network. The network could extract both temporal and spatial information of the equipment to recognize its activities in a long video. The recognition results are further compiled and analyzed to identify the equipment productivity. The proposed method was tested to recognize the excavator activities (digging, swinging, and loading) on real construction sites. The results showed that the method outperformed existing equipment activity recognition methods in terms of accuracy and robustness.},
  isbn = {978-0-7844-8243-8}
}

@inproceedings{chenVisionBasedExcavatorActivity2019a,
  title = {Vision-{{Based Excavator Activity Recognition}} and {{Productivity Analysis}} in {{Construction}}},
  booktitle = {Computing in {{Civil Engineering}} 2019: {{Data}}, {{Sensing}}, and {{Analytics}} - {{Selected Papers}} from the {{ASCE International Conference}} on {{Computing}} in {{Civil Engineering}} 2019},
  author = {Chen, C. and Zhu, Z. and Hammad, A. and Ahmed, W.},
  date = {2019},
  pages = {241--248},
  abstract = {Equipment activity recognition plays an important role in automating the analysis of onsite construction productivity, considering that human observation is always labor-intensive and time-consuming. Recently, several methods have been proposed to recognize the activity of construction equipment from videos. However, one of their common issues is the failure to conduct the recognition in a long video for classifying a sequence of equipment activities. This paper proposes a novel equipment recognition method with the support of a three-dimensional (3D) convolutional neural network. The network could extract both temporal and spatial information of the equipment to recognize its activities in a long video. The recognition results are further compiled and analyzed to identify the equipment productivity. The proposed method was tested to recognize the excavator activities (digging, swinging, and loading) on real construction sites. The results showed that the method outperformed existing equipment activity recognition methods in terms of accuracy and robustness.},
  isbn = {978-0-7844-8243-8}
}

@inproceedings{choDevelopmentParametricLibraries2016,
  title = {Development of Parametric Libraries for {{BIM}} of {{Korean}} Traditional Wooden Structure({{HanOk}})},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Cho, J. and Lee, B. and Yoon, J.},
  date = {2016},
  abstract = {The purpose of this study is to develop a building information modelling (BIM) design process for Korean traditional wooden construction (HanOk). Member design information and parametric libraries have been derived from the BIM design procedure. The design created through this developed process is examined using the libraries for HanOk construction.},
  isbn = {978-3-903039-00-1}
}

@inproceedings{choDevelopmentParametricLibraries2016a,
  title = {Development of Parametric Libraries for {{BIM}} of {{Korean}} Traditional Wooden Structure({{HanOk}})},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Cho, J. and Lee, B. and Yoon, J.},
  date = {2016},
  abstract = {The purpose of this study is to develop a building information modelling (BIM) design process for Korean traditional wooden construction (HanOk). Member design information and parametric libraries have been derived from the BIM design procedure. The design created through this developed process is examined using the libraries for HanOk construction.},
  isbn = {978-3-903039-00-1}
}

@article{cisternasTimeWorklifeConflict2020,
  title = {Time in Work-Life Conflict: {{The}} Case of Academic Women in Managerial Universities | {{El}} Tiempo En El Conflicto Trabajo-Vida: {{El}} Caso de Las Académicas En La Universidad Managerial},
  author = {Cisternas, C. F. and Navia, A. C.},
  date = {2020},
  journaltitle = {Psicoperspectivas},
  volume = {19},
  number = {3},
  doi = {10.5027/psicoperspectivas-Vol19-Issue3-fulltext-2051},
  abstract = {Background In recent decades, the university and academic work have been reorganized under the guidance of Neomanagement, cultivating a new ethos in its culture and subjects. International studies show an accelerated, hyper-productive, competitive, and hyper-individualized academy with important consequences for the lives of academics (Gill, 2009; Jenkins, 2020; Slaughter, \& Leslie, 1997). In this regard, the literature consistently reports increased stress and anxiety; intensification, extensification, and diversification of work; job insecurity; feelings of lack of recognition and hyper-responsibility (Gill, 2009; Langford, 2010; Shahid et al., 2016). The academy, accelerated and competitive, is configured as an absorbing and demanding work space, while seducing through promises of success and recognition. In this way, the subjects, trapped in the academy, recognize that they are under pressure to successfully fulfill the goals of their work while developing vital non-academic projects (Langford, 2010; Shahid et al., 2016). Likewise, a series of investigations show how academics associate subjective discomfort with the daily difficulty of reconciling work and life demands (Metcalfe et al., 2008). This difficulty is particularly accentuated in academic women (Ivancheva et al., 2019; Jenkins, 2020; Shahid et al., 2016). While probity and meritocratic systems at the base of academic management have mitigated arbitrariness and historical gender gaps in universities, successful female researchers have assumed a high personal cost. This personal cost is related to the so-called work-life conflict (Pérez, 2014), and its dimensions such as: the double workday, the choice between a scientific career or forming a family, as well as social pressure and individual responsibility for reconciling the demands of academia and family life. The dimension of time is a central aspect in this conflict and its study has been reduced to the unequal use and value between men and women (Ivancheva et al., 2019; Jenkins, 2020), neglecting subjective and qualitative aspects. Aims In this paper we propose to understand, in a specific and situated way, how academics build time and its relation to the work-life conflict in a context of managerialization of Chilean universities (Denzin \& Lincoln, 2003; Flick, 2004). Method \& procedures Twenty researchers from different disciplines and Chilean universities (private and state) participated in this study, with funded research projects and scientific production in indexed journals (Scopus or WoS). Likewise, all of them are perceived as women who have dependent relationships (children or other people to care for). For the production of data, we opted for the technique of active interviews, whose distinctive quality is the production of discourses, through the fluid and flexible interaction between interviewers and interviewees (Holstein, \& Gubrium, 1995). The analysis of the data was guided by the strategy of interpretive repertoires (Potter, \& Wetherell, 1987). Results \& discussion In this section we present three interpretive repertoires, which do not seek to give an account of a particular pattern for each participant, but to show the construction of time and to identify recurrent subjective positions around the work-life conflict. The first repertoire is an analytical category that groups multiple stories about unfinished tasks and work, and demands that emerge again and again. The overload of activities in the stories of the scholars are a central axis to represent time as a dimension that urges and governs the experience of the researchers. This repertoire then refers to how speakers construct time as infinite, demanding and overflowing, while taking a subjective position in which time is suffered. The second repertoire identified refers to the construction of time as an object to be administered. This repertoire shows a definition of time as a resource to be measured, calculated, managed and optimized. As opposed to and simultaneously with the previous repertoire, where time is constructed as a continuum of activities without limit, this second repertoire shows a contained time, limited and circumscribed to manipulable units. The third repertoire groups a series of stories where the scholars show creativity and alternatives to the conventional modes of organization and use of time. In this repertoire, time emerges as a dynamic conformation of heterogeneous and multidirectional units, disassociating itself from its linear order that only moves forward or backward in one direction. Thus, this category - above all - questions the experience and universal meaning of time, where women and men are subjected to a standard and universal time (Wajcman, 2017). Conclusion The results presented show that the construction of time and the subjective position in the face of the capital-life conflict is crossed by gender dimensions. Thus, in the face of an imposing academic work, it is possible to construct a rhetoric of suffering time and simultaneously another around time as a resource that must be rigorously administered in order to construct the temporal, spatial and symbolic borders between work and life. These stories of control and the establishment of limits appear to be crucial for organizing everyday life and show an active subjective position that seeks to respond individually to the capital-life conflict. The third repertoire opens lights on a polyphonic and alternative feminine temporal experience, which positions itself creatively to articulate and reconcile times, challenging the canonical model of social time in work. In this way, this work is, above all, a comprehensive exercise of time from the feminine experience and how through it the hegemony of the temporal dimension is cracked, which not only hides a vision centered on masculine experiences, but also a perspective proper to Western capitalist societies. Although the times of life and (academic) work appear to be irreconcilable and confrontational, the stories analyzed show how academics continually attempt to articulate them and to weave a bridge between the two. The repertoires make visible from the everyday, an active search that provides continuity to the spheres of work and life; allowing levels of agency in this scenario of intelligible time, where alternate subjectivities are filtered and resisted.}
}

@article{cisternasTimeWorklifeConflict2020a,
  title = {Time in Work-Life Conflict: {{The}} Case of Academic Women in Managerial Universities | {{El}} Tiempo En El Conflicto Trabajo-Vida: {{El}} Caso de Las Académicas En La Universidad Managerial},
  author = {Cisternas, C.F. and Navia, A.C.},
  date = {2020},
  journaltitle = {Psicoperspectivas},
  volume = {19},
  number = {3},
  doi = {10.5027/psicoperspectivas-Vol19-Issue3-fulltext-2051},
  abstract = {Background In recent decades, the university and academic work have been reorganized under the guidance of Neomanagement, cultivating a new ethos in its culture and subjects. International studies show an accelerated, hyper-productive, competitive, and hyper-individualized academy with important consequences for the lives of academics (Gill, 2009; Jenkins, 2020; Slaughter, \& Leslie, 1997). In this regard, the literature consistently reports increased stress and anxiety; intensification, extensification, and diversification of work; job insecurity; feelings of lack of recognition and hyper-responsibility (Gill, 2009; Langford, 2010; Shahid et al., 2016). The academy, accelerated and competitive, is configured as an absorbing and demanding work space, while seducing through promises of success and recognition. In this way, the subjects, trapped in the academy, recognize that they are under pressure to successfully fulfill the goals of their work while developing vital non-academic projects (Langford, 2010; Shahid et al., 2016). Likewise, a series of investigations show how academics associate subjective discomfort with the daily difficulty of reconciling work and life demands (Metcalfe et al., 2008). This difficulty is particularly accentuated in academic women (Ivancheva et al., 2019; Jenkins, 2020; Shahid et al., 2016). While probity and meritocratic systems at the base of academic management have mitigated arbitrariness and historical gender gaps in universities, successful female researchers have assumed a high personal cost. This personal cost is related to the so-called work-life conflict (Pérez, 2014), and its dimensions such as: the double workday, the choice between a scientific career or forming a family, as well as social pressure and individual responsibility for reconciling the demands of academia and family life. The dimension of time is a central aspect in this conflict and its study has been reduced to the unequal use and value between men and women (Ivancheva et al., 2019; Jenkins, 2020), neglecting subjective and qualitative aspects. Aims In this paper we propose to understand, in a specific and situated way, how academics build time and its relation to the work-life conflict in a context of managerialization of Chilean universities (Denzin \& Lincoln, 2003; Flick, 2004). Method \& procedures Twenty researchers from different disciplines and Chilean universities (private and state) participated in this study, with funded research projects and scientific production in indexed journals (Scopus or WoS). Likewise, all of them are perceived as women who have dependent relationships (children or other people to care for). For the production of data, we opted for the technique of active interviews, whose distinctive quality is the production of discourses, through the fluid and flexible interaction between interviewers and interviewees (Holstein, \& Gubrium, 1995). The analysis of the data was guided by the strategy of interpretive repertoires (Potter, \& Wetherell, 1987). Results \& discussion In this section we present three interpretive repertoires, which do not seek to give an account of a particular pattern for each participant, but to show the construction of time and to identify recurrent subjective positions around the work-life conflict. The first repertoire is an analytical category that groups multiple stories about unfinished tasks and work, and demands that emerge again and again. The overload of activities in the stories of the scholars are a central axis to represent time as a dimension that urges and governs the experience of the researchers. This repertoire then refers to how speakers construct time as infinite, demanding and overflowing, while taking a subjective position in which time is suffered. The second repertoire identified refers to the construction of time as an object to be administered. This repertoire shows a definition of time as a resource to be measured, calculated, managed and optimized. As opposed to and simultaneously with the previous repertoire, where time is constructed as a continuum of activities without limit, this second repertoire shows a contained time, limited and circumscribed to manipulable units. The third repertoire groups a series of stories where the scholars show creativity and alternatives to the conventional modes of organization and use of time. In this repertoire, time emerges as a dynamic conformation of heterogeneous and multidirectional units, disassociating itself from its linear order that only moves forward or backward in one direction. Thus, this category - above all - questions the experience and universal meaning of time, where women and men are subjected to a standard and universal time (Wajcman, 2017). Conclusion The results presented show that the construction of time and the subjective position in the face of the capital-life conflict is crossed by gender dimensions. Thus, in the face of an imposing academic work, it is possible to construct a rhetoric of suffering time and simultaneously another around time as a resource that must be rigorously administered in order to construct the temporal, spatial and symbolic borders between work and life. These stories of control and the establishment of limits appear to be crucial for organizing everyday life and show an active subjective position that seeks to respond individually to the capital-life conflict. The third repertoire opens lights on a polyphonic and alternative feminine temporal experience, which positions itself creatively to articulate and reconcile times, challenging the canonical model of social time in work. In this way, this work is, above all, a comprehensive exercise of time from the feminine experience and how through it the hegemony of the temporal dimension is cracked, which not only hides a vision centered on masculine experiences, but also a perspective proper to Western capitalist societies. Although the times of life and (academic) work appear to be irreconcilable and confrontational, the stories analyzed show how academics continually attempt to articulate them and to weave a bridge between the two. The repertoires make visible from the everyday, an active search that provides continuity to the spheres of work and life; allowing levels of agency in this scenario of intelligible time, where alternate subjectivities are filtered and resisted.}
}

@article{corrissActionImaginationFormation1998,
  title = {Action and Imagination in the Formation of Images},
  author = {Corriss, D. and Kose, G.},
  date = {1998},
  journaltitle = {Perceptual and Motor Skills},
  volume = {87},
  pages = {979--983},
  doi = {10.2466/pms.1998.87.3.979},
  abstract = {This study examined the influence of motor enactment on the formation of mental images. Following a procedure originally used by Piaget and Inhelder in 1971, 5-yr.-old children were assigned to one of four treatments. They visually examined block configurations, imagined the construction of the configurations, imagined enacting the construction, or carried out the actual construction. When the original configurations were removed, the children were asked to reconstruct them from memory. Analysis showed that the children in the imaginary enactment and actual construction conditions were more accurate than those in the other conditions. The findings are discussed as supporting an action-based understanding of imagination.},
  issue = {3 PART 1}
}

@article{corrissActionImaginationFormation1998a,
  title = {Action and Imagination in the Formation of Images},
  author = {Corriss, D. and Kose, G.},
  date = {1998},
  journaltitle = {Perceptual and Motor Skills},
  volume = {87},
  pages = {979--983},
  doi = {10.2466/pms.1998.87.3.979},
  abstract = {This study examined the influence of motor enactment on the formation of mental images. Following a procedure originally used by Piaget and Inhelder in 1971, 5-yr.-old children were assigned to one of four treatments. They visually examined block configurations, imagined the construction of the configurations, imagined enacting the construction, or carried out the actual construction. When the original configurations were removed, the children were asked to reconstruct them from memory. Analysis showed that the children in the imaginary enactment and actual construction conditions were more accurate than those in the other conditions. The findings are discussed as supporting an action-based understanding of imagination.},
  issue = {3 PART 1}
}

@inproceedings{coupeteNewChallengesHumanrobot2016,
  title = {New Challenges for Human-Robot Collaboration in an Industrial Context: {{Acceptability}} and Natural Collaboration},
  booktitle = {Fifth Workshop" towards a {{Framework}} for {{Joint Action}}", {{iEEE RO-MAN}} 2016},
  author = {Coupeté, Eva and Weistroffer, Vincent and Hugues, Olivier and Moutarde, Fabien and Manitsaris, Sotiris and Fuchs, Philippe},
  date = {2016}
}

@article{crespoAdaptiveDetectionAttention2009,
  title = {An Adaptive Detection/Attention Mechanism for Real Time Robot Operation},
  author = {Crespo, J.L. and Faiña, A. and Duro, R.J.},
  date = {2009},
  journaltitle = {Neurocomputing},
  volume = {72},
  number = {4-6},
  pages = {850--860},
  doi = {10.1016/j.neucom.2008.06.023},
  abstract = {During the lifetime of a mobile robot, the number and complexity of the stimuli it receives may be quite high. Therefore, the construction of a detection system considering the whole sensorial space is usually not a viable proposition when aiming for real time operation. It becomes necessary to build some kind of sensorial hierarchy map to put some order into how detectors are applied. This is what is usually called an attentional system, and it provides a framework for applying detectors in a more efficient manner. In this paper, an architecture for developing attentional functions for robots that must operate in real time in dynamic environments is presented. This architecture is based on the concept of attentor and it allows for the real time adaptation to the environment and tasks to be performed in a natural manner. One of the main requirements imposed on the design of the architecture was the capability of handling different sensorial modalities and attentional streams in a transparent manner while, at the same time, being able to progressively create more complex attentional structures. The architecture is particularized for its implementation in a real robot. © 2008 Elsevier B.V. All rights reserved.}
}

@article{crespoAdaptiveDetectionAttention2009a,
  title = {An Adaptive Detection/Attention Mechanism for Real Time Robot Operation},
  author = {Crespo, J.L. and Faiña, A. and Duro, R.J.},
  date = {2009},
  journaltitle = {Neurocomputing},
  volume = {72},
  number = {4-6},
  pages = {850--860},
  doi = {10.1016/j.neucom.2008.06.023},
  abstract = {During the lifetime of a mobile robot, the number and complexity of the stimuli it receives may be quite high. Therefore, the construction of a detection system considering the whole sensorial space is usually not a viable proposition when aiming for real time operation. It becomes necessary to build some kind of sensorial hierarchy map to put some order into how detectors are applied. This is what is usually called an attentional system, and it provides a framework for applying detectors in a more efficient manner. In this paper, an architecture for developing attentional functions for robots that must operate in real time in dynamic environments is presented. This architecture is based on the concept of attentor and it allows for the real time adaptation to the environment and tasks to be performed in a natural manner. One of the main requirements imposed on the design of the architecture was the capability of handling different sensorial modalities and attentional streams in a transparent manner while, at the same time, being able to progressively create more complex attentional structures. The architecture is particularized for its implementation in a real robot. © 2008 Elsevier B.V. All rights reserved.}
}

@article{daiSharedControlBased2021,
  title = {Shared {{Control Based}} on a {{Brain-Computer Interface}} for {{Human-Multirobot Cooperation}}},
  author = {Dai, W. and Liu, Y. and Lu, H. and Zhou, Z. and Zhen, Z.},
  date = {2021},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {6123--6130},
  doi = {10.1109/LRA.2021.3091170},
  abstract = {Currently, distributed multi-robot systems (MRSs) can meet the requirements of various tasks in complex environments. Nevertheless, the inevitable disadvantages of robot sensor errors, communication delays, and obstructive environmental factors hinder the operation of MRSs. Therefore, a shared control approach supported by human intention has emerged, relying on human experience and knowledge to improve cooperation. With firefighting tasks as the application background, this letter considers a brain-computer interface as the means of input for human intention and proposes a layered shared control framework suitable for human-multirobot cooperation. In the upper layer of the framework, an intention field model is used to construct the shared intention of the human and robots, and in the lower layer, a policy-blending model is employed to fuse the various velocity components for shared intention, formation control, and obstacle avoidance. Ultimately, the proposed human-multirobot shared control framework effectively avoids the inherent disadvantages of a single control source (either the human or robots), enabling the robot team to efficiently, safely and flexibly complete all tasks. In addition, we have designed and performed both simulated and practical experiments to fully illustrate the effectiveness and operability of the proposed shared control framework.}
}

@article{daiSharedControlBased2021a,
  title = {Shared {{Control Based}} on a {{Brain-Computer Interface}} for {{Human-Multirobot Cooperation}}},
  author = {Dai, W. and Liu, Y. and Lu, H. and Zhou, Z. and Zhen, Z.},
  date = {2021},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {6123--6130},
  doi = {10.1109/LRA.2021.3091170},
  abstract = {Currently, distributed multi-robot systems (MRSs) can meet the requirements of various tasks in complex environments. Nevertheless, the inevitable disadvantages of robot sensor errors, communication delays, and obstructive environmental factors hinder the operation of MRSs. Therefore, a shared control approach supported by human intention has emerged, relying on human experience and knowledge to improve cooperation. With firefighting tasks as the application background, this letter considers a brain-computer interface as the means of input for human intention and proposes a layered shared control framework suitable for human-multirobot cooperation. In the upper layer of the framework, an intention field model is used to construct the shared intention of the human and robots, and in the lower layer, a policy-blending model is employed to fuse the various velocity components for shared intention, formation control, and obstacle avoidance. Ultimately, the proposed human-multirobot shared control framework effectively avoids the inherent disadvantages of a single control source (either the human or robots), enabling the robot team to efficiently, safely and flexibly complete all tasks. In addition, we have designed and performed both simulated and practical experiments to fully illustrate the effectiveness and operability of the proposed shared control framework.}
}

@inproceedings{dallelInHARDIndustrialHumanAction2020,
  title = {{{InHARD-Industrial Human Action Recognition Dataset}} in the {{Context}} of {{Industrial Collaborative Robotics}}},
  booktitle = {Proceedings of the 2020 {{IEEE International Conference}} on {{Human-Machine Systems}}, {{ICHMS}} 2020},
  author = {Dallel, M. and Havard, V. and Baudry, D. and Savatier, X.},
  date = {2020},
  doi = {10.1109/ICHMS49158.2020.9209531},
  abstract = {Nowadays, humans and robots are working more closely together. This increases business productivity and product quality, leading to efficiency and growth. However, human and robot collaboration is rather static; robots move to a specific position then humans perform their tasks while being assisted by the robots. In order to get a dynamic collaboration, robots need to understand the human's intention and learn to recognize the performed actions complementing therefore his capabilities and relieving him of arduous tasks. Consequently, there is a need for a human action recognition dataset for Machine Learning algorithms. Currently available depth-based and RGB+D+S based human action recognition datasets have a number of limitations, counting the lack of training samples along with distinct class labels, camera views, diversity of subjects and more importantly the absence of actual industrial human actions in an industrial environment. Actual action recognition datasets include simple daily, mutual, or healthrelated actions. Therefore, in this paper we introduce an RGB+ S dataset named 'Industrial Human Action Recognition Dataset' (InHARD) from a real-world setting for industrial human action recognition with over 2 million frames, collected from 16 distinct subjects. This dataset contains 13 different industrial action classes and over 4800 action samples. The introduction of this dataset should allow us the study and development of various learning techniques for the task of human actions analysis inside industrial environments involving human robot collaborations.},
  isbn = {978-1-72815-871-6}
}

@inproceedings{dallelInHARDIndustrialHumanAction2020a,
  title = {{{InHARD-Industrial Human Action Recognition Dataset}} in the {{Context}} of {{Industrial Collaborative Robotics}}},
  booktitle = {Proceedings of the 2020 {{IEEE International Conference}} on {{Human-Machine Systems}}, {{ICHMS}} 2020},
  author = {Dallel, M. and Havard, V. and Baudry, D. and Savatier, X.},
  date = {2020},
  doi = {10.1109/ICHMS49158.2020.9209531},
  abstract = {Nowadays, humans and robots are working more closely together. This increases business productivity and product quality, leading to efficiency and growth. However, human and robot collaboration is rather static; robots move to a specific position then humans perform their tasks while being assisted by the robots. In order to get a dynamic collaboration, robots need to understand the human's intention and learn to recognize the performed actions complementing therefore his capabilities and relieving him of arduous tasks. Consequently, there is a need for a human action recognition dataset for Machine Learning algorithms. Currently available depth-based and RGB+D+S based human action recognition datasets have a number of limitations, counting the lack of training samples along with distinct class labels, camera views, diversity of subjects and more importantly the absence of actual industrial human actions in an industrial environment. Actual action recognition datasets include simple daily, mutual, or healthrelated actions. Therefore, in this paper we introduce an RGB+ S dataset named 'Industrial Human Action Recognition Dataset' (InHARD) from a real-world setting for industrial human action recognition with over 2 million frames, collected from 16 distinct subjects. This dataset contains 13 different industrial action classes and over 4800 action samples. The introduction of this dataset should allow us the study and development of various learning techniques for the task of human actions analysis inside industrial environments involving human robot collaborations.},
  isbn = {978-1-72815-871-6}
}

@article{danielInimInertialImages2021,
  title = {Inim: {{Inertial}} Images Construction with Applications to Activity Recognition},
  author = {Daniel, N. and Klein, I.},
  date = {2021},
  journaltitle = {Sensors},
  volume = {21},
  number = {14},
  doi = {10.3390/s21144787},
  abstract = {Human activity recognition aims to classify the user activity in various applications like healthcare, gesture recognition and indoor navigation. In the latter, smartphone location recognition is gaining more attention as it enhances indoor positioning accuracy. Commonly the smartphone’s inertial sensor readings are used as input to a machine learning algorithm which performs the classification. There are several approaches to tackle such a task: feature based approaches, one dimensional deep learning algorithms, and two dimensional deep learning architectures. When using deep learning approaches, feature engineering is redundant. In addition, while utilizing two-dimensional deep learning approaches enables to utilize methods from the well-established computer vision domain. In this paper, a framework for smartphone location and human activity recognition, based on the smartphone’s inertial sensors, is proposed. The contributions of this work are a novel time series encoding approach, from inertial signals to inertial images, and transfer learning from computer vision domain to the inertial sensors classification problem. Four different datasets are employed to show the benefits of using the proposed approach. In addition, as the proposed framework performs classification on inertial sensors readings, it can be applied for other classification tasks using inertial data. It can also be adopted to handle other types of sensory data collected for a classification task.}
}

@article{danielInimInertialImages2021a,
  title = {Inim: {{Inertial}} Images Construction with Applications to Activity Recognition},
  author = {Daniel, N. and Klein, I.},
  date = {2021},
  journaltitle = {Sensors},
  volume = {21},
  number = {14},
  doi = {10.3390/s21144787},
  abstract = {Human activity recognition aims to classify the user activity in various applications like healthcare, gesture recognition and indoor navigation. In the latter, smartphone location recognition is gaining more attention as it enhances indoor positioning accuracy. Commonly the smartphone’s inertial sensor readings are used as input to a machine learning algorithm which performs the classification. There are several approaches to tackle such a task: feature based approaches, one dimensional deep learning algorithms, and two dimensional deep learning architectures. When using deep learning approaches, feature engineering is redundant. In addition, while utilizing two-dimensional deep learning approaches enables to utilize methods from the well-established computer vision domain. In this paper, a framework for smartphone location and human activity recognition, based on the smartphone’s inertial sensors, is proposed. The contributions of this work are a novel time series encoding approach, from inertial signals to inertial images, and transfer learning from computer vision domain to the inertial sensors classification problem. Four different datasets are employed to show the benefits of using the proposed approach. In addition, as the proposed framework performs classification on inertial sensors readings, it can be applied for other classification tasks using inertial data. It can also be adopted to handle other types of sensory data collected for a classification task.}
}

@article{daniHumanintheLoopRobotControl2020,
  title = {Human-in-the-{{Loop Robot Control}} for {{Human-Robot Collaboration}}: {{Human Intention Estimation}} and {{Safe Trajectory Tracking Control}} for {{Collaborative Tasks}}},
  author = {Dani, A. P. and Salehi, I. and Rotithor, G. and Trombetta, D. and Ravichandar, H.},
  date = {2020},
  journaltitle = {IEEE Control Systems},
  volume = {40},
  number = {6},
  pages = {29--56},
  doi = {10.1109/MCS.2020.3019725},
  abstract = {The prospect of a collaborative work environment between humans and robotic automation in a manufacturing setting [1] provides the motivation for finding innovative solutions to human-in-the-loop control for safe, efficient, and trustworthy human-robot collaboration (HRC), or HR interaction (HRI), in cyberphysical human systems (CPHSs) [2], [3]. Studies in [4] show that collaborative automation can be beneficial to 90\% of approximately 300,000 small-to-medium-scale enterprises in the United States. In the paradigm of human-centered automation [5], human safety, ergonomics, and the collaborative efficiency of the work are given the utmost importance. Traditional methods to ensure the safety of humans around factory robots involve the use of cages. Recent work looked beyond cage-based safety to provide robot control and sensing-driven solutions for human safety around robots [6]-[8].}
}

@article{daniHumanintheLoopRobotControl2020a,
  title = {Human-in-the-{{Loop Robot Control}} for {{Human-Robot Collaboration}}: {{Human Intention Estimation}} and {{Safe Trajectory Tracking Control}} for {{Collaborative Tasks}}},
  author = {Dani, A.P. and Salehi, I. and Rotithor, G. and Trombetta, D. and Ravichandar, H.},
  date = {2020},
  journaltitle = {IEEE Control Systems},
  volume = {40},
  number = {6},
  pages = {29--56},
  doi = {10.1109/MCS.2020.3019725},
  abstract = {The prospect of a collaborative work environment between humans and robotic automation in a manufacturing setting [1] provides the motivation for finding innovative solutions to human-in-the-loop control for safe, efficient, and trustworthy human-robot collaboration (HRC), or HR interaction (HRI), in cyberphysical human systems (CPHSs) [2], [3]. Studies in [4] show that collaborative automation can be beneficial to 90\% of approximately 300,000 small-to-medium-scale enterprises in the United States. In the paradigm of human-centered automation [5], human safety, ergonomics, and the collaborative efficiency of the work are given the utmost importance. Traditional methods to ensure the safety of humans around factory robots involve the use of cages. Recent work looked beyond cage-based safety to provide robot control and sensing-driven solutions for human safety around robots [6]-[8].}
}

@article{darkoBuildingInformationModeling2020,
  title = {Building Information Modeling ({{BIM}})-Based Modular Integrated Construction Risk Management – {{Critical}} Survey and Future Needs},
  author = {Darko, Amos and Chan, Albert P.C. and Yang, Yang and Tetteh, Mershack O.},
  date = {2020-12},
  journaltitle = {Computers in Industry},
  volume = {123},
  pages = {103327},
  issn = {01663615},
  doi = {10.1016/j.compind.2020.103327},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166361520305613},
  abstract = {Modular integrated construction (MiC) is an innovative construction technology wherein complete building modules are produced and preassembled in an offsite factory before their final installation on the building site. It is fundamentally different from and has many advantages over the traditional onsite construction technology. However, it still involves several risks. To successfully implement MiC projects, effective MiC risk management (MiCRM) is crucial. Building information modeling (BIM) and BIM-related digital technologies have been applied to facilitate MiCRM in recent years. While numerous MiC studies exist, a critical analysis of BIM-based MiCRM is still missing. This study aims to conduct a critical survey of BIM-based MiCRM, and to offer recommendations about research gaps and future research directions. This was achieved by systematically identifying and critically reviewing related publications from four outlooks: (1) MiCRM through BIM used alone, (2) MiCRM through BIM used alongside sensing and tracking technologies (STTs), (3) MiCRM through BIM used alongside 3D model creation and comparison technologies (3D-MCCTs), and (4) other applications. Results indicated that using BIM alone for MiCRM has focused more on the design phase. The overall idea to use BIM-STTs integration for MiCRM is very young. In this direction, BIM-RFID integration has received most of the attention, although BIM-GIS integration is rarely explored. There are limited works around integrating BIM with 3D-MCCTs such as photogrammetry and augmented and virtual realities for MiCRM. While schedule- and cost-related risks have gained much attention in current BIM-based MiCRM research, facilities management, sustainability, and safety risks are largely ignored. Based upon identified gaps, this study suggested future research directions, including, e.g.: (1) BIM-based MiCRM software development, (2) fully automated and practical BIM-based MiCRM systems development, and (3) BIM-automatic rule checking integration for MiCRM. This study contributes to a solid understanding of BIM-based MiCRM and delivers a useful reference for its future practice and improvement within the industry.},
  file = {C:\Users\leemar\Zotero\storage\PRDNWFZD\1-s2.0-S0166361520305613-main.pdf}
}

@article{darkoBuildingInformationModeling2020a,
  title = {Building Information Modeling ({{BIM}})-Based Modular Integrated Construction Risk Management – {{Critical}} Survey and Future Needs},
  author = {Darko, Amos and Chan, Albert P.C. and Yang, Yang and Tetteh, Mershack O.},
  date = {2020},
  journaltitle = {Computers in Industry},
  volume = {123},
  pages = {103327},
  publisher = {{Elsevier B.V.}},
  issn = {01663615},
  doi = {10.1016/j.compind.2020.103327},
  url = {https://doi.org/10.1016/j.compind.2020.103327},
  abstract = {Modular integrated construction (MiC) is an innovative construction technology wherein complete building modules are produced and preassembled in an offsite factory before their final installation on the building site. It is fundamentally different from and has many advantages over the traditional onsite construction technology. However, it still involves several risks. To successfully implement MiC projects, effective MiC risk management (MiCRM) is crucial. Building information modeling (BIM) and BIM-related digital technologies have been applied to facilitate MiCRM in recent years. While numerous MiC studies exist, a critical analysis of BIM-based MiCRM is still missing. This study aims to conduct a critical survey of BIM-based MiCRM, and to offer recommendations about research gaps and future research directions. This was achieved by systematically identifying and critically reviewing related publications from four outlooks: (1) MiCRM through BIM used alone, (2) MiCRM through BIM used alongside sensing and tracking technologies (STTs), (3) MiCRM through BIM used alongside 3D model creation and comparison technologies (3D-MCCTs), and (4) other applications. Results indicated that using BIM alone for MiCRM has focused more on the design phase. The overall idea to use BIM-STTs integration for MiCRM is very young. In this direction, BIM-RFID integration has received most of the attention, although BIM-GIS integration is rarely explored. There are limited works around integrating BIM with 3D-MCCTs such as photogrammetry and augmented and virtual realities for MiCRM. While schedule- and cost-related risks have gained much attention in current BIM-based MiCRM research, facilities management, sustainability, and safety risks are largely ignored. Based upon identified gaps, this study suggested future research directions, including, e.g.: (1) BIM-based MiCRM software development, (2) fully automated and practical BIM-based MiCRM systems development, and (3) BIM-automatic rule checking integration for MiCRM. This study contributes to a solid understanding of BIM-based MiCRM and delivers a useful reference for its future practice and improvement within the industry.},
  keywords = {BIM-based MiC risk management,Building information modeling (BIM),Digital technologies,Industry 4.0,Modular integrated construction (MiC)},
  file = {C:\Users\leemar\Zotero\storage\74NHI6UU\BIM-based modular integrated construction risk management .pdf}
}

@book{dayKnowledgebasedDesignIndustrialised2019,
  title = {Knowledge-Based Design in Industrialised House Building: {{A}} Case-Study for Prefabricated Timber Walls},
  author = {Day, G. and Gasparri, E. and Aitchison, M.},
  date = {2019},
  journaltitle = {Lecture Notes in Civil Engineering},
  volume = {24},
  doi = {10.1007/978-3-030-03676-8_40},
  abstract = {This chapter illustrates how the adoption of a knowledge-based engineering approach may provide a powerful tool for the industrialised house building sector to manage the complex and multidisciplinary nature of design, fabrication and installation. The research focuses on timber technologies and prefabricated timber components, which are frequently selected in preference to other industrialised building systems because of the advantages they offer in terms of weight, workability and sustainability strategies. A knowledge-based engineering methodology is explored for the design of prefabricated timber-framed external walls, encoding both “explicit” and “tacit” knowledge into a digital three-dimensional model. Results demonstrate how such an approach could significantly change common design practices by shifting the major phase of design effort to earlier stages in the project cycle, thereby minimising re-work, reducing data fragmentation and potentially removing the need for drawings. A key finding of this paper is that model interoperability, maintenance and reuse becomes unlikely if an agreed methodology, including a description logic, is not adopted. Despite the need for a rigorous approach, the ability to capture, manage and reuse design knowledge could be of significant benefit to emerging industrialised house building ventures.},
  pagetotal = {989-1016},
  file = {C:\Users\leemar\Zotero\storage\Z7ZLVE5L\Knowledgebased-design-in-industrialised-house-building-A-casestudy-for-prefabricated-timber-wallsLecture-Notes-in-Civil-Engineering.pdf}
}

@book{dayKnowledgebasedDesignIndustrialised2019a,
  title = {Knowledge-Based Design in Industrialised House Building: {{A}} Case-Study for Prefabricated Timber Walls},
  author = {Day, G. and Gasparri, E. and Aitchison, M.},
  date = {2019},
  journaltitle = {Lecture Notes in Civil Engineering},
  volume = {24},
  doi = {10.1007/978-3-030-03676-8_40},
  abstract = {This chapter illustrates how the adoption of a knowledge-based engineering approach may provide a powerful tool for the industrialised house building sector to manage the complex and multidisciplinary nature of design, fabrication and installation. The research focuses on timber technologies and prefabricated timber components, which are frequently selected in preference to other industrialised building systems because of the advantages they offer in terms of weight, workability and sustainability strategies. A knowledge-based engineering methodology is explored for the design of prefabricated timber-framed external walls, encoding both “explicit” and “tacit” knowledge into a digital three-dimensional model. Results demonstrate how such an approach could significantly change common design practices by shifting the major phase of design effort to earlier stages in the project cycle, thereby minimising re-work, reducing data fragmentation and potentially removing the need for drawings. A key finding of this paper is that model interoperability, maintenance and reuse becomes unlikely if an agreed methodology, including a description logic, is not adopted. Despite the need for a rigorous approach, the ability to capture, manage and reuse design knowledge could be of significant benefit to emerging industrialised house building ventures.},
  pagetotal = {989-1016},
  file = {C:\Users\leemar\Zotero\storage\T9WSXE37\Knowledgebased-design-in-industrialised-house-building-A-casestudy-for-prefabricated-timber-wallsLecture-Notes-in-Civil-Engineering.pdf}
}

@book{demskiAutomaticTargetingSentry2013,
  title = {Automatic Targeting Sentry Turret for Distributed Systems},
  author = {Demski, P. and Grzejszczak, T. and Jȩdrasiak, K. and Mikulski, M.},
  date = {2013},
  journaltitle = {Studies in Computational Intelligence},
  volume = {481},
  doi = {10.1007/978-3-319-00369-6_3},
  abstract = {Today most popular systems are constructed with the idea of collaboration. In software we can see a drastic increase of cloud-oriented applications, in electronics more devices are designed with CAN and Ethernet communications, and in robotics and defense whole systems are linked as unmanned sensor and agent networks. This paper describes the fundamental design principles of an automatic sentry turret in a distributed multi-agent system. The work is focused on the design of the turret system itself and the system architecture for distributed robotic applications. The papers is divided into the following sections: introduction, turret construction, system architecture, automatic target detection and aiming, and summary Module ©Springer International Publishing Switzerland 2013.},
  isbn = {978-3-319-00368-9},
  pagetotal = {47-55}
}

@book{demskiAutomaticTargetingSentry2013a,
  title = {Automatic Targeting Sentry Turret for Distributed Systems},
  author = {Demski, P. and Grzejszczak, T. and Jȩdrasiak, K. and Mikulski, M.},
  date = {2013},
  journaltitle = {Studies in Computational Intelligence},
  volume = {481},
  doi = {10.1007/978-3-319-00369-6_3},
  abstract = {Today most popular systems are constructed with the idea of collaboration. In software we can see a drastic increase of cloud-oriented applications, in electronics more devices are designed with CAN and Ethernet communications, and in robotics and defense whole systems are linked as unmanned sensor and agent networks. This paper describes the fundamental design principles of an automatic sentry turret in a distributed multi-agent system. The work is focused on the design of the turret system itself and the system architecture for distributed robotic applications. The papers is divided into the following sections: introduction, turret construction, system architecture, automatic target detection and aiming, and summary Module ©Springer International Publishing Switzerland 2013.},
  isbn = {978-3-319-00368-9},
  pagetotal = {47-55}
}

@article{deoliveiraSoftwareForestSpecies2019,
  title = {Software for Forest Species Recognition Based on Digital Images of Wood},
  author = {family=Oliveira, given=W., prefix=de, useprefix=true and Filho, P.L.P. and Martins, J.G.},
  date = {2019},
  journaltitle = {Floresta},
  volume = {49},
  number = {3},
  pages = {543--552},
  doi = {10.5380/rf.v49i3.60075},
  abstract = {Classifying forest species is an essential process for the correct management of wood and forest control. After cutting off the trunk of the tree, many of the characteristics of the species are lost and identifying them becomes a much more difficult task. In this context, an anatomical analysis of the wood becomes necessary, needing to be done by specialists who know very well the cellular structures of each species. However, such methodology approaches few automated techniques, making it a delayed and error-prone activity. These factors undermine environmental control and decision-making. The use of computer vision is an alternative to automatic recognition, since it allows the development of intelligent systems, in which, from images, are able to detect features and perform a final classification. One of the techniques of Computer Vision is the use of Convolutional Neural Networks, technique that represents the state of the art in this area, it is the construction of models capable of interpreting patterns in images. This research addresses experiments using convolutional neural networks for recognizing forest species from digital images. Two original datasets were used, one including macroscopic images and the other including microscopic images, for which three models were created: scale recognition, species recognition from macroscopic images and species recognition from microscopic. The best models provide 100\% recognition rates for the scale dataset, 98.73\% for the macroscopic and 99.11\% for the microscopic which made possible to develop a software as a final product, using these three models.}
}

@article{diabSkillMaNSkillbasedRobotic2020,
  title = {{{SkillMaN}} — {{A}} Skill-Based Robotic Manipulation Framework Based on Perception and Reasoning},
  author = {Diab, Mohammed and Pomarlan, Mihai and Beßler, Daniel and Akbari, Aliakbar and Rosell, Jan and Bateman, John and Beetz, Michael},
  date = {2020-12},
  journaltitle = {Robotics and Autonomous Systems},
  volume = {134},
  publisher = {{Elsevier B.V.}},
  issn = {09218890},
  doi = {10.1016/j.robot.2020.103653},
  abstract = {One of the problems that service robotics deals with is to bring mobile manipulators to work in semi-structured human scenarios, which requires an efficient and flexible way to execute every-day tasks, like serve a cup in a cluttered environment. Usually, for those tasks, the combination of symbolic and geometric levels of planning is necessary, as well as the integration of perception models with knowledge to guide both planning levels, resulting in a sequence of actions or skills which, according to the current knowledge of the world, may be executed. This paper proposes a planning and execution framework, called SkillMaN, for robotic manipulation tasks, which is equipped with a module with experiential knowledge (learned from its experience or given by the user) on how to execute a set of skills, like pick-up, put-down or open a drawer, using workflows as well as robot trajectories. The framework also contains an execution assistant with geometric tools and reasoning capabilities to manage how to actually execute the sequence of motions to perform a manipulation task (which are forwarded to the executor module), as well as the capacity to store the relevant information to the experiential knowledge for further usage, and the capacity to interpret the actual perceived situation (in case the preconditions of an action do not hold) and to feed back the updated state to the planner to resume from there, allowing the robot to adapt to non-expected situations. To evaluate the viability of the proposed framework, an experiment has been proposed involving different skills performed with various types of objects in different scene contexts.},
  keywords = {Adaptation,Every-day tasks,Knowledge-based Reasoning,Manipulation planning,Navigation,Semantic Skill}
}

@article{diabSkillMaNSkillbasedRobotic2020a,
  title = {{{SkillMaN}} — {{A}} Skill-Based Robotic Manipulation Framework Based on Perception and Reasoning},
  author = {Diab, Mohammed and Pomarlan, Mihai and Beßler, Daniel and Akbari, Aliakbar and Rosell, Jan and Bateman, John and Beetz, Michael},
  date = {2020-12-01},
  journaltitle = {Robotics and Autonomous Systems},
  volume = {134},
  publisher = {{Elsevier B.V.}},
  issn = {09218890},
  doi = {10.1016/j.robot.2020.103653},
  abstract = {One of the problems that service robotics deals with is to bring mobile manipulators to work in semi-structured human scenarios, which requires an efficient and flexible way to execute every-day tasks, like serve a cup in a cluttered environment. Usually, for those tasks, the combination of symbolic and geometric levels of planning is necessary, as well as the integration of perception models with knowledge to guide both planning levels, resulting in a sequence of actions or skills which, according to the current knowledge of the world, may be executed. This paper proposes a planning and execution framework, called SkillMaN, for robotic manipulation tasks, which is equipped with a module with experiential knowledge (learned from its experience or given by the user) on how to execute a set of skills, like pick-up, put-down or open a drawer, using workflows as well as robot trajectories. The framework also contains an execution assistant with geometric tools and reasoning capabilities to manage how to actually execute the sequence of motions to perform a manipulation task (which are forwarded to the executor module), as well as the capacity to store the relevant information to the experiential knowledge for further usage, and the capacity to interpret the actual perceived situation (in case the preconditions of an action do not hold) and to feed back the updated state to the planner to resume from there, allowing the robot to adapt to non-expected situations. To evaluate the viability of the proposed framework, an experiment has been proposed involving different skills performed with various types of objects in different scene contexts.},
  keywords = {★,Adaptation,Every-day tasks,Knowledge-based Reasoning,Manipulation planning,Navigation,Semantic Skill},
  file = {C:\Users\leemar\Zotero\storage\7Z32LUJJ\1-s2.0-S0921889020304930-main.pdf}
}

@article{diezAUTMOD3IntegrationDesign2007,
  title = {{{AUTMOD3}}: {{The}} Integration of Design and Planning Tools for Automatic Modular Construction},
  author = {Diez, R. and Padrón, V.M. and Abderrahim, M. and Balaguer, C.},
  date = {2007},
  journaltitle = {International Journal of Advanced Robotic Systems},
  volume = {4},
  number = {4},
  pages = {457--468},
  doi = {10.5772/5671},
  abstract = {Europe is facing a fast growing need for affordable, high quality housing, which can not be solved by means of traditional or conventional building technology and its associated methods of construction. One of the solutions to this problem is the application of high quality modular construction, which defines a new building process as the assembly of pre-fabricated modules in the construction site. As part of this philosophy, AUTMOD3 is an automatic modular construction software environment, developed in the frame of the EU project FutureHome. The system seamlessly integrates architectural design, planning and simulation tools in a wellknown CAD program commonly used by designers. Architectural design using previously defined 3D and 2D modules or modularisation of the traditional building design are the main objectives of the AUTMOD3 design tool. The production planning and the on-site modular assembly planning are the main task to be performed by the planning tool. The AUTMOD3 assembly planning tool generates the trajectories, which can be applied directly to a robotized crane develop in the project FutureHome.}
}

@article{diezAUTMOD3IntegrationDesign2007a,
  title = {{{AUTMOD3}}: {{The}} Integration of Design and Planning Tools for Automatic Modular Construction},
  author = {Diez, R. and Padrón, V.M. and Abderrahim, M. and Balaguer, C.},
  date = {2007},
  journaltitle = {International Journal of Advanced Robotic Systems},
  volume = {4},
  number = {4},
  pages = {457--468},
  doi = {10.5772/5671},
  abstract = {Europe is facing a fast growing need for affordable, high quality housing, which can not be solved by means of traditional or conventional building technology and its associated methods of construction. One of the solutions to this problem is the application of high quality modular construction, which defines a new building process as the assembly of pre-fabricated modules in the construction site. As part of this philosophy, AUTMOD3 is an automatic modular construction software environment, developed in the frame of the EU project FutureHome. The system seamlessly integrates architectural design, planning and simulation tools in a wellknown CAD program commonly used by designers. Architectural design using previously defined 3D and 2D modules or modularisation of the traditional building design are the main objectives of the AUTMOD3 design tool. The production planning and the on-site modular assembly planning are the main task to be performed by the planning tool. The AUTMOD3 assembly planning tool generates the trajectories, which can be applied directly to a robotized crane develop in the project FutureHome.}
}

@article{dilesLightweightStereotomyGlassFiber2018,
  title = {Lightweight {{Stereotomy}} with {{Glass-Fiber Reinforced Plastic}}},
  author = {Diles, J.},
  date = {2018},
  journaltitle = {Nexus Network Journal},
  volume = {20},
  number = {3},
  pages = {645--669},
  doi = {10.1007/s00004-018-0376-x},
  abstract = {Stereotomy is historically synonymous with stone construction and solid architectural poché. Yet stereotomy need not be limited to dense materials and compression-only structural forms. With the aim of developing stereotomic architecture that employs parts that are exceptionally expressive—rather than exceptionally heavy—this paper explores constructions made from glass-fiber reinforced plastic, a contemporary lightweight material. The research also recognizes that the volumetric parts and networks of joints employed for stereotomy have important visual as well as physical consequences. By focusing on creative applications of descriptive geometry, the projects presented in this paper seek to make explicit stereotomy’s unique combination of graphic and constructional qualities. Using a novel system of tessellations derived from digital simulations, the research puts computational techniques in service of stereotomy’s formal questions, developing visually animated assemblies of parts. The architectural qualities of these assemblies as well as the constructional feasibility of lightweight stereotomic parts were tested through a series of designs that culminated in large architectural constructions, including a free-standing wall, a pavilion prototype and a free-standing interior pavilion employing lightweight, free-form Cyclopean masonry.}
}

@article{dilesLightweightStereotomyGlassFiber2018a,
  title = {Lightweight {{Stereotomy}} with {{Glass-Fiber Reinforced Plastic}}},
  author = {Diles, J.},
  date = {2018},
  journaltitle = {Nexus Network Journal},
  volume = {20},
  number = {3},
  pages = {645--669},
  doi = {10.1007/s00004-018-0376-x},
  abstract = {Stereotomy is historically synonymous with stone construction and solid architectural poché. Yet stereotomy need not be limited to dense materials and compression-only structural forms. With the aim of developing stereotomic architecture that employs parts that are exceptionally expressive—rather than exceptionally heavy—this paper explores constructions made from glass-fiber reinforced plastic, a contemporary lightweight material. The research also recognizes that the volumetric parts and networks of joints employed for stereotomy have important visual as well as physical consequences. By focusing on creative applications of descriptive geometry, the projects presented in this paper seek to make explicit stereotomy’s unique combination of graphic and constructional qualities. Using a novel system of tessellations derived from digital simulations, the research puts computational techniques in service of stereotomy’s formal questions, developing visually animated assemblies of parts. The architectural qualities of these assemblies as well as the constructional feasibility of lightweight stereotomic parts were tested through a series of designs that culminated in large architectural constructions, including a free-standing wall, a pavilion prototype and a free-standing interior pavilion employing lightweight, free-form Cyclopean masonry.}
}

@article{dineGraphbasedSimultaneousLocalization2016,
  title = {Graph-Based Simultaneous Localization and Mapping},
  author = {Dine, A. and Elouardi, A. and Vincke, B. and Bouaziz, S.},
  date = {2016},
  journaltitle = {IEEE Robotics and Automation Magazine},
  volume = {23},
  number = {4},
  pages = {160--173},
  doi = {10.1109/MRA.2016.2580466},
  abstract = {This article deals with the computational complexity issue of graphbased simultaneous localization and mapping (SLAM). SLAM allows a robot that is navigating in an unknown environment to build a map of this environment while simultaneously determining the robot pose on this map. Graph-based SLAM is a smoothing method that uses a graph to represent and solve the SLAM problem. We first propose a graph construction that takes advantage of the incremental and sparse characteristics of graph-based SLAM. This incremental construction is exploited to perform several algorithmic optimizations. Second, we present a study of using a heterogeneous architecture to implement the graph-based SLAM algorithm. Indeed, the emergence of recent heterogeneous embedded architectures should lead to a great advance in the design of embedded systems-based robotics applications. As a result of this study, an algorithm-architecture mapping is proposed for a central processing unit-graphics processing unit (CPU-GPU)- based architecture. The study also investigates how this kind of architecture can speed up graph-based SLAM by offloading some critical compute-intensive tasks of the algorithm on the GPU. Some common data sets are used to compare our implementations to the state of the art.}
}

@article{dineGraphbasedSimultaneousLocalization2016a,
  title = {Graph-Based Simultaneous Localization and Mapping},
  author = {Dine, A. and Elouardi, A. and Vincke, B. and Bouaziz, S.},
  date = {2016},
  journaltitle = {IEEE Robotics and Automation Magazine},
  volume = {23},
  number = {4},
  pages = {160--173},
  doi = {10.1109/MRA.2016.2580466},
  abstract = {This article deals with the computational complexity issue of graphbased simultaneous localization and mapping (SLAM). SLAM allows a robot that is navigating in an unknown environment to build a map of this environment while simultaneously determining the robot pose on this map. Graph-based SLAM is a smoothing method that uses a graph to represent and solve the SLAM problem. We first propose a graph construction that takes advantage of the incremental and sparse characteristics of graph-based SLAM. This incremental construction is exploited to perform several algorithmic optimizations. Second, we present a study of using a heterogeneous architecture to implement the graph-based SLAM algorithm. Indeed, the emergence of recent heterogeneous embedded architectures should lead to a great advance in the design of embedded systems-based robotics applications. As a result of this study, an algorithm-architecture mapping is proposed for a central processing unit-graphics processing unit (CPU-GPU)- based architecture. The study also investigates how this kind of architecture can speed up graph-based SLAM by offloading some critical compute-intensive tasks of the algorithm on the GPU. Some common data sets are used to compare our implementations to the state of the art.}
}

@article{dingBIMbasedTasklevelPlanning2020,
  title = {{{BIM-based}} Task-Level Planning for Robotic Brick Assembly through Image-Based {{3D}} Modeling},
  author = {Ding, Lieyun and Jiang, Weiguang and Zhou, Ying and Zhou, Cheng and Liu, Sheng},
  date = {2020-01},
  journaltitle = {Advanced Engineering Informatics},
  shortjournal = {Advanced Engineering Informatics},
  volume = {43},
  pages = {100993},
  issn = {14740346},
  doi = {10.1016/j.aei.2019.100993},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S147403461930566X},
  urldate = {2023-03-23},
  langid = {english}
}

@article{dingThreedimensionalConstructionOmnidirectional2015,
  title = {Three-Dimensional Construction and Omni-Directional Rolling Analysis of a Novel Frame-like Lattice Modular Robot},
  author = {Ding, W. and Wu, J. and Yao, Y.},
  date = {2015},
  journaltitle = {Chinese Journal of Mechanical Engineering (English Edition)},
  volume = {28},
  number = {4},
  pages = {691--701},
  doi = {10.3901/CJME.2015.0316.059},
  abstract = {Lattice modular robots possess diversity actuation methods, such as electric telescopic rod, gear rack, magnet, robot arm, etc. The researches on lattice modular robots mainly focus on their hardware descriptions and reconfiguration algorithms. Meanwhile, their design architectures and actuation methods perform slow telescopic and moving speeds, relative low actuation force verse weight ratio, and without internal space to carry objects. To improve the mechanical performance and reveal the locomotion and reconfiguration binary essences of the lattice modular robots, a novel cube-shaped, frame-like, pneumatic-based reconfigurable robot module called pneumatic expandable cube (PE-Cube) is proposed. The three-dimensional (3D) expanding construction and omni-directional rolling analysis of the constructed robots are the main focuses. The PE-Cube with three degrees of freedom (DoFs) is assembled by replacing the twelve edges of a cube with pneumatic cylinders. The proposed symmetric construction condition makes the constructed robots possess the same properties in each supporting state, and a binary control strategy cooperated with binary actuator (pneumatic cylinder) is directly adopted to control the PE-Cube. Taking an eight PE-Cube modules' construction as example, its dynamic rolling simulation, static rolling condition, and turning gait are illustrated and discussed. To testify telescopic synchronization, respond speed, locomotion feasibility, and repeatability and reliability of hardware system, an experimental pneumatic-based robotic system is built and the rolling and turning experiments of the eight PE-Cube modules' construction are carried out. As an extension, the locomotion feasibility of a thirty-two PE-Cube modules' construction is analyzed and proved, including dynamic rolling simulation, static rolling condition, and dynamic analysis in free tipping process. The proposed PE-Cube module, construction method, and locomotion analysis enrich the family of the lattice modular robot and provide the instruction to design the lattice modular robot.}
}

@article{dingThreedimensionalConstructionOmnidirectional2015a,
  title = {Three-Dimensional Construction and Omni-Directional Rolling Analysis of a Novel Frame-like Lattice Modular Robot},
  author = {Ding, W. and Wu, J. and Yao, Y.},
  date = {2015},
  journaltitle = {Chinese Journal of Mechanical Engineering (English Edition)},
  volume = {28},
  number = {4},
  pages = {691--701},
  doi = {10.3901/CJME.2015.0316.059},
  abstract = {Lattice modular robots possess diversity actuation methods, such as electric telescopic rod, gear rack, magnet, robot arm, etc. The researches on lattice modular robots mainly focus on their hardware descriptions and reconfiguration algorithms. Meanwhile, their design architectures and actuation methods perform slow telescopic and moving speeds, relative low actuation force verse weight ratio, and without internal space to carry objects. To improve the mechanical performance and reveal the locomotion and reconfiguration binary essences of the lattice modular robots, a novel cube-shaped, frame-like, pneumatic-based reconfigurable robot module called pneumatic expandable cube (PE-Cube) is proposed. The three-dimensional (3D) expanding construction and omni-directional rolling analysis of the constructed robots are the main focuses. The PE-Cube with three degrees of freedom (DoFs) is assembled by replacing the twelve edges of a cube with pneumatic cylinders. The proposed symmetric construction condition makes the constructed robots possess the same properties in each supporting state, and a binary control strategy cooperated with binary actuator (pneumatic cylinder) is directly adopted to control the PE-Cube. Taking an eight PE-Cube modules' construction as example, its dynamic rolling simulation, static rolling condition, and turning gait are illustrated and discussed. To testify telescopic synchronization, respond speed, locomotion feasibility, and repeatability and reliability of hardware system, an experimental pneumatic-based robotic system is built and the rolling and turning experiments of the eight PE-Cube modules' construction are carried out. As an extension, the locomotion feasibility of a thirty-two PE-Cube modules' construction is analyzed and proved, including dynamic rolling simulation, static rolling condition, and dynamic analysis in free tipping process. The proposed PE-Cube module, construction method, and locomotion analysis enrich the family of the lattice modular robot and provide the instruction to design the lattice modular robot.}
}

@article{draganPolicyblendingFormalismShared2013,
  title = {A Policy-Blending Formalism for Shared Control},
  author = {Dragan, Anca D. and Srinivasa, Siddhartha S.},
  date = {2013},
  journaltitle = {International Journal of Robotics Research},
  volume = {32},
  number = {7},
  pages = {790--805},
  issn = {02783649},
  doi = {10.1177/0278364913490324},
  abstract = {In shared control teleoperation, the robot assists the user in accomplishing the desired task, making teleoperation easier and more seamless. Rather than simply executing the user's input, which is hindered by the inadequacies of the interface, the robot attempts to predict the user's intent, and assists in accomplishing it. In this work, we are interested in the scientific underpinnings of assistance: we propose an intuitive formalism that captures assistance as policy blending, illustrate how some of the existing techniques for shared control instantiate it, and provide a principled analysis of its main components: prediction of user intent and its arbitration with the user input. We define the prediction problem, with foundations in inverse reinforcement learning, discuss simplifying assumptions that make it tractable, and test these on data from users teleoperating a robotic manipulator. We define the arbitration problem from a control-theoretic perspective, and turn our attention to what users consider good arbitration. We conduct a user study that analyzes the effect of different factors on the performance of assistance, indicating that arbitration should be contextual: it should depend on the robot's confidence in itself and in the user, and even the particulars of the user. Based on the study, we discuss challenges and opportunities that a robot sharing the control with the user might face: adaptation to the context and the user, legibility of behavior, and the closed loop between prediction and user behavior. © The Author(s) 2013.},
  isbn = {0278364913490},
  keywords = {arbitration,human-robot collaboration,intent prediction,shared control,sliding autonomy,teleoperation}
}

@article{draganPolicyblendingFormalismShared2013a,
  title = {A Policy-Blending Formalism for Shared Control},
  author = {Dragan, Anca D. and Srinivasa, Siddhartha S.},
  date = {2013},
  journaltitle = {International Journal of Robotics Research},
  volume = {32},
  number = {7},
  pages = {790--805},
  issn = {02783649},
  doi = {10.1177/0278364913490324},
  abstract = {In shared control teleoperation, the robot assists the user in accomplishing the desired task, making teleoperation easier and more seamless. Rather than simply executing the user's input, which is hindered by the inadequacies of the interface, the robot attempts to predict the user's intent, and assists in accomplishing it. In this work, we are interested in the scientific underpinnings of assistance: we propose an intuitive formalism that captures assistance as policy blending, illustrate how some of the existing techniques for shared control instantiate it, and provide a principled analysis of its main components: prediction of user intent and its arbitration with the user input. We define the prediction problem, with foundations in inverse reinforcement learning, discuss simplifying assumptions that make it tractable, and test these on data from users teleoperating a robotic manipulator. We define the arbitration problem from a control-theoretic perspective, and turn our attention to what users consider good arbitration. We conduct a user study that analyzes the effect of different factors on the performance of assistance, indicating that arbitration should be contextual: it should depend on the robot's confidence in itself and in the user, and even the particulars of the user. Based on the study, we discuss challenges and opportunities that a robot sharing the control with the user might face: adaptation to the context and the user, legibility of behavior, and the closed loop between prediction and user behavior. © The Author(s) 2013.},
  isbn = {0278364913490},
  keywords = {arbitration,human-robot collaboration,intent prediction,shared control,sliding autonomy,teleoperation},
  file = {C:\Users\leemar\Zotero\storage\B5GCN6YR\dragan2012shared.pdf}
}

@article{duanSEMGBasedIdentificationHand2016,
  title = {{{sEMG-Based Identification}} of {{Hand Motion Commands Using Wavelet Neural Network Combined With Discrete Wavelet Transform}}},
  author = {Duan, Feng and Dai, Lili and Chang, Wennan and Chen, Zengqiang and Zhu, Chi and Li, Wei},
  date = {2016-03},
  journaltitle = {IEEE Transactions on Industrial Electronics},
  shortjournal = {IEEE Trans. Ind. Electron.},
  volume = {63},
  number = {3},
  pages = {1923--1934},
  issn = {0278-0046, 1557-9948},
  doi = {10.1109/TIE.2015.2497212},
  url = {http://ieeexplore.ieee.org/document/7315041/},
  urldate = {2023-11-12}
}

@article{duHumanRobotCollaborative2021,
  title = {Human–{{Robot Collaborative Control}} in a {{Virtual-Reality-Based Telepresence System}}},
  author = {Du, Jianhao and Do, Ha Manh and Sheng, Weihua},
  date = {2021-09},
  journaltitle = {International Journal of Social Robotics},
  volume = {13},
  number = {6},
  pages = {1295--1306},
  issn = {1875-4791},
  doi = {10.1007/s12369-020-00718-w},
  url = {https://link.springer.com/10.1007/s12369-020-00718-w},
  abstract = {In this paper, we develop a robotic telepresence system to provide remote users with immersive embodiment in local environments through a custom-designed mobile robot. The proposed telepresence system uses a virtual reality (VR) device to connect a remote user to the robot. Three dimensional visual data from a RGB-D camera are rendered for real-time stereoscopic display in the VR device, which forms a deeply-coupled human machine system and creates an immersive experience of telepresence. Based on a user study, it is found that better user experience can be achieved by allowing the robot to track the speaker while being aware of the intention of the remote user. To this end we propose a human-robot collaborative control framework based on human intention recognition and sound localization. The intentions of head movement of the remote user are inferred based on the motion of the VR device using hidden Markov models. The speaker is tracked through sound source localization using a microphone array. A collaborative control scheme is developed to fuse the control from the robot and the remote user. Experiments are conducted in both one-to-one and one-to-two remote conversation scenarios. The results show that the proposed system can significantly improve the immersiveness and performance of robotic telepresence systems, therefore greatly enhancing the user experience of such telepresence systems.}
}

@article{duHumanRobotCollaborative2021a,
  title = {Human–{{Robot Collaborative Control}} in a {{Virtual-Reality-Based Telepresence System}}},
  author = {Du, Jianhao and Do, Ha Manh and Sheng, Weihua},
  date = {2021-09-09},
  journaltitle = {International Journal of Social Robotics},
  volume = {13},
  number = {6},
  pages = {1295--1306},
  issn = {1875-4791},
  doi = {10.1007/s12369-020-00718-w},
  url = {https://link.springer.com/10.1007/s12369-020-00718-w},
  abstract = {In this paper, we develop a robotic telepresence system to provide remote users with immersive embodiment in local environments through a custom-designed mobile robot. The proposed telepresence system uses a virtual reality (VR) device to connect a remote user to the robot. Three dimensional visual data from a RGB-D camera are rendered for real-time stereoscopic display in the VR device, which forms a deeply-coupled human machine system and creates an immersive experience of telepresence. Based on a user study, it is found that better user experience can be achieved by allowing the robot to track the speaker while being aware of the intention of the remote user. To this end we propose a human-robot collaborative control framework based on human intention recognition and sound localization. The intentions of head movement of the remote user are inferred based on the motion of the VR device using hidden Markov models. The speaker is tracked through sound source localization using a microphone array. A collaborative control scheme is developed to fuse the control from the robot and the remote user. Experiments are conducted in both one-to-one and one-to-two remote conversation scenarios. The results show that the proposed system can significantly improve the immersiveness and performance of robotic telepresence systems, therefore greatly enhancing the user experience of such telepresence systems.}
}

@inproceedings{dunchevaBIMenabledHealthAmp2018,
  title = {{{BIM-enabled}} Health \&amp; Safety Analysis of Cross Laminated Timber Onsite Assembly Process},
  booktitle = {17th {{International Conference}} on {{Modeling}} and {{Applied Simulation}}, {{MAS}} 2018},
  author = {Duncheva, T. and BuHamdan, S. and Hairstans, R. and Al-Hussein, M.},
  date = {2018},
  pages = {136--145},
  abstract = {There is a global need for sustainable urban housing and offsite timber systems such as Cross Laminated Timber construction can be part of the solution to this need. However, the health and safety (H\&S) impacts of CLT installation technologies have not yet been investigated utilising BIM enabled. This research project used a case study method to analyse the constructability of CLT panels installation and a System Dynamics (SD) simulation model was construed to analyse workers’ time spent using hand tools for prolonged time, with potential health impacts. The results demonstrated that CLT installation H\&S impacts could be correlated to CLT connections specification. These findings shine new light on Design for Safety (DfS) considerations for CLT medium rise construction with regards to social sustainability, in the context of urban residential buildings.},
  isbn = {978-88-85741-09-6}
}

@inproceedings{dunchevaBIMenabledHealthAmp2018a,
  title = {{{BIM-enabled}} Health \&amp; Safety Analysis of Cross Laminated Timber Onsite Assembly Process},
  booktitle = {17th {{International Conference}} on {{Modeling}} and {{Applied Simulation}}, {{MAS}} 2018},
  author = {Duncheva, T. and BuHamdan, S. and Hairstans, R. and Al-Hussein, M.},
  date = {2018},
  pages = {136--145},
  abstract = {There is a global need for sustainable urban housing and offsite timber systems such as Cross Laminated Timber construction can be part of the solution to this need. However, the health and safety (H\&S) impacts of CLT installation technologies have not yet been investigated utilising BIM enabled. This research project used a case study method to analyse the constructability of CLT panels installation and a System Dynamics (SD) simulation model was construed to analyse workers’ time spent using hand tools for prolonged time, with potential health impacts. The results demonstrated that CLT installation H\&S impacts could be correlated to CLT connections specification. These findings shine new light on Design for Safety (DfS) considerations for CLT medium rise construction with regards to social sustainability, in the context of urban residential buildings.},
  isbn = {978-88-85741-09-6}
}

@article{durandRethinkingUnderrepresentedEthnicities2021,
  title = {Rethinking Under-Represented Ethnicities in {{ELT}} Materials through a Critical Discourse Analysis-Oriented Model},
  author = {Durand, S.},
  date = {2021},
  journaltitle = {Mextesol Journal},
  volume = {45},
  number = {1},
  abstract = {English Language Teaching (ELT) materials are not only pedagogical sources, but they also actively build a vision of reality, often reproducing, legitimizing and perpetuating certain hegemonic discourses. Even if injustice and inequalities are denounced in some materials, global issues are just mentioned rather than problematized and discriminated ethnicities are commonly represented as passive entities with no voice or agency on their own issues. In this article, a model and its operationalization are proposed in order to depict how language teachers can write materials to fight back passive constructions embedded in ELT textbooks and build, through activities based on critical discourse analysis techniques, strong and combative representations of discriminated minorities. The model seeks to critically engage learners in discussing social inequalities and encourage further analysis on how, through language, underrepresented minorities resist and debunk power. First, some examples are given of how weak representations of minorities are portrayed in ELT materials. Secondly, the model, based on Gee’s (2011) three-level definition and Macgilchrist’s (2016) generative perspective of discourse analysis, is explained. Finally, two examples of the model are presented in order to show how passive constructions could be dismantled by giving a voice to silenced ethnicities that are either challenging power or fighting for recognition through text or talk.}
}

@article{durandRethinkingUnderrepresentedEthnicities2021a,
  title = {Rethinking Under-Represented Ethnicities in {{ELT}} Materials through a Critical Discourse Analysis-Oriented Model},
  author = {Durand, S.},
  date = {2021},
  journaltitle = {Mextesol Journal},
  volume = {45},
  number = {1},
  abstract = {English Language Teaching (ELT) materials are not only pedagogical sources, but they also actively build a vision of reality, often reproducing, legitimizing and perpetuating certain hegemonic discourses. Even if injustice and inequalities are denounced in some materials, global issues are just mentioned rather than problematized and discriminated ethnicities are commonly represented as passive entities with no voice or agency on their own issues. In this article, a model and its operationalization are proposed in order to depict how language teachers can write materials to fight back passive constructions embedded in ELT textbooks and build, through activities based on critical discourse analysis techniques, strong and combative representations of discriminated minorities. The model seeks to critically engage learners in discussing social inequalities and encourage further analysis on how, through language, underrepresented minorities resist and debunk power. First, some examples are given of how weak representations of minorities are portrayed in ELT materials. Secondly, the model, based on Gee’s (2011) three-level definition and Macgilchrist’s (2016) generative perspective of discourse analysis, is explained. Finally, two examples of the model are presented in order to show how passive constructions could be dismantled by giving a voice to silenced ethnicities that are either challenging power or fighting for recognition through text or talk.}
}

@article{eastonMeasuringMappingDisplacement2020,
  title = {Measuring and Mapping Displacement: {{The}} Problem of Quantification in the Battle against Gentrification},
  shorttitle = {Measuring and Mapping Displacement},
  author = {Easton, Sue and Lees, Loretta and Hubbard, Phil and Tate, Nicholas},
  date = {2020-02},
  journaltitle = {Urban Studies},
  shortjournal = {Urban Studies},
  volume = {57},
  number = {2},
  pages = {286--306},
  issn = {0042-0980, 1360-063X},
  doi = {10.1177/0042098019851953},
  url = {http://journals.sagepub.com/doi/10.1177/0042098019851953},
  urldate = {2023-09-16},
  abstract = {Debates concerning residential population displacement in the context of gentrification remain vociferous, but are hampered by a lack of empirical evidence of the extent of the displacement occurring. The lack of quantitative evidence on gentrification-induced displacement and the difficulties in collecting it has long hampered the fight against it. Based on a systematic review of quantitative studies of the displacement associated with gentrification, this article considers how researchers have attempted to measure displacement using a range of statistical and mapping techniques reflecting the multi-dimensional character of gentrification. We note that these techniques often struggle to provide meaningful estimates of the number of individuals and households displaced by gentrification, something compounded by the lack of data available on a sufficiently granular temporal and spatial scale. Noting the limitations of extant methods, we conclude by considering the potential of more novel data sources and emergent methods involving the processing of larger amounts of (micro)data, as well as participatory GIS methods that involve affected communities themselves. This implies that whilst the quantitative study of displacement remains difficult, patterns and processes of displacement can be inferred through existing data sources, as well as data generated from those who themselves have experienced displacement.},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\93TR7Z5U\Easton 等。 - 2020 - Measuring and mapping displacement The problem of.pdf}
}

@article{edwinModelingConstructionExperimental2017,
  title = {Modeling, Construction and Experimental Validation of Actuated Rolling Dynamics of the Cylindrical {{Transforming Roving-Rolling Explorer}} ({{TRREx}})},
  author = {Edwin, L. and Mazzoleni, A. and Gemmer, T. and Ferguson, S.},
  date = {2017},
  journaltitle = {Acta Astronautica},
  volume = {132},
  pages = {43--53},
  doi = {10.1016/j.actaastro.2016.11.006},
  abstract = {Planetary surface exploration technology over the past few years has seen significant advancements on multiple fronts. Robotic exploration platforms are becoming more sophisticated and capable of embarking on more challenging missions. More unconventional designs, particularly transforming architectures that have multiple modes of locomotion, are being studied. This work explores the capabilities of one such novel transforming rover called the Transforming Roving-Rolling Explorer (TRREx). Biologically inspired by the armadillo and the golden-wheel spider, the TRREx has two modes of locomotion: it can traverse on six wheels like a conventional rover on benign terrain, but can transform into a sphere when necessary to negotiate steep rugged slopes. The ability to self-propel in the spherical configuration, even in the absence of a negative gradient, increases the TRREx's versatility and its concept value. This paper describes construction and testing of a prototype cylindrical TRREx that demonstrates that “actuated rolling” can be achieved, and also presents a dynamic model of this prototype version of the TRREx that can be used to investigate the feasibility and value of such self-propelled locomotion. Finally, we present results that validate our dynamic model by comparing results from computer simulations made using the dynamic model to experimental results acquired from test runs using the prototype.}
}

@article{edwinModelingConstructionExperimental2017a,
  title = {Modeling, Construction and Experimental Validation of Actuated Rolling Dynamics of the Cylindrical {{Transforming Roving-Rolling Explorer}} ({{TRREx}})},
  author = {Edwin, L. and Mazzoleni, A. and Gemmer, T. and Ferguson, S.},
  date = {2017},
  journaltitle = {Acta Astronautica},
  volume = {132},
  pages = {43--53},
  doi = {10.1016/j.actaastro.2016.11.006},
  abstract = {Planetary surface exploration technology over the past few years has seen significant advancements on multiple fronts. Robotic exploration platforms are becoming more sophisticated and capable of embarking on more challenging missions. More unconventional designs, particularly transforming architectures that have multiple modes of locomotion, are being studied. This work explores the capabilities of one such novel transforming rover called the Transforming Roving-Rolling Explorer (TRREx). Biologically inspired by the armadillo and the golden-wheel spider, the TRREx has two modes of locomotion: it can traverse on six wheels like a conventional rover on benign terrain, but can transform into a sphere when necessary to negotiate steep rugged slopes. The ability to self-propel in the spherical configuration, even in the absence of a negative gradient, increases the TRREx's versatility and its concept value. This paper describes construction and testing of a prototype cylindrical TRREx that demonstrates that “actuated rolling” can be achieved, and also presents a dynamic model of this prototype version of the TRREx that can be used to investigate the feasibility and value of such self-propelled locomotion. Finally, we present results that validate our dynamic model by comparing results from computer simulations made using the dynamic model to experimental results acquired from test runs using the prototype.}
}

@article{el-mahdyBehaviorNaturalOrganisms2017,
  title = {Behavior of Natural Organisms as a Mimicking Tool in Architecture},
  author = {El-Mahdy, D.},
  date = {2017},
  journaltitle = {International Journal of Design and Nature and Ecodynamics},
  volume = {12},
  number = {2},
  pages = {214--224},
  doi = {10.2495/DNE-V12-N2-214-224},
  abstract = {The relation in between architecture and nature has been one of combination for the last 400 years. Throughout history, architects have looked to nature for inspirations for building shapes, forms, and ornamentation without understanding nature's behavior. Moreover, new architectural approaches are being called for integrating nature as a tool for solving problems and enhancing adaptation within the context. This has been recently implemented in biomimicry theories that are applied in design processes. Biomimicry is considered a new discipline that studies living organisms' design and behavior in nature to solve human problems. Not only does this help in finding new ways for adaptation, it also generates new sources of inspiration for aesthetic expressions. This is of great importance nowadays as buildings are becoming inefficient; consuming a lot of energy, materials, and resources. Furthermore, construction processes are becoming increasingly unsustainable. While on the other hand organisms are creating effective and intelligent solutions in their homes by using less material. Engineers can also mimic natural methods of construction for building and design rather than their exact shapes. In addition, they also lead to efficiency in terms of energy, material usage, time, effort, and cost and can promote more adaptable, sustainable, and optimum solutions. This research paper aims to explain the organism's behavior when producing the material and translating it by using a digital tool by mimicking its behavior in construction. Methodology used for this process involves case studies analysis and observations of living organisms' behavior. The cases selected apply biological techniques through their construction process. This involves using natural organisms to produce physical components for architectural product design. Results from the experimental and case studies will aim to conclude a set of findings on approaches for linking organism behavior with future construction processes.}
}

@article{el-mahdyBehaviorNaturalOrganisms2017a,
  title = {Behavior of Natural Organisms as a Mimicking Tool in Architecture},
  author = {El-Mahdy, D.},
  date = {2017},
  journaltitle = {International Journal of Design and Nature and Ecodynamics},
  volume = {12},
  number = {2},
  pages = {214--224},
  doi = {10.2495/DNE-V12-N2-214-224},
  abstract = {The relation in between architecture and nature has been one of combination for the last 400 years. Throughout history, architects have looked to nature for inspirations for building shapes, forms, and ornamentation without understanding nature's behavior. Moreover, new architectural approaches are being called for integrating nature as a tool for solving problems and enhancing adaptation within the context. This has been recently implemented in biomimicry theories that are applied in design processes. Biomimicry is considered a new discipline that studies living organisms' design and behavior in nature to solve human problems. Not only does this help in finding new ways for adaptation, it also generates new sources of inspiration for aesthetic expressions. This is of great importance nowadays as buildings are becoming inefficient; consuming a lot of energy, materials, and resources. Furthermore, construction processes are becoming increasingly unsustainable. While on the other hand organisms are creating effective and intelligent solutions in their homes by using less material. Engineers can also mimic natural methods of construction for building and design rather than their exact shapes. In addition, they also lead to efficiency in terms of energy, material usage, time, effort, and cost and can promote more adaptable, sustainable, and optimum solutions. This research paper aims to explain the organism's behavior when producing the material and translating it by using a digital tool by mimicking its behavior in construction. Methodology used for this process involves case studies analysis and observations of living organisms' behavior. The cases selected apply biological techniques through their construction process. This involves using natural organisms to produce physical components for architectural product design. Results from the experimental and case studies will aim to conclude a set of findings on approaches for linking organism behavior with future construction processes.}
}

@article{elfakiRevolutionizingSocialRobotics2023,
  title = {Revolutionizing {{Social Robotics}}: {{A Cloud-Based Framework}} for {{Enhancing}} the {{Intelligence}} and {{Autonomy}} of {{Social Robots}}},
  shorttitle = {Revolutionizing {{Social Robotics}}},
  author = {Elfaki, Abdelrahman Osman and Abduljabbar, Mohammed and Ali, Luqman and Alnajjar, Fady and Mehiar, Dua’a and Marei, Ashraf M. and Alhmiedat, Tareq and Al-Jumaily, Adel},
  date = {2023-03-24},
  journaltitle = {Robotics},
  shortjournal = {Robotics},
  volume = {12},
  number = {2},
  pages = {48},
  issn = {2218-6581},
  doi = {10.3390/robotics12020048},
  url = {https://www.mdpi.com/2218-6581/12/2/48},
  urldate = {2023-11-14},
  abstract = {Social robots have the potential to revolutionize the way we interact with technology, providing a wide range of services and applications in various domains, such as healthcare, education, and entertainment. However, most existing social robotics platforms are operated based on embedded computers, which limits the robot’s capabilities to access advanced AI-based platforms available online and which are required for sophisticated physical human–robot interactions (such as Google Cloud AI, Microsoft Azure Machine Learning, IBM Watson, ChatGPT, etc.). In this research project, we introduce a cloud-based framework that utilizes the benefits of cloud computing and clustering to enhance the capabilities of social robots and overcome the limitations of current embedded platforms. The proposed framework was tested in different robots to assess the general feasibility of the solution, including a customized robot, “BuSaif”, and commercialized robots, “Husky”, “NAO”, and “Pepper”. Our findings suggest that the implementation of the proposed platform will result in more intelligent and autonomous social robots that can be utilized by a broader range of users, including those with less expertise. The present study introduces a novel methodology for augmenting the functionality of social robots, concurrently simplifying their utilization for non-experts. This approach has the potential to open up novel possibilities within the domain of social robotics.},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\K2P99FRW\Elfaki 等。 - 2023 - Revolutionizing Social Robotics A Cloud-Based Fra.pdf}
}

@article{elliott-cooperMovingMarcuseGentrification2020,
  title = {Moving beyond {{Marcuse}}: {{Gentrification}}, Displacement and the Violence of Un-Homing},
  shorttitle = {Moving beyond {{Marcuse}}},
  author = {Elliott-Cooper, Adam and Hubbard, Phil and Lees, Loretta},
  date = {2020-06},
  journaltitle = {Progress in Human Geography},
  shortjournal = {Progress in Human Geography},
  volume = {44},
  number = {3},
  pages = {492--509},
  issn = {0309-1325, 1477-0288},
  doi = {10.1177/0309132519830511},
  url = {http://journals.sagepub.com/doi/10.1177/0309132519830511},
  urldate = {2023-09-16},
  abstract = {Displacement has become one of the most prominent themes in contemporary geographical debates, used to describe processes of dispossession and forced eviction at a diverse range of scales. Given its frequent deployment in studies describing the consequences of gentrification, this paper seeks to better define and conceptualise displacement as a process of un-homing, noting that while gentrification can prompt processes of eviction, expulsion and exclusion operating at different scales and speeds, it always ruptures the connection between people and place. On this basis – and recognising displacement as a form of violence – this paper concludes that the diverse scales and temporalities of displacement need to be better elucidated so that their negative emotional, psychosocial and material impacts can be more fully documented, and resisted.},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\K9HEPIWI\Elliott-Cooper 等。 - 2020 - Moving beyond Marcuse Gentrification, displacemen.pdf}
}

@article{erdenAssistingManualWelding2011,
  title = {Assisting Manual Welding with Robot},
  author = {Erden, Mustafa Suphi and Marić, Bobby},
  date = {2011-08},
  journaltitle = {Robotics and Computer-Integrated Manufacturing},
  shortjournal = {Robotics and Computer-Integrated Manufacturing},
  volume = {27},
  number = {4},
  pages = {818--828},
  issn = {07365845},
  doi = {10.1016/j.rcim.2011.01.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0736584511000172},
  urldate = {2023-08-18},
  langid = {english}
}

@article{erolCoordinatedControlAssistive2008,
  title = {Coordinated Control of Assistive Robotic Devices for Activities of Daily Living Tasks},
  author = {Erol, D. and Sarkar, N.},
  date = {2008},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume = {16},
  number = {3},
  pages = {278--285},
  doi = {10.1109/TNSRE.2008.922668},
  abstract = {Recent research in rehabilitation indicates that tasks that focus on activities of daily living (ADL) are likely to show significant increase in motor recovery after stroke. Most ADL tasks require patients to coordinate their arm and hand movements to complete these tasks. This paper presents a new control approach for robot-assisted rehabilitation of stroke patients that enables them to perform ADL by providing controlled and coordinated assistance to both arm and hand movement. The control architecture is represented in terms of a hybrid system model combining a high-level controller for decision-making and two low-level assistive controllers (arm and hand controllers) for arm and hand motion assistance. The presented controller is implemented on a test-bed and the results of this implementation are presented to demonstrate the feasibility of the proposed control architecture. © 2006 IEEE.}
}

@article{erolCoordinatedControlAssistive2008a,
  title = {Coordinated Control of Assistive Robotic Devices for Activities of Daily Living Tasks},
  author = {Erol, D. and Sarkar, N.},
  date = {2008},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume = {16},
  number = {3},
  pages = {278--285},
  doi = {10.1109/TNSRE.2008.922668},
  abstract = {Recent research in rehabilitation indicates that tasks that focus on activities of daily living (ADL) are likely to show significant increase in motor recovery after stroke. Most ADL tasks require patients to coordinate their arm and hand movements to complete these tasks. This paper presents a new control approach for robot-assisted rehabilitation of stroke patients that enables them to perform ADL by providing controlled and coordinated assistance to both arm and hand movement. The control architecture is represented in terms of a hybrid system model combining a high-level controller for decision-making and two low-level assistive controllers (arm and hand controllers) for arm and hand motion assistance. The presented controller is implemented on a test-bed and the results of this implementation are presented to demonstrate the feasibility of the proposed control architecture. © 2006 IEEE.}
}

@article{ervinBriefHistoryTentative2020,
  title = {A Brief History and Tentative Taxonomy of Digital Landscape Architecture},
  author = {Ervin, S.M.},
  date = {2020},
  journaltitle = {Journal of Digital Landscape Architecture},
  volume = {2020},
  number = {5},
  pages = {2--11},
  doi = {10.14627/537690001},
  abstract = {“Digital landscape architecture” may either mean “digital approaches to the design of analog landscapes” or “the design of digital landscapes”. These two distinct meanings challenge some conventional assumptions about landscapes and landscape elements; and highlight emergent (increasingly digital) approaches to the design, construction, and enjoyment of landscapes. For descriptive and analytical purposes, I propose a distinction between analog / pre-digital (‘Olmstedian’) landscapes and (‘postOlmstedian’) digital landscapes, where the digital component may be only in representation (the most common form to date); in algorithmic conception, or in robotic construction (increasingly common); or in embedded digital components and cyber-physical landscape features (still rare). In the not-so-distant future I predict we will likely see hybrid organic/digital (‘bionic’) landscapes.}
}

@article{ervinBriefHistoryTentative2020a,
  title = {A Brief History and Tentative Taxonomy of Digital Landscape Architecture},
  author = {Ervin, S.M.},
  date = {2020},
  journaltitle = {Journal of Digital Landscape Architecture},
  volume = {2020},
  number = {5},
  pages = {2--11},
  doi = {10.14627/537690001},
  abstract = {“Digital landscape architecture” may either mean “digital approaches to the design of analog landscapes” or “the design of digital landscapes”. These two distinct meanings challenge some conventional assumptions about landscapes and landscape elements; and highlight emergent (increasingly digital) approaches to the design, construction, and enjoyment of landscapes. For descriptive and analytical purposes, I propose a distinction between analog / pre-digital (‘Olmstedian’) landscapes and (‘postOlmstedian’) digital landscapes, where the digital component may be only in representation (the most common form to date); in algorithmic conception, or in robotic construction (increasingly common); or in embedded digital components and cyber-physical landscape features (still rare). In the not-so-distant future I predict we will likely see hybrid organic/digital (‘bionic’) landscapes.}
}

@inproceedings{escorciaAutomatedVisionbasedRecognition2012,
  title = {Automated Vision-Based Recognition of Construction Worker Actions for Building Interior Construction Operations Using {{RGBD}} Cameras},
  booktitle = {Construction {{Research Congress}} 2012: {{Construction Challenges}} in a {{Flat World}}, {{Proceedings}} of the 2012 {{Construction Research Congress}}},
  author = {Escorcia, V. and Dávila, M. A. and Golparvar-Fard, M. and Niebles, J. C.},
  date = {2012},
  pages = {879--888},
  doi = {10.1061/9780784412329.089},
  abstract = {In this paper we present a novel method for reliable recognition of construction workers and their actions using color and depth data from a Microsoft Kinect sensor. Our algorithm is based on machine learning techniques, in which meaningful visual features are extracted based on the estimated body pose of workers. We adopt a bag-of-poses representation for worker actions and combine it with powerful discriminative classifiers to achieve accurate action recognition. The discriminative framework is able to focus on the visual aspects that are distinctive and can detect and recognize actions from different workers. We train and test our algorithm by using 80 videos from four workers involved in five drywall related construction activities. These videos were all collected from drywall construction activities inside of an under construction dining hall facility. The proposed algorithm is further validated by recognizing the actions of a construction worker that was never seen before in the training dataset. Experimental results show that our method achieves an average precision of 85.28 percent. The results reflect the promise of the proposed method for automated assessment of craftsmen productivity, safety, and occupational health at indoor environments. © 2012 ASCE.},
  isbn = {978-0-7844-1232-9}
}

@inproceedings{escorciaAutomatedVisionbasedRecognition2012a,
  title = {Automated Vision-Based Recognition of Construction Worker Actions for Building Interior Construction Operations Using {{RGBD}} Cameras},
  booktitle = {Construction {{Research Congress}} 2012: {{Construction Challenges}} in a {{Flat World}}, {{Proceedings}} of the 2012 {{Construction Research Congress}}},
  author = {Escorcia, V. and Dávila, M.A. and Golparvar-Fard, M. and Niebles, J.C.},
  date = {2012},
  pages = {879--888},
  doi = {10.1061/9780784412329.089},
  abstract = {In this paper we present a novel method for reliable recognition of construction workers and their actions using color and depth data from a Microsoft Kinect sensor. Our algorithm is based on machine learning techniques, in which meaningful visual features are extracted based on the estimated body pose of workers. We adopt a bag-of-poses representation for worker actions and combine it with powerful discriminative classifiers to achieve accurate action recognition. The discriminative framework is able to focus on the visual aspects that are distinctive and can detect and recognize actions from different workers. We train and test our algorithm by using 80 videos from four workers involved in five drywall related construction activities. These videos were all collected from drywall construction activities inside of an under construction dining hall facility. The proposed algorithm is further validated by recognizing the actions of a construction worker that was never seen before in the training dataset. Experimental results show that our method achieves an average precision of 85.28 percent. The results reflect the promise of the proposed method for automated assessment of craftsmen productivity, safety, and occupational health at indoor environments. © 2012 ASCE.},
  isbn = {978-0-7844-1232-9}
}

@book{estivill-castroHighPerformanceRelaying2014,
  title = {High Performance Relaying of {{C}}++11 Objects across Processes and Logic-Labeled Finite-State Machines},
  author = {Estivill-Castro, V. and Hexel, R. and Lusty, C.},
  date = {2014},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {8810},
  doi = {10.1007/978-3-319-11900-7_16},
  abstract = {We present gusimplewhiteboard, a software architecture analogous to ROS:services and ROS:messages, that enables the construction and extremely efficient inter-process relaying of message-types as C++11 objects, All gusimplewhiteboard objects reside in shared memory. Moreover, our principle is to use idempotent message communication, in direct contrast to previously released platforms for robotic-module communication, that are based on an event-driven subscriber model that queues and multi-threads. We combine this with compiled, timetriggered, logic-labeled finite state machines (llfsms) the are executed concurrently, but scheduled sequentially, in an extremely efficient manner, removing all race conditions and requirements for explicit synchronisation. Together, these tools enable effective robotic behaviour design, where arrangements of llfsms can be organised as hierarchies of machines and submachines, enabling composition of very complex systems. They have proven to be very powerful for Model-Driven Development, capable of simulation, validation, and formal verification.},
  pagetotal = {182-194}
}

@book{estivill-castroHighPerformanceRelaying2014a,
  title = {High Performance Relaying of {{C}}++11 Objects across Processes and Logic-Labeled Finite-State Machines},
  author = {Estivill-Castro, V. and Hexel, R. and Lusty, C.},
  date = {2014},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {8810},
  doi = {10.1007/978-3-319-11900-7_16},
  abstract = {We present gusimplewhiteboard, a software architecture analogous to ROS:services and ROS:messages, that enables the construction and extremely efficient inter-process relaying of message-types as C++11 objects, All gusimplewhiteboard objects reside in shared memory. Moreover, our principle is to use idempotent message communication, in direct contrast to previously released platforms for robotic-module communication, that are based on an event-driven subscriber model that queues and multi-threads. We combine this with compiled, timetriggered, logic-labeled finite state machines (llfsms) the are executed concurrently, but scheduled sequentially, in an extremely efficient manner, removing all race conditions and requirements for explicit synchronisation. Together, these tools enable effective robotic behaviour design, where arrangements of llfsms can be organised as hierarchies of machines and submachines, enabling composition of very complex systems. They have proven to be very powerful for Model-Driven Development, capable of simulation, validation, and formal verification.},
  pagetotal = {182-194}
}

@article{fangSematicPriorknowledgeaidedMonocular2020,
  title = {A Sematic and Prior-Knowledge-Aided Monocular Localization Method for Construction-Related Entities},
  author = {Fang, Q. and Li, H. and Luo, X. and Li, C. and An, W.},
  date = {2020},
  journaltitle = {Computer-Aided Civil and Infrastructure Engineering},
  volume = {35},
  number = {9},
  pages = {979--996},
  doi = {10.1111/mice.12541},
  abstract = {The real-time location of construction-related entities is some of the most useful basic information for automated construction management. However, the implementation of most existing localization methods is limited due to the weak adaptability to construction sites. In this paper, we enhance the monocular vision technique for the localization of construction-related entities by a sematic and prior knowledge-based method. A deep learning algorithm is employed to segment the sematic instance in the images, and then the prior knowledge model specifies projection strategies for entities corresponding to various scenarios. Results show that the proposed method achieves satisfying positioning accuracy, is robust in low-ratio occlusions, and can help facilitate safety early warning, activity recognition, and productivity analysis.}
}

@article{fangSematicPriorknowledgeaidedMonocular2020a,
  title = {A Sematic and Prior-Knowledge-Aided Monocular Localization Method for Construction-Related Entities},
  author = {Fang, Q. and Li, H. and Luo, X. and Li, C. and An, W.},
  date = {2020},
  journaltitle = {Computer-Aided Civil and Infrastructure Engineering},
  volume = {35},
  number = {9},
  pages = {979--996},
  doi = {10.1111/mice.12541},
  abstract = {The real-time location of construction-related entities is some of the most useful basic information for automated construction management. However, the implementation of most existing localization methods is limited due to the weak adaptability to construction sites. In this paper, we enhance the monocular vision technique for the localization of construction-related entities by a sematic and prior knowledge-based method. A deep learning algorithm is employed to segment the sematic instance in the images, and then the prior knowledge model specifies projection strategies for entities corresponding to various scenarios. Results show that the proposed method achieves satisfying positioning accuracy, is robust in low-ratio occlusions, and can help facilitate safety early warning, activity recognition, and productivity analysis.}
}

@inproceedings{fannyDevelopingCriticalRobot2020,
  title = {Developing a {{Critical Robot Literacy}} for {{Young People}} from {{Conceptual Metaphors Analysis}}},
  booktitle = {Proceedings - {{Frontiers}} in {{Education Conference}}, {{FIE}}},
  author = {Fanny, B. and Julie, H. and Anne-Sophie, C.},
  date = {2020},
  volume = {2020-Octob},
  doi = {10.1109/FIE44824.2020.9273959},
  abstract = {This Research-to-Practice Full Paper presents a reflective analysis of robotic literacy activities focused on children and teenagers. Robotic literacy is integrated or being integrated into the education system for children at an early age all around the world. Most of the teachers in charge of this education lack skills and are left to fend for themselves. This study proposes to focus on the discourses made by teachers and learners during such activities, and especially the metaphors used spontaneously. It takes shape through two robotic literacy activities. The first activity involved the robots BeeBot, BlueBot and Ozobot in seven classes of children from 3 to 10 years old. The second activity consisted of a five half-days training for 13 participants from 8 to 15 years old. They designed, built and programmed a robot. Young people's representations and interactions with robots involved in educational activities are observed to contribute to the development of questions for critical technology education. Analyses are carried out using the conceptual metaphor theory of Lakoff and Jonhson. Three roles are identified: the metaphor that helps to understand, the metaphor that makes tangible, and the metaphor that serves as a catchphrase. A metaphor can take more than one role and, whatever its role, can be classified as a living or non-living metaphor. Using living metaphors may hide aspects of the machine and raises ethical issues, inter alia. It is then essential to deconstruct young people's representations of the machine. This can be achieved by analyzing robots as social constructions that reflect human intentions.},
  isbn = {978-1-72818-961-1}
}

@inproceedings{fannyDevelopingCriticalRobot2020a,
  title = {Developing a {{Critical Robot Literacy}} for {{Young People}} from {{Conceptual Metaphors Analysis}}},
  booktitle = {Proceedings - {{Frontiers}} in {{Education Conference}}, {{FIE}}},
  author = {Fanny, B. and Julie, H. and Anne-Sophie, C.},
  date = {2020},
  volume = {2020-Octob},
  doi = {10.1109/FIE44824.2020.9273959},
  abstract = {This Research-to-Practice Full Paper presents a reflective analysis of robotic literacy activities focused on children and teenagers. Robotic literacy is integrated or being integrated into the education system for children at an early age all around the world. Most of the teachers in charge of this education lack skills and are left to fend for themselves. This study proposes to focus on the discourses made by teachers and learners during such activities, and especially the metaphors used spontaneously. It takes shape through two robotic literacy activities. The first activity involved the robots BeeBot, BlueBot and Ozobot in seven classes of children from 3 to 10 years old. The second activity consisted of a five half-days training for 13 participants from 8 to 15 years old. They designed, built and programmed a robot. Young people's representations and interactions with robots involved in educational activities are observed to contribute to the development of questions for critical technology education. Analyses are carried out using the conceptual metaphor theory of Lakoff and Jonhson. Three roles are identified: the metaphor that helps to understand, the metaphor that makes tangible, and the metaphor that serves as a catchphrase. A metaphor can take more than one role and, whatever its role, can be classified as a living or non-living metaphor. Using living metaphors may hide aspects of the machine and raises ethical issues, inter alia. It is then essential to deconstruct young people's representations of the machine. This can be achieved by analyzing robots as social constructions that reflect human intentions.},
  isbn = {978-1-72818-961-1}
}

@inproceedings{fariaMeYouTogether2017,
  title = {“{{Me}} and You Together” Movement Impact in Multi-User Collaboration Tasks},
  booktitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Faria, Miguel and Silva, Rui and Alves-Oliveira, Patricia and Melo, Francisco S. and Paiva, Ana},
  date = {2017-09},
  pages = {2793--2798},
  publisher = {{IEEE}},
  location = {{Vancouver, BC}},
  doi = {10.1109/IROS.2017.8206109},
  url = {http://ieeexplore.ieee.org/document/8206109/},
  urldate = {2023-08-19},
  eventtitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  isbn = {978-1-5386-2682-5}
}

@article{felbrichNovelRapidAdditive2018,
  title = {A Novel Rapid Additive Manufacturing Concept for Architectural Composite Shell Construction Inspired by the Shell Formation in Land Snails},
  author = {Felbrich, B. and Wulle, F. and Allgaier, C. and Menges, A. and Verl, A. and Wurst, K.-H. and Nebelsick, J.H.},
  date = {2018},
  journaltitle = {Bioinspiration and Biomimetics},
  volume = {13},
  number = {2},
  doi = {10.1088/1748-3190/aaa50d},
  abstract = {State-of-the-art rapid additive manufacturing (RAM) - specifically fused filament fabrication (FFF) - has gained popularity among architects, engineers and designers for the quick prototyping of technical devices, the rapid production of small series and even the construction scale fabrication of architectural elements. The spectrum of producible shapes and the resolution of detail, however, are determined and constrained by the layer-based nature of the fabrication process. These aspects significantly limit FFF-based approaches for the prefabrication and in situ fabrication of free-form shells at the architectural scale. Snails exhibit a shell building process that suggests ways to overcome these limits. They produce a soft, pliable proteinaceous film - the periostracum - which later hardens and serves, among other functions, as a form-giving surface for an inner calcium carbonate layer. Snail shell formation is interpreted from a technical point of view to extract potentially useful aspects for a biomimetic transfer. A RAM concept for the continuous extrusion of thin free-form composite shells inspired by the snail shell formation is presented.}
}

@article{felbrichNovelRapidAdditive2018a,
  title = {A Novel Rapid Additive Manufacturing Concept for Architectural Composite Shell Construction Inspired by the Shell Formation in Land Snails},
  author = {Felbrich, B. and Wulle, F. and Allgaier, C. and Menges, A. and Verl, A. and Wurst, K.-H. and Nebelsick, J.H.},
  date = {2018},
  journaltitle = {Bioinspiration and Biomimetics},
  volume = {13},
  number = {2},
  doi = {10.1088/1748-3190/aaa50d},
  abstract = {State-of-the-art rapid additive manufacturing (RAM) - specifically fused filament fabrication (FFF) - has gained popularity among architects, engineers and designers for the quick prototyping of technical devices, the rapid production of small series and even the construction scale fabrication of architectural elements. The spectrum of producible shapes and the resolution of detail, however, are determined and constrained by the layer-based nature of the fabrication process. These aspects significantly limit FFF-based approaches for the prefabrication and in situ fabrication of free-form shells at the architectural scale. Snails exhibit a shell building process that suggests ways to overcome these limits. They produce a soft, pliable proteinaceous film - the periostracum - which later hardens and serves, among other functions, as a form-giving surface for an inner calcium carbonate layer. Snail shell formation is interpreted from a technical point of view to extract potentially useful aspects for a biomimetic transfer. A RAM concept for the continuous extrusion of thin free-form composite shells inspired by the snail shell formation is presented.}
}

@article{fengDistributedControlMultiple1997,
  title = {Distributed Control of a Multiple Tethered Mobile Robot System for Highway Maintenance and Construction},
  author = {Feng, X. and Velinsky, S.A.},
  date = {1997},
  journaltitle = {Microcomputers in Civil Engineering},
  volume = {12},
  number = {6},
  pages = {383--392},
  abstract = {The development of a distributed control system for a multiple mobile robot system is described. The mobile robots considered have been termed tethered mobile robots (TMRs). The TMRs are differentially steered, wheeled mobile robots tethered to a support vehicle, and they have been designed for automating highway maintenance and construction. The control system consists of a network of a host computer and several real-time dynamic controllers running under Windows for Workgroups and DOS operating systems, respectively. Advanced industrial embedding technology is applied to the hardware design, and the system's fault-tolerance is achieved from a distributed architecture and overall condition monitoring. The object-oriented and hardware-independent software programming provides a graphic user interface and flexibility for a large number of highway maintenance and construction tasks. It also provides convenience for any other mobile robotics research applications. © 1997 Microcomputers in Civil Engineering. Published by Blackwell Publishers.}
}

@article{fengDistributedControlMultiple1997a,
  title = {Distributed Control of a Multiple Tethered Mobile Robot System for Highway Maintenance and Construction},
  author = {Feng, X. and Velinsky, S.A.},
  date = {1997},
  journaltitle = {Computer-Aided Civil and Infrastructure Engineering},
  volume = {12},
  number = {6},
  pages = {383--392},
  doi = {10.1111/0885-9507.00071},
  abstract = {The development of a distributed control system for a multiple mobile robot system is described. The mobile robots considered have been termed tethered mobile robots (TMRs). The TMRs are differentially steered, wheeled mobile robots tethered to a support vehicle, and they have been designed for automating highway maintenance and construction. The control system consists of a network of a host computer and several real-time dynamic controllers running under Windows for Workgroups and DOS operating systems, respectively. Advanced industrial embedding technology is applied to the hardware design, and the system's fault-tolerance is achieved from a distributed architecture and overall condition monitoring. The object-oriented and hardware-independent software programming provides a graphic user interface and flexibility for a large number of highway maintenance and construction tasks. It also provides convenience for any other mobile robotics research applications. © 1997 Microcomputers in Civil Engineering. Published by Blackwell Publishers.}
}

@article{fengDistributedControlMultiple1997b,
  title = {Distributed Control of a Multiple Tethered Mobile Robot System for Highway Maintenance and Construction},
  author = {Feng, X. and Velinsky, S.A.},
  date = {1997},
  journaltitle = {Microcomputers in Civil Engineering},
  volume = {12},
  number = {6},
  pages = {383--392},
  abstract = {The development of a distributed control system for a multiple mobile robot system is described. The mobile robots considered have been termed tethered mobile robots (TMRs). The TMRs are differentially steered, wheeled mobile robots tethered to a support vehicle, and they have been designed for automating highway maintenance and construction. The control system consists of a network of a host computer and several real-time dynamic controllers running under Windows for Workgroups and DOS operating systems, respectively. Advanced industrial embedding technology is applied to the hardware design, and the system's fault-tolerance is achieved from a distributed architecture and overall condition monitoring. The object-oriented and hardware-independent software programming provides a graphic user interface and flexibility for a large number of highway maintenance and construction tasks. It also provides convenience for any other mobile robotics research applications. © 1997 Microcomputers in Civil Engineering. Published by Blackwell Publishers.}
}

@article{fengDistributedControlMultiple1997c,
  title = {Distributed Control of a Multiple Tethered Mobile Robot System for Highway Maintenance and Construction},
  author = {Feng, X. and Velinsky, S.A.},
  date = {1997},
  journaltitle = {Computer-Aided Civil and Infrastructure Engineering},
  volume = {12},
  number = {6},
  pages = {383--392},
  doi = {10.1111/0885-9507.00071},
  abstract = {The development of a distributed control system for a multiple mobile robot system is described. The mobile robots considered have been termed tethered mobile robots (TMRs). The TMRs are differentially steered, wheeled mobile robots tethered to a support vehicle, and they have been designed for automating highway maintenance and construction. The control system consists of a network of a host computer and several real-time dynamic controllers running under Windows for Workgroups and DOS operating systems, respectively. Advanced industrial embedding technology is applied to the hardware design, and the system's fault-tolerance is achieved from a distributed architecture and overall condition monitoring. The object-oriented and hardware-independent software programming provides a graphic user interface and flexibility for a large number of highway maintenance and construction tasks. It also provides convenience for any other mobile robotics research applications. © 1997 Microcomputers in Civil Engineering. Published by Blackwell Publishers.}
}

@article{fengResearchPfControl2008,
  title = {Research on Pf Control for Construction Telerobot with Force Telepresence},
  author = {Feng, S. and Zhao, D. and Shang, T. and Deng, L.},
  date = {2008},
  journaltitle = {Nongye Jixie Xuebao/Transactions of the Chinese Society of Agricultural Machinery},
  volume = {39},
  number = {2},
  pages = {120--124},
  abstract = {Combining the feature of bilateral hydraulic servo control systems, based on the analysis of force telepresence techniques presently used in a construction robot system, a position-force architecture was formed by using a new controller which used a force sensor and a hydraulic motor controlled by an electro hydraulic servo valve to constitute a hydraulic force controller. This replaced the traditional pp architecture widely used in the construction robot system. The experimental results indicated that the new design improved the transparency of the teleoperation of construction telerobot system with force telepresence.}
}

@article{fengResearchPfControl2008a,
  title = {Research on Pf Control for Construction Telerobot with Force Telepresence},
  author = {Feng, S. and Zhao, D. and Shang, T. and Deng, L.},
  date = {2008},
  journaltitle = {Nongye Jixie Xuebao/Transactions of the Chinese Society of Agricultural Machinery},
  volume = {39},
  number = {2},
  pages = {120--124},
  abstract = {Combining the feature of bilateral hydraulic servo control systems, based on the analysis of force telepresence techniques presently used in a construction robot system, a position-force architecture was formed by using a new controller which used a force sensor and a hydraulic motor controlled by an electro hydraulic servo valve to constitute a hydraulic force controller. This replaced the traditional pp architecture widely used in the construction robot system. The experimental results indicated that the new design improved the transparency of the teleoperation of construction telerobot system with force telepresence.}
}

@inproceedings{finchUnderstandingChallengesCircular2020,
  title = {Understanding the Challenges of Circular Economy Construction through Full-Scale Prototyping},
  booktitle = {Proceedings of the {{International Conference}} of {{Architectural Science Association}}},
  author = {Finch, G. and Marriage, G. and Gjerde, M. and Pelosi, A. and Patel, Y.},
  date = {2020},
  volume = {2020-Novem},
  pages = {1283--1292},
  abstract = {Applying the Circular Economy paradigm in the built environment requires buildings to be designed for deconstruction and material recovery. Achieving circularity is complicated by the fact that requirements for deconstruction are at odds with most current mainstream construction techniques. The widespread adoption of single-use fixings, adhesives and composite materials mean that it is rarely economically or technically feasible to recover materials. To address this issue a highly modified structural timber framing solution has been designed that separates traditionally dependant layers of a buildings weather resistant envelope. As part of evaluating the viability of this modified framing solution a full-scale building prototype was constructed. The prototype adopted an entirely modular, prefabricated lightweight structural frame with provision for the reversible fixing of structural cavity battens, cladding, purlins and internal linings. Experimental thermally modified plywood cladding materials, using a bespoke concealed bracket, were also designed and deployed. The design-build process worked effectively to highlight limitations within the proposed circular building system, however it was observed that many of the issues found could have been identified using detailed BIM modelling (down to a fixing level).},
  isbn = {978-0-9923835-7-2}
}

@inproceedings{finchUnderstandingChallengesCircular2020a,
  title = {Understanding the Challenges of Circular Economy Construction through Full-Scale Prototyping},
  booktitle = {Proceedings of the {{International Conference}} of {{Architectural Science Association}}},
  author = {Finch, G. and Marriage, G. and Gjerde, M. and Pelosi, A. and Patel, Y.},
  date = {2020},
  volume = {2020-Novem},
  pages = {1283--1292},
  abstract = {Applying the Circular Economy paradigm in the built environment requires buildings to be designed for deconstruction and material recovery. Achieving circularity is complicated by the fact that requirements for deconstruction are at odds with most current mainstream construction techniques. The widespread adoption of single-use fixings, adhesives and composite materials mean that it is rarely economically or technically feasible to recover materials. To address this issue a highly modified structural timber framing solution has been designed that separates traditionally dependant layers of a buildings weather resistant envelope. As part of evaluating the viability of this modified framing solution a full-scale building prototype was constructed. The prototype adopted an entirely modular, prefabricated lightweight structural frame with provision for the reversible fixing of structural cavity battens, cladding, purlins and internal linings. Experimental thermally modified plywood cladding materials, using a bespoke concealed bracket, were also designed and deployed. The design-build process worked effectively to highlight limitations within the proposed circular building system, however it was observed that many of the issues found could have been identified using detailed BIM modelling (down to a fixing level).},
  isbn = {978-0-9923835-7-2}
}

@article{finioMeasurementDefinitionGentrification2022,
  title = {Measurement and {{Definition}} of {{Gentrification}} in {{Urban Studies}} and {{Planning}}},
  author = {Finio, Nicholas},
  date = {2022-05},
  journaltitle = {Journal of Planning Literature},
  shortjournal = {Journal of Planning Literature},
  volume = {37},
  number = {2},
  pages = {249--264},
  issn = {0885-4122, 1552-6593},
  doi = {10.1177/08854122211051603},
  url = {http://journals.sagepub.com/doi/10.1177/08854122211051603},
  urldate = {2023-09-16},
  abstract = {The amount of empirical research on the extent, causes, and consequences of gentrification continues to expand. This article reviews the methods utilized to delimit and quantify gentrification in the literature. Such measurement is undertaken in order to assess the consequences of gentrification, such as displacement, over various time scales and geographies. Recent research has demonstrated that the use of different quantitative definitions of gentrification may yield conflicting research results, and further, can muddy the waters for policymaking and political discourse. This article critically assesses the breadth of quantitative definitions and offers recommendations for future studies.},
  langid = {english}
}

@article{fletcherAdaptiveAutomationAssembly2020,
  title = {Adaptive Automation Assembly: {{Identifying}} System Requirements for Technical Efficiency and Worker Satisfaction},
  shorttitle = {Adaptive Automation Assembly},
  author = {Fletcher, Sarah R. and Johnson, Teegan and Adlon, Tobias and Larreina, Jon and Casla, Patricia and Parigot, Laure and Alfaro, Pedro J. and Otero, María Del Mar},
  date = {2020-01},
  journaltitle = {Computers \& Industrial Engineering},
  shortjournal = {Computers \& Industrial Engineering},
  volume = {139},
  pages = {105772},
  issn = {03608352},
  doi = {10.1016/j.cie.2019.03.036},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S036083521930172X},
  urldate = {2023-08-19},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\GB8R5V5B\Fletcher 等。 - 2020 - Adaptive automation assembly Identifying system r.pdf}
}

@article{FlightAssembledArchitecture2014,
  title = {The {{Flight Assembled Architecture}} Installation: {{Cooperative}} Construction with Flying Machines},
  shorttitle = {The {{Flight Assembled Architecture}} Installation},
  date = {2014-08},
  journaltitle = {IEEE Control Systems},
  shortjournal = {IEEE Control Syst.},
  volume = {34},
  number = {4},
  pages = {46--64},
  issn = {1066-033X, 1941-000X},
  doi = {10.1109/MCS.2014.2320359},
  url = {https://ieeexplore.ieee.org/document/6853477/},
  urldate = {2023-09-19}
}

@article{Forsyth1990,
  author = {Forsyth, D.R.},
  date = {1990},
  journaltitle = {Group Dynamics}
}

@article{fremontVisionbasedPeopleDetection2016,
  title = {Vision-Based People Detection System for Heavy Machine Applications},
  author = {Fremont, V. and Bui, M. T. and Boukerroui, D. and Letort, P.},
  date = {2016},
  journaltitle = {Sensors (Switzerland)},
  volume = {16},
  number = {1},
  doi = {10.3390/s16010128},
  abstract = {This paper presents a vision-based people detection system for improving safety in heavy machines. We propose a perception system composed of a monocular fisheye camera and a LiDAR. Fisheye cameras have the advantage of a wide field-of-view, but the strong distortions that they create must be handled at the detection stage. Since people detection in fisheye images has not been well studied, we focus on investigating and quantifying the impact that strong radial distortions have on the appearance of people, and we propose approaches for handling this specificity, adapted from state-of-the-art people detection approaches. These adaptive approaches nevertheless have the drawback of high computational cost and complexity. Consequently, we also present a framework for harnessing the LiDAR modality in order to enhance the detection algorithm for different camera positions. A sequential LiDAR-based fusion architecture is used, which addresses directly the problem of reducing false detections and computational cost in an exclusively vision-based system. A heavy machine dataset was built, and different experiments were carried out to evaluate the performance of the system. The results are promising, in terms of both processing speed and performance.}
}

@article{fremontVisionbasedPeopleDetection2016a,
  title = {Vision-Based People Detection System for Heavy Machine Applications},
  author = {Fremont, V. and Bui, M.T. and Boukerroui, D. and Letort, P.},
  date = {2016},
  journaltitle = {Sensors (Switzerland)},
  volume = {16},
  number = {1},
  doi = {10.3390/s16010128},
  abstract = {This paper presents a vision-based people detection system for improving safety in heavy machines. We propose a perception system composed of a monocular fisheye camera and a LiDAR. Fisheye cameras have the advantage of a wide field-of-view, but the strong distortions that they create must be handled at the detection stage. Since people detection in fisheye images has not been well studied, we focus on investigating and quantifying the impact that strong radial distortions have on the appearance of people, and we propose approaches for handling this specificity, adapted from state-of-the-art people detection approaches. These adaptive approaches nevertheless have the drawback of high computational cost and complexity. Consequently, we also present a framework for harnessing the LiDAR modality in order to enhance the detection algorithm for different camera positions. A sequential LiDAR-based fusion architecture is used, which addresses directly the problem of reducing false detections and computational cost in an exclusively vision-based system. A heavy machine dataset was built, and different experiments were carried out to evaluate the performance of the system. The results are promising, in terms of both processing speed and performance.}
}

@article{frenchWhatCanManagement2009,
  title = {What Can Management Theories Offer Evidence-Based Practice? {{A}} Comparative Analysis of Measurement Tools for Organisational Context},
  author = {French, B. and Thomas, L. H. and Baker, P. and Burton, C. R. and Pennington, L. and Roddam, H.},
  date = {2009},
  journaltitle = {Implementation Science},
  volume = {4},
  number = {1},
  doi = {10.1186/1748-5908-4-28},
  abstract = {Background. Given the current emphasis on networks as vehicles for innovation and change in health service delivery, the ability to conceptualise and measure organisational enablers for the social construction of knowledge merits attention. This study aimed to develop a composite tool to measure the organisational context for evidence-based practice (EBP) in healthcare. Methods. A structured search of the major healthcare and management databases for measurement tools from four domains: research utilisation (RU), research activity (RA), knowledge management (KM), and organisational learning (OL). Included studies were reports of the development or use of measurement tools that included organisational factors. Tools were appraised for face and content validity, plus development and testing methods. Measurement tool items were extracted, merged across the four domains, and categorised within a constructed framework describing the absorptive and receptive capacities of organisations. Results. Thirty measurement tools were identified and appraised. Eighteen tools from the four domains were selected for item extraction and analysis. The constructed framework consists of seven categories relating to three core organisational attributes of vision, leadership, and a learning culture, and four stages of knowledge need, acquisition of new knowledge, knowledge sharing, and knowledge use. Measurement tools from RA or RU domains had more items relating to the categories of leadership, and acquisition of new knowledge; while tools from KM or learning organisation domains had more items relating to vision, learning culture, knowledge need, and knowledge sharing. There was equal emphasis on knowledge use in the different domains. Conclusion. If the translation of evidence into knowledge is viewed as socially mediated, tools to measure the organisational context of EBP in healthcare could be enhanced by consideration of related concepts from the organisational and management sciences. Comparison of measurement tools across domains suggests that there is scope within EBP for supplementing the current emphasis on human and technical resources to support information uptake and use by individuals. Consideration of measurement tools from the fields of KM and OL shows more content related to social mechanisms to facilitate knowledge recognition, translation, and transfer between individuals and groups. © 2009 French et al; licensee BioMed Central Ltd.}
}

@article{frenchWhatCanManagement2009a,
  title = {What Can Management Theories Offer Evidence-Based Practice? {{A}} Comparative Analysis of Measurement Tools for Organisational Context},
  author = {French, B. and Thomas, L.H. and Baker, P. and Burton, C.R. and Pennington, L. and Roddam, H.},
  date = {2009},
  journaltitle = {Implementation Science},
  volume = {4},
  number = {1},
  doi = {10.1186/1748-5908-4-28},
  abstract = {Background. Given the current emphasis on networks as vehicles for innovation and change in health service delivery, the ability to conceptualise and measure organisational enablers for the social construction of knowledge merits attention. This study aimed to develop a composite tool to measure the organisational context for evidence-based practice (EBP) in healthcare. Methods. A structured search of the major healthcare and management databases for measurement tools from four domains: research utilisation (RU), research activity (RA), knowledge management (KM), and organisational learning (OL). Included studies were reports of the development or use of measurement tools that included organisational factors. Tools were appraised for face and content validity, plus development and testing methods. Measurement tool items were extracted, merged across the four domains, and categorised within a constructed framework describing the absorptive and receptive capacities of organisations. Results. Thirty measurement tools were identified and appraised. Eighteen tools from the four domains were selected for item extraction and analysis. The constructed framework consists of seven categories relating to three core organisational attributes of vision, leadership, and a learning culture, and four stages of knowledge need, acquisition of new knowledge, knowledge sharing, and knowledge use. Measurement tools from RA or RU domains had more items relating to the categories of leadership, and acquisition of new knowledge; while tools from KM or learning organisation domains had more items relating to vision, learning culture, knowledge need, and knowledge sharing. There was equal emphasis on knowledge use in the different domains. Conclusion. If the translation of evidence into knowledge is viewed as socially mediated, tools to measure the organisational context of EBP in healthcare could be enhanced by consideration of related concepts from the organisational and management sciences. Comparison of measurement tools across domains suggests that there is scope within EBP for supplementing the current emphasis on human and technical resources to support information uptake and use by individuals. Consideration of measurement tools from the fields of KM and OL shows more content related to social mechanisms to facilitate knowledge recognition, translation, and transfer between individuals and groups. © 2009 French et al; licensee BioMed Central Ltd.}
}

@article{friesOceanSensorImaging2015,
  title = {Ocean Sensor “Imaging” Arrays Based on Bio-Inspired Architectures and 2-{{D}}/3-{{D}} Construction},
  author = {Fries, D.P. and Starr, C.A. and Barton, G.W.},
  date = {2015},
  journaltitle = {Marine Technology Society Journal},
  volume = {49},
  number = {3},
  pages = {43--49},
  doi = {10.4031/MTSJ.49.3.17},
  abstract = {Many common ocean sensor systems measure a localized space above a single sensor element. Single-point measurements give magnitude but not necessarily direction information. Expanding single sensor elements, such as used in salinity sensors, into arrays permits spatial distribution measurements and allows flux visualizations. Furthermore, applying microsystem technology to these macro sensor systems can yield imaging arrays with high-resolution spatial/temporal sensing functions. Extending such high spatial resolution imaging over large areas is a desirable feature for new “vision” modes on autonomous robotic systems and for deployable ocean sensor systems. The work described here explores the use of printed circuit board (PCB) technology for new sensing concepts and designs. In order to create rigid-conformal, large area imaging “camera” systems, we have merged flexible PCB substrates with rigid constructions from 3-D printing. This approach merges the 2-D flexible electronics world of printed circuits with the 3-D printed packaging world. Furthermore, employing architectures used by biology as a basis for our imaging systems, we explored naturally and biologically inspired designs, their relationships to visual imagining, and alternate mechanical systems of perception. Through the use of bio-inspiration, a framework is laid out to base further research on design for packaging of ocean sensors and arrays. Using 3-D printed exoskeleton’s rigid form with flexible printed circuits, one can create systems that are both rigid and form-fitting with 3-D shape and enable new sensor systems for various ocean sensory applications.}
}

@article{friesOceanSensorImaging2015a,
  title = {Ocean Sensor “Imaging” Arrays Based on Bio-Inspired Architectures and 2-{{D}}/3-{{D}} Construction},
  author = {Fries, D.P. and Starr, C.A. and Barton, G.W.},
  date = {2015},
  journaltitle = {Marine Technology Society Journal},
  volume = {49},
  number = {3},
  pages = {43--49},
  doi = {10.4031/MTSJ.49.3.17},
  abstract = {Many common ocean sensor systems measure a localized space above a single sensor element. Single-point measurements give magnitude but not necessarily direction information. Expanding single sensor elements, such as used in salinity sensors, into arrays permits spatial distribution measurements and allows flux visualizations. Furthermore, applying microsystem technology to these macro sensor systems can yield imaging arrays with high-resolution spatial/temporal sensing functions. Extending such high spatial resolution imaging over large areas is a desirable feature for new “vision” modes on autonomous robotic systems and for deployable ocean sensor systems. The work described here explores the use of printed circuit board (PCB) technology for new sensing concepts and designs. In order to create rigid-conformal, large area imaging “camera” systems, we have merged flexible PCB substrates with rigid constructions from 3-D printing. This approach merges the 2-D flexible electronics world of printed circuits with the 3-D printed packaging world. Furthermore, employing architectures used by biology as a basis for our imaging systems, we explored naturally and biologically inspired designs, their relationships to visual imagining, and alternate mechanical systems of perception. Through the use of bio-inspiration, a framework is laid out to base further research on design for packaging of ocean sensors and arrays. Using 3-D printed exoskeleton’s rigid form with flexible printed circuits, one can create systems that are both rigid and form-fitting with 3-D shape and enable new sensor systems for various ocean sensory applications.}
}

@inproceedings{frischmannHighOrderFinite2014,
  title = {High Order {{Finite Elements}} for Mid-Frequency Vibro-Acoustics},
  booktitle = {Proceedings of the {{International Conference}} on {{Structural Dynamic}} , {{EURODYN}}},
  author = {Frischmann, F. and Kollmannsberger, S. and Rabold, A. and Rank, E.},
  date = {2014},
  volume = {2014-Janua},
  pages = {3341--3348},
  abstract = {The quantification of vibroacoustic properties in multi-floor timber buildings is currently still based on measurements and computational models are rarely used in practice. One reason surely is a lack of validated and robust numeric schemes for vibro-acoustic simulations covering mid-range frequencies which can be integrated smoothly into the planning process of multi-floor timber buildings. To this end, we lay out a pipeline for the prediction of mid-frequency vibro-acoustic behavior of laminated timber constructions by modal analysis using three-dimensional high-order finite elements. The integration into the planning process is achieved by deriving the computational model from IFC-based building information models.},
  isbn = {978-972-752-165-4}
}

@inproceedings{frischmannHighOrderFinite2014a,
  title = {High Order {{Finite Elements}} for Mid-Frequency Vibro-Acoustics},
  booktitle = {Proceedings of the {{International Conference}} on {{Structural Dynamic}} , {{EURODYN}}},
  author = {Frischmann, F. and Kollmannsberger, S. and Rabold, A. and Rank, E.},
  date = {2014},
  volume = {2014-Janua},
  pages = {3341--3348},
  abstract = {The quantification of vibroacoustic properties in multi-floor timber buildings is currently still based on measurements and computational models are rarely used in practice. One reason surely is a lack of validated and robust numeric schemes for vibro-acoustic simulations covering mid-range frequencies which can be integrated smoothly into the planning process of multi-floor timber buildings. To this end, we lay out a pipeline for the prediction of mid-frequency vibro-acoustic behavior of laminated timber constructions by modal analysis using three-dimensional high-order finite elements. The integration into the planning process is achieved by deriving the computational model from IFC-based building information models.},
  isbn = {978-972-752-165-4}
}

@inproceedings{fujitaAssessmentOperatorsMental2010,
  title = {Assessment of Operators' Mental Strain Induced by Hand-over Motion of Industrial Robot Manipulator},
  booktitle = {19th {{International Symposium}} in {{Robot}} and {{Human Interactive Communication}}},
  author = {Fujita, Marina and Kato, Ryu and Tamio, Arai},
  date = {2010-09},
  pages = {361--366},
  publisher = {{IEEE}},
  location = {{Viareggio, Italy}},
  doi = {10.1109/ROMAN.2010.5598689},
  url = {http://ieeexplore.ieee.org/document/5598689/},
  urldate = {2023-08-19},
  eventtitle = {2010 {{RO-MAN}}: {{The}} 19th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}},
  isbn = {978-1-4244-7991-7}
}

@article{furnariRecognizingPersonalLocations2017,
  title = {Recognizing {{Personal Locations From Egocentric Videos}}},
  author = {Furnari, A. and Farinella, G. M. and Battiato, S.},
  date = {2017},
  journaltitle = {IEEE Transactions on Human-Machine Systems},
  volume = {47},
  number = {1},
  pages = {6--18},
  doi = {10.1109/THMS.2016.2612002},
  abstract = {Contextual awareness in wearable computing allows for construction of intelligent systems, which are able to interact with the user in a more natural way. In this paper, we study how personal locations arising from the user's daily activities can be recognized from egocentric videos. We assume that few training samples are available for learning purposes. Considering the diversity of the devices available on the market, we introduce a benchmark dataset containing egocentric videos of eight personal locations acquired by a user with four different wearable cameras. To make our analysis useful in real-world scenarios, we propose a method to reject negative locations, i.e., those not belonging to any of the categories of interest for the end-user. We assess the performances of the main state-of-the-art representations for scene and object classification on the considered task, as well as the influence of device-specific factors such as the field of view and the wearing modality. Concerning the different device-specific factors, experiments revealed that the best results are obtained using a head-mounted wide-angular device. Our analysis shows the effectiveness of using representations based on convolutional neural networks, employing basic transfer learning techniques and an entropy-based rejection algorithm.}
}

@article{furnariRecognizingPersonalLocations2017a,
  title = {Recognizing {{Personal Locations From Egocentric Videos}}},
  author = {Furnari, A. and Farinella, G.M. and Battiato, S.},
  date = {2017},
  journaltitle = {IEEE Transactions on Human-Machine Systems},
  volume = {47},
  number = {1},
  pages = {6--18},
  doi = {10.1109/THMS.2016.2612002},
  abstract = {Contextual awareness in wearable computing allows for construction of intelligent systems, which are able to interact with the user in a more natural way. In this paper, we study how personal locations arising from the user's daily activities can be recognized from egocentric videos. We assume that few training samples are available for learning purposes. Considering the diversity of the devices available on the market, we introduce a benchmark dataset containing egocentric videos of eight personal locations acquired by a user with four different wearable cameras. To make our analysis useful in real-world scenarios, we propose a method to reject negative locations, i.e., those not belonging to any of the categories of interest for the end-user. We assess the performances of the main state-of-the-art representations for scene and object classification on the considered task, as well as the influence of device-specific factors such as the field of view and the wearing modality. Concerning the different device-specific factors, experiments revealed that the best results are obtained using a head-mounted wide-angular device. Our analysis shows the effectiveness of using representations based on convolutional neural networks, employing basic transfer learning techniques and an entropy-based rejection algorithm.}
}

@article{garciaDiscreteRoboticAssemblies2019,
  title = {Discrete Robotic Assemblies towards an Automated Architecture},
  author = {García, M.J. and Retsin, G. and Soler, V.},
  date = {2019},
  journaltitle = {Spool},
  volume = {6},
  number = {1},
  pages = {35--42},
  doi = {10.7480/spool.2019.1.3891},
  abstract = {The projects featured in this paper aim to demonstrate the potential of Discrete Robotic Assembly in architecture. Although still in its early stages, this research proves that there is an increase in construction efficiency within a discrete design framework. The research shows how a limited set of assembly possibilities eases the automation of the manufacturing process and leads to a reduction of labour, construction time, and cost. This intrinsic link between discrete design methods and automation hints at a potential shift in the construction industry governed by a new paradigm in computational design, where architectural elements are defined from and for automation.}
}

@article{garciaDiscreteRoboticAssemblies2019a,
  title = {Discrete Robotic Assemblies towards an Automated Architecture},
  author = {García, M.J. and Retsin, G. and Soler, V.},
  date = {2019},
  journaltitle = {Spool},
  volume = {6},
  number = {1},
  pages = {35--42},
  doi = {10.7480/spool.2019.1.3891},
  abstract = {The projects featured in this paper aim to demonstrate the potential of Discrete Robotic Assembly in architecture. Although still in its early stages, this research proves that there is an increase in construction efficiency within a discrete design framework. The research shows how a limited set of assembly possibilities eases the automation of the manufacturing process and leads to a reduction of labour, construction time, and cost. This intrinsic link between discrete design methods and automation hints at a potential shift in the construction industry governed by a new paradigm in computational design, where architectural elements are defined from and for automation.}
}

@inproceedings{gaudryEcologicalMassTimber2019,
  title = {Ecological Mass Timber as an Answer to Affordable Housing in {{Switzerland}}?},
  booktitle = {20th {{Congress}} of {{IABSE}}, {{New York City}} 2019: {{The Evolving Metropolis}} - {{Report}}},
  author = {Gaudry, L. and Nembrini, J. and Chabloz, M. and Schmid, M. and Golchan, D.},
  date = {2019},
  pages = {622--630},
  abstract = {The lightness and thermal performances of timber has led designers to consider using it for urban densification and to make it the key for a more sustainable and affordable construction industry. This project of a timber-framed high-rise building will become one of the tallest in Switzerland to adopt a wooden construction, using a mix of two types of manufactured wood: cross-laminated timber (CLT) for structural walls and glue-laminated timber (a.k.a. glulam) combined to an upper concrete layer linked with screws for the slabs. The use of timber sourced from local forest is considered by the engineers because its abundance in Switzerland. The concrete layer is needed to reach a high level of acoustic performance and to efficiently create horizontal diaphragms for earthquake resistance. It also enables the reduction of the thickness of the complex. The lower wooden surfaces with warm natural appearance are visible from the rooms, as well as the vertical surfaces of the CLT wall supporting them. The project reveals the complexity for timber structures to simultaneously comply with regulations concerning structural, fire safety, acoustical and earthquake-resistance performances. Building Information Modeling (BIM) allows excellent technical installations coordination to reach a high degree of prefabrication.},
  isbn = {978-3-85748-165-9}
}

@inproceedings{gaudryEcologicalMassTimber2019a,
  title = {Ecological Mass Timber as an Answer to Affordable Housing in {{Switzerland}}?},
  booktitle = {20th {{Congress}} of {{IABSE}}, {{New York City}} 2019: {{The Evolving Metropolis}} - {{Report}}},
  author = {Gaudry, L. and Nembrini, J. and Chabloz, M. and Schmid, M. and Golchan, D.},
  date = {2019},
  pages = {622--630},
  abstract = {The lightness and thermal performances of timber has led designers to consider using it for urban densification and to make it the key for a more sustainable and affordable construction industry. This project of a timber-framed high-rise building will become one of the tallest in Switzerland to adopt a wooden construction, using a mix of two types of manufactured wood: cross-laminated timber (CLT) for structural walls and glue-laminated timber (a.k.a. glulam) combined to an upper concrete layer linked with screws for the slabs. The use of timber sourced from local forest is considered by the engineers because its abundance in Switzerland. The concrete layer is needed to reach a high level of acoustic performance and to efficiently create horizontal diaphragms for earthquake resistance. It also enables the reduction of the thickness of the complex. The lower wooden surfaces with warm natural appearance are visible from the rooms, as well as the vertical surfaces of the CLT wall supporting them. The project reveals the complexity for timber structures to simultaneously comply with regulations concerning structural, fire safety, acoustical and earthquake-resistance performances. Building Information Modeling (BIM) allows excellent technical installations coordination to reach a high degree of prefabrication.},
  isbn = {978-3-85748-165-9}
}

@article{gaziSoiveillanceSelfconsciousnessSocial2018,
  title = {Soiveillance: {{Self-consciousness}} and the Social Network in {{Hideaki Anno}}’s {{Love}} \&amp; {{Pop}}},
  author = {Gazi, J.},
  date = {2018},
  journaltitle = {Surveillance and Society},
  volume = {16},
  number = {1},
  pages = {84--111},
  doi = {10.24908/ss.v16i1.6434},
  abstract = {This article analyses the surveillance aesthetic of Hideaki Anno’s 1998 film Love \& Pop. It is proposed that the film communicates the concept of “soiveillance”—a watching (veillance) that is of one’s self (soi). What underpins soiveillance is the paranoia associated with social surveillance (Marwick 2012), specifically the self-consciousness involved in the image sharing that constructs the virtual self of the social media user (Willett 2009). With its theme of enjo kosai—or “paid-dates” between adult males and female teenagers—Love \& Pop’s communication of soiveillance further illuminates the impact of one’s gender status within the social network, and the manner in which real-world patriarchy and misogyny pass into the virtual construction of selves. The methodology used to argue these points rests on a reconfigured take on the term “scopophilia” within the study of visual media. Scopophilia, rethought as a love of vision itself, aligns with Murakami’s (2000) theory of the superflat on three key points: the acknowledgment that emerging technologies have created new image-functions and image-structures that require a broadening of our theoretical vocabulary; an atemporal approach to the reading of images, such that a late-nineties film like Anno’s can provide important insights into 21st century concerns; and a recognition of intermedial convergence, which allows us to read the activity of online video sharing as a form of narrative equivalent to the sequencing of shots within a cinematic montage.}
}

@article{gaziSoiveillanceSelfconsciousnessSocial2018a,
  title = {Soiveillance: {{Self-consciousness}} and the Social Network in {{Hideaki Anno}}’s {{Love}} \&amp; {{Pop}}},
  author = {Gazi, J.},
  date = {2018},
  journaltitle = {Surveillance and Society},
  volume = {16},
  number = {1},
  pages = {84--111},
  doi = {10.24908/ss.v16i1.6434},
  abstract = {This article analyses the surveillance aesthetic of Hideaki Anno’s 1998 film Love \& Pop. It is proposed that the film communicates the concept of “soiveillance”—a watching (veillance) that is of one’s self (soi). What underpins soiveillance is the paranoia associated with social surveillance (Marwick 2012), specifically the self-consciousness involved in the image sharing that constructs the virtual self of the social media user (Willett 2009). With its theme of enjo kosai—or “paid-dates” between adult males and female teenagers—Love \& Pop’s communication of soiveillance further illuminates the impact of one’s gender status within the social network, and the manner in which real-world patriarchy and misogyny pass into the virtual construction of selves. The methodology used to argue these points rests on a reconfigured take on the term “scopophilia” within the study of visual media. Scopophilia, rethought as a love of vision itself, aligns with Murakami’s (2000) theory of the superflat on three key points: the acknowledgment that emerging technologies have created new image-functions and image-structures that require a broadening of our theoretical vocabulary; an atemporal approach to the reading of images, such that a late-nineties film like Anno’s can provide important insights into 21st century concerns; and a recognition of intermedial convergence, which allows us to read the activity of online video sharing as a form of narrative equivalent to the sequencing of shots within a cinematic montage.}
}

@inproceedings{geierCriteriaCatalogueAnalysis2019,
  title = {Criteria Catalogue and Analysis Model to Manage Complexity in Prefabricated Timber Construction},
  booktitle = {{{IOP Conference Series}}: {{Earth}} and {{Environmental Science}}},
  author = {Geier, S. and Schwehr, P.},
  date = {2019},
  volume = {323},
  number = {1},
  doi = {10.1088/1755-1315/323/1/012046},
  abstract = {Prefabricated timber construction often comes with demanding planning processes and uncertainties due to higher complexity. Hence, a great potential to optimize design, construction, and economic efficiency is not put to use. In the future, the challenge will be to have project management that is able to handle complexity. The criteria catalogue and the analysis model, developed in my doctoral thesis at TU Munich, are a first step towards the systematic and typological structuring of prefabricated timber construction in terms of complexity. The criteria catalogue makes it possible to describe and record functional and technical specifications as well as the aspects of the design and construction process and implementation, in terms of less or greater complexity. The project-specific system presentation in the analysis model is the basis for a common understanding and a transparent and target-oriented exchange of information among different disciplines, including the client. The application of the model in practice is described by means of a case study. The outlook of this paper describes how the developed analysis model provides a new approach in order to support planning security in Building Information Modeling (BIM).}
}

@article{geierCriteriaCatalogueAnalysis2019a,
  title = {Criteria Catalogue and Analysis Model to Manage Complexity in Prefabricated Timber Construction},
  author = {Geier, S and Schwehr, P},
  date = {2019-09-06},
  journaltitle = {IOP Conference Series: Earth and Environmental Science},
  volume = {323},
  number = {1},
  pages = {012046},
  issn = {1755-1315},
  doi = {10.1088/1755-1315/323/1/012046},
  url = {https://iopscience.iop.org/article/10.1088/1755-1315/323/1/012046},
  abstract = {Prefabricated timber construction often comes with demanding planning processes and uncertainties due to higher complexity. Hence, a great potential to optimize design, construction, and economic efficiency is not put to use. In the future, the challenge will be to have project management that is able to handle complexity. The criteria catalogue and the analysis model, developed in my doctoral thesis at TU Munich, are a first step towards the systematic and typological structuring of prefabricated timber construction in terms of complexity. The criteria catalogue makes it possible to describe and record functional and technical specifications as well as the aspects of the design and construction process and implementation, in terms of less or greater complexity. The project-specific system presentation in the analysis model is the basis for a common understanding and a transparent and target-oriented exchange of information among different disciplines, including the client. The application of the model in practice is described by means of a case study. The outlook of this paper describes how the developed analysis model provides a new approach in order to support planning security in Building Information Modeling (BIM).}
}

@article{geierLeanWOODResilientDesign2019,
  title = {{{leanWOOD}} – towards Resilient Design and Building Processes},
  author = {Geier, S},
  date = {2019-09-06},
  journaltitle = {IOP Conference Series: Earth and Environmental Science},
  volume = {323},
  number = {1},
  pages = {012019},
  issn = {1755-1315},
  doi = {10.1088/1755-1315/323/1/012019},
  url = {https://iopscience.iop.org/article/10.1088/1755-1315/323/1/012019},
  abstract = {With the introduction of the concept of resilience in the discourse of building design, design and building processes have to react to complex challenges presented by the extension of the perspective from physical building structure to living space. Instead of conserving effort, resilience demands integrated and argumentative processes and interdisciplinary cooperation. Forerunners in industrialized timber construction have long-standing experience and are starting points for new advanced design processes. The international leanWOOD project (2014-2017) aimed at outlining the requirements for future timber building planning processes to put them on a broader base and thus contribute to advanced processes in the future. To achieve resilience in building design, rigid and sequential process-chains must turn into flexible, argumentative process approaches. The paper illustrates the key elements for resilience-oriented design processes, discusses procurement and cooperation models, identifies pitfalls in current development and outlines the impact on resilient buildings. Finally, the outlook shows the potential of the implementation of BIM to this change towards resilient design and building processes.},
  file = {C:\Users\leemar\Zotero\storage\4U55I2XV\Geier_2019_IOP_Conf._Ser.%3A_Earth_Environ._Sci._323_012019.pdf}
}

@inproceedings{geierLeanWOODResilientDesign2019a,
  title = {{{LeanWOOD}} - {{Towards}} Resilient Design and Building Processes},
  booktitle = {{{IOP Conference Series}}: {{Earth}} and {{Environmental Science}}},
  author = {Geier, S.},
  date = {2019},
  volume = {323},
  number = {1},
  doi = {10.1088/1755-1315/323/1/012019},
  url = {https://iopscience.iop.org/article/10.1088/1755-1315/323/1/012019},
  abstract = {With the introduction of the concept of resilience in the discourse of building design, design and building processes have to react to complex challenges presented by the extension of the perspective from physical building structure to living space. Instead of conserving effort, resilience demands integrated and argumentative processes and interdisciplinary cooperation. Forerunners in industrialized timber construction have long-standing experience and are starting points for new advanced design processes. The international leanWOOD project (2014-2017) aimed at outlining the requirements for future timber building planning processes to put them on a broader base and thus contribute to advanced processes in the future. To achieve resilience in building design, rigid and sequential process-chains must turn into flexible, argumentative process approaches. The paper illustrates the key elements for resilience-oriented design processes, discusses procurement and cooperation models, identifies pitfalls in current development and outlines the impact on resilient buildings. Finally, the outlook shows the potential of the implementation of BIM to this change towards resilient design and building processes.},
  file = {C:\Users\leemar\Zotero\storage\WINSFX5B\Geier_2019_IOP_Conf._Ser.%3A_Earth_Environ._Sci._323_012019.pdf}
}

@article{gendreauModularArchitectureMicrofactories2010,
  title = {Modular Architecture of the Microfactories for Automatic Micro-Assembly},
  author = {Gendreau, D. and Gauthier, M. and Hériban, D. and Lutz, P.},
  date = {2010},
  journaltitle = {Robotics and Computer-Integrated Manufacturing},
  volume = {26},
  number = {4},
  pages = {354--360},
  doi = {10.1016/j.rcim.2009.11.013},
  abstract = {The construction of a new generation of MEMS which includes micro-assembly steps in the current microfabrication process is a big challenge. It is necessary to develop new production means named micromanufacturing systems in order to perform these new assembly steps. The classical approach called "top-down" which consists in a functional analysis and a definition of the tasks sequences is insufficient for micromanufacturing systems. Indeed, the technical and physical constraints of the microworld (e.g. the adhesion phenomenon) must be taken into account in order to design reliable micromanufacturing systems. A new method of designing micromanufacturing systems is presented in this paper. Our approach combines the general "top-down" approach with a "bottom-up" approach which takes into account technical constraints. The method enables to build a modular architecture for micromanufacturing systems. In order to obtain this modular architecture, we have devised an original identification technique of modules and an association technique of modules. This work has been used to design the controller of an experimental robotic micro-assembly station. © 2009 Elsevier Ltd. All rights reserved.}
}

@article{gendreauModularArchitectureMicrofactories2010a,
  title = {Modular Architecture of the Microfactories for Automatic Micro-Assembly},
  author = {Gendreau, D. and Gauthier, M. and Hériban, D. and Lutz, P.},
  date = {2010},
  journaltitle = {Robotics and Computer-Integrated Manufacturing},
  volume = {26},
  number = {4},
  pages = {354--360},
  doi = {10.1016/j.rcim.2009.11.013},
  abstract = {The construction of a new generation of MEMS which includes micro-assembly steps in the current microfabrication process is a big challenge. It is necessary to develop new production means named micromanufacturing systems in order to perform these new assembly steps. The classical approach called "top-down" which consists in a functional analysis and a definition of the tasks sequences is insufficient for micromanufacturing systems. Indeed, the technical and physical constraints of the microworld (e.g. the adhesion phenomenon) must be taken into account in order to design reliable micromanufacturing systems. A new method of designing micromanufacturing systems is presented in this paper. Our approach combines the general "top-down" approach with a "bottom-up" approach which takes into account technical constraints. The method enables to build a modular architecture for micromanufacturing systems. In order to obtain this modular architecture, we have devised an original identification technique of modules and an association technique of modules. This work has been used to design the controller of an experimental robotic micro-assembly station. © 2009 Elsevier Ltd. All rights reserved.}
}

@article{gharbiaRoboticTechnologiesOnsite2020,
  title = {Robotic Technologies for On-Site Building Construction: {{A}} Systematic Review},
  shorttitle = {Robotic Technologies for On-Site Building Construction},
  author = {Gharbia, Marwan and Chang-Richards, Alice and Lu, Yuqian and Zhong, Ray Y. and Li, Heng},
  date = {2020-11},
  journaltitle = {Journal of Building Engineering},
  shortjournal = {Journal of Building Engineering},
  volume = {32},
  pages = {101584},
  issn = {23527102},
  doi = {10.1016/j.jobe.2020.101584},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352710220313607},
  urldate = {2023-03-20},
  langid = {english}
}

@article{glotonRoleManualKinesthesis1996,
  title = {The Role of Manual Kinesthesis in Building and in Using Mental Representations of Bidimensional Objects | {{Rôle}} de La Kinesthésie Manuelle Dans La Construction et l'utilisation de Représentations d'objets Bidimensionnels},
  author = {Gloton, C. and Bellan, D. and Poitou, J.-P.},
  date = {1996},
  journaltitle = {Travail Humain},
  volume = {59},
  number = {2},
  pages = {137--153},
  abstract = {From a phylogenetic viewpoint, perceptual information linked to manual activity is an integral part of human thought. Moreover, design office operators prefer to draw manually and even manipulate scale models when developping objects which are particularly complex. This research is a first attempt to show that kinesthesic activity could, under specific conditions, benefit visual treatment of information, in constructing and memorising representations available for later use. It contrasts with other work, which opposes vision to kinesthesis or, more often, vision to touch. In this way, it is a new direction for research. Two distinct experiments attempt to measure the effects of manual exploration of two dimensional drawn figures in a recognition task. The first experiment, taken as an extreme control condition, separates kinesthesic processes from visual control to find if, even in these restrictive conditions, the two perceptual modes can help each other. In a first phase intended to allow encoding to work, subjects were to construct spatial representations of the objects. Thus, in the vision-kinesthesis condition, they use kinesthesic activity without any direct visual control. Then they are asked to recognize visually the correct response among five distractors. The second experiment allows kinesthesic processes to act under visual control. It includes two phases : an encoding stage, as in the first experiment ; and a second period intended to be a recall stage in which subjects must again recognize the correct response among distractors. Since, the effects of kinesthesis are assumed to differ according to subject abilities, in both the first and second experiments several groups were constituted to test this factor, from psychology students considered to be an inexperienced population, to high school engineering students, assumed to be a skilled group with regard to drawing activities. The results show that without visual control, kinesthesic activity not only does not make visual work easier, but can even be considered as an interfering task, which disrupts visual information treatment. It is proposed that attention is insufficient to manage both of the perceptual modes. In the second part of this work, even though we cannot assert that kinesthesis always helps visual information treatment, it is shown that in some conditions there is some improvement, especially when the task appears too difficult, when compared with visual performance alone. Kinesthesis seems to be especially useful when storing spatial information in memory, for later recall in a recognition task. These results indicate the potential value of further research along these lines. They also point to the need for a Computer Assisted Design workstation incorporating an analogical manual interface.}
}

@article{glotonRoleManualKinesthesis1996a,
  title = {The Role of Manual Kinesthesis in Building and in Using Mental Representations of Bidimensional Objects | {{Rôle}} de La Kinesthésie Manuelle Dans La Construction et l'utilisation de Représentations d'objets Bidimensionnels},
  author = {Gloton, C. and Bellan, D. and Poitou, J.-P.},
  date = {1996},
  journaltitle = {Travail Humain},
  volume = {59},
  number = {2},
  pages = {137--153},
  abstract = {From a phylogenetic viewpoint, perceptual information linked to manual activity is an integral part of human thought. Moreover, design office operators prefer to draw manually and even manipulate scale models when developping objects which are particularly complex. This research is a first attempt to show that kinesthesic activity could, under specific conditions, benefit visual treatment of information, in constructing and memorising representations available for later use. It contrasts with other work, which opposes vision to kinesthesis or, more often, vision to touch. In this way, it is a new direction for research. Two distinct experiments attempt to measure the effects of manual exploration of two dimensional drawn figures in a recognition task. The first experiment, taken as an extreme control condition, separates kinesthesic processes from visual control to find if, even in these restrictive conditions, the two perceptual modes can help each other. In a first phase intended to allow encoding to work, subjects were to construct spatial representations of the objects. Thus, in the vision-kinesthesis condition, they use kinesthesic activity without any direct visual control. Then they are asked to recognize visually the correct response among five distractors. The second experiment allows kinesthesic processes to act under visual control. It includes two phases : an encoding stage, as in the first experiment ; and a second period intended to be a recall stage in which subjects must again recognize the correct response among distractors. Since, the effects of kinesthesis are assumed to differ according to subject abilities, in both the first and second experiments several groups were constituted to test this factor, from psychology students considered to be an inexperienced population, to high school engineering students, assumed to be a skilled group with regard to drawing activities. The results show that without visual control, kinesthesic activity not only does not make visual work easier, but can even be considered as an interfering task, which disrupts visual information treatment. It is proposed that attention is insufficient to manage both of the perceptual modes. In the second part of this work, even though we cannot assert that kinesthesis always helps visual information treatment, it is shown that in some conditions there is some improvement, especially when the task appears too difficult, when compared with visual performance alone. Kinesthesis seems to be especially useful when storing spatial information in memory, for later recall in a recognition task. These results indicate the potential value of further research along these lines. They also point to the need for a Computer Assisted Design workstation incorporating an analogical manual interface.}
}

@article{gobinArtConnectivity2016,
  title = {An {{Art}} of {{Connectivity}}},
  author = {Gobin, T. and Andraos, S. and Schwartz, T.},
  date = {2016},
  journaltitle = {Architectural Design},
  volume = {86},
  number = {5},
  pages = {68--73},
  doi = {10.1002/ad.2091},
  abstract = {Do building information modelling (BIM) systems sufficiently cater for the subtleties of the architect's role? Tristan Gobin, Sebastian Andraos and Thibault Schwartz of London-based robot control specialists HAL Robotics think not. They advocate the development of systems that offer more levels of abstraction, allowing architects, engineers and others who are not necessarily familiar with source code to assist in the elaboration of platform languages. Only then will they become true tools for creativity that reinforce continuity between the various actors involved in building design and construction.}
}

@article{gobinArtConnectivity2016a,
  title = {An {{Art}} of {{Connectivity}}},
  author = {Gobin, T. and Andraos, S. and Schwartz, T.},
  date = {2016},
  journaltitle = {Architectural Design},
  volume = {86},
  number = {5},
  pages = {68--73},
  doi = {10.1002/ad.2091},
  abstract = {Do building information modelling (BIM) systems sufficiently cater for the subtleties of the architect's role? Tristan Gobin, Sebastian Andraos and Thibault Schwartz of London-based robot control specialists HAL Robotics think not. They advocate the development of systems that offer more levels of abstraction, allowing architects, engineers and others who are not necessarily familiar with source code to assist in the elaboration of platform languages. Only then will they become true tools for creativity that reinforce continuity between the various actors involved in building design and construction.}
}

@article{golparvar-fardAutomatedProgressMonitoring2015,
  title = {Automated Progress Monitoring Using Unordered Daily Construction Photographs and {{IFC-based}} Building Information Models},
  author = {Golparvar-Fard, M. and Peña-Mora, F. and Savarese, S.},
  date = {2015},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {29},
  number = {1},
  doi = {10.1061/(ASCE)CP.1943-5487.0000205},
  abstract = {Accurate and efficient tracking, analysis and visualization of as-built (actual) status of buildings under construction are critical components of a successful project monitoring. Such information directly supports control decision-making and if automated, can significantly impact management of a project. This paper presents a new automated approach for recognition of physical progress based on two emerging sources of information: (1) unordered daily construction photo collections, which are currently collected at almost no cost on all construction sites; and (2) building information models (BIMs), which are increasingly turning into binding components of architecture/engineering/construction contracts. First, given a set of unordered and uncalibrated site photographs, an approach based on structure-from-motion, multiview stereo, and voxel coloring and labeling algorithms is presented that calibrates cameras, photorealistically reconstructs a dense as-built point cloud model in four dimensions (three dimensions + time), and traverses and labels the scene for occupancy. This strategy explicitly accounts for occlusions and allows input images to be taken far apart and widely distributed around the environment. An Industry Foundation Class-based (IFC-based) BIM is subsequently fused into the as-built scene by a robust registration step and is traversed and labeled for expected progress visibility. Next, a machine-learning scheme built upon a Bayesian probabilistic model is proposed that automatically detects physical progress in the presence of occlusions and demonstrates that physical progress monitoring at schedule activity level could be fully automated. Finally, the system enables the expected and reconstructed elements to be explored with an interactive, image-based, three-dimensional (3D) viewer where deviations are automatically color-coded over the IFC-based BIM. To that extent, the underlying hypotheses and algorithms for generating integrated four-dimensional (4D) as-built and as-planned models plus automated progress monitoring are presented. Experimental results are reported for challenging image data sets collected under different lighting conditions and severe occlusions from two ongoing building construction projects. This marks the presented model as being the first probabilistic model for automated progress tracking and visualization of deviations that incorporates both as-planned models and unordered daily photographs in a principled way.}
}

@article{golparvar-fardAutomatedProgressMonitoring2015a,
  title = {Automated Progress Monitoring Using Unordered Daily Construction Photographs and {{IFC-based}} Building Information Models},
  author = {Golparvar-Fard, M. and Peña-Mora, F. and Savarese, S.},
  date = {2015},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {29},
  number = {1},
  doi = {10.1061/(ASCE)CP.1943-5487.0000205},
  abstract = {Accurate and efficient tracking, analysis and visualization of as-built (actual) status of buildings under construction are critical components of a successful project monitoring. Such information directly supports control decision-making and if automated, can significantly impact management of a project. This paper presents a new automated approach for recognition of physical progress based on two emerging sources of information: (1) unordered daily construction photo collections, which are currently collected at almost no cost on all construction sites; and (2) building information models (BIMs), which are increasingly turning into binding components of architecture/engineering/construction contracts. First, given a set of unordered and uncalibrated site photographs, an approach based on structure-from-motion, multiview stereo, and voxel coloring and labeling algorithms is presented that calibrates cameras, photorealistically reconstructs a dense as-built point cloud model in four dimensions (three dimensions + time), and traverses and labels the scene for occupancy. This strategy explicitly accounts for occlusions and allows input images to be taken far apart and widely distributed around the environment. An Industry Foundation Class-based (IFC-based) BIM is subsequently fused into the as-built scene by a robust registration step and is traversed and labeled for expected progress visibility. Next, a machine-learning scheme built upon a Bayesian probabilistic model is proposed that automatically detects physical progress in the presence of occlusions and demonstrates that physical progress monitoring at schedule activity level could be fully automated. Finally, the system enables the expected and reconstructed elements to be explored with an interactive, image-based, three-dimensional (3D) viewer where deviations are automatically color-coded over the IFC-based BIM. To that extent, the underlying hypotheses and algorithms for generating integrated four-dimensional (4D) as-built and as-planned models plus automated progress monitoring are presented. Experimental results are reported for challenging image data sets collected under different lighting conditions and severe occlusions from two ongoing building construction projects. This marks the presented model as being the first probabilistic model for automated progress tracking and visualization of deviations that incorporates both as-planned models and unordered daily photographs in a principled way.}
}

@article{golparvar-fardVisionbasedActionRecognition2013,
  title = {Vision-Based Action Recognition of Earthmoving Equipment Using Spatio-Temporal Features and Support Vector Machine Classifiers},
  author = {Golparvar-Fard, M. and Heydarian, A. and Niebles, J. C.},
  date = {2013},
  journaltitle = {Advanced Engineering Informatics},
  volume = {27},
  number = {4},
  pages = {652--663},
  doi = {10.1016/j.aei.2013.09.001},
  abstract = {Video recordings of earthmoving construction operations provide understandable data that can be used for benchmarking and analyzing their performance. These recordings further support project managers to take corrective actions on performance deviations and in turn improve operational efficiency. Despite these benefits, manual stopwatch studies of previously recorded videos can be labor-intensive, may suffer from biases of the observers, and are impractical after substantial period of observations. This paper presents a new computer vision based algorithm for recognizing single actions of earthmoving construction equipment. This is particularly a challenging task as equipment can be partially occluded in site video streams and usually come in wide variety of sizes and appearances. The scale and pose of the equipment actions can also significantly vary based on the camera configurations. In the proposed method, a video is initially represented as a collection of spatio-temporal visual features by extracting space-time interest points and describing each feature with a Histogram of Oriented Gradients (HOG). The algorithm automatically learns the distributions of the spatio-temporal features and action categories using a multi-class Support Vector Machine (SVM) classifier. This strategy handles noisy feature points arisen from typical dynamic backgrounds. Given a video sequence captured from a fixed camera, the multi-class SVM classifier recognizes and localizes equipment actions. For the purpose of evaluation, a new video dataset is introduced which contains 859 sequences from excavator and truck actions. This dataset contains large variations of equipment pose and scale, and has varied backgrounds and levels of occlusion. The experimental results with average accuracies of 86.33\% and 98.33\% show that our supervised method outperforms previous algorithms for excavator and truck action recognition. The results hold the promise for applicability of the proposed method for construction activity analysis. © 2013 Elsevier Ltd. All rights reserved.}
}

@article{golparvar-fardVisionbasedActionRecognition2013a,
  title = {Vision-Based Action Recognition of Earthmoving Equipment Using Spatio-Temporal Features and Support Vector Machine Classifiers},
  author = {Golparvar-Fard, M. and Heydarian, A. and Niebles, J.C.},
  date = {2013},
  journaltitle = {Advanced Engineering Informatics},
  volume = {27},
  number = {4},
  pages = {652--663},
  doi = {10.1016/j.aei.2013.09.001},
  abstract = {Video recordings of earthmoving construction operations provide understandable data that can be used for benchmarking and analyzing their performance. These recordings further support project managers to take corrective actions on performance deviations and in turn improve operational efficiency. Despite these benefits, manual stopwatch studies of previously recorded videos can be labor-intensive, may suffer from biases of the observers, and are impractical after substantial period of observations. This paper presents a new computer vision based algorithm for recognizing single actions of earthmoving construction equipment. This is particularly a challenging task as equipment can be partially occluded in site video streams and usually come in wide variety of sizes and appearances. The scale and pose of the equipment actions can also significantly vary based on the camera configurations. In the proposed method, a video is initially represented as a collection of spatio-temporal visual features by extracting space-time interest points and describing each feature with a Histogram of Oriented Gradients (HOG). The algorithm automatically learns the distributions of the spatio-temporal features and action categories using a multi-class Support Vector Machine (SVM) classifier. This strategy handles noisy feature points arisen from typical dynamic backgrounds. Given a video sequence captured from a fixed camera, the multi-class SVM classifier recognizes and localizes equipment actions. For the purpose of evaluation, a new video dataset is introduced which contains 859 sequences from excavator and truck actions. This dataset contains large variations of equipment pose and scale, and has varied backgrounds and levels of occlusion. The experimental results with average accuracies of 86.33\% and 98.33\% show that our supervised method outperforms previous algorithms for excavator and truck action recognition. The results hold the promise for applicability of the proposed method for construction activity analysis. © 2013 Elsevier Ltd. All rights reserved.}
}

@article{gomaaThermalPerformanceExploration2019,
  title = {Thermal Performance Exploration of {{3D}} Printed Cob},
  author = {Gomaa, M. and Carfrae, J. and Goodhew, S. and Jabi, W. and Veliz Reyes, A.},
  date = {2019},
  journaltitle = {Architectural Science Review},
  volume = {62},
  number = {3},
  pages = {230--237},
  doi = {10.1080/00038628.2019.1606776},
  abstract = {This paper investigates the thermal properties of 3D printed Cob, a monolithic earth construction technique based on robotically extruded subsoil and locally available organic fibres. The relevance of 3D printed earthen construction materials and the transition from vernacular construction towards a digitally-enabled process are critically discussed. The use of robotic manufacturing is outlined and the methodology to produce the necessary samples for thermal measurement is detailed. The results of the 3D printed samples are compared with traditionally-constructed Cob material of the same dimensions. The assessment has revealed strong potential for 3D printed cob as compared to its manually constructed counterparts in terms of thermal conductivity. Moreover, the testing process has helped in identifying several challenges in the 3D printing process of cob and the assessment of its thermal properties, which will ultimately bring the work closer to full-scale applications.}
}

@article{gomaaThermalPerformanceExploration2019a,
  title = {Thermal Performance Exploration of {{3D}} Printed Cob},
  author = {Gomaa, M. and Carfrae, J. and Goodhew, S. and Jabi, W. and Veliz Reyes, A.},
  date = {2019},
  journaltitle = {Architectural Science Review},
  volume = {62},
  number = {3},
  pages = {230--237},
  doi = {10.1080/00038628.2019.1606776},
  abstract = {This paper investigates the thermal properties of 3D printed Cob, a monolithic earth construction technique based on robotically extruded subsoil and locally available organic fibres. The relevance of 3D printed earthen construction materials and the transition from vernacular construction towards a digitally-enabled process are critically discussed. The use of robotic manufacturing is outlined and the methodology to produce the necessary samples for thermal measurement is detailed. The results of the 3D printed samples are compared with traditionally-constructed Cob material of the same dimensions. The assessment has revealed strong potential for 3D printed cob as compared to its manually constructed counterparts in terms of thermal conductivity. Moreover, the testing process has helped in identifying several challenges in the 3D printing process of cob and the assessment of its thermal properties, which will ultimately bring the work closer to full-scale applications.}
}

@article{gombolayComputationalDesignMixedinitiative2017,
  title = {Computational Design of Mixed-Initiative Human–Robot Teaming That Considers Human Factors: Situational Awareness, Workload, and Workflow Preferences},
  shorttitle = {Computational Design of Mixed-Initiative Human–Robot Teaming That Considers Human Factors},
  author = {Gombolay, Matthew and Bair, Anna and Huang, Cindy and Shah, Julie},
  date = {2017-06},
  journaltitle = {The International Journal of Robotics Research},
  shortjournal = {The International Journal of Robotics Research},
  volume = {36},
  number = {5-7},
  pages = {597--617},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364916688255},
  url = {http://journals.sagepub.com/doi/10.1177/0278364916688255},
  urldate = {2023-08-20},
  langid = {english}
}

@article{gombolayDecisionmakingAuthorityTeam2015,
  title = {Decision-Making Authority, Team Efficiency and Human Worker Satisfaction in Mixed Human–Robot Teams},
  author = {Gombolay, Matthew C. and Gutierrez, Reymundo A. and Clarke, Shanelle G. and Sturla, Giancarlo F. and Shah, Julie A.},
  date = {2015-10},
  journaltitle = {Autonomous Robots},
  shortjournal = {Auton Robot},
  volume = {39},
  number = {3},
  pages = {293--312},
  issn = {0929-5593, 1573-7527},
  doi = {10.1007/s10514-015-9457-9},
  url = {http://link.springer.com/10.1007/s10514-015-9457-9},
  urldate = {2023-08-20},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\LATVVSNN\Gombolay 等。 - 2015 - Decision-making authority, team efficiency and hum.pdf}
}

@article{gongObjectRecognitionTracking2011,
  title = {An Object Recognition, Tracking, and Contextual Reasoning-Based Video Interpretation Method for Rapid Productivity Analysis of Construction Operations},
  author = {Gong, J. and Caldas, C. H.},
  date = {2011},
  journaltitle = {Automation in Construction},
  volume = {20},
  number = {8},
  pages = {1211--1226},
  doi = {10.1016/j.autcon.2011.05.005},
  abstract = {Measuring the process of construction operations for productivity improvement remains a difficult task for most construction companies due to the manual effort required in most activity measurement methods. This paper proposed and described the elements, processes, and algorithms that comprise a computational and intelligent construction video interpretation method. A number of vision-based construction object recognition and tracking methods were evaluated to provide guidance for algorithm selection. A prototype system was developed to integrate the proposed video analysis processes and selected computer vision algorithms. Videos of construction operations were analyzed to validate the proposed method. Comparing to the traditional manual construction video analysis method, the proposed method provided a semi-automated video interpretation method. The new method enabled the interpretation of these videos into productivity information, such as working processes, cycle times, and delays, with an accuracy that was comparable to manual analysis, without the limitations of on-site human observation. © 2011 Elsevier B.V. All rights reserved.}
}

@article{gongObjectRecognitionTracking2011a,
  title = {An Object Recognition, Tracking, and Contextual Reasoning-Based Video Interpretation Method for Rapid Productivity Analysis of Construction Operations},
  author = {Gong, J. and Caldas, C.H.},
  date = {2011},
  journaltitle = {Automation in Construction},
  volume = {20},
  number = {8},
  pages = {1211--1226},
  doi = {10.1016/j.autcon.2011.05.005},
  abstract = {Measuring the process of construction operations for productivity improvement remains a difficult task for most construction companies due to the manual effort required in most activity measurement methods. This paper proposed and described the elements, processes, and algorithms that comprise a computational and intelligent construction video interpretation method. A number of vision-based construction object recognition and tracking methods were evaluated to provide guidance for algorithm selection. A prototype system was developed to integrate the proposed video analysis processes and selected computer vision algorithms. Videos of construction operations were analyzed to validate the proposed method. Comparing to the traditional manual construction video analysis method, the proposed method provided a semi-automated video interpretation method. The new method enabled the interpretation of these videos into productivity information, such as working processes, cycle times, and delays, with an accuracy that was comparable to manual analysis, without the limitations of on-site human observation. © 2011 Elsevier B.V. All rights reserved.}
}

@inproceedings{gonsalvesHumanMotionAnalysis2009,
  title = {Human Motion Analysis Using {{3D}} Range Imaging Technology},
  booktitle = {2009 26th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2009},
  author = {Gonsalves, R. and Teizer, J.},
  date = {2009},
  pages = {76--85},
  doi = {10.22260/isarc2009/0044},
  abstract = {Human motion analysis and tracking are a significant research area in the domain of computer vision. Existing systems of today focus on detection of human targets by analyzing their movements in order to recognize the different activities performed by them. Our research work mainly focuses on using detection and tracking of human targets using a 3D range image camera [1] for surveillance purposes in order to ensure the safety of construction workers and also to monitor their posture and movements for heath related purposes in an active work zone. For this purpose the tracking algorithm proposed performs the segmentation of a human target (i.e. construction worker) from a range image video sequence and then models and tags them in order that their location can be continuously monitored. Unlike most other available systems, our system focuses on using the range or distance information since they indicate how far (in terms of meters) a human target is located away from the camera and more importantly because they are capable of generating a 3D perspective of the human target (i.e. by method of 3D point clouds). The range video sequence is obtained by using a special range image camera, which is an optical imaging system which offers real time 3D image data. Furthermore, the segmented human target is modeled by image skeletonization using a star skeleton structure [7]. This model in future research can be used in conjunction with HMM's (Hidden Markov Models) for human activity recognition. The system designed calculates the angles between different body parts to analyze the posture of a construction worker. It also incorporates the use of a particle filter [2] to trace the path of the construction worker in order to classify different work-related activities. Our system is also capable of detecting multiple people and tracking each of their paths separately in a given work environment.}
}

@inproceedings{gonsalvesHumanMotionAnalysis2009a,
  title = {Human Motion Analysis Using {{3D}} Range Imaging Technology},
  booktitle = {2009 26th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2009},
  author = {Gonsalves, R. and Teizer, J.},
  date = {2009},
  pages = {76--85},
  doi = {10.22260/isarc2009/0044},
  abstract = {Human motion analysis and tracking are a significant research area in the domain of computer vision. Existing systems of today focus on detection of human targets by analyzing their movements in order to recognize the different activities performed by them. Our research work mainly focuses on using detection and tracking of human targets using a 3D range image camera [1] for surveillance purposes in order to ensure the safety of construction workers and also to monitor their posture and movements for heath related purposes in an active work zone. For this purpose the tracking algorithm proposed performs the segmentation of a human target (i.e. construction worker) from a range image video sequence and then models and tags them in order that their location can be continuously monitored. Unlike most other available systems, our system focuses on using the range or distance information since they indicate how far (in terms of meters) a human target is located away from the camera and more importantly because they are capable of generating a 3D perspective of the human target (i.e. by method of 3D point clouds). The range video sequence is obtained by using a special range image camera, which is an optical imaging system which offers real time 3D image data. Furthermore, the segmented human target is modeled by image skeletonization using a star skeleton structure [7]. This model in future research can be used in conjunction with HMM's (Hidden Markov Models) for human activity recognition. The system designed calculates the angles between different body parts to analyze the posture of a construction worker. It also incorporates the use of a particle filter [2] to trace the path of the construction worker in order to classify different work-related activities. Our system is also capable of detecting multiple people and tracking each of their paths separately in a given work environment.}
}

@article{gonzalez-merinoLowcostPrototypeAutomate2021,
  title = {Low-Cost Prototype to Automate the {{3D}} Digitization of Pieces: {{An}} Application Example and Comparison},
  author = {González-Merino, R. and Sánchez-López, E. and Romero, P.E. and Rodero, J. and Hidalgo-Fernández, R.E.},
  date = {2021},
  journaltitle = {Sensors},
  volume = {21},
  number = {8},
  doi = {10.3390/s21082580},
  abstract = {This work is aimed at describing the design of a mechanical and programmable 3D capturing system to be used by either 3D scanner or DSLR camera through photogrammetry. Both methods are widely used in diverse areas, from engineering, architecture or archaeology, up to the field of medicine; but they also entail certain disadvantages, such as the high costs of certain equipment, such as scanners with some precision, and the need to resort to specialized operatives, among others. The purpose of this design is to create a robust, precise and cost-effective system that improves the limitations of the present equipment on the market, such as robotic arms or rotary tables. For this reason, a preliminary study has been conducted to analyse the needs of improvement, later, we have focused on the 3D design and prototyping. For its construction, there have been used the FDM additive technology and structural components that are easy to find in the market. With regards to electronic components, basic electronics and Arduino-based 3D printers firmware have been selected. For system testing, the capture equipment consists of a Spider Artec 3D Scanner and a Nikon 5100 SLR Camera. Finally, 3D models have been developed by comparing the 3D meshes obtained by the two methods, obtaining satisfactory results.}
}

@article{gonzalez-merinoLowcostPrototypeAutomate2021a,
  title = {Low-Cost Prototype to Automate the {{3D}} Digitization of Pieces: {{An}} Application Example and Comparison},
  author = {González-Merino, R. and Sánchez-López, E. and Romero, P.E. and Rodero, J. and Hidalgo-Fernández, R.E.},
  date = {2021},
  journaltitle = {Sensors},
  volume = {21},
  number = {8},
  doi = {10.3390/s21082580},
  abstract = {This work is aimed at describing the design of a mechanical and programmable 3D capturing system to be used by either 3D scanner or DSLR camera through photogrammetry. Both methods are widely used in diverse areas, from engineering, architecture or archaeology, up to the field of medicine; but they also entail certain disadvantages, such as the high costs of certain equipment, such as scanners with some precision, and the need to resort to specialized operatives, among others. The purpose of this design is to create a robust, precise and cost-effective system that improves the limitations of the present equipment on the market, such as robotic arms or rotary tables. For this reason, a preliminary study has been conducted to analyse the needs of improvement, later, we have focused on the 3D design and prototyping. For its construction, there have been used the FDM additive technology and structural components that are easy to find in the market. With regards to electronic components, basic electronics and Arduino-based 3D printers firmware have been selected. For system testing, the capture equipment consists of a Spider Artec 3D Scanner and a Nikon 5100 SLR Camera. Finally, 3D models have been developed by comparing the 3D meshes obtained by the two methods, obtaining satisfactory results.}
}

@article{gonzalez-naldaGenericArchitectureBuilding2016,
  title = {Towards a Generic Architecture for Building Modular Cps as Applied to Mobile Robotics},
  author = {González-Nalda, P. and Etxeberria-Agiriano, I. and Calvo, I.},
  date = {2016},
  journaltitle = {International Journal of Online Engineering},
  volume = {12},
  number = {1},
  pages = {4--8},
  doi = {10.3991/ijoe.v12i1.4833},
  abstract = {This paper presents a generic architecture for the design of Cyber-Physical Systems (CPS) based on inexpensive and easily available hardware and open source software components. This architecture provides a framework aimed at building CPS in a robust, flexible and modular way. The presented architecture intends to ease the construction of this kind of systems together with its evolution and management. The potential of the proposed architecture is illustrated by means of a case study consisting of a mobile robotics application built with low cost hardware modules. There is a large community of users for these components and plenty of related technical information is available. As a consequence, these inexpensive components were found suitable for being used at different application domains, including research and education.}
}

@article{gonzalez-naldaGenericArchitectureBuilding2016a,
  title = {Towards a Generic Architecture for Building Modular Cps as Applied to Mobile Robotics},
  author = {González-Nalda, P. and Etxeberria-Agiriano, I. and Calvo, I.},
  date = {2016},
  journaltitle = {International Journal of Online Engineering},
  volume = {12},
  number = {1},
  pages = {4--8},
  doi = {10.3991/ijoe.v12i1.4833},
  abstract = {This paper presents a generic architecture for the design of Cyber-Physical Systems (CPS) based on inexpensive and easily available hardware and open source software components. This architecture provides a framework aimed at building CPS in a robust, flexible and modular way. The presented architecture intends to ease the construction of this kind of systems together with its evolution and management. The potential of the proposed architecture is illustrated by means of a case study consisting of a mobile robotics application built with low cost hardware modules. There is a large community of users for these components and plenty of related technical information is available. As a consequence, these inexpensive components were found suitable for being used at different application domains, including research and education.}
}

@inproceedings{gorurElasticNetworksReshaping2014,
  title = {Elastic Networks in Reshaping Human Intentions by Proactive Social Robot Moves},
  booktitle = {{{IEEE RO-MAN}} 2014 - 23rd {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}: {{Human-Robot Co-Existence}}: {{Adaptive Interfaces}} and {{Systems}} for {{Daily Life}}, {{Therapy}}, {{Assistance}} and {{Socially Engaging Interactions}}},
  author = {Gorur, O. C. and Erkmen, A. M.},
  date = {2014},
  pages = {1012--1017},
  doi = {10.1109/ROMAN.2014.6926385},
  abstract = {This paper focuses on reshaping a previously detected human intention into a desired one, using contextual motions of mobile robots, which are in our applications, autonomous mobile 2-steps stairs and a chair. Our system first estimates the current intention based on human heading and trajectory depicted as orientation and location. Our previous reshaping applications have shown that the current human intention has to be deviated towards the new desired one in phases. In our novel approach, Elastic network generates way points of trajectories each of which acts as transient trajectories directed towards the desired intention's location. Our methodology aims at generating an 'intention trajectory' towards the final goal. The initial way points possess destabilizing effects on the obstinance of the person intention making the 'robot gain the curiosity and the trust of the person'. Each way point generated by the elastic network is executed by moves of an adequate robot (here mobile 2-steps or chair) in adequate directions (towards coffee table, PC, TV, library). After each robot moves, the resulting human intention is estimated and compared to the desired goal in the intention space. Intention trajectories are searched in two modes: The 'confident mode' and the 'suspicious mode' which are defining human body-mood detected relying on proxemics. This paper analyzes our novel approach of planning trajectories via elastic networks based on these two modes.},
  isbn = {978-1-4799-6763-6}
}

@inproceedings{gorurElasticNetworksReshaping2014a,
  title = {Elastic Networks in Reshaping Human Intentions by Proactive Social Robot Moves},
  booktitle = {{{IEEE RO-MAN}} 2014 - 23rd {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}: {{Human-Robot Co-Existence}}: {{Adaptive Interfaces}} and {{Systems}} for {{Daily Life}}, {{Therapy}}, {{Assistance}} and {{Socially Engaging Interactions}}},
  author = {Gorur, O.C. and Erkmen, A.M.},
  date = {2014},
  pages = {1012--1017},
  doi = {10.1109/ROMAN.2014.6926385},
  abstract = {This paper focuses on reshaping a previously detected human intention into a desired one, using contextual motions of mobile robots, which are in our applications, autonomous mobile 2-steps stairs and a chair. Our system first estimates the current intention based on human heading and trajectory depicted as orientation and location. Our previous reshaping applications have shown that the current human intention has to be deviated towards the new desired one in phases. In our novel approach, Elastic network generates way points of trajectories each of which acts as transient trajectories directed towards the desired intention's location. Our methodology aims at generating an 'intention trajectory' towards the final goal. The initial way points possess destabilizing effects on the obstinance of the person intention making the 'robot gain the curiosity and the trust of the person'. Each way point generated by the elastic network is executed by moves of an adequate robot (here mobile 2-steps or chair) in adequate directions (towards coffee table, PC, TV, library). After each robot moves, the resulting human intention is estimated and compared to the desired goal in the intention space. Intention trajectories are searched in two modes: The 'confident mode' and the 'suspicious mode' which are defining human body-mood detected relying on proxemics. This paper analyzes our novel approach of planning trajectories via elastic networks based on these two modes.},
  isbn = {978-1-4799-6763-6}
}

@inproceedings{grenzfurtnerApplicationFailureMode2016,
  title = {Application of Failure Mode and Effects Analysis in the Instustrial Housebuilding Industry},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Grenzfurtner, W. and Gronalt, M.},
  date = {2016},
  abstract = {Failure mode and effects analysis (FMEA) is a well-known method in quality management (QM). Until now only less research is done in the application of quality and process improvement with FMEA in the construction industry. FMEA supports the involvement of experts' information, allows engineers to get contextual information to problems and enables to assess possible failure regarding to their relevance. Reasons for that can be found in the common project based manner of building projects, which do not support application of FMEA for improvement projects. Industrialised housebuilding, where project based order fulfilment is combined with process views, starts changing the need for QM-methods in the construction industry. Also because of upcoming use of Building Information Modelling (BIM) concepts a need for appropriate QM-methods is generated, to support the development of usable design standards. In addition it is estimated positive because of the involvement of employees experiences which is a common source of improvement ideas in construction industry. An FMEA case study is applied during an improvement project in an industrialized housebuilding company to test how well it works for this application. The method is further assessed with a use case as well as by findings of interviewed employees.},
  isbn = {978-3-903039-00-1}
}

@inproceedings{grenzfurtnerApplicationFailureMode2016a,
  title = {Application of Failure Mode and Effects Analysis in the Instustrial Housebuilding Industry},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Grenzfurtner, W. and Gronalt, M.},
  date = {2016},
  abstract = {Failure mode and effects analysis (FMEA) is a well-known method in quality management (QM). Until now only less research is done in the application of quality and process improvement with FMEA in the construction industry. FMEA supports the involvement of experts' information, allows engineers to get contextual information to problems and enables to assess possible failure regarding to their relevance. Reasons for that can be found in the common project based manner of building projects, which do not support application of FMEA for improvement projects. Industrialised housebuilding, where project based order fulfilment is combined with process views, starts changing the need for QM-methods in the construction industry. Also because of upcoming use of Building Information Modelling (BIM) concepts a need for appropriate QM-methods is generated, to support the development of usable design standards. In addition it is estimated positive because of the involvement of employees experiences which is a common source of improvement ideas in construction industry. An FMEA case study is applied during an improvement project in an industrialized housebuilding company to test how well it works for this application. The method is further assessed with a use case as well as by findings of interviewed employees.},
  isbn = {978-3-903039-00-1}
}

@inproceedings{greweFirstPersonPerspective2020,
  title = {First Person Perspective Video Activity Recognition},
  booktitle = {Proceedings of {{SPIE}} - {{The International Society}} for {{Optical Engineering}}},
  author = {Grewe, L. and Hu, C. and Tank, K. and Jaiswal, A. and Martin, T. and Sutaria, S. and Huynh, T. and Bustos, F. D.},
  date = {2020},
  volume = {11423},
  doi = {10.1117/12.2557922},
  abstract = {The initial development of two First-Person Perspective Video Activity Recognition Systems is discussed. The first system, the First Person Fall Detection or UFall, can be used to recognize when a person wearing or holding the mobile vision system has fallen. The problem of fall detection is tackled from the unique first-person perspective. The second system, the directed CrossWalk System (UCross), involves detection of the user movement across a crosswalk and is intended for use in helping a low vision person navigate. In both cases, the user is wearing or holding the camera device for purposes of monitoring or inspection of the environment. This first-person perspective yields unusual fall data and this is captured and used for the creation of a fall detection system. For both systems Machine Learning is employed using video input to trained Long-Term Short-Term (LSTM) Networks. These first-perspective video activity recognition systems use the Tensorflow framework [1] and is deployed using mobile phones for proof of concept. These applications could be useful for low vision people and in the case of fall detection for senior citizens, police, construction and other inspection-oriented jobs to help users who have fallen. The success and challenges faced with this unique first-person perspective data are presented along with future avenues of work.},
  isbn = {978-1-5106-3623-1}
}

@inproceedings{greweFirstPersonPerspective2020a,
  title = {First Person Perspective Video Activity Recognition},
  booktitle = {Proceedings of {{SPIE}} - {{The International Society}} for {{Optical Engineering}}},
  author = {Grewe, L. and Hu, C. and Tank, K. and Jaiswal, A. and Martin, T. and Sutaria, S. and Huynh, T. and Bustos, F.D.},
  date = {2020},
  volume = {11423},
  doi = {10.1117/12.2557922},
  abstract = {The initial development of two First-Person Perspective Video Activity Recognition Systems is discussed. The first system, the First Person Fall Detection or UFall, can be used to recognize when a person wearing or holding the mobile vision system has fallen. The problem of fall detection is tackled from the unique first-person perspective. The second system, the directed CrossWalk System (UCross), involves detection of the user movement across a crosswalk and is intended for use in helping a low vision person navigate. In both cases, the user is wearing or holding the camera device for purposes of monitoring or inspection of the environment. This first-person perspective yields unusual fall data and this is captured and used for the creation of a fall detection system. For both systems Machine Learning is employed using video input to trained Long-Term Short-Term (LSTM) Networks. These first-perspective video activity recognition systems use the Tensorflow framework [1] and is deployed using mobile phones for proof of concept. These applications could be useful for low vision people and in the case of fall detection for senior citizens, police, construction and other inspection-oriented jobs to help users who have fallen. The success and challenges faced with this unique first-person perspective data are presented along with future avenues of work.},
  isbn = {978-1-5106-3623-1}
}

@inproceedings{Grigore20134622,
  title = {Joint Action Understanding Improves Robot-to-Human Object Handover},
  author = {Grigore, E.C. and Eder, K. and Pipe, A.G. and Melhuish, C. and Leonards, U.},
  date = {2013},
  series = {{{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  pages = {4622--4629},
  doi = {10.1109/IROS.2013.6697021},
  art_number = {6697021}
}

@inproceedings{groenewoltCollaborativeHumanRobotTimber2023,
  title = {Collaborative {{Human-Robot Timber Construction}}},
  author = {Groenewolt, Abel and Krieg, Oliver and Menges, Achim},
  date = {2023},
  pages = {407--416},
  location = {{Graz, Austria}},
  doi = {10.52842/conf.ecaade.2023.1.407},
  url = {http://papers.cumincad.org/cgi-bin/works/paper/ecaade2023_414},
  urldate = {2023-09-26},
  abstract = {This paper presents a case study of collaborative human-robot construction, in the form of a 10-day workshop in robotically assisted construction of curved timber surfaces. The construction process developed for the workshop shows that employing computational design in combination with industrial robots can result in a demand for various kinds of labor, with a range of skill levels: in addition to tasks requiring specialized computational design skills, the proposed construction process also leads to simplification of construction tasks, by eliminating the need to measure on-site.},
  eventtitle = {{{eCAADe}} 2023:  {{Digital Design Reconsidered}}},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\A9ADQJN6\Groenewolt 等。 - 2023 - Collaborative Human-Robot Timber Construction.pdf}
}

@article{groomCanRobotsBe2007,
  title = {Can Robots Be Teammates?: {{Benchmarks}} in Human–Robot Teams},
  shorttitle = {Can Robots Be Teammates?},
  author = {Groom, Victoria and Nass, Clifford},
  date = {2007-11-01},
  journaltitle = {Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems},
  shortjournal = {IS},
  volume = {8},
  number = {3},
  pages = {483--500},
  issn = {1572-0373, 1572-0381},
  doi = {10.1075/is.8.3.10gro},
  url = {http://www.jbe-platform.com/content/journals/10.1075/is.8.3.10gro},
  urldate = {2023-08-20},
  abstract = {The team has become a popular model to organize joint human–robot behavior. Robot teammates are designed with high-levels of autonomy and well-developed coordination skills to aid humans in unpredictable environments. In this paper, we challenge the assumption that robots will succeed as teammates alongside humans. Drawing from the literature on human teams, we evaluate robots’ potential to meet the requirements of successful teammates. We argue that lacking humanlike mental models and a sense of self, robots may prove untrustworthy and will be rejected from human teams. Benchmarks for evaluating human–robot teams are included, as are guidelines for defining alternative structures for human–robot groups.},
  langid = {english}
}

@article{gusmaobrissiReviewInteractionsRobotic2021,
  title = {A Review on the Interactions of Robotic Systems and Lean Principles in Offsite Construction},
  author = {Gusmao Brissi, Sara and Wong Chong, Oscar and Debs, Luciana and Zhang, Jiansong},
  date = {2021},
  journaltitle = {Engineering, Construction and Architectural Management},
  issn = {09699988},
  doi = {10.1108/ECAM-10-2020-0809},
  abstract = {Purpose: The purpose is two-fold: (1) to explore the interactions of robotic systems and lean construction in the context of offsite construction (OC) that were addressed in the literature published between 2008 and 2019 and (2) to identify the gaps in such interactions while discussing how addressing those gaps can benefit not only OC but the architecture, engineering and construction (AEC) industry as a whole. Design/methodology/approach: First, a systematic literature review (SLR) identified journal papers addressing the interactions of automation and lean in OC. Then, the researchers focused the analysis on the under-researched subtopic of robotic systems. The focused analysis includes discussing the interactions identified in the SLR through a matrix of interactions and utilizing literature beyond the previously identified articles for future research directions on robotic systems and lean construction in OC. Findings: The study found 35 journal papers that addressed automation and lean in the context of OC. Most of the identified literature focused on interactions of BIM and lean construction, while only nine focused on the interactions of robotic systems and lean construction. Identified literature related to robotic systems mainly addressed robots and automated equipment. Additional interactions were identified in the realm of wearable devices, unmanned aerial vehicles/automated guided vehicles and digital fabrication/computer numerical control (CNC) machines. Originality/value: This is one of the first studies dedicated to exploring the interactions of robotic systems and lean construction in OC. Also, it proposes a categorization for construction automation and a matrix of interactions between construction automation and lean construction.},
  keywords = {★,Construction automation,Lean construction,Offsite construction,Robotic systems,Systematic literature review},
  file = {C:\Users\leemar\Zotero\storage\4DEGJCT4\10-1108_ECAM-10-2020-0809.pdf}
}

@article{guterstamDecodingIllusorySelflocation2015,
  title = {Decoding Illusory Self-Location from Activity in the Human Hippocampus},
  author = {Guterstam, A. and Björnsdotter, M. and Bergouignan, L. and Gentile, G. and Li, T.-Q. and Ehrsson, H. Henrik},
  date = {2015},
  journaltitle = {Frontiers in Human Neuroscience},
  volume = {9},
  doi = {10.3389/fnhum.2015.00412},
  abstract = {Decades of research have demonstrated a role for the hippocampus in spatial navigation and episodic and spatial memory. However, empirical evidence linking hippocampal activity to the perceptual experience of being physically located at a particular place in the environment is lacking. In this study, we used a multisensory out-of-body illusion to perceptually ‘teleport’ six healthy participants between two different locations in the scanner room during high-resolution functional magnetic resonance imaging (fMRI). The participants were fitted with MRI-compatible head-mounted displays that changed their first-person visual perspective to that of a pair of cameras placed in one of two corners of the scanner room. To elicit the illusion of being physically located in this position, we delivered synchronous visuo-tactile stimulation in the form of an object moving toward the cameras coupled with touches applied to the participant’s chest. Asynchronous visuo-tactile stimulation did not induce the illusion and served as a control condition. We found that illusory self-location could be successfully decoded from patterns of activity in the hippocampus in all of the participants in the synchronous (P {$<$} 0.05) but not in the asynchronous condition (P {$>$} 0.05). At the group-level, the decoding accuracy was significantly higher in the synchronous than in the asynchronous condition (P = 0.012). These findings associate hippocampal activity with the perceived location of the bodily self in space, which suggests that the human hippocampus is involved not only in spatial navigation and memory but also in the construction of our sense of bodily self-location.},
  issue = {JULY}
}

@article{guterstamDecodingIllusorySelflocation2015a,
  title = {Decoding Illusory Self-Location from Activity in the Human Hippocampus},
  author = {Guterstam, A. and Björnsdotter, M. and Bergouignan, L. and Gentile, G. and Li, T.-Q. and Henrik Ehrsson, H.},
  date = {2015},
  journaltitle = {Frontiers in Human Neuroscience},
  volume = {9},
  doi = {10.3389/fnhum.2015.00412},
  abstract = {Decades of research have demonstrated a role for the hippocampus in spatial navigation and episodic and spatial memory. However, empirical evidence linking hippocampal activity to the perceptual experience of being physically located at a particular place in the environment is lacking. In this study, we used a multisensory out-of-body illusion to perceptually ‘teleport’ six healthy participants between two different locations in the scanner room during high-resolution functional magnetic resonance imaging (fMRI). The participants were fitted with MRI-compatible head-mounted displays that changed their first-person visual perspective to that of a pair of cameras placed in one of two corners of the scanner room. To elicit the illusion of being physically located in this position, we delivered synchronous visuo-tactile stimulation in the form of an object moving toward the cameras coupled with touches applied to the participant’s chest. Asynchronous visuo-tactile stimulation did not induce the illusion and served as a control condition. We found that illusory self-location could be successfully decoded from patterns of activity in the hippocampus in all of the participants in the synchronous (P {$<$} 0.05) but not in the asynchronous condition (P {$>$} 0.05). At the group-level, the decoding accuracy was significantly higher in the synchronous than in the asynchronous condition (P = 0.012). These findings associate hippocampal activity with the perceived location of the bodily self in space, which suggests that the human hippocampus is involved not only in spatial navigation and memory but also in the construction of our sense of bodily self-location.},
  issue = {JULY}
}

@article{guThickpanelOrigamiCube2021,
  title = {Thick-Panel {{Origami Cube}}},
  author = {Gu, Y. and Wei, G. and Chen, Y.},
  date = {2021},
  journaltitle = {Mechanism and Machine Theory},
  volume = {164},
  doi = {10.1016/j.mechmachtheory.2021.104411},
  abstract = {This paper presents a new method for constructing a novel thick-panel origami cube. By replacing the equivalent 4R-spherical linkage in a four-crease zero-thickness origami vertex with a plane-symmetric Bricard linkage, the thick-panel form of a general plane-symmetric four-crease origami vertex is identified and constructed. The proposed thick-panel vertex preserves the kinematics of the original four-crease origami vertex. Then, by utilizing the proposed thick-panel vertex, a thick-panel cube is constructed based on the zero-thickness origami cube that was proposed in our previous work. Through mechanism decomposition, geometric constraints and kinematic properties of the corresponding integrated mechanism are investigated and formulated, which reveals the kinematic equivalence between the thick-panel and zero-thickness forms of the origami cube. In addition, a prototype of the proposed thick-panel origami cube is fabricated, verifying its kinematic properties. The proposed technique can be extended to the design and construction of thick-panel polyhedrons with potential applications in the fields such as aerospace exploration, robotics and architecture.}
}

@article{guThickpanelOrigamiCube2021a,
  title = {Thick-Panel {{Origami Cube}}},
  author = {Gu, Y. and Wei, G. and Chen, Y.},
  date = {2021},
  journaltitle = {Mechanism and Machine Theory},
  volume = {164},
  doi = {10.1016/j.mechmachtheory.2021.104411},
  abstract = {This paper presents a new method for constructing a novel thick-panel origami cube. By replacing the equivalent 4R-spherical linkage in a four-crease zero-thickness origami vertex with a plane-symmetric Bricard linkage, the thick-panel form of a general plane-symmetric four-crease origami vertex is identified and constructed. The proposed thick-panel vertex preserves the kinematics of the original four-crease origami vertex. Then, by utilizing the proposed thick-panel vertex, a thick-panel cube is constructed based on the zero-thickness origami cube that was proposed in our previous work. Through mechanism decomposition, geometric constraints and kinematic properties of the corresponding integrated mechanism are investigated and formulated, which reveals the kinematic equivalence between the thick-panel and zero-thickness forms of the origami cube. In addition, a prototype of the proposed thick-panel origami cube is fabricated, verifying its kinematic properties. The proposed technique can be extended to the design and construction of thick-panel polyhedrons with potential applications in the fields such as aerospace exploration, robotics and architecture.}
}

@article{hackStructuralStayinplaceFormwork2020,
  title = {Structural Stay-in-Place Formwork for Robotic in Situ Fabrication of Non-Standard Concrete Structures: {{A}} Real Scale Architectural Demonstrator},
  author = {Hack, N. and Dörfler, K. and Walzer, A.N. and Wangler, T. and Mata-Falcón, J. and Kumar, N. and Buchli, J. and Kaufmann, W. and Flatt, R.J. and Gramazio, F. and Gramazio, F. and Kohler, M.},
  date = {2020},
  journaltitle = {Automation in Construction},
  volume = {115},
  doi = {10.1016/j.autcon.2020.103197},
  abstract = {Concrete is a highly versatile construction material, not only for the reason that it has excellent properties in terms of structural performance, building physics, availability and price, but also because it can be moulded into virtually any shape regardless of its geometric complexity. However, even though current digital design tools allow to effortlessly design and calculate structures, which are exploiting these properties, this potential remains all too often unrealized. This is due to the fact that geometrically complex concrete structures require expensive, one-of-a kind formwork, which can often not be reused or even recycled. Consequently, the current practice for producing non-standard curvilinear architecture in reinforced concrete is neither ecologically sustainable nor economically feasible for a broader range of architectural typologies. Additive Manufacturing (AM) processes, like 3D printing with concrete, on the other hand, currently struggle with the integration of structural reinforcement, limiting the technique to predominantly compression-loaded applications. This research addresses both issues and proposes Mesh Mould, a robotic fabrication process that unifies concrete formwork and structural reinforcement, and hence potentially reduces formwork waste and construction costs for non-standard reinforced concrete constructions. The development of a fully automated robotic fabrication process involved various research disciplines, including architecture, material science, mechanical engineering, robotics as well as civil engineering. This paper describes the technological developments of the Mesh Mould construction system that were necessary to meet the challenges of 1:1 construction. The results are demonstrated in a final loadbearing structure, the Mesh Mould wall of the DFAB HOUSE on NEST.}
}

@article{hackStructuralStayinplaceFormwork2020a,
  title = {Structural Stay-in-Place Formwork for Robotic in Situ Fabrication of Non-Standard Concrete Structures: {{A}} Real Scale Architectural Demonstrator},
  author = {Hack, N. and Dörfler, K. and Walzer, A.N. and Wangler, T. and Mata-Falcón, J. and Kumar, N. and Buchli, J. and Kaufmann, W. and Flatt, R.J. and Gramazio, F. and Gramazio, F. and Kohler, M.},
  date = {2020},
  journaltitle = {Automation in Construction},
  volume = {115},
  doi = {10.1016/j.autcon.2020.103197},
  abstract = {Concrete is a highly versatile construction material, not only for the reason that it has excellent properties in terms of structural performance, building physics, availability and price, but also because it can be moulded into virtually any shape regardless of its geometric complexity. However, even though current digital design tools allow to effortlessly design and calculate structures, which are exploiting these properties, this potential remains all too often unrealized. This is due to the fact that geometrically complex concrete structures require expensive, one-of-a kind formwork, which can often not be reused or even recycled. Consequently, the current practice for producing non-standard curvilinear architecture in reinforced concrete is neither ecologically sustainable nor economically feasible for a broader range of architectural typologies. Additive Manufacturing (AM) processes, like 3D printing with concrete, on the other hand, currently struggle with the integration of structural reinforcement, limiting the technique to predominantly compression-loaded applications. This research addresses both issues and proposes Mesh Mould, a robotic fabrication process that unifies concrete formwork and structural reinforcement, and hence potentially reduces formwork waste and construction costs for non-standard reinforced concrete constructions. The development of a fully automated robotic fabrication process involved various research disciplines, including architecture, material science, mechanical engineering, robotics as well as civil engineering. This paper describes the technological developments of the Mesh Mould construction system that were necessary to meet the challenges of 1:1 construction. The results are demonstrated in a final loadbearing structure, the Mesh Mould wall of the DFAB HOUSE on NEST.}
}

@inproceedings{haiyanManufactureAssemblyMechanism2020,
  title = {Manufacture and Assembly Mechanism of Dougong},
  booktitle = {{{IOP Conference Series}}: {{Materials Science}} and {{Engineering}}},
  author = {Haiyan, D. and Hong, Z. and Bin, M.},
  date = {2020},
  volume = {960},
  number = {2},
  doi = {10.1088/1757-899X/960/2/022008},
  abstract = {Dougong [斗栱] is a bracket between column, beam, and rafter in traditional timber structure building in China. It has several bearing blocks, named dou [斗], and some bracket arms, named gong [栱]. All components are connected by sunmao [榫卯]. It was born from the capital and later developed into a bracket that does not have to be related to the column. During the last 3000 years, its status in traditional architecture has been rising. In the Qing Dynasty, the architectural design work started it as the core. The chief aim of this research is to explore the possibility and key issues of using dougong for the prefabricated buildings. This research documents a folk building project in China from three aspects: the construction organization, the dougong component manufacture and assembly. After that, we study the mechanism and analyze the traditional technology. Finally, the study provides some suggestions for the prefabricated building. The first aspect is the construction organization. The component manufacture team needs more specialized skills than the assembly team. The two teams exchange information through the code on components and simple language. The proportion of dougong manufacture workload on the standard floor is 40\%. The second aspect is the dougong component manufacture. A master carpenter, a chief engineer, is in charge of three tasks: architectural design, material requirements planning, and templates making. After that, he directed 4 carpenters to make components accorded with the templates. The dougong components are universal. Besides, carpenters assemble and code the completed gong components in layers in the carpentry yard. Each layer of gong uses 1 English capital letter to code. The other components are unassembled and uncoded. The third aspect is the dougong component assembly. The assembly team's workers need only simple skills to complete their work. Limited by the low precision of the hand-made method, they need to fine-tune the size of the gong at the joint between the gong and the column. In this project, the lowest component of dougong is gong, so, the workers assemble 5 layers of gongs into the columns from bottom to top first, and then assemble several dous between the gongs. The completed sunmaos at this stage are not tightly fitted, which leaves room for adjustment of the upper components of the dougong. The research we have done indicates that compared with the assembly stage, the manufacturing stage is a concentrated section of the technology and workload. So, the key to modernizing traditional buildings is the modernization of this stage, especially the dougong manufacture. If it is realized, we can save at least 40\% hand-made workload of the standard floor. At the same time, the components will achieve higher accuracy, which is beneficial to improve the assembly speed and quality. Also, in the future, BIM can be utilized based on the traditional design method, which is significant to the inheritance and improvement of dougong technology.}
}

@inproceedings{haiyanManufactureAssemblyMechanism2020a,
  title = {Manufacture and Assembly Mechanism of Dougong},
  booktitle = {{{IOP Conference Series}}: {{Materials Science}} and {{Engineering}}},
  author = {Haiyan, D. and Hong, Z. and Bin, M.},
  date = {2020},
  volume = {960},
  number = {2},
  doi = {10.1088/1757-899X/960/2/022008},
  abstract = {Dougong [斗栱] is a bracket between column, beam, and rafter in traditional timber structure building in China. It has several bearing blocks, named dou [斗], and some bracket arms, named gong [栱]. All components are connected by sunmao [榫卯]. It was born from the capital and later developed into a bracket that does not have to be related to the column. During the last 3000 years, its status in traditional architecture has been rising. In the Qing Dynasty, the architectural design work started it as the core. The chief aim of this research is to explore the possibility and key issues of using dougong for the prefabricated buildings. This research documents a folk building project in China from three aspects: the construction organization, the dougong component manufacture and assembly. After that, we study the mechanism and analyze the traditional technology. Finally, the study provides some suggestions for the prefabricated building. The first aspect is the construction organization. The component manufacture team needs more specialized skills than the assembly team. The two teams exchange information through the code on components and simple language. The proportion of dougong manufacture workload on the standard floor is 40\%. The second aspect is the dougong component manufacture. A master carpenter, a chief engineer, is in charge of three tasks: architectural design, material requirements planning, and templates making. After that, he directed 4 carpenters to make components accorded with the templates. The dougong components are universal. Besides, carpenters assemble and code the completed gong components in layers in the carpentry yard. Each layer of gong uses 1 English capital letter to code. The other components are unassembled and uncoded. The third aspect is the dougong component assembly. The assembly team's workers need only simple skills to complete their work. Limited by the low precision of the hand-made method, they need to fine-tune the size of the gong at the joint between the gong and the column. In this project, the lowest component of dougong is gong, so, the workers assemble 5 layers of gongs into the columns from bottom to top first, and then assemble several dous between the gongs. The completed sunmaos at this stage are not tightly fitted, which leaves room for adjustment of the upper components of the dougong. The research we have done indicates that compared with the assembly stage, the manufacturing stage is a concentrated section of the technology and workload. So, the key to modernizing traditional buildings is the modernization of this stage, especially the dougong manufacture. If it is realized, we can save at least 40\% hand-made workload of the standard floor. At the same time, the components will achieve higher accuracy, which is beneficial to improve the assembly speed and quality. Also, in the future, BIM can be utilized based on the traditional design method, which is significant to the inheritance and improvement of dougong technology.}
}

@article{hamannDesignTechniquesRobots1985,
  title = {Design Techniques for Robots. {{Space}} Applications},
  author = {Hamann, R.J.},
  date = {1985},
  journaltitle = {Robotics},
  volume = {1},
  number = {4},
  pages = {223--250},
  doi = {10.1016/S0167-8493(85)90151-2},
  abstract = {This article is based on a report commissioned by the European Space Agency and available as ESA CR(P)2048. It deals with analytical techniques and technologies required for the design and developed of robotic manipulators in space. In general, it has appeared that many techniques developed for terrestrial applications may be used for a space manipulator system. However, the space environment introduces constraints, requiring considerable modifications to the techniques identified. In short these can be summarized as•Increased requirement for system autonomy and realibility•Different mass-velocity operating regime•Adaptation to limited (on-board) computing power. © 1985 Elsevier Science Ltd. All rights reserved.}
}

@article{hamannDesignTechniquesRobots1985a,
  title = {Design Techniques for Robots. {{Space}} Applications},
  author = {Hamann, R.J.},
  date = {1985},
  journaltitle = {Robotics},
  volume = {1},
  number = {4},
  pages = {223--250},
  doi = {10.1016/S0167-8493(85)90151-2},
  abstract = {This article is based on a report commissioned by the European Space Agency and available as ESA CR(P)2048. It deals with analytical techniques and technologies required for the design and developed of robotic manipulators in space. In general, it has appeared that many techniques developed for terrestrial applications may be used for a space manipulator system. However, the space environment introduces constraints, requiring considerable modifications to the techniques identified. In short these can be summarized as•Increased requirement for system autonomy and realibility•Different mass-velocity operating regime•Adaptation to limited (on-board) computing power. © 1985 Elsevier Science Ltd. All rights reserved.}
}

@book{hamannSwarmRoboticsFormal2018,
  title = {Swarm {{Robotics}}: {{A Formal Approach}}},
  shorttitle = {Swarm {{Robotics}}},
  author = {Hamann, Heiko},
  date = {2018},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-74528-2},
  url = {http://link.springer.com/10.1007/978-3-319-74528-2},
  urldate = {2023-09-20},
  isbn = {978-3-319-74526-8 978-3-319-74528-2},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\TYECZ9DB\Hamann - 2018 - Swarm Robotics A Formal Approach.pdf}
}

@article{hamlinTETROBOTModularApproach1997,
  title = {{{TETROBOT}}: {{A}} Modular Approach to Parallel Robotics},
  author = {Hamlin, G.J. and Sanderson, A.C.},
  date = {1997},
  journaltitle = {IEEE Robotics and Automation Magazine},
  volume = {4},
  number = {1},
  doi = {10.1109/100.580984},
  abstract = {The TETROBOT is an actuated robotic structure which may be reassembled into many different configurations while still being controlled by the same hardware and software architecture. The TETROBOT system addresses the needs of application domains, such as space, undersea, mining, and construction, where adaptation to unstructured and changing environments and custom design for rapid implementation are required.}
}

@article{hamlinTETROBOTModularApproach1997a,
  title = {{{TETROBOT}}: {{A}} Modular Approach to Parallel Robotics},
  author = {Hamlin, Gregory J. and Sanderson, Arthur C.},
  date = {1997-03},
  journaltitle = {IEEE Robotics and Automation Magazine},
  volume = {4},
  number = {1},
  pages = {42--50},
  issn = {10709932},
  doi = {10.1109/100.580984},
  url = {http://ieeexplore.ieee.org/document/580984/},
  abstract = {The TETROBOT is an actuated robotic structure which may be reassembled into many different configurations while still being controlled by the same hardware and software architecture. The TETROBOT system addresses the needs of application domains, such as space, undersea, mining, and construction, where adaptation to unstructured and changing environments and custom design for rapid implementation are required.},
  keywords = {Hyperredundant,Modular robotics,Parallel robotics,Spherical joint}
}

@article{hamraRoleVehiclesIdentification2011,
  title = {The Role of Vehicles' Identification Techniques in Transportation Planning - {{Modeling}} Concept},
  author = {Hamra, W. E. and Attallah, Y.},
  date = {2011},
  journaltitle = {Alexandria Engineering Journal},
  volume = {50},
  number = {4},
  pages = {391--398},
  doi = {10.1016/j.aej.2012.01.001},
  abstract = {Every day, new development projects are coming to cope with the growing population and their corresponding life activities, and this is translated in a higher travel demand and disastrous congestion in most cities of the world, especially the private transport oriented societies. Traffic impact studies became a must for the construction of new developments. But, in many cases, the scope of such studies is limited to a close proximity, while the developments impact remains much more beyond the site vicinity. Transportation studies that have been carried till now have a sizable margin of approximation as a result of two main deficiencies that are obvious for people involved in the field of traffic modeling and transportation planning: Is that there is no common, comprehensive, accurate and up-to-date source of information that can be relied on by the on-going transportation studies.The second deficiency is that in spite of exhausting congestion, people are still sticking to their private cars for doing their daily activities. Focusing on the mentioned deficiencies and their negative consequences, the main purpose of this research is to introduce and implement through a set of developed interfaces the concept of real-time transportation modeling, and justify the need and importance of Radio Frequency Identification (RFID) Technique in achieving a comprehensive database for strategic planning parameters that can affect passengers' travel behavior and consequently the transport modal split. However, the research concept and applications are flexible to deal with other floating data collection techniques such as mobile phones data analysis, as well as license plate recognition and other systems. The paper explains the role of floating traffic data collection techniques in providing accurate real-time statistics for the following types of information: origin/destination data, traffic composition, trip rates, parking rates, parking turnover data, traffic contraventions, traffic growth factors, link traffic volumes, turning movement traffic volumes, vehicles' classification, and security related data regarding suspected vehicles. The research modeling work is based on PTV-Vision software, VISUM and VISSIM that are currently used in most of the international research studies. The research applications are programming in Microsoft excel and visual basic and thus are compatible with any modeling software. © 2011 Faculty of Engineering, Alexandria University. Production and hosting by Elsevier B.V. All rights reserved.}
}

@article{hamraRoleVehiclesIdentification2011a,
  title = {The Role of Vehicles' Identification Techniques in Transportation Planning - {{Modeling}} Concept},
  author = {Hamra, W.E. and Attallah, Y.},
  date = {2011},
  journaltitle = {Alexandria Engineering Journal},
  volume = {50},
  number = {4},
  pages = {391--398},
  doi = {10.1016/j.aej.2012.01.001},
  abstract = {Every day, new development projects are coming to cope with the growing population and their corresponding life activities, and this is translated in a higher travel demand and disastrous congestion in most cities of the world, especially the private transport oriented societies. Traffic impact studies became a must for the construction of new developments. But, in many cases, the scope of such studies is limited to a close proximity, while the developments impact remains much more beyond the site vicinity. Transportation studies that have been carried till now have a sizable margin of approximation as a result of two main deficiencies that are obvious for people involved in the field of traffic modeling and transportation planning: Is that there is no common, comprehensive, accurate and up-to-date source of information that can be relied on by the on-going transportation studies.The second deficiency is that in spite of exhausting congestion, people are still sticking to their private cars for doing their daily activities. Focusing on the mentioned deficiencies and their negative consequences, the main purpose of this research is to introduce and implement through a set of developed interfaces the concept of real-time transportation modeling, and justify the need and importance of Radio Frequency Identification (RFID) Technique in achieving a comprehensive database for strategic planning parameters that can affect passengers' travel behavior and consequently the transport modal split. However, the research concept and applications are flexible to deal with other floating data collection techniques such as mobile phones data analysis, as well as license plate recognition and other systems. The paper explains the role of floating traffic data collection techniques in providing accurate real-time statistics for the following types of information: origin/destination data, traffic composition, trip rates, parking rates, parking turnover data, traffic contraventions, traffic growth factors, link traffic volumes, turning movement traffic volumes, vehicles' classification, and security related data regarding suspected vehicles. The research modeling work is based on PTV-Vision software, VISUM and VISSIM that are currently used in most of the international research studies. The research applications are programming in Microsoft excel and visual basic and thus are compatible with any modeling software. © 2011 Faculty of Engineering, Alexandria University. Production and hosting by Elsevier B.V. All rights reserved.}
}

@article{haoHypergraphNeuralNetwork2021,
  title = {Hypergraph {{Neural Network}} for {{Skeleton-Based Action Recognition}}},
  author = {Hao, X. and Li, J. and Guo, Y. and Jiang, T. and Yu, M.},
  date = {2021},
  journaltitle = {IEEE Transactions on Image Processing},
  volume = {30},
  pages = {2263--2275},
  doi = {10.1109/TIP.2021.3051495},
  abstract = {Recently, skeleton-based human action recognition has attracted a lot of research attention in the field of computer vision. Graph convolutional networks (GCNs), which model the human body skeletons as spatial-temporal graphs, have shown excellent results. However, the existing methods only focus on the local physical connection between the joints, and ignore the non-physical dependencies among joints. To address this issue, we propose a hypergraph neural network (Hyper-GNN) to capture both spatial-temporal information and high-order dependencies for skeleton-based action recognition. In particular, to overcome the influence of noise caused by unrelated joints, we design the Hyper-GNN to extract the local and global structure information via the hyperedge (i.e., non-physical connection) constructions. In addition, the hypergraph attention mechanism and improved residual module are induced to further obtain the discriminative feature representations. Finally, a three-stream Hyper-GNN fusion architecture is adopted in the whole framework for action recognition. The experimental results performed on two benchmark datasets demonstrate that our proposed method can achieve the best performance when compared with the state-of-the-art skeleton-based methods.}
}

@article{haoHypergraphNeuralNetwork2021a,
  title = {Hypergraph {{Neural Network}} for {{Skeleton-Based Action Recognition}}},
  author = {Hao, X. and Li, J. and Guo, Y. and Jiang, T. and Yu, M.},
  date = {2021},
  journaltitle = {IEEE Transactions on Image Processing},
  volume = {30},
  pages = {2263--2275},
  doi = {10.1109/TIP.2021.3051495},
  abstract = {Recently, skeleton-based human action recognition has attracted a lot of research attention in the field of computer vision. Graph convolutional networks (GCNs), which model the human body skeletons as spatial-temporal graphs, have shown excellent results. However, the existing methods only focus on the local physical connection between the joints, and ignore the non-physical dependencies among joints. To address this issue, we propose a hypergraph neural network (Hyper-GNN) to capture both spatial-temporal information and high-order dependencies for skeleton-based action recognition. In particular, to overcome the influence of noise caused by unrelated joints, we design the Hyper-GNN to extract the local and global structure information via the hyperedge (i.e., non-physical connection) constructions. In addition, the hypergraph attention mechanism and improved residual module are induced to further obtain the discriminative feature representations. Finally, a three-stream Hyper-GNN fusion architecture is adopted in the whole framework for action recognition. The experimental results performed on two benchmark datasets demonstrate that our proposed method can achieve the best performance when compared with the state-of-the-art skeleton-based methods.}
}

@article{hawasGaitIdentificationConvolutional2019,
  title = {Gait Identification by Convolutional Neural Networks and Optical Flow},
  author = {Hawas, A. R. and El-Khobby, H. A. and Abd-Elnaby, M. and El-Samie, F. E. Abd},
  date = {2019},
  journaltitle = {Multimedia Tools and Applications},
  volume = {78},
  number = {18},
  pages = {25873--25888},
  doi = {10.1007/s11042-019-7638-9},
  abstract = {Non-interactive biometric systems have gained an enormous interest from computer vision researchers as they provide more efficient and reliable ways of identification and authorization from a distance. Gait and face recognition are types of non-interactive biometric systems without users’ cooperation with the surveillance system. On the contrary to face recognition, gait recognition can manage low-resolution and low-brightness images. It aims to know the individuals based on their style and way of walking. Gait recognition has numerous applications in several domains, such as healthcare monitoring, security systems, and surveillance systems for indoor and outdoor activities. Yet, gait recognition performance is frequently deteriorated by some variety of factors, such as viewing angle variations, and clothing changes. Recently, deep learning models have been employed efficiently in gait recognition systems. They are more generic, since the feature construction process is completely automated. This paper presents gait features measured automatically in the midst of walking for the recognition system. To extract these features from a video of a moving object, two vital modules are used, namely the motion detection and tracking, and the feature extraction. Accordingly, the principal module serves to distinguish the walking style in an image sequence or video. A background subtraction technique is executed to fragment the movement of the background, and the moving area related to the spatial silhouette is correctly tracked and segmented. The second module “Feature Extraction” is used to extract the features from the sequence of silhouette images. The gait cycle is calculated from the shape changes of the silhouettes, and it is used to construct a small sequence of Gait Energy Images (GEI). The optical flow of the GEI is measured to extract only the moving parts and exclude the static ones. Finally, the Convolution Neural Network (CNN) is fed with the optical flow output to build unique features. These features are used for neural network training, and evaluation is performed on popular gait benchmark datasets. The obtained results reveal an accuracy level of 95\% with more resistance to view and probe changes.}
}

@article{hawasGaitIdentificationConvolutional2019a,
  title = {Gait Identification by Convolutional Neural Networks and Optical Flow},
  author = {Hawas, A.R. and El-Khobby, H.A. and Abd-Elnaby, M. and Abd El-Samie, F.E.},
  date = {2019},
  journaltitle = {Multimedia Tools and Applications},
  volume = {78},
  number = {18},
  pages = {25873--25888},
  doi = {10.1007/s11042-019-7638-9},
  abstract = {Non-interactive biometric systems have gained an enormous interest from computer vision researchers as they provide more efficient and reliable ways of identification and authorization from a distance. Gait and face recognition are types of non-interactive biometric systems without users’ cooperation with the surveillance system. On the contrary to face recognition, gait recognition can manage low-resolution and low-brightness images. It aims to know the individuals based on their style and way of walking. Gait recognition has numerous applications in several domains, such as healthcare monitoring, security systems, and surveillance systems for indoor and outdoor activities. Yet, gait recognition performance is frequently deteriorated by some variety of factors, such as viewing angle variations, and clothing changes. Recently, deep learning models have been employed efficiently in gait recognition systems. They are more generic, since the feature construction process is completely automated. This paper presents gait features measured automatically in the midst of walking for the recognition system. To extract these features from a video of a moving object, two vital modules are used, namely the motion detection and tracking, and the feature extraction. Accordingly, the principal module serves to distinguish the walking style in an image sequence or video. A background subtraction technique is executed to fragment the movement of the background, and the moving area related to the spatial silhouette is correctly tracked and segmented. The second module “Feature Extraction” is used to extract the features from the sequence of silhouette images. The gait cycle is calculated from the shape changes of the silhouettes, and it is used to construct a small sequence of Gait Energy Images (GEI). The optical flow of the GEI is measured to extract only the moving parts and exclude the static ones. Finally, the Convolution Neural Network (CNN) is fed with the optical flow output to build unique features. These features are used for neural network training, and evaluation is performed on popular gait benchmark datasets. The obtained results reveal an accuracy level of 95\% with more resistance to view and probe changes.}
}

@inproceedings{Hayes2016246,
  title = {Exploring Implicit Human Responses to Robot Mistakes in a Learning from Demonstration Task},
  author = {Hayes, C.J. and Moosaei, M. and Riek, L.D.},
  date = {2016},
  series = {25th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}, {{RO-MAN}} 2016},
  pages = {246--252},
  doi = {10.1109/ROMAN.2016.7745138},
  art_number = {7745138}
}

@inproceedings{hayesChallengesSharedEnvironmentHumanRobot2013,
  title = {Challenges in {{Shared-Environment Human-Robot Collaboration}}},
  author = {Hayes, Bradley and Scassellati, Brian},
  date = {2013-01}
}

@book{heerCitiesEntanglementsSocial2019,
  title = {Cities of {{Entanglements}}: {{Social Life}} in {{Johannesburg}} and {{Maputo Through Ethnographic Comparison}}},
  shorttitle = {Cities of {{Entanglements}}},
  author = {Heer, Barbara},
  date = {2019-09-24},
  series = {Urban {{Studies}}},
  edition = {1},
  publisher = {{transcript Verlag}},
  location = {{Bielefeld, Germany}},
  doi = {10.14361/9783839447970},
  url = {https://www.transcript-open.de/isbn/4797},
  urldate = {2023-09-03},
  abstract = {How do people live together in cities shaped by inequality? This comparative ethnography of two African cities, Maputo and Johannesburg, presents a new narrative about social life in cities often described as sharply divided. Based on the ethnography of entangled lives unfolding in a township and in a suburb in Johannesburg, in a bairro and in an elite neighborhood in Maputo, the book includes case studies of relations between domestic workers and their employers, failed attempts by urban elites to close off their neighborhoods, and entanglements emerging in religious spaces and in shopping malls. Systematizing comparison as an experience-based method, the book makes an important contribution to urban anthropology, comparative urbanism and urban studies.},
  isbn = {978-3-8376-4797-6 978-3-8394-4797-0},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\S9QW67NY\Heer - 2019 - Cities of Entanglements Social Life in Johannesbu.pdf}
}

@article{heesomImplementingHBIMApproach2020,
  title = {Implementing a {{HBIM}} Approach to Manage the Translocation of Heritage Buildings},
  author = {Heesom, D. and Boden, P. and Hatfield, A. and De Los Santos Melo, A. and Czarska-Chukwurah, F.},
  date = {2020},
  journaltitle = {Engineering, Construction and Architectural Management},
  doi = {10.1108/ECAM-06-2020-0405},
  abstract = {Purpose: The purpose of the paper is to present a study which exploited synergies between the fields of Heritage BIM, conservation and building translocation to develop a new approach to support a digitally enabled translocation process. The translocation (or relocation) of buildings or structures is a niche area of the construction sector and much of the significant work in this field has focused on the relocation of heritage buildings. However, hitherto there was a paucity of work between translocation and the process and technology of BIM. Design/methodology/approach: The study employed a constructive research approach to analyse the phenomenon of heritage translocation. As part of this approach, semi-structured interviews were undertaken with professionals engaged in heritage translocation projects within the UK, and this was supported by a multi-faceted review of literature within the cross cutting themes of translocation and HBIM. Building on the results, a BIM-enabled process was implemented to support the translocation of a 19th-century timber framed building in the UK. Findings: Following analysis of results of semi-structured interviews and supported by findings from prevailing literature in the field of translocation and HBIM, a HBIM for Translocation Conceptual Framework (TransHBIM) was developed. Building on the key constructs of the framework, a HBIM-based workflow was implemented to develop a digitally enabled translocation process, which provided a new approach to managing and documenting heritage translocation where disassembly and reconstruction are utilised. The workflow provided a more effective way of documenting individual elements of the building within a digital environment opening up potential for new simulation of the entire process. Originality/value: Current approaches to translocation involve traditional/manual methods of recording the building and cataloguing the key heritage elements for all aspects of the process. This new approach implements BIM technologies and processes along with the use of barcode or RFID tags to create a digital bridge between the physical elements of the building and the BIM database. This provides more accurate recording of the heritage and also opens up opportunities to support the process with additional digital simulation techniques enhancing the efficiency of the entire process.},
  file = {C:\Users\leemar\Zotero\storage\6K5E54MW\Implementing-a-HBIM-approach-to-manage-the-translocation-of-heritage-buildingsEngineering-Construction-and-Architectural-Management.pdf}
}

@article{heesomImplementingHBIMApproach2020a,
  title = {Implementing a {{HBIM}} Approach to Manage the Translocation of Heritage Buildings},
  author = {Heesom, D. and Boden, P. and Hatfield, A. and De Los Santos Melo, A. and Czarska-Chukwurah, F.},
  date = {2020},
  journaltitle = {Engineering, Construction and Architectural Management},
  doi = {10.1108/ECAM-06-2020-0405},
  abstract = {Purpose: The purpose of the paper is to present a study which exploited synergies between the fields of Heritage BIM, conservation and building translocation to develop a new approach to support a digitally enabled translocation process. The translocation (or relocation) of buildings or structures is a niche area of the construction sector and much of the significant work in this field has focused on the relocation of heritage buildings. However, hitherto there was a paucity of work between translocation and the process and technology of BIM. Design/methodology/approach: The study employed a constructive research approach to analyse the phenomenon of heritage translocation. As part of this approach, semi-structured interviews were undertaken with professionals engaged in heritage translocation projects within the UK, and this was supported by a multi-faceted review of literature within the cross cutting themes of translocation and HBIM. Building on the results, a BIM-enabled process was implemented to support the translocation of a 19th-century timber framed building in the UK. Findings: Following analysis of results of semi-structured interviews and supported by findings from prevailing literature in the field of translocation and HBIM, a HBIM for Translocation Conceptual Framework (TransHBIM) was developed. Building on the key constructs of the framework, a HBIM-based workflow was implemented to develop a digitally enabled translocation process, which provided a new approach to managing and documenting heritage translocation where disassembly and reconstruction are utilised. The workflow provided a more effective way of documenting individual elements of the building within a digital environment opening up potential for new simulation of the entire process. Originality/value: Current approaches to translocation involve traditional/manual methods of recording the building and cataloguing the key heritage elements for all aspects of the process. This new approach implements BIM technologies and processes along with the use of barcode or RFID tags to create a digital bridge between the physical elements of the building and the BIM database. This provides more accurate recording of the heritage and also opens up opportunities to support the process with additional digital simulation techniques enhancing the efficiency of the entire process.},
  file = {C:\Users\leemar\Zotero\storage\E9MKT3QP\Implementing-a-HBIM-approach-to-manage-the-translocation-of-heritage-buildingsEngineering-Construction-and-Architectural-Management.pdf}
}

@inproceedings{hegdeApplicationRealtimeVideo2018,
  title = {Application of Real-Time Video Streaming and Analytics to Breakdown Rig Connection Process},
  booktitle = {Proceedings of the {{Annual Offshore Technology Conference}}},
  author = {Hegde, C. and Awan, O. and Wiemers, T.},
  date = {2018},
  volume = {4},
  pages = {2505--2518},
  doi = {10.4043/28742-ms},
  abstract = {Invisible lost time (ILT) has been estimated to contribute significantly to well construction costs. Reduction of drilling connection time can lead to significant savings, especially in offshore drilling projects. The overall time of a drilling connection can easily be measured using conventional sensors on the rig. However, to gain further insight into the source of operational inefficiencies it is beneficial to breakdown the overall drilling connection process into smaller sub-processes and quantify the time spent doing each. Current sensor technology does not allow us to easily measure these sub-processes on the rig. In this paper, we outline a deep learning-based computer vision method to analyze and measure such sub-processes within the overall drilling connection process using a real-time video feed. Video of the drilling connections is streamed in real-time using a novel IT framework. In a proof of concept exercise, we applied image recognition techniques to enable us to breakdown and classify the sub-processes during the drilling connections. Convolutional neural networks (CNNs) - a deep learning algorithm - are used to analyze these video images frame by frame to identify rig activities. The workflow includes an analytics pipeline to capture video on the rig, transfer of data to the office, video recognition analysis, tabulation of results, and delivery of this result to a graphical interface for cognitive analytics. We performed experiments wherein CNNs were used on the video images to diagnose rig activities with good accuracy. Incorporating the temporal information using a recurrent network has been shown to further improve analysis accuracy. The described workflow is a suggested method for automating the detection of inefficiencies on drilling rigs using rig floor video and machine learning. For the demonstration case, we successfully analyzed video captured on an offshore rig and derived high value useful information using machine learning. This video analysis information can be further combined with conventional drilling sensor data to boost accuracy to identify and confirm rig activities and to quantify invisible lost time during each connection. The presented techniques demonstrate the potential of video analytics as a reliable, low-cost means to effectively "microanalyze" various rig operations with the aim to identify and replicate best composite performance.},
  isbn = {978-1-5108-6253-1}
}

@inproceedings{hegdeApplicationRealtimeVideo2018a,
  title = {Application of Real-Time Video Streaming and Analytics to Breakdown Rig Connection Process},
  booktitle = {Proceedings of the {{Annual Offshore Technology Conference}}},
  author = {Hegde, C. and Awan, O. and Wiemers, T.},
  date = {2018},
  volume = {4},
  pages = {2505--2518},
  doi = {10.4043/28742-ms},
  abstract = {Invisible lost time (ILT) has been estimated to contribute significantly to well construction costs. Reduction of drilling connection time can lead to significant savings, especially in offshore drilling projects. The overall time of a drilling connection can easily be measured using conventional sensors on the rig. However, to gain further insight into the source of operational inefficiencies it is beneficial to breakdown the overall drilling connection process into smaller sub-processes and quantify the time spent doing each. Current sensor technology does not allow us to easily measure these sub-processes on the rig. In this paper, we outline a deep learning-based computer vision method to analyze and measure such sub-processes within the overall drilling connection process using a real-time video feed. Video of the drilling connections is streamed in real-time using a novel IT framework. In a proof of concept exercise, we applied image recognition techniques to enable us to breakdown and classify the sub-processes during the drilling connections. Convolutional neural networks (CNNs) - a deep learning algorithm - are used to analyze these video images frame by frame to identify rig activities. The workflow includes an analytics pipeline to capture video on the rig, transfer of data to the office, video recognition analysis, tabulation of results, and delivery of this result to a graphical interface for cognitive analytics. We performed experiments wherein CNNs were used on the video images to diagnose rig activities with good accuracy. Incorporating the temporal information using a recurrent network has been shown to further improve analysis accuracy. The described workflow is a suggested method for automating the detection of inefficiencies on drilling rigs using rig floor video and machine learning. For the demonstration case, we successfully analyzed video captured on an offshore rig and derived high value useful information using machine learning. This video analysis information can be further combined with conventional drilling sensor data to boost accuracy to identify and confirm rig activities and to quantify invisible lost time during each connection. The presented techniques demonstrate the potential of video analytics as a reliable, low-cost means to effectively "microanalyze" various rig operations with the aim to identify and replicate best composite performance.},
  isbn = {978-1-5108-6253-1}
}

@inproceedings{henekBIMBasedTimberStructures2017,
  title = {{{BIM-Based Timber Structures Refurbishment}} of the {{Immovable Heritage Listed Buildings}}},
  booktitle = {{{IOP Conference Series}}: {{Earth}} and {{Environmental Science}}},
  author = {Henek, V. and Venkrbec, V.},
  date = {2017},
  volume = {95},
  number = {6},
  doi = {10.1088/1755-1315/95/6/062002},
  abstract = {The use of Building information model (BIM) design tools is no longer an exception, but a common issue. When designing new buildings or complex renovations using BIM, the benefits have already been repeatedly published. The essence of BIM is to create a multidimensional geometric model of a planned building electronically on a computer, supplemented with the necessary information in advance of the construction process. Refurbishment is a specific process that combines both - new structures and demolished structures, or structures that need to be dismantled, repaired, and then returned to the original position. Often it can be historically valuable part of the building. BIM-based repairs and refurbishments of the constructions, especially complicated repairs of the structures of roof trusses of immovable heritage listed buildings, have not yet been credibly presented. However, the use of BIM tools may be advantageous in this area, because user can quickly response to the necessary changes that may be needed during refurbishments, but also in connection with the quick assessment and cost estimation of any unexpected additional works. The paper deals with the use of BIM in the field of repairs and refurbishment of the buildings in general. The emphasis on monumentally protected elements was priority. Advantage of the proposal research is demonstrated on case study of the refurbishment of the immovable heritage listed truss roof. According to this study, this construction was realized in the Czech Republic. Case study consists of 3D modelled truss parts and the connected technological workflow base. The project work was carried out in one common model environment.}
}

@inproceedings{henekBIMBasedTimberStructures2017a,
  title = {{{BIM-Based Timber Structures Refurbishment}} of the {{Immovable Heritage Listed Buildings}}},
  booktitle = {{{IOP Conference Series}}: {{Earth}} and {{Environmental Science}}},
  author = {Henek, V. and Venkrbec, V.},
  date = {2017},
  volume = {95},
  number = {6},
  doi = {10.1088/1755-1315/95/6/062002},
  abstract = {The use of Building information model (BIM) design tools is no longer an exception, but a common issue. When designing new buildings or complex renovations using BIM, the benefits have already been repeatedly published. The essence of BIM is to create a multidimensional geometric model of a planned building electronically on a computer, supplemented with the necessary information in advance of the construction process. Refurbishment is a specific process that combines both - new structures and demolished structures, or structures that need to be dismantled, repaired, and then returned to the original position. Often it can be historically valuable part of the building. BIM-based repairs and refurbishments of the constructions, especially complicated repairs of the structures of roof trusses of immovable heritage listed buildings, have not yet been credibly presented. However, the use of BIM tools may be advantageous in this area, because user can quickly response to the necessary changes that may be needed during refurbishments, but also in connection with the quick assessment and cost estimation of any unexpected additional works. The paper deals with the use of BIM in the field of repairs and refurbishment of the buildings in general. The emphasis on monumentally protected elements was priority. Advantage of the proposal research is demonstrated on case study of the refurbishment of the immovable heritage listed truss roof. According to this study, this construction was realized in the Czech Republic. Case study consists of 3D modelled truss parts and the connected technological workflow base. The project work was carried out in one common model environment.}
}

@inproceedings{heydarianAutomatedBenchmarkingMonitoring2012,
  title = {Automated Benchmarking and Monitoring of an Earthmoving Operation's Carbon Footprint Using Video Cameras and a Greenhouse Gas Estimation Model},
  booktitle = {Congress on {{Computing}} in {{Civil Engineering}}, {{Proceedings}}},
  author = {Heydarian, A. and Memarzadeh, M. and Golparvar-Fard, M.},
  date = {2012},
  pages = {509--516},
  doi = {10.1061/9780784412343.0064},
  abstract = {Benchmarking and monitoring are critical steps toward improving operational efficiency of earthmoving equipment and minimizing their environmental impacts. Despite the importance, the relationship between operational efficiency and total pollutant emissions of these operations has not been fully understood. To establish such relationship and find ways to minimize the excessive environmental impacts due to reduced operational efficiencies, there is a need for an inexpensive and automated benchmarking and monitoring method. This paper presents a novel cost-effective method for monitoring carbon footprint of earthmoving operations using a vision-based equipment action recognition method along with pollutant emission inventories of construction actions. First a site video stream is represented as a collection of spatio-temporal features by extracting space-time interest points and describing each feature with a histogram of oriented gradients. The algorithm automatically learns the probability distributions of the spatio-temporal features and action categories using a multiple binary support vector machine classifier. Next, using a new temporal sliding window model, the equipment action categories are classified over a long sequence of video frames. The recognized time-series of equipment actions are placed in an emission and carbon footprint estimation model where based on the amount of emission for each equipment action, the overall Green House Gas emissions are analyzed. The proposed method is validated for several videos collected on an on-going construction project. The preliminary results with average action recognition accuracy of 85\% reflect the promise that the proposed approach can help practitioners understand operational efficiency of their construction activities and minimize excessive environmental impacts due to reduced operational efficiencies. © 2012 American Society of Civil Engineers.},
  isbn = {978-0-7844-1234-3}
}

@inproceedings{heydarianAutomatedBenchmarkingMonitoring2012a,
  title = {Automated Benchmarking and Monitoring of an Earthmoving Operation's Carbon Footprint Using Video Cameras and a Greenhouse Gas Estimation Model},
  booktitle = {Congress on {{Computing}} in {{Civil Engineering}}, {{Proceedings}}},
  author = {Heydarian, A. and Memarzadeh, M. and Golparvar-Fard, M.},
  date = {2012},
  pages = {509--516},
  doi = {10.1061/9780784412343.0064},
  abstract = {Benchmarking and monitoring are critical steps toward improving operational efficiency of earthmoving equipment and minimizing their environmental impacts. Despite the importance, the relationship between operational efficiency and total pollutant emissions of these operations has not been fully understood. To establish such relationship and find ways to minimize the excessive environmental impacts due to reduced operational efficiencies, there is a need for an inexpensive and automated benchmarking and monitoring method. This paper presents a novel cost-effective method for monitoring carbon footprint of earthmoving operations using a vision-based equipment action recognition method along with pollutant emission inventories of construction actions. First a site video stream is represented as a collection of spatio-temporal features by extracting space-time interest points and describing each feature with a histogram of oriented gradients. The algorithm automatically learns the probability distributions of the spatio-temporal features and action categories using a multiple binary support vector machine classifier. Next, using a new temporal sliding window model, the equipment action categories are classified over a long sequence of video frames. The recognized time-series of equipment actions are placed in an emission and carbon footprint estimation model where based on the amount of emission for each equipment action, the overall Green House Gas emissions are analyzed. The proposed method is validated for several videos collected on an on-going construction project. The preliminary results with average action recognition accuracy of 85\% reflect the promise that the proposed approach can help practitioners understand operational efficiency of their construction activities and minimize excessive environmental impacts due to reduced operational efficiencies. © 2012 American Society of Civil Engineers.},
  isbn = {978-0-7844-1234-3}
}

@article{Hoffman2007,
  title = {Collaboration in Human-Robot Teams},
  author = {Hoffman, G. and Breazeal, C.},
  date = {2007},
  journaltitle = {AIAA Intelligent Systems Technical Conference}
}

@inproceedings{Hoffman20071,
  title = {Effects of Anticipatory Action on Human-Robot Teamwork Efficiency, Fluency, and Perception of Team},
  author = {Hoffman, G. and Breazeal, C.},
  date = {2007},
  series = {{{HRI}} 2007 - {{Proceedings}} of the 2007 {{ACM}}/{{IEEE Conference}} on {{Human-Robot Interaction}} - {{Robot}} as {{Team Member}}},
  pages = {1--8},
  doi = {10.1145/1228716.1228718}
}

@article{Hoffman2007952,
  title = {Cost-Based Anticipatory Action Selection for Human-Robot Fluency},
  author = {Hoffman, G. and Breazeal, C.},
  date = {2007},
  journaltitle = {IEEE Transactions on Robotics},
  volume = {23},
  number = {5},
  pages = {952--961},
  doi = {10.1109/TRO.2007.907483}
}

@article{Hoffman2008,
  title = {Anticipatory Perceptual Simulation for Human-Robot Joint Practice: {{Theory}} and Application Study},
  author = {Hoffman, G. and Breazeal, C.},
  date = {2008},
  journaltitle = {AAAI}
}

@inproceedings{Hoffman2010718,
  title = {Synchronization in Human-Robot {{Musicianship}}},
  author = {Hoffman, G. and Weinberg, G.},
  date = {2010},
  series = {Proceedings - {{IEEE International Workshop}} on {{Robot}} and {{Human Interactive Communication}}},
  pages = {718--724},
  doi = {10.1109/ROMAN.2010.5598690},
  art_number = {5598690}
}

@article{Hoffman2011233,
  title = {G. {{Weinberg}}, Interactive Improvisation with a Robotic Marimba Player in Musical Robots and Interactive Multimodal Systems},
  author = {Hoffman, G.},
  date = {2011},
  journaltitle = {(Springer},
  pages = {233--251}
}

@article{Hoffman201489,
  title = {Designing Robots with Movement in Mind},
  author = {Hoffman, G. and Ju, W.},
  date = {2014},
  journaltitle = {Journal of Human-Robot Interaction},
  volume = {3},
  number = {1},
  pages = {89--122}
}

@article{hoffmanAnticipatoryPerceptualSimulation,
  title = {Anticipatory {{Perceptual Simulation}} for {{Human-Robot Joint Practice}}: {{Theory}} and {{Application Study}}},
  author = {Hoffman, Guy and Breazeal, Cynthia},
  abstract = {With the aim of fluency and efficiency in human-robot teams, we have developed a cognitive architecture based on the neuro-psychological principles of anticipation and perceptual simulation through top-down biasing. An instantiation of this architecture was implemented on a non-anthropomorphic robotic lamp, performing in a human-robot collaborative task. In a human-subject study, in which the robot works on a joint task with untrained subjects, we find our approach to be significantly more efficient and fluent than in a comparable system without anticipatory perceptual simulation. We also show the robot and the human to be increasingly contributing at a similar rate. Through self-report, we find significant differences between the two conditions in the sense of team fluency, the team’s improvement over time, and the robot’s contribution to the efficiency and fluency. We also find difference in verbal attitudes towards the robot: most notably, subjects working with the anticipatory robot attribute more positive and more human qualities to the robot, but display increased self-blame and self-deprecation.},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\MTEHAEX7\Hoffman 與 Breazeal - Anticipatory Perceptual Simulation for Human-Robot.pdf}
}

@article{hofmannAutomationRoboticsHuman2003,
  title = {Automation and Robotics for Human Mars Exploration ({{AROMA}})},
  author = {Hofmann, P. and Von Richter, A.},
  date = {2003},
  journaltitle = {Acta Astronautica},
  volume = {53},
  number = {4-10},
  pages = {399--404},
  doi = {10.1016/S0094-5765(03)00127-9},
  abstract = {Automation and Robotics (A\&R) systems are a key technology for Mars exploration. All over the world initiatives in this field aim at developing new A\&R systems and technologies for planetary surface exploration. From December 2000 to February 2002 Kayser-Threde GmbH, Munich, Germany lead a study called AROMA (Automation and Robotics for Human Mars Exploration) under ESA contract in order to define a reference architecture of A\&R elements in support of a human Mars exploration program. One of the goals of this effort is to initiate new developments and to maintain the competitiveness of European industry within this field. © 2003 Published by Elsevier Science Ltd.}
}

@article{hofmannAutomationRoboticsHuman2003a,
  title = {Automation and Robotics for Human Mars Exploration ({{AROMA}})},
  author = {Hofmann, P. and Von Richter, A.},
  date = {2003},
  journaltitle = {Acta Astronautica},
  volume = {53},
  number = {4-10},
  pages = {399--404},
  doi = {10.1016/S0094-5765(03)00127-9},
  abstract = {Automation and Robotics (A\&R) systems are a key technology for Mars exploration. All over the world initiatives in this field aim at developing new A\&R systems and technologies for planetary surface exploration. From December 2000 to February 2002 Kayser-Threde GmbH, Munich, Germany lead a study called AROMA (Automation and Robotics for Human Mars Exploration) under ESA contract in order to define a reference architecture of A\&R elements in support of a human Mars exploration program. One of the goals of this effort is to initiate new developments and to maintain the competitiveness of European industry within this field. © 2003 Published by Elsevier Science Ltd.}
}

@article{houConstructionFuzzyMap2014,
  title = {Construction of Fuzzy Map for Autonomous Mobile Robots Based on Fuzzy Confidence Model},
  author = {Hou, J.-F. and Chang, Y.-Z. and Hsu, M.-H. and Lee, S.-T. and Wu, C.-T.},
  date = {2014},
  journaltitle = {Mathematical Problems in Engineering},
  volume = {2014},
  doi = {10.1155/2014/526781},
  abstract = {This paper presents the use of fuzzy models to explicitly consider sensor uncertainty and finite resolution in solving the SLAM (simultaneous localization and mapping) problem for autonomous mobile robots. The approach establishes fuzzy confidence models in describing occupied obstacles and available space. The problem is transformed into an optimization task of minimizing the alignment error between newly scanned local fuzzy maps and selected parts of a developing global fuzzy map. In aligning local fuzzy maps into a global fuzzy map, we developed a prediction strategy to crop the most potential part from the sensed local fuzzy maps to be overlapped with the global fuzzy map. A mobile vehicle equipped with a laser range finder, the Hokuyo URG-04LX, is used to demonstrate the procedure of fuzzy map building. Experimental results show that the proposed architecture is effective in generating a comprehensive global fuzzy map, which is suitable for both human comprehension and path design during real-time navigation. © 2014 Jung-Fu Hou et al.}
}

@article{houConstructionFuzzyMap2014a,
  title = {Construction of Fuzzy Map for Autonomous Mobile Robots Based on Fuzzy Confidence Model},
  author = {Hou, J.-F. and Chang, Y.-Z. and Hsu, M.-H. and Lee, S.-T. and Wu, C.-T.},
  date = {2014},
  journaltitle = {Mathematical Problems in Engineering},
  volume = {2014},
  doi = {10.1155/2014/526781},
  abstract = {This paper presents the use of fuzzy models to explicitly consider sensor uncertainty and finite resolution in solving the SLAM (simultaneous localization and mapping) problem for autonomous mobile robots. The approach establishes fuzzy confidence models in describing occupied obstacles and available space. The problem is transformed into an optimization task of minimizing the alignment error between newly scanned local fuzzy maps and selected parts of a developing global fuzzy map. In aligning local fuzzy maps into a global fuzzy map, we developed a prediction strategy to crop the most potential part from the sensed local fuzzy maps to be overlapped with the global fuzzy map. A mobile vehicle equipped with a laser range finder, the Hokuyo URG-04LX, is used to demonstrate the procedure of fuzzy map building. Experimental results show that the proposed architecture is effective in generating a comprehensive global fuzzy map, which is suitable for both human comprehension and path design during real-time navigation. © 2014 Jung-Fu Hou et al.}
}

@article{howardComputerIntegrationReducing1989,
  title = {Computer Integration: {{Reducing}} Fragmentation in {{AEC}} Industry},
  author = {Howard, H.C. and Levitt, R.E. and Paulson, B.C. and Pohl, J.G. and Tatum, C.B.},
  date = {1989},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {3},
  number = {1},
  pages = {18--32},
  doi = {10.1061/(ASCE)0887-3801(1989)3:1(18)},
  abstract = {Emerging and existing computer technologies can be synthesized in ways that provide new kinds of decision support for integrating the data, design decisions, and knowledge normally dispersed among the many participants in the architecture/engineering/construction (AEC) process. This paper briefly examines the origins and impacts of fragmentation in the industry in the U.S. and describes six thrust areas where computer-integrated design and construction can substantially improve the competitiveness of the U.S. AEC industry and the quality of its products. In each of these thrust areas, AEC problems pose important challenges to developing technologies for artificial intelligence, graphic and nongraphic databases, process automation and robotics, and management and dissemination of technology. The application of these advanced computer technologies and the AEC industry offers the promise of significant gains in productivity and will infuse new excitement into civil engineering education and practice. © ASCE.}
}

@article{howardComputerIntegrationReducing1989a,
  title = {Computer Integration: {{Reducing}} Fragmentation in {{AEC}} Industry},
  author = {Howard, H.C. and Levitt, R.E. and Paulson, B.C. and Pohl, J.G. and Tatum, C.B.},
  date = {1989},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {3},
  number = {1},
  pages = {18--32},
  doi = {10.1061/(ASCE)0887-3801(1989)3:1(18)},
  abstract = {Emerging and existing computer technologies can be synthesized in ways that provide new kinds of decision support for integrating the data, design decisions, and knowledge normally dispersed among the many participants in the architecture/engineering/construction (AEC) process. This paper briefly examines the origins and impacts of fragmentation in the industry in the U.S. and describes six thrust areas where computer-integrated design and construction can substantially improve the competitiveness of the U.S. AEC industry and the quality of its products. In each of these thrust areas, AEC problems pose important challenges to developing technologies for artificial intelligence, graphic and nongraphic databases, process automation and robotics, and management and dissemination of technology. The application of these advanced computer technologies and the AEC industry offers the promise of significant gains in productivity and will infuse new excitement into civil engineering education and practice. © ASCE.}
}

@article{hsuAffordableHousingPolicy2011,
  title = {The {{Affordable Housing Policy}} and {{Mechanism}} in {{Taiwan}}─{{A Case Study}} of {{Taipei City}}},
  author = {Hsu, Yun-Han},
  date = {2011}
}

@inproceedings{Huang2015,
  title = {Adaptive Coordination Strategies for Human-Robot Handovers},
  author = {Huang, C.-M. and Cakmak, M. and Mutlu, B.},
  date = {2015},
  series = {Robotics: {{Science}} and {{Systems}}},
  volume = {11},
  doi = {10.15607/RSS.2015.XI.031}
}

@article{hurkxkensShiftingSandsExperimental2021,
  title = {Shifting Sands: {{Experimental}} Robotic Earth-Moving Strategies in Dynamic Coastal Environments},
  author = {Hurkxkens, I. and Pigram, D. and Melsom, J.},
  date = {2021},
  journaltitle = {Journal of Digital Landscape Architecture},
  volume = {2021},
  number = {6},
  pages = {66--74},
  doi = {10.14627/537705003},
  abstract = {The increased prevalence of storm surge events that cause extreme erosion in coastal environments points to the delicate balance that exists in the perpetual formation processes of dunes. While coastal defence structures and traditional beach nourishment strategies can alleviate some of the dam-aging force of ongoing wave action, they don't provide a lasting solution and often produce undesirable side-effects. Design authority in this contested area of landscape transformation is often limited to engineers and shaped by reductionist economic or risk management factors. Through investigations in digital landscape fabrication techniques, this paper reconsiders the role of design in these evolving systems while demonstrating the potential for on-site, adaptive, and dynamic construction processes. By creating resilience through adaptive topographies of natural granular material, this paper proposes to establish a new equilibrium between natural processes and robotic earth-moving strategies. By combining a wave tank with natural beach sand, computational modelling and robotic beach sand manipu-lations, emergent topologies and open-ended design proposals are enabled under the continuous influence of water movements. The experiments were conducted in a two-week international masterclass at the School of Architecture, University of Technology, Sydney, where adaptive feedback systems for coastal remediation were studied in relation to the Northern Beaches of Sydney. As such, this paper presents a novel coastal design approach towards autonomous construction in dynamic environments, combining various technologies to generate new paths of research and design investigation.}
}

@article{hurkxkensShiftingSandsExperimental2021a,
  title = {Shifting Sands: {{Experimental}} Robotic Earth-Moving Strategies in Dynamic Coastal Environments},
  author = {Hurkxkens, I. and Pigram, D. and Melsom, J.},
  date = {2021},
  journaltitle = {Journal of Digital Landscape Architecture},
  volume = {2021},
  number = {6},
  pages = {66--74},
  doi = {10.14627/537705003},
  abstract = {The increased prevalence of storm surge events that cause extreme erosion in coastal environments points to the delicate balance that exists in the perpetual formation processes of dunes. While coastal defence structures and traditional beach nourishment strategies can alleviate some of the dam-aging force of ongoing wave action, they don't provide a lasting solution and often produce undesirable side-effects. Design authority in this contested area of landscape transformation is often limited to engineers and shaped by reductionist economic or risk management factors. Through investigations in digital landscape fabrication techniques, this paper reconsiders the role of design in these evolving systems while demonstrating the potential for on-site, adaptive, and dynamic construction processes. By creating resilience through adaptive topographies of natural granular material, this paper proposes to establish a new equilibrium between natural processes and robotic earth-moving strategies. By combining a wave tank with natural beach sand, computational modelling and robotic beach sand manipu-lations, emergent topologies and open-ended design proposals are enabled under the continuous influence of water movements. The experiments were conducted in a two-week international masterclass at the School of Architecture, University of Technology, Sydney, where adaptive feedback systems for coastal remediation were studied in relation to the Northern Beaches of Sydney. As such, this paper presents a novel coastal design approach towards autonomous construction in dynamic environments, combining various technologies to generate new paths of research and design investigation.}
}

@book{hutterFieldServiceRobotics2018,
  title = {Field and {{Service Robotics}}},
  editor = {Hutter, Marco and Siegwart, Roland},
  date = {2018},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  volume = {5},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-67361-5},
  url = {http://link.springer.com/10.1007/978-3-319-67361-5},
  urldate = {2023-11-13},
  isbn = {978-3-319-67360-8 978-3-319-67361-5},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\CC3K5IC3\Hutter 與 Siegwart - 2018 - Field and Service Robotics.pdf}
}

@article{huynh-theHierarchicalTopicModeling2018,
  title = {Hierarchical Topic Modeling with Pose-Transition Feature for Action Recognition Using {{3D}} Skeleton Data},
  author = {Huynh-The, T. and Hua, C.-H. and Tu, N. Anh and Hur, T. and Bang, J. and Kim, D. and Amin, M. B. and Kang, B. H. and Seung, H. and Shin, S.-Y. and Kim, E.-S. and Lee, S.},
  date = {2018},
  journaltitle = {Information Sciences},
  volume = {444},
  pages = {20--35},
  doi = {10.1016/j.ins.2018.02.042},
  abstract = {Despite impressive achievements in image processing and artificial intelligence in the past decade, understanding video-based action remains a challenge. However, the intensive development of 3D computer vision in recent years has brought more potential research opportunities in pose-based action detection and recognition. Thanks to the advantages of depth camera devices like the Microsoft Kinect sensor, we developed an effective approach to in-depth analysis of indoor actions using skeleton information, in which skeleton-based feature extraction and topic model-based learning are two major contributions. Geometric features, i.e. joint distance, joint angle, and joint-plane distance are calculated in the spatio-temporal dimension. These features are merged into two types, called pose and transition features, and then are provided to codebook construction to convert sparse features into visual words by k-means clustering. An efficient hierarchical model is developed to describe the full correlation of feature - poselet - action based on Pachinko Allocation Model. This model has the potential to uncover more hidden poselets, which have been recognized as the valuable information and help to differentiate pose-sharing actions. The experimental results on several well-known datasets, such as MSR Action 3D, MSR Daily Activity 3D, Florence 3D Action, UTKinect-Action 3D, and NTU RGB+D Action Recognition, demonstrate the high recognition accuracy of the proposed method. Our method outperforms state-of-the-art methods in the field in most dataset benchmarks.}
}

@article{huynh-theHierarchicalTopicModeling2018a,
  title = {Hierarchical Topic Modeling with Pose-Transition Feature for Action Recognition Using {{3D}} Skeleton Data},
  author = {Huynh-The, T. and Hua, C.-H. and Anh Tu, N. and Hur, T. and Bang, J. and Kim, D. and Amin, M.B. and Kang, B.H. and Seung, H. and Shin, S.-Y. and Kim, E.-S. and Lee, S.},
  date = {2018},
  journaltitle = {Information Sciences},
  volume = {444},
  pages = {20--35},
  doi = {10.1016/j.ins.2018.02.042},
  abstract = {Despite impressive achievements in image processing and artificial intelligence in the past decade, understanding video-based action remains a challenge. However, the intensive development of 3D computer vision in recent years has brought more potential research opportunities in pose-based action detection and recognition. Thanks to the advantages of depth camera devices like the Microsoft Kinect sensor, we developed an effective approach to in-depth analysis of indoor actions using skeleton information, in which skeleton-based feature extraction and topic model-based learning are two major contributions. Geometric features, i.e. joint distance, joint angle, and joint-plane distance are calculated in the spatio-temporal dimension. These features are merged into two types, called pose and transition features, and then are provided to codebook construction to convert sparse features into visual words by k-means clustering. An efficient hierarchical model is developed to describe the full correlation of feature - poselet - action based on Pachinko Allocation Model. This model has the potential to uncover more hidden poselets, which have been recognized as the valuable information and help to differentiate pose-sharing actions. The experimental results on several well-known datasets, such as MSR Action 3D, MSR Daily Activity 3D, Florence 3D Action, UTKinect-Action 3D, and NTU RGB+D Action Recognition, demonstrate the high recognition accuracy of the proposed method. Our method outperforms state-of-the-art methods in the field in most dataset benchmarks.}
}

@book{iacovinoPartialAsymmetryFederal2010,
  title = {Partial Asymmetry and Federal Construction: {{Accommodating}} Diversity in the {{Canadian}} Constitution},
  author = {Iacovino, R.},
  date = {2010},
  journaltitle = {Asymmetric Autonomy and the Settlement of Ethnic Conflicts},
  abstract = {In a cursory overview of asymmetrical federations, the Canadian case stands out in several respects. First, although a strong secessionist movement exists in Quebec, there has been little recourse to violence that would necessitate international mediation. Second, a recent "pact" or settlement that addresses the secessionist movement has not been in-stituted - indeed, the most recent constitutional rounds ended in 1992 with the failure of the Charlottetown Accord, and the subsequent rejection of independence in the Quebec referendum closed the case. What remains is the persistent claim that the status quo contains within it the necessary institutional mechanisms to alleviate such pressures. Indeed, the recent history of intergovernmental relations and constitutionalism in Canada is marked by a curious measure of indifference for one of the most powerful secessionist movements in the world. Third, with regard to cultural and territorial autonomy, Canada is marked by "diversity of diversities" that often undercut one another in the country's attempt to find an agreement that satisfies all of its constituent partners. Nation building in Canada has thus been characterized in part by various attempts to recognize the country's politically salient identities, often resulting in clashing visions that are metaconstitutional in nature (Cairns 1992). Finally, with regard to the place of nation building activities and attempts to consolidate national identity as the basis for citizenship and representation, Canada is caught between formal procedural markers of identification that apply uniformly across the country and a constant challenge from Quebec, which has undertaken a coherent nationbuilding strategy of its own since the "Quiet Revolution" in the 1960s. Moreover, one is struck by the extent to which asymmetry in Canada is at once as viscerally rejected as it is embraced. This has resulted in a situation where theorists and scholars have for the most part vaunted its merits and its "inevitable" foray into Canada's institutional landscape, while at the same time garnering much negative reaction from federal legislators, in part due to a large body of literature documenting its unpopular status among the general population (Seidle and Bishop 2005). As such, in Canada there exists a curious relationship with asymmetry. Its capacity to accommodate diversity has produced a seemingly unending body of thought that includes considerations about: its role in structuring relations between constituent units in the country's history as a well-acknowledged "fact" (see Milne 1991; Watts 1999); the fact that it has over time nourished debates that range from attempts to shed light on the country's actual founding principles to a novel way forward in a global world (see, for example, Kelly and Laforest 2004); its status as the most likely candidate to address Canada's persistent constitutional impasse;1 as the best way forward in addressing the policy interdependence between federal and provincial governments, particularly in terms of fiscal arrangements; as the logical consequence of deep-seated sociological differences in relation to the existence of Quebec (McRoberts 1997; Webber 1994), with a majority Francophone population, as well as in the case of Aboriginal peoples;2 and generally, as a vehicle for infusing Canadian federalism with a measure of flexibility that allows for constant adaptation to changing international and domestic circumstances. Indeed, Canada is something of a beacon for discourses on asymmetry, challenging singular understandings of political community and producing what some have called a "Canadian school" over questions of diversity, or a unique "Canadian conversation" (Kernerman 2006) that at once appeals to creative tensions about belonging and serves to keep the question of diversity alive. At the same time, asymmetrical federalism has also served as a catalyst for debates about what is "wrong" with Canadian federalism. In this sense, it is taken as symptomatic of a failure to consolidate a sense of overarching national identity in the country through nation-building efforts at the center and as a strategy of appeasement in responding to what is a perceived as an illegitimate countervailing and competing projet de société in Quebec. As a result, asymmetry in Canada is often approached indirectly, presented as a consequence of differential policy choices or administrative dealings between governments; as the outcome of intergovernmental practices and functional requirements in order to accommodate disparate needs of constituent units, and so on, rather than as a defining principle that reflects, fundamentally, the meaning and purpose of Canadian federalism. It is this narrative - one of an institutional and structuring principle that exists in the shadows, appearing now and again, eliciting tensions old and new, and strong reactions that touch upon sentiments of allegiance as well as notions of fairness - that will be recounted in this chapter. Kenneth McRoberts (2000, 25) captures this dynamic succinctly: "Canada more than ever is a multi-national state in terms of its underlying social and cultural reality. Yet, it's also more than ever a nation-state in its dominant discourse and political institutions." The disjuncture between practice and discourse is clear in Canada, and it in part nourishes the notion that asymmetrical solutions can only be partially enacted - as an outgrowth of effective governance. A further note must be considered in introducing asymmetrical federalism in Canada. Since calls for asymmetry are based on prescriptive measures for federalism, normative concerns cannot be sidestepped in contemporary debates. One must avoid proceeding with analysis by looking only at the structure of society, as this neglects the nation-building efforts undertaken over the years by both Canada and Quebec. To look only at the state, however, would be to miss out on some underlying reasons for asymmetry and the "federal spirit" - the idea that difference is one of the underlying purposes of federalism rather than a stumbling block to achieving unity. As such, this chapter will straddle these two approaches, looking at the interplay between the norm of asymmetry in Canada and actual attempts to institutionalize or accept it in fact. Asymmetry in Canada invokes existential questions related to self-identification. It should not merely be approached as a pragmatic institutional device meant to lessen conflict. Moreover, this chapter will demonstrate that the constitutional politics of difference and asymmetrical federalism as an institutional corollary is the Canadian contribution to political science that dare not speak its name. Diversity management in Canada has taken an eerily uniform bent, leaving the country with what I argue is largely a myth about its commitment to recognizing diversity, largely propagated due to its formal adherence to sociocultural diversity (multiculturalism) and personal bilingualism while shunning serious efforts at instituting formal asymmetry as the logical outcome of the recognition of national pluralism. 3 As such, asymmetry in Canada is only partly in force because it must constantly contend with a powerful nation-building project that defines the country through the equality of individuals and provinces, multicul-turalism, and bilingualism from coast to coast. Copyright © 2010 University of Pennsylvania Press.},
  isbn = {978-0-8122-4230-0},
  pagetotal = {75-96}
}

@book{iacovinoPartialAsymmetryFederal2010a,
  title = {Partial Asymmetry and Federal Construction: {{Accommodating}} Diversity in the {{Canadian}} Constitution},
  author = {Iacovino, R.},
  date = {2010},
  journaltitle = {Asymmetric Autonomy and the Settlement of Ethnic Conflicts},
  abstract = {In a cursory overview of asymmetrical federations, the Canadian case stands out in several respects. First, although a strong secessionist movement exists in Quebec, there has been little recourse to violence that would necessitate international mediation. Second, a recent "pact" or settlement that addresses the secessionist movement has not been in-stituted - indeed, the most recent constitutional rounds ended in 1992 with the failure of the Charlottetown Accord, and the subsequent rejection of independence in the Quebec referendum closed the case. What remains is the persistent claim that the status quo contains within it the necessary institutional mechanisms to alleviate such pressures. Indeed, the recent history of intergovernmental relations and constitutionalism in Canada is marked by a curious measure of indifference for one of the most powerful secessionist movements in the world. Third, with regard to cultural and territorial autonomy, Canada is marked by "diversity of diversities" that often undercut one another in the country's attempt to find an agreement that satisfies all of its constituent partners. Nation building in Canada has thus been characterized in part by various attempts to recognize the country's politically salient identities, often resulting in clashing visions that are metaconstitutional in nature (Cairns 1992). Finally, with regard to the place of nation building activities and attempts to consolidate national identity as the basis for citizenship and representation, Canada is caught between formal procedural markers of identification that apply uniformly across the country and a constant challenge from Quebec, which has undertaken a coherent nationbuilding strategy of its own since the "Quiet Revolution" in the 1960s. Moreover, one is struck by the extent to which asymmetry in Canada is at once as viscerally rejected as it is embraced. This has resulted in a situation where theorists and scholars have for the most part vaunted its merits and its "inevitable" foray into Canada's institutional landscape, while at the same time garnering much negative reaction from federal legislators, in part due to a large body of literature documenting its unpopular status among the general population (Seidle and Bishop 2005). As such, in Canada there exists a curious relationship with asymmetry. Its capacity to accommodate diversity has produced a seemingly unending body of thought that includes considerations about: its role in structuring relations between constituent units in the country's history as a well-acknowledged "fact" (see Milne 1991; Watts 1999); the fact that it has over time nourished debates that range from attempts to shed light on the country's actual founding principles to a novel way forward in a global world (see, for example, Kelly and Laforest 2004); its status as the most likely candidate to address Canada's persistent constitutional impasse;1 as the best way forward in addressing the policy interdependence between federal and provincial governments, particularly in terms of fiscal arrangements; as the logical consequence of deep-seated sociological differences in relation to the existence of Quebec (McRoberts 1997; Webber 1994), with a majority Francophone population, as well as in the case of Aboriginal peoples;2 and generally, as a vehicle for infusing Canadian federalism with a measure of flexibility that allows for constant adaptation to changing international and domestic circumstances. Indeed, Canada is something of a beacon for discourses on asymmetry, challenging singular understandings of political community and producing what some have called a "Canadian school" over questions of diversity, or a unique "Canadian conversation" (Kernerman 2006) that at once appeals to creative tensions about belonging and serves to keep the question of diversity alive. At the same time, asymmetrical federalism has also served as a catalyst for debates about what is "wrong" with Canadian federalism. In this sense, it is taken as symptomatic of a failure to consolidate a sense of overarching national identity in the country through nation-building efforts at the center and as a strategy of appeasement in responding to what is a perceived as an illegitimate countervailing and competing projet de société in Quebec. As a result, asymmetry in Canada is often approached indirectly, presented as a consequence of differential policy choices or administrative dealings between governments; as the outcome of intergovernmental practices and functional requirements in order to accommodate disparate needs of constituent units, and so on, rather than as a defining principle that reflects, fundamentally, the meaning and purpose of Canadian federalism. It is this narrative - one of an institutional and structuring principle that exists in the shadows, appearing now and again, eliciting tensions old and new, and strong reactions that touch upon sentiments of allegiance as well as notions of fairness - that will be recounted in this chapter. Kenneth McRoberts (2000, 25) captures this dynamic succinctly: "Canada more than ever is a multi-national state in terms of its underlying social and cultural reality. Yet, it's also more than ever a nation-state in its dominant discourse and political institutions." The disjuncture between practice and discourse is clear in Canada, and it in part nourishes the notion that asymmetrical solutions can only be partially enacted - as an outgrowth of effective governance. A further note must be considered in introducing asymmetrical federalism in Canada. Since calls for asymmetry are based on prescriptive measures for federalism, normative concerns cannot be sidestepped in contemporary debates. One must avoid proceeding with analysis by looking only at the structure of society, as this neglects the nation-building efforts undertaken over the years by both Canada and Quebec. To look only at the state, however, would be to miss out on some underlying reasons for asymmetry and the "federal spirit" - the idea that difference is one of the underlying purposes of federalism rather than a stumbling block to achieving unity. As such, this chapter will straddle these two approaches, looking at the interplay between the norm of asymmetry in Canada and actual attempts to institutionalize or accept it in fact. Asymmetry in Canada invokes existential questions related to self-identification. It should not merely be approached as a pragmatic institutional device meant to lessen conflict. Moreover, this chapter will demonstrate that the constitutional politics of difference and asymmetrical federalism as an institutional corollary is the Canadian contribution to political science that dare not speak its name. Diversity management in Canada has taken an eerily uniform bent, leaving the country with what I argue is largely a myth about its commitment to recognizing diversity, largely propagated due to its formal adherence to sociocultural diversity (multiculturalism) and personal bilingualism while shunning serious efforts at instituting formal asymmetry as the logical outcome of the recognition of national pluralism. 3 As such, asymmetry in Canada is only partly in force because it must constantly contend with a powerful nation-building project that defines the country through the equality of individuals and provinces, multicul-turalism, and bilingualism from coast to coast. Copyright © 2010 University of Pennsylvania Press.},
  isbn = {978-0-8122-4230-0},
  pagetotal = {75-96}
}

@article{Igwe20221960,
  type = {Article},
  title = {Construction Workspace Management: Critical Review and Roadmap},
  author = {Igwe, Charles and Nasiri, Fuzhan and Hammad, Amin},
  date = {2022},
  journaltitle = {International Journal of Construction Management},
  volume = {22},
  number = {10},
  pages = {1960--1973},
  doi = {10.1080/15623599.2020.1756028},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083855219&doi=10.1080%2f15623599.2020.1756028&partnerID=40&md5=53e40c737afe4dca2a9211d5a3560930},
  publication_stage = {Final},
  source = {Scopus}
}

@book{InternationalConferenceBuildings2014,
  title = {International {{Conference}} on {{Buildings}} and {{Environment}}, {{EnviBUILD}} 2013},
  date = {2014},
  journaltitle = {Advanced Materials Research},
  volume = {899},
  abstract = {The proceedings contain 120 papers. The special focus in this conference is on Indoor Environment and its Hygienic Aspects, Energy and Environmental Assessment of Sustainable Buildings, Nearly Zero Energy Buildings, Intelligent Buildings and Technologies, Effective Ventilation of Buildings, Renewable Materials and Energy Sources, Daylighting and Insolation, Building Acoustic and Building Simulation. The topics include: Analysis of energy and internal environment improvements in a single family house; application of BIM process by the evaluation of building energy sustainability; comparison of simulated and actual energy use of a hospital building in Austria; energy consumption and CO2 emission of buildings built with industrialized technology; evaluation of energy efficiency in retrofitting residential buildings with large-panel structures; house in passive standard - thermal bridges; nearly zero-energy requirements and the reference buildings; the effects of the soils thermal field onto the energy performance of buildings; thermal bridges minimizing through typical details in low energy designing; thermal bridges minimizing through window jamb in low energy buildings; transformation determinants of existing urban hotels while taking into account all aspects of sustainable development; cost optimality and/or sustainability in our building's life; optimization of building envelope components based on life cycle environmental impacts and costs; alternative way of thermal protection by thermal barrier; determination of linear thermal transmittance for curved detail; applying evolutionary computing to energy efficient architectural design; experimental measurements and numerical simulations of dynamic thermal performance of external timber frame wall; impact of facade colouring on temperature and light conditions of buildings, housing estates, and environment; improvements of energy balance of existing residential buildings; numerical analysis and measurement results of a window sill; optimization of swimming pool hall's envelope with respect to thermal and moisture design; the natural physical cavity energy regime of double-skin façade; thermal and moisture problems of wooden windows; windows in buildings - diagnostics of selected properties after time of using; wooden window structure and its thermo-humid mode; thermal properties of wooden buildings in relation to computer software; a software optimization of the solar energy system performance; comparison of modelled distribution of thermal fields at seasonal ground storage segments; electricity storage in passive house in central Europe region; evaluation of possible use of foliage as a fuel for small combustion equipment; a new type of heat exchanger for ventilation in buildings with nearly-zero energy consumption; comparison of the impact of the ventilation ducts on thermal properties of the exterior walls; experimental verification of air quality in primary schools; natural ventilation and forced warm air ventilation in offices; the effect of air condition on reduction of CO2 concentration in buildings in family houses; analysis of summer overheating in elementary school building; case study of light pollution in urbanized area of Slovakia; design as a tool for environmental therapy in the fight against lifestyle diseases; design of balcony from the point of view of daylighting; design of school environment in the 21st century; interior environment of the buildings hit by floods; sunlight penetration through sloped window apertures; thermal stability of the summer period in schoolrooms; exploring the contact comfort within complex well-being in microenvironment; air-tightness and acoustic properties of superadobe system; calculation and experimental evaluation of the thermal resistance of a structure with reflective insulation; controlling and testing of the uneven wall surface; correlation relationships between properties of brick body and their use in building practice; impact of concrete recycled materials on some properties of concrete; influence of fluidized fly ash on the selected physical-mechanical properties of the autoclaved aerated concrete; possibilities of thermal analysis for the evaluation of construction materials; risk analysis of asbestos structures and their impact on the internal environment of buildings; study of the properties of the environmentally friendly insulation materials; thermal properties of selected lightweight wooden walls and windows in the regime of long time testing; timber as renewable building material and its use in modern architecture; timber - traditional material history or vision in architectural design; transient pulse method for measuring of heat conductivity of autoclaved aerated concrete; use of multi-criteria optimization for selection of building materials for reconstruction; application of phase change materials to reduce the risk of overheating of building interior; door bottom joint design and its influence on sound transmission of the door; influence of double transparent facades on acoustic comfort at the workplace; the dispersion of acoustic energy in the dissemination from the source; the assessment of sports halls - the analysis of reverberation time, strength and clarity; a case study of the fire-resistance of traditional brick vaults; assessment and damage for building structures risk analysis methods; fire protection aspects of low-energy buildings; instruments for risk analysis as an alternative decision-making method in the forensic sciences; risk analysis of steel construction projects documentation blast furnaces; utilization of risk analysis methods in decision-making process on fitness of rehabilitation; performance-guided building design and refurbishment within a semantically augmented optimization environment; an expert system for the cost-optimal refurbishment of buildings; the concept of minimalism in sustainable residential buildings; the idea of modularity and small prefabrication of low-cost housing concepts and utilization of the construction waste.},
  isbn = {978-3-03835-040-8}
}

@book{InternationalConferenceBuildings2014a,
  title = {International {{Conference}} on {{Buildings}} and {{Environment}}, {{EnviBUILD}} 2013},
  date = {2014},
  journaltitle = {Advanced Materials Research},
  volume = {899},
  abstract = {The proceedings contain 120 papers. The special focus in this conference is on Indoor Environment and its Hygienic Aspects, Energy and Environmental Assessment of Sustainable Buildings, Nearly Zero Energy Buildings, Intelligent Buildings and Technologies, Effective Ventilation of Buildings, Renewable Materials and Energy Sources, Daylighting and Insolation, Building Acoustic and Building Simulation. The topics include: Analysis of energy and internal environment improvements in a single family house; application of BIM process by the evaluation of building energy sustainability; comparison of simulated and actual energy use of a hospital building in Austria; energy consumption and CO2 emission of buildings built with industrialized technology; evaluation of energy efficiency in retrofitting residential buildings with large-panel structures; house in passive standard - thermal bridges; nearly zero-energy requirements and the reference buildings; the effects of the soils thermal field onto the energy performance of buildings; thermal bridges minimizing through typical details in low energy designing; thermal bridges minimizing through window jamb in low energy buildings; transformation determinants of existing urban hotels while taking into account all aspects of sustainable development; cost optimality and/or sustainability in our building's life; optimization of building envelope components based on life cycle environmental impacts and costs; alternative way of thermal protection by thermal barrier; determination of linear thermal transmittance for curved detail; applying evolutionary computing to energy efficient architectural design; experimental measurements and numerical simulations of dynamic thermal performance of external timber frame wall; impact of facade colouring on temperature and light conditions of buildings, housing estates, and environment; improvements of energy balance of existing residential buildings; numerical analysis and measurement results of a window sill; optimization of swimming pool hall's envelope with respect to thermal and moisture design; the natural physical cavity energy regime of double-skin façade; thermal and moisture problems of wooden windows; windows in buildings - diagnostics of selected properties after time of using; wooden window structure and its thermo-humid mode; thermal properties of wooden buildings in relation to computer software; a software optimization of the solar energy system performance; comparison of modelled distribution of thermal fields at seasonal ground storage segments; electricity storage in passive house in central Europe region; evaluation of possible use of foliage as a fuel for small combustion equipment; a new type of heat exchanger for ventilation in buildings with nearly-zero energy consumption; comparison of the impact of the ventilation ducts on thermal properties of the exterior walls; experimental verification of air quality in primary schools; natural ventilation and forced warm air ventilation in offices; the effect of air condition on reduction of CO2 concentration in buildings in family houses; analysis of summer overheating in elementary school building; case study of light pollution in urbanized area of Slovakia; design as a tool for environmental therapy in the fight against lifestyle diseases; design of balcony from the point of view of daylighting; design of school environment in the 21st century; interior environment of the buildings hit by floods; sunlight penetration through sloped window apertures; thermal stability of the summer period in schoolrooms; exploring the contact comfort within complex well-being in microenvironment; air-tightness and acoustic properties of superadobe system; calculation and experimental evaluation of the thermal resistance of a structure with reflective insulation; controlling and testing of the uneven wall surface; correlation relationships between properties of brick body and their use in building practice; impact of concrete recycled materials on some properties of concrete; influence of fluidized fly ash on the selected physical-mechanical properties of the autoclaved aerated concrete; possibilities of thermal analysis for the evaluation of construction materials; risk analysis of asbestos structures and their impact on the internal environment of buildings; study of the properties of the environmentally friendly insulation materials; thermal properties of selected lightweight wooden walls and windows in the regime of long time testing; timber as renewable building material and its use in modern architecture; timber - traditional material history or vision in architectural design; transient pulse method for measuring of heat conductivity of autoclaved aerated concrete; use of multi-criteria optimization for selection of building materials for reconstruction; application of phase change materials to reduce the risk of overheating of building interior; door bottom joint design and its influence on sound transmission of the door; influence of double transparent facades on acoustic comfort at the workplace; the dispersion of acoustic energy in the dissemination from the source; the assessment of sports halls - the analysis of reverberation time, strength and clarity; a case study of the fire-resistance of traditional brick vaults; assessment and damage for building structures risk analysis methods; fire protection aspects of low-energy buildings; instruments for risk analysis as an alternative decision-making method in the forensic sciences; risk analysis of steel construction projects documentation blast furnaces; utilization of risk analysis methods in decision-making process on fitness of rehabilitation; performance-guided building design and refurbishment within a semantically augmented optimization environment; an expert system for the cost-optimal refurbishment of buildings; the concept of minimalism in sustainable residential buildings; the idea of modularity and small prefabrication of low-cost housing concepts and utilization of the construction waste.},
  isbn = {978-3-03835-040-8}
}

@inproceedings{IOPConferenceSeries2017,
  title = {{{IOP Conference Series}}: {{Earth}} and {{Environmental Science}}},
  booktitle = {{{IOP Conference Series}}: {{Earth}} and {{Environmental Science}}},
  date = {2017},
  volume = {2},
  abstract = {The proceedings contain 68 papers. The topics discussed include: world multidisciplinary earth sciences symposium - WMESS 2017; fire resistance of large-scale cross-laminated timber panels; tracer tests history in the Alburni Massif (southern Italy); BIM-based timber structures refurbishment of the immovable heritage listed buildings; geo-mechanical characterization of carbonate rock masses by means of laser scanner technique; research of influence of noise pollution on the value of the threshold current tangible; study on controlling factors of formation and evolution of earth forest in Yuanmou area, Yunnan, China; extreme precipitation in Poland in the years 1951-2010; application of natural mineral additives in construction; cost-assessment analysis of local vehicle scrapping facility; monitoring and assessment of water retention measures in agricultural land; influence of the palaeo-landslides on the project of rehabilitation of a national road in the southern Carpathian area; assessment of the alteration of granitic rocks and its influence on alkalis release; laboratory investigation of buried pipes using geogrid and EPS geofoam block; particle size characteristics of fluvial suspended sediment in proglacial streams, King George island, south Shetland island; evaluation of surface runoff generation processes using a rainfall simulator: a small scale laboratory experiment; and reservoir considerations and direct uses of SaÄo Pedro do Sul hydromineral and geothermal field, northern Portugal.}
}

@inproceedings{IOPConferenceSeries2017a,
  title = {{{IOP Conference Series}}: {{Earth}} and {{Environmental Science}}},
  booktitle = {{{IOP Conference Series}}: {{Earth}} and {{Environmental Science}}},
  date = {2017},
  volume = {2},
  abstract = {The proceedings contain 68 papers. The topics discussed include: world multidisciplinary earth sciences symposium - WMESS 2017; fire resistance of large-scale cross-laminated timber panels; tracer tests history in the Alburni Massif (southern Italy); BIM-based timber structures refurbishment of the immovable heritage listed buildings; geo-mechanical characterization of carbonate rock masses by means of laser scanner technique; research of influence of noise pollution on the value of the threshold current tangible; study on controlling factors of formation and evolution of earth forest in Yuanmou area, Yunnan, China; extreme precipitation in Poland in the years 1951-2010; application of natural mineral additives in construction; cost-assessment analysis of local vehicle scrapping facility; monitoring and assessment of water retention measures in agricultural land; influence of the palaeo-landslides on the project of rehabilitation of a national road in the southern Carpathian area; assessment of the alteration of granitic rocks and its influence on alkalis release; laboratory investigation of buried pipes using geogrid and EPS geofoam block; particle size characteristics of fluvial suspended sediment in proglacial streams, King George island, south Shetland island; evaluation of surface runoff generation processes using a rainfall simulator: a small scale laboratory experiment; and reservoir considerations and direct uses of SaÄo Pedro do Sul hydromineral and geothermal field, northern Portugal.}
}

@article{Iqbal2014,
  title = {Assessing Group Synchrony during a Rhythmic Social Activity: {{A}} Systemic Approach},
  author = {Iqbal, T. and Riek, L.},
  date = {2014},
  journaltitle = {6th Conference of the International Society for Gesture Studies (ISGS)}
}

@article{Iqbal2014,
  title = {Role Distribution in Synchronous Human-Robot Joint Action},
  author = {Iqbal, T. and Riek, L.D.},
  date = {2014},
  journaltitle = {Proc. of IEEE ROMAN, Towards a Framework for Joint Action}
}

@article{Iqbal2014,
  title = {A Model for Time-Synchronized Sensing and Motion to Support Human-Robot Fluency},
  author = {Iqbal, T. and Gonzales, M.J. and Riek, L.D.},
  date = {2014},
  journaltitle = {Proc. of ACM/IEEE HRI, Workshop on Timing in HRI}
}

@inproceedings{Iqbal201490,
  title = {Mobile Robots and Marching Humans: {{Measuring}} Synchronous Joint Action While in Motion},
  author = {Iqbal, T. and Gonzales, M.J. and Riek, L.D.},
  date = {2014},
  series = {{{AAAI Fall Symposium}} - {{Technical Report}}},
  volume = {FS-14-01},
  pages = {90--92}
}

@inproceedings{Iqbal2015400,
  title = {Joint Action Perception to Enable Fluent Human-Robot Teamwork},
  author = {Iqbal, T. and Gonzales, M.J. and Riek, L.D.},
  date = {2015},
  series = {Proceedings - {{IEEE International Workshop}} on {{Robot}} and {{Human Interactive Communication}}},
  volume = {2015-November},
  pages = {400--406},
  doi = {10.1109/ROMAN.2015.7333671},
  art_number = {7333671}
}

@inproceedings{Iqbal2015581,
  title = {Detecting and Synthesizing Synchronous Joint Action in Human-Robot Teams},
  author = {Iqbal, T. and Riek, L.D.},
  date = {2015},
  series = {{{ICMI}} 2015 - {{Proceedings}} of the 2015 {{ACM International Conference}} on {{Multimodal Interaction}}},
  pages = {581--585},
  doi = {10.1145/2818346.2823315}
}

@article{Iqbal2016,
  title = {Tempo Adaptation and Anticipation Methods for Human-Robot Teams},
  author = {Iqbal, T. and Moosaei, M. and Riek, L.D.},
  date = {2016},
  journaltitle = {RSS, Planning HRI: Shared Autonomy Collab. Robot. Workshop}
}

@article{Iqbal20163,
  title = {A Method for Automatic Detection of Psychomotor Entrainment},
  author = {Iqbal, T. and Riek, L.D.},
  date = {2016},
  journaltitle = {IEEE Transactions on Affective Computing},
  volume = {7},
  number = {1},
  pages = {3--16},
  doi = {10.1109/TAFFC.2015.2445335},
  art_number = {7123596}
}

@article{Iqbal2016909,
  title = {Movement Coordination in Human-Robot Teams: {{A}} Dynamical Systems Approach},
  author = {Iqbal, T. and Rack, S. and Riek, L.D.},
  date = {2016},
  journaltitle = {IEEE Transactions on Robotics},
  volume = {32},
  number = {4},
  pages = {909--919},
  doi = {10.1109/TRO.2016.2570240},
  art_number = {7494678}
}

@article{Iqbal20171712,
  title = {Coordination Dynamics in Multihuman Multirobot Teams},
  author = {Iqbal, T. and Riek, L.D.},
  date = {2017},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {2},
  number = {3},
  pages = {1712--1717},
  doi = {10.1109/LRA.2017.2673864},
  art_number = {7862739}
}

@incollection{iqbalHumanRobotTeamingApproaches2019,
  title = {Human-{{Robot Teaming}}: {{Approaches}} from {{Joint Action}} and {{Dynamical Systems}}},
  booktitle = {Humanoid {{Robotics}}: {{A Reference}}},
  author = {Iqbal, Tariq and Riek, Laurel D.},
  editor = {Goswami, Ambarish and Vadakkepat, Prahlad},
  date = {2019},
  pages = {2293--2312},
  publisher = {{Springer Netherlands}},
  location = {{Dordrecht}},
  doi = {10.1007/978-94-007-6046-2_137},
  url = {https://doi.org/10.1007/978-94-007-6046-2_137},
  abstract = {As robots start to work alongside people, they are expected to coordinate fluently with humans in teams. Many researchers have explored the problems involved in building more interactive and cooperative robots. In this chapter, we discuss recent work and the main application areas in human-robot teaming. We also shed light on some practical challenges to achieving fluent human-robot coordination and conclude the chapter with future directions for approaching these problems.},
  isbn = {978-94-007-6046-2}
}

@incollection{iqbalHumanRobotTeamingApproaches2019a,
  title = {Human-{{Robot Teaming}}: {{Approaches}} from {{Joint Action}} and {{Dynamical Systems}}},
  booktitle = {Humanoid {{Robotics}}: {{A Reference}}},
  author = {Iqbal, Tariq and Riek, Laurel D.},
  date = {2019-01-01},
  pages = {2293--2312},
  publisher = {{Springer Netherlands}},
  location = {{Dordrecht}},
  doi = {10.1007/978-94-007-6046-2_137},
  url = {http://link.springer.com/10.1007/978-94-007-6046-2_137},
  abstract = {As robots start to work alongside people, they are expected to coordinate fluently with humans in teams. Many researchers have explored the problems involved in building more interactive and cooperative robots. In this chapter, we discuss recent work and the main application areas in human-robot teaming. We also shed light on some practical challenges to achieving fluent human-robot coordination and conclude the chapter with future directions for approaching these problems.},
  isbn = {978-94-007-6046-2},
  keywords = {Coordination,Dynamical group modeling,Human-robot interaction,Human-robot teaming,Joint action},
  file = {C:\Users\leemar\Zotero\storage\JQYQDNCZ\978-94-007-6046-2_137.pdf}
}

@inproceedings{ISARC2017Proceedings2017,
  title = {{{ISARC}} 2017 - {{Proceedings}} of the 34th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  booktitle = {{{ISARC}} 2017 - {{Proceedings}} of the 34th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  date = {2017},
  abstract = {The proceedings contain 151 papers. The topics discussed include: employing outlier and novelty detection for checking the integrity of BIM to IFC entity associations; decision support tool for multi-criteria analyses of the quality of large building stock; dimensional variability analysis of construction assemblies using kinematics chains and building information models; development of a BIM-based integrated model for CAD-to-CAM production automation; first monitoring and analysis of the manufacturing and installation process of timber based 2D modules for accomplishing a future robotic building envelope upgrading; bottom-up cognitive analysis of bionic inspection robot for construction site; improving indoor location tracking quality for construction and facility management; evaluation of crane operators' performance and situation awareness during lifting operations; a high-resolution intelligence implementation based on design-to-robotic-production and-operation strategies; flexible management for concrete curing at low temperature based on learning from cases; linked data system for sharing construction safety information; and integration of structural health control in BIM for current and future residential buildings.}
}

@inproceedings{ISARC2017Proceedings2017a,
  title = {{{ISARC}} 2017 - {{Proceedings}} of the 34th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  booktitle = {{{ISARC}} 2017 - {{Proceedings}} of the 34th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  date = {2017},
  abstract = {The proceedings contain 151 papers. The topics discussed include: employing outlier and novelty detection for checking the integrity of BIM to IFC entity associations; decision support tool for multi-criteria analyses of the quality of large building stock; dimensional variability analysis of construction assemblies using kinematics chains and building information models; development of a BIM-based integrated model for CAD-to-CAM production automation; first monitoring and analysis of the manufacturing and installation process of timber based 2D modules for accomplishing a future robotic building envelope upgrading; bottom-up cognitive analysis of bionic inspection robot for construction site; improving indoor location tracking quality for construction and facility management; evaluation of crane operators' performance and situation awareness during lifting operations; a high-resolution intelligence implementation based on design-to-robotic-production and-operation strategies; flexible management for concrete curing at low temperature based on learning from cases; linked data system for sharing construction safety information; and integration of structural health control in BIM for current and future residential buildings.}
}

@book{istratovaResearchIntelligentSystem2022,
  title = {Research of an {{Intelligent System}} for {{Face Recognition}} on {{Embedded Platforms}} with {{Limited Computing Power}}},
  author = {Istratova, E. and Sin, D. and Egor, B.},
  date = {2022},
  journaltitle = {Lecture Notes in Networks and Systems},
  volume = {395},
  doi = {10.1007/978-981-16-9480-6_34},
  abstract = {Today, computer vision technologies are used in many areas of human activity. There are many methods for extracting faces in the original image, the most promising of which is the use of algorithms based on neural networks. The aim of the study was to design and test an intelligent system for face recognition on embedded platforms with limited computing power. In the course of a preliminary analysis of machine learning methods for solving the problem, it was found that it is most expedient to use machine learning methods based on the analysis of facial micro-motions with the subsequent construction of a map of points. Based on the data obtained, a face identification system was developed using computer vision technology, which was based on a method for creating complex architectures using various features with additional algorithms. A distinctive feature of the developed intelligent system is the ability to analyze several frames that confirm micro-movements of the head or blinking. As a result of testing the resulting system using the gradient boosting algorithm for regression trees, a map of 68 face points was obtained, on the basis of which human faces were identified with objects from the database.},
  isbn = {9789811694790},
  pagetotal = {354-362}
}

@book{istratovaResearchIntelligentSystem2022a,
  title = {Research of an {{Intelligent System}} for {{Face Recognition}} on {{Embedded Platforms}} with {{Limited Computing Power}}},
  author = {Istratova, E. and Sin, D. and Egor, B.},
  date = {2022},
  journaltitle = {Lecture Notes in Networks and Systems},
  volume = {395},
  doi = {10.1007/978-981-16-9480-6_34},
  abstract = {Today, computer vision technologies are used in many areas of human activity. There are many methods for extracting faces in the original image, the most promising of which is the use of algorithms based on neural networks. The aim of the study was to design and test an intelligent system for face recognition on embedded platforms with limited computing power. In the course of a preliminary analysis of machine learning methods for solving the problem, it was found that it is most expedient to use machine learning methods based on the analysis of facial micro-motions with the subsequent construction of a map of points. Based on the data obtained, a face identification system was developed using computer vision technology, which was based on a method for creating complex architectures using various features with additional algorithms. A distinctive feature of the developed intelligent system is the ability to analyze several frames that confirm micro-movements of the head or blinking. As a result of testing the resulting system using the gradient boosting algorithm for regression trees, a map of 68 face points was obtained, on the basis of which human faces were identified with objects from the database.},
  isbn = {9789811694790},
  pagetotal = {354-362}
}

@inproceedings{iturraldeRefurbishingHomesElderly2012,
  title = {Refurbishing Homes for Elderly Using {{BIM}} and {{CNC}} Technology},
  booktitle = {2012 {{Proceedings}} of the 29th {{International Symposium}} of {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2012},
  author = {Iturralde, K.},
  date = {2012},
  doi = {10.22260/isarc2012/0033},
  abstract = {Purpose: This article was developed in the context of research on a construction system based on CAD-CAM-BIM and CNC (Computer Numerically Controlled) technology and it is focused on the implementation of sustainable refurbish-ments in historic districts. During field work in historic districts, it was established that more than 25\% of the population in these areas is older than 60, and most of them have lived in the same apartment or house their whole live. The problem is that these old timberframed buildings require better equipment to fit elderly peoples' characteristics. For instance, a better distribution of space in the home would be beneficial to the elderly. To ensure better living conditions for the aging society, comfortable and big bathrooms, corridors, and doors are necessary, instead of the narrow and cramped current spaces. Likewise, more space for the installation of technological equipment is needed to support people who are disabled. Automated homes for the elderly require machinery that take up a significant amount of space. Moreover the installation of new equipment and redistribution of space has to be done rapidly so that the process creates minimum disturbance. The construction system that is being developed gives priority to the preservation of the current timber-framed structure and masonry walls, instead of dismantling the inner structure. This way, the refurbishment works are less traumatizing and the elderly and their elderly neighbors can continue to live in their homes. Method: The construction system is designed for different building contexts to demonstrate its universal applicability. Before being applied in a real situation, the first step was to ensure the refurbishment system's suitability using virtual tools. For this purpose, a BIM-building simulator was used. The preliminary works focused on two different building typologies. The first typology is an apartment building (located in Bilbao) with a common staircase where properties are divided horizontally. The second typology is a terraced house located in London. In both cases, the refurbishment system was compared to traditional refurbishment processes. The parameters of comparison have been refurbishment costs, timing, and quantity of used energy. In both cases the project was personalized for a disabled aged person. Results \& Discussion: A proper refurbishment process grounded on CAD-CAM-BIM and CNC-technology needs to be based on detailed and exact measurements. Moreover, it is advisable to collect data more than once during the refurbishment process because the timber-framed building could move some millimeters. To avoid problems due to measurement errors, the CNC-fabricated pieces should offer measurement tolerances in order to facilitate the assembly and staging process. These first steps of the project - the defining of the refurbishment system - take a long time, since all the joints must be designed in 3D. This delay in the design process will be reduced when a detailed BIM-library is set up. However, the duration of the building site process is clearly shortened and that is why how disturbance is minimized. The construction system enables a flexibility of the inner distribution and the BIMsoftware helps with the tracking or monitoring of changes in the future. If the health condition of the elderly person requires more care or supply, modifications in the home can be fixed easily.}
}

@inproceedings{iturraldeRefurbishingHomesElderly2012a,
  title = {Refurbishing Homes for Elderly Using {{BIM}} and {{CNC}} Technology},
  booktitle = {2012 {{Proceedings}} of the 29th {{International Symposium}} of {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2012},
  author = {Iturralde, K.},
  date = {2012},
  doi = {10.22260/isarc2012/0033},
  abstract = {Purpose: This article was developed in the context of research on a construction system based on CAD-CAM-BIM and CNC (Computer Numerically Controlled) technology and it is focused on the implementation of sustainable refurbish-ments in historic districts. During field work in historic districts, it was established that more than 25\% of the population in these areas is older than 60, and most of them have lived in the same apartment or house their whole live. The problem is that these old timberframed buildings require better equipment to fit elderly peoples' characteristics. For instance, a better distribution of space in the home would be beneficial to the elderly. To ensure better living conditions for the aging society, comfortable and big bathrooms, corridors, and doors are necessary, instead of the narrow and cramped current spaces. Likewise, more space for the installation of technological equipment is needed to support people who are disabled. Automated homes for the elderly require machinery that take up a significant amount of space. Moreover the installation of new equipment and redistribution of space has to be done rapidly so that the process creates minimum disturbance. The construction system that is being developed gives priority to the preservation of the current timber-framed structure and masonry walls, instead of dismantling the inner structure. This way, the refurbishment works are less traumatizing and the elderly and their elderly neighbors can continue to live in their homes. Method: The construction system is designed for different building contexts to demonstrate its universal applicability. Before being applied in a real situation, the first step was to ensure the refurbishment system's suitability using virtual tools. For this purpose, a BIM-building simulator was used. The preliminary works focused on two different building typologies. The first typology is an apartment building (located in Bilbao) with a common staircase where properties are divided horizontally. The second typology is a terraced house located in London. In both cases, the refurbishment system was compared to traditional refurbishment processes. The parameters of comparison have been refurbishment costs, timing, and quantity of used energy. In both cases the project was personalized for a disabled aged person. Results \& Discussion: A proper refurbishment process grounded on CAD-CAM-BIM and CNC-technology needs to be based on detailed and exact measurements. Moreover, it is advisable to collect data more than once during the refurbishment process because the timber-framed building could move some millimeters. To avoid problems due to measurement errors, the CNC-fabricated pieces should offer measurement tolerances in order to facilitate the assembly and staging process. These first steps of the project - the defining of the refurbishment system - take a long time, since all the joints must be designed in 3D. This delay in the design process will be reduced when a detailed BIM-library is set up. However, the duration of the building site process is clearly shortened and that is why how disturbance is minimized. The construction system enables a flexibility of the inner distribution and the BIMsoftware helps with the tracking or monitoring of changes in the future. If the health condition of the elderly person requires more care or supply, modifications in the home can be fixed easily.}
}

@article{jacinto-villegasNovelWearableHaptic2017,
  title = {A {{Novel Wearable Haptic Controller}} for {{Teleoperating Robotic Platforms}}},
  author = {Jacinto-Villegas, J.M. and Satler, M. and Filippeschi, A. and Bergamasco, M. and Ragaglia, M. and Argiolas, A. and Niccolini, M. and Avizzano, C.A.},
  date = {2017},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {2},
  number = {4},
  pages = {2072--2079},
  doi = {10.1109/LRA.2017.2720850},
  abstract = {This letter presents a novel wearable haptic controller (WHC) system suitable for teleoperation of demolition machines and robotic platforms. With regard to existing operator controller unit composed by passive joysticks, the WHC has been designed to provide force feedback to the user, hence improving the user performance during the teleoperation of different robotic platforms and the interaction with the environment on the remote construction sites. The haptic feedback is provided through two compact parallel kinematic (CPK) interfaces that will be presented within the paper. The CPK implements a novel variant of the Delta kinematics which allows minimizing the radial encumbrance while preserving same operational workspace. In addition, we propose a new interaction modality that provides users the feeling of directly maneuvering the end-effector of the demolition machine. Finally, the architecture of the proposed system is presented and the results of some preliminary evaluation tests are discussed. The experiments have been performed in simulated environments and on a real machine.}
}

@article{jacinto-villegasNovelWearableHaptic2017a,
  title = {A {{Novel Wearable Haptic Controller}} for {{Teleoperating Robotic Platforms}}},
  author = {Jacinto-Villegas, J.M. and Satler, M. and Filippeschi, A. and Bergamasco, M. and Ragaglia, M. and Argiolas, A. and Niccolini, M. and Avizzano, C.A.},
  date = {2017},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {2},
  number = {4},
  pages = {2072--2079},
  doi = {10.1109/LRA.2017.2720850},
  abstract = {This letter presents a novel wearable haptic controller (WHC) system suitable for teleoperation of demolition machines and robotic platforms. With regard to existing operator controller unit composed by passive joysticks, the WHC has been designed to provide force feedback to the user, hence improving the user performance during the teleoperation of different robotic platforms and the interaction with the environment on the remote construction sites. The haptic feedback is provided through two compact parallel kinematic (CPK) interfaces that will be presented within the paper. The CPK implements a novel variant of the Delta kinematics which allows minimizing the radial encumbrance while preserving same operational workspace. In addition, we propose a new interaction modality that provides users the feeling of directly maneuvering the end-effector of the demolition machine. Finally, the architecture of the proposed system is presented and the results of some preliminary evaluation tests are discussed. The experiments have been performed in simulated environments and on a real machine.}
}

@article{jangBuildingInformationModeling2021,
  title = {Building Information Modeling ({{BIM}})-Based Modular Integrated Construction Risk Management – {{Critical}} Survey and Future Needs},
  author = {Jang, Junyoung and Ahn, Seungjun and Cha, Seung Hyun and Cho, Kyeongwoon and Koo, Choongwan and Kim, Tae Wan},
  date = {2021-01},
  journaltitle = {Journal of Computational Design and Engineering},
  volume = {8},
  number = {1},
  pages = {1--14},
  issn = {2288-5048},
  doi = {10.1093/jcde/qwaa071},
  url = {https://academic.oup.com/jcde/article/8/1/1/5959726},
  abstract = {Although offsite construction (OSC) has emerged as a promising solution to low productivity issues in the construction industry, knowledge for effective management of OSC projects is yet to be explored and developed further. To enhance our understanding of the landscape of the current OSC management knowledge, this study identified and reviewed 83 operation-level OSC management papers. By mapping the papers on three dimensions (i.e. OSC project type, project phase, and management area), this review sheds light on the knowledge areas addressed more frequently than the other areas over time in a detailed manner. The review also shows that papers on planning, manufacturing, maintenance phases and schedule, resources, and stakeholder management areas have a relatively large number of citations, implying a great interest in these research areas. Finally, the review discusses that substantial research work is still required in the areas of OSC execution strategy, emerging technologies in offsite manufacturing and schedule management, internet of things (IoT)-based material logistics planning and tracking, building information model-based visualization and decision support, and social and environmental effects of stakeholder engagement in OSC projects.}
}

@article{jangBuildingInformationModeling2021a,
  title = {Building Information Modeling ({{BIM}})-Based Modular Integrated Construction Risk Management – {{Critical}} Survey and Future Needs},
  author = {Jang, Junyoung and Ahn, Seungjun and Cha, Seung Hyun and Cho, Kyeongwoon and Koo, Choongwan and Kim, Tae Wan},
  date = {2021-01-25},
  journaltitle = {Journal of Computational Design and Engineering},
  volume = {8},
  number = {1},
  pages = {1--14},
  issn = {2288-5048},
  doi = {10.1093/jcde/qwaa071},
  url = {https://academic.oup.com/jcde/article/8/1/1/5959726},
  abstract = {Although offsite construction (OSC) has emerged as a promising solution to low productivity issues in the construction industry, knowledge for effective management of OSC projects is yet to be explored and developed further. To enhance our understanding of the landscape of the current OSC management knowledge, this study identified and reviewed 83 operation-level OSC management papers. By mapping the papers on three dimensions (i.e. OSC project type, project phase, and management area), this review sheds light on the knowledge areas addressed more frequently than the other areas over time in a detailed manner. The review also shows that papers on planning, manufacturing, maintenance phases and schedule, resources, and stakeholder management areas have a relatively large number of citations, implying a great interest in these research areas. Finally, the review discusses that substantial research work is still required in the areas of OSC execution strategy, emerging technologies in offsite manufacturing and schedule management, internet of things (IoT)-based material logistics planning and tracking, building information model-based visualization and decision support, and social and environmental effects of stakeholder engagement in OSC projects.}
}

@article{Jarrassé2012,
  title = {A Framework to Describe, Analyze and Generate Interactive Motor Behaviors},
  author = {Jarrassé, N. and Charalambous, T. and Burdet, E.},
  date = {2012},
  journaltitle = {PLoS ONE},
  volume = {7},
  number = {11},
  doi = {10.1371/journal.pone.0049945},
  art_number = {e49945}
}

@article{jarrasseFrameworkDescribeAnalyze2012,
  title = {A {{Framework}} to {{Describe}}, {{Analyze}} and {{Generate Interactive Motor Behaviors}}},
  author = {Jarrassé, Nathanaël and Charalambous, Themistoklis and Burdet, Etienne},
  editor = {Ernst, Marc O.},
  date = {2012-11-30},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS ONE},
  volume = {7},
  number = {11},
  pages = {e49945},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0049945},
  url = {https://dx.plos.org/10.1371/journal.pone.0049945},
  urldate = {2023-04-24},
  abstract = {While motor interaction between a robot and a human, or between humans, has important implications for society as well as promising applications, little research has been devoted to its investigation. In particular, it is important to understand the different ways two agents can interact and generate suitable interactive behaviors. Towards this end, this paper introduces a framework for the description and implementation of interactive behaviors of two agents performing a joint motor task. A taxonomy of interactive behaviors is introduced, which can classify tasks and cost functions that represent the way each agent interacts. The role of an agent interacting during a motor task can be directly explained from the cost function this agent is minimizing and the task constraints. The novel framework is used to interpret and classify previous works on human-robot motor interaction. Its implementation power is demonstrated by simulating representative interactions of two humans. It also enables us to interpret and explain the role distribution and switching between roles when performing joint motor tasks.},
  langid = {english},
  file = {/Volumes/WIP/library/file.pdf}
}

@article{jensenFrameworkInteractiveHuman2020,
  title = {A Framework for Interactive Human–Robot Design Exploration},
  author = {Jensen, M.B. and Foged, I.W. and Andersen, H.J.},
  date = {2020},
  journaltitle = {International Journal of Architectural Computing},
  volume = {18},
  number = {3},
  pages = {235--253},
  doi = {10.1177/1478077120911588},
  abstract = {This study seeks to identify key aspects for increased integration of interactive robotics within the creative design process. Through its character as foundational research, the study aims to contribute to the advancement of new explorative design methods to support architects in their exploration of fabrication and assembly of an integrated performance-driven architecture. The article describes and investigates a proposed design framework for supporting an interactive human–robot design process. The proposed framework is examined through a 3-week architectural studio, with university master students exploring the design of a brick construction with the support of an interactive robotic platform. Evaluation of the proposed framework was done by triangulation of the authors’ qualitative user observations, quantitative logging of the students’ individual design processes, and through questionnaires completed after finishing the studies. The result suggests that interactive human–robot fabrication is a relevant mode of design with positive effect on the process of creative design exploration.}
}

@article{jensenFrameworkInteractiveHuman2020a,
  title = {A Framework for Interactive Human–Robot Design Exploration},
  author = {Jensen, M.B. and Foged, I.W. and Andersen, H.J.},
  date = {2020},
  journaltitle = {International Journal of Architectural Computing},
  volume = {18},
  number = {3},
  pages = {235--253},
  doi = {10.1177/1478077120911588},
  abstract = {This study seeks to identify key aspects for increased integration of interactive robotics within the creative design process. Through its character as foundational research, the study aims to contribute to the advancement of new explorative design methods to support architects in their exploration of fabrication and assembly of an integrated performance-driven architecture. The article describes and investigates a proposed design framework for supporting an interactive human–robot design process. The proposed framework is examined through a 3-week architectural studio, with university master students exploring the design of a brick construction with the support of an interactive robotic platform. Evaluation of the proposed framework was done by triangulation of the authors’ qualitative user observations, quantitative logging of the students’ individual design processes, and through questionnaires completed after finishing the studies. The result suggests that interactive human–robot fabrication is a relevant mode of design with positive effect on the process of creative design exploration.}
}

@inproceedings{jiangDoesBackgroundReally2018,
  title = {Does Background Really Matter? {{Worker}} Activity Recognition in Unconstrained Construction Environment},
  booktitle = {2018 {{IEEE}} 15th {{International Conference}} on {{Wearable}} and {{Implantable Body Sensor Networks}}, {{BSN}} 2018},
  author = {Jiang, H. and Cai, Y. and Zeng, X. and Huang, M.-C.},
  date = {2018},
  volume = {2018-Janua},
  pages = {50--53},
  doi = {10.1109/BSN.2018.8329656},
  abstract = {In order to prevent the construction injuries effectively, it is essential to fully understand the accident causation in construction. Worker action detection and recognition can be treated as the initial step of further productivity and risk factor analysis. With the development of computer vision and machine learning techniques, monitoring worker activity automatically and continuously using camera becomes feasible and promising. In this paper, we focus on worker activity recognition problem and propose an automate recognition system based on an unconstrained worker activity video dataset, in which both coarse-grained and fine-grained actions coexist. Videos are segmented by graph cuts energy minimization. Neural network technique is integrated with principle component analysis for recognizing workers' activities automatically. Discussion on different scenario settings and comparison to the state-of-the-art method are provided. Experimental results show that the average accuracy outperforms the state-of-the-art results.},
  isbn = {978-1-5386-1109-8}
}

@inproceedings{jiangDoesBackgroundReally2018a,
  title = {Does Background Really Matter? {{Worker}} Activity Recognition in Unconstrained Construction Environment},
  booktitle = {2018 {{IEEE}} 15th {{International Conference}} on {{Wearable}} and {{Implantable Body Sensor Networks}}, {{BSN}} 2018},
  author = {Jiang, H. and Cai, Y. and Zeng, X. and Huang, M.-C.},
  date = {2018},
  volume = {2018-Janua},
  pages = {50--53},
  doi = {10.1109/BSN.2018.8329656},
  abstract = {In order to prevent the construction injuries effectively, it is essential to fully understand the accident causation in construction. Worker action detection and recognition can be treated as the initial step of further productivity and risk factor analysis. With the development of computer vision and machine learning techniques, monitoring worker activity automatically and continuously using camera becomes feasible and promising. In this paper, we focus on worker activity recognition problem and propose an automate recognition system based on an unconstrained worker activity video dataset, in which both coarse-grained and fine-grained actions coexist. Videos are segmented by graph cuts energy minimization. Neural network technique is integrated with principle component analysis for recognizing workers' activities automatically. Discussion on different scenario settings and comparison to the state-of-the-art method are provided. Experimental results show that the average accuracy outperforms the state-of-the-art results.},
  isbn = {978-1-5386-1109-8}
}

@article{jiangMechanismArchitectureHybrid2012,
  title = {Mechanism Architecture of Hybrid Serial-Parallel Robot Dog},
  author = {Jiang, M. and Li, L.},
  date = {2012},
  journaltitle = {Jixie Gongcheng Xuebao/Journal of Mechanical Engineering},
  volume = {48},
  number = {1},
  pages = {19--24},
  doi = {10.3901/JME.2012.01.019},
  abstract = {The research of biomimetic robot has become one of the hottest spots of robotics. As living beings evolving for many years, it is difficulty that kinematics features of organisms can completely be realized by man-made mechanisms. In order to overcome the disadvantages of low stiffness and weak function of hind limbs, which widely exist in biomimetic robot, robot dog is studied as an example to propose the rule of importance/weight so as to simplify movement joints. In other words, by considering the base behavioral characteristics and the physical construction of each joint, main functions are put in order according their importance so that each movement joint can be easily designed with mechanical structure. Based on the work mentioned above, 24-DOF robot dog is designed by using 2-DOF parallel rotation machines (RGRR-I and RGRR-II), as well as 1-DOF joint structure. It has many advantages such as simple structure, easy manufacture, high stiffness, convenient control, agile movement, etc. This method may be useful to design other kinds of biomimetic robot. ©2012 Journal of Mechanical Engineering.}
}

@article{jiangMechanismArchitectureHybrid2012a,
  title = {Mechanism Architecture of Hybrid Serial-Parallel Robot Dog},
  author = {Jiang, M. and Li, L.},
  date = {2012},
  journaltitle = {Jixie Gongcheng Xuebao/Journal of Mechanical Engineering},
  volume = {48},
  number = {1},
  pages = {19--24},
  doi = {10.3901/JME.2012.01.019},
  abstract = {The research of biomimetic robot has become one of the hottest spots of robotics. As living beings evolving for many years, it is difficulty that kinematics features of organisms can completely be realized by man-made mechanisms. In order to overcome the disadvantages of low stiffness and weak function of hind limbs, which widely exist in biomimetic robot, robot dog is studied as an example to propose the rule of importance/weight so as to simplify movement joints. In other words, by considering the base behavioral characteristics and the physical construction of each joint, main functions are put in order according their importance so that each movement joint can be easily designed with mechanical structure. Based on the work mentioned above, 24-DOF robot dog is designed by using 2-DOF parallel rotation machines (RGRR-I and RGRR-II), as well as 1-DOF joint structure. It has many advantages such as simple structure, easy manufacture, high stiffness, convenient control, agile movement, etc. This method may be useful to design other kinds of biomimetic robot. ©2012 Journal of Mechanical Engineering.}
}

@article{jiangPersonalizedComputationalModel2022,
  title = {A {{Personalized Computational Model}} for {{Human-Like Automated Decision-Making}}},
  author = {Jiang, Longsheng and Wang, Yue},
  date = {2022-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {19},
  number = {2},
  pages = {850--863},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2021.3060727},
  url = {https://ieeexplore.ieee.org/document/9371373/},
  urldate = {2023-11-13},
  file = {D:\Lib\978-3-319-67361-5.pdf}
}

@inproceedings{jiangUnderstandingContextsRobot2020,
  title = {Understanding Contexts inside Robot and Human Manipulation Tasks through Vision-Language Model and Ontology System in Video Streams},
  booktitle = {{{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Jiang, C. and Dehghan, M. and Jagersand, M.},
  date = {2020},
  pages = {8366--8372},
  doi = {10.1109/IROS45743.2020.9340905},
  abstract = {Manipulation tasks in daily life, such as pouring water, unfold through human intentions. Being able to process contextual knowledge from these Activities of Daily Living (ADLs) over time can help us understand manipulation intentions, which are essential for an intelligent robot to transition smoothly between various manipulation actions. In this paper, to model the intended concepts of manipulation, we present a vision dataset under a strictly constrained knowledge domain for both robot and human manipulations, where manipulation concepts and relations are stored by an ontology system in a taxonomic manner. Furthermore, we propose a scheme to generate a combination of visual attentions and an evolving knowledge graph filled with commonsense knowledge. Our scheme works with real-world camera streams and fuses an attention-based Vision-Language model with the ontology system. The experimental results demonstrate that the proposed scheme can successfully represent the evolution of an intended object manipulation procedure for both robots and humans. The proposed scheme allows the robot to mimic human-like intentional behaviors by watching real-time videos. We aim to develop this scheme further for real-world robot intelligence in Human-Robot Interaction.},
  isbn = {978-1-72816-212-6}
}

@inproceedings{jiangUnderstandingContextsRobot2020a,
  title = {Understanding Contexts inside Robot and Human Manipulation Tasks through Vision-Language Model and Ontology System in Video Streams},
  booktitle = {{{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Jiang, C. and Dehghan, M. and Jagersand, M.},
  date = {2020},
  pages = {8366--8372},
  doi = {10.1109/IROS45743.2020.9340905},
  abstract = {Manipulation tasks in daily life, such as pouring water, unfold through human intentions. Being able to process contextual knowledge from these Activities of Daily Living (ADLs) over time can help us understand manipulation intentions, which are essential for an intelligent robot to transition smoothly between various manipulation actions. In this paper, to model the intended concepts of manipulation, we present a vision dataset under a strictly constrained knowledge domain for both robot and human manipulations, where manipulation concepts and relations are stored by an ontology system in a taxonomic manner. Furthermore, we propose a scheme to generate a combination of visual attentions and an evolving knowledge graph filled with commonsense knowledge. Our scheme works with real-world camera streams and fuses an attention-based Vision-Language model with the ontology system. The experimental results demonstrate that the proposed scheme can successfully represent the evolution of an intended object manipulation procedure for both robots and humans. The proposed scheme allows the robot to mimic human-like intentional behaviors by watching real-time videos. We aim to develop this scheme further for real-world robot intelligence in Human-Robot Interaction.},
  isbn = {978-1-72816-212-6}
}

@inproceedings{jinProactivecooperativeNavigationHumanlike2020,
  title = {Proactive-Cooperative Navigation in Human-like Environment for Autonomous Robots},
  booktitle = {{{ICINCO}} 2020 - {{Proceedings}} of the 17th {{International Conference}} on {{Informatics}} in {{Control}}, {{Automation}} and {{Robotics}}},
  author = {Jin, W. and Salaris, P. and Martinet, P.},
  date = {2020},
  pages = {412--419},
  abstract = {This work1 deals with the problem of navigating a robot in a constrained human-like environment. We provide a method to generate a control strategy that enables the robot to proactively move in order to induce desired and socially acceptable cooperative behaviors in neighboring pedestrians. Contrary to other control strategies that simply aim to passively avoid neighboring pedestrians, this approach aims to simplify the navigation task of a robot by looking for cooperation with humans, especially in crowded and constrained environments. The co-navigation process between humans and a robot is formalized as a multi-objective optimization problem and a control strategy is obtained through the Model Predictive Control (MPC) approach. The Extended Headed Social Force Model with Collision Prediction (EHSFM with CP) is used to predict the human motion. Different social behaviors of humans when moving in a group are also taken into account. A switching strategy between purely reactive and proactive-cooperative planning depending on the evaluation of human intentions is also furnished. Validation of the proactive-cooperative planner enables the robot to generate more socially and understandable behaviors is done with different navigation scenarios.},
  isbn = {978-989-758-442-8}
}

@inproceedings{jinProactivecooperativeNavigationHumanlike2020a,
  title = {Proactive-Cooperative Navigation in Human-like Environment for Autonomous Robots},
  booktitle = {{{ICINCO}} 2020 - {{Proceedings}} of the 17th {{International Conference}} on {{Informatics}} in {{Control}}, {{Automation}} and {{Robotics}}},
  author = {Jin, W. and Salaris, P. and Martinet, P.},
  date = {2020},
  pages = {412--419},
  abstract = {This work1 deals with the problem of navigating a robot in a constrained human-like environment. We provide a method to generate a control strategy that enables the robot to proactively move in order to induce desired and socially acceptable cooperative behaviors in neighboring pedestrians. Contrary to other control strategies that simply aim to passively avoid neighboring pedestrians, this approach aims to simplify the navigation task of a robot by looking for cooperation with humans, especially in crowded and constrained environments. The co-navigation process between humans and a robot is formalized as a multi-objective optimization problem and a control strategy is obtained through the Model Predictive Control (MPC) approach. The Extended Headed Social Force Model with Collision Prediction (EHSFM with CP) is used to predict the human motion. Different social behaviors of humans when moving in a group are also taken into account. A switching strategy between purely reactive and proactive-cooperative planning depending on the evaluation of human intentions is also furnished. Validation of the proactive-cooperative planner enables the robot to generate more socially and understandable behaviors is done with different navigation scenarios.},
  isbn = {978-989-758-442-8}
}

@inproceedings{jiSharedAutonomyFramework2020,
  title = {Towards {{Shared Autonomy Framework}} for {{Human-Aware Motion Planning}} in {{Industrial Human-Robot Collaboration}}},
  booktitle = {{{IEEE International Conference}} on {{Automation Science}} and {{Engineering}}},
  author = {Ji, Z. and Liu, Q. and Xu, W. and Liu, Z. and Yao, B. and Xiong, B. and Zhou, Z.},
  date = {2020},
  volume = {2020-Augus},
  pages = {411--417},
  doi = {10.1109/CASE48305.2020.9217003},
  abstract = {Industrial human-robot collaboration (HRC) is a promising production mode that enables humans and robots complete a joint set of tasks in a shared workplace. In this context, to facilitate efficient and safe collaboration, an industrial robot needs to understand its human teammate's behavior and develop human-aware motion planning. However, the systematic theoretical explanation on this subject is limited. Shared autonomy allows the human intervention in the control loop of the autonomous robot to achieve human-robot common goals. In this paper, the framework of shared autonomy into industrial HRC context is presented. In the sight of shared autonomy, considering the intention of human behavior is partially observable, we formalize the human-aware motion planning as a Partially Observable Markov Decision Process (POMDP), where the robot addresses the sequential decision making problems under the uncertainty of human's intention. Moreover, the shared autonomy framework and its detailed systematic enabling approaches for human-aware motion planning is presented. The feasibility of the presented framework and approaches is also validated by the case study of a HRC assembly scenario, which could accomplish more fluent and safe collaboration.},
  isbn = {978-1-72816-904-0}
}

@inproceedings{jiSharedAutonomyFramework2020a,
  title = {Towards {{Shared Autonomy Framework}} for {{Human-Aware Motion Planning}} in {{Industrial Human-Robot Collaboration}}},
  booktitle = {{{IEEE International Conference}} on {{Automation Science}} and {{Engineering}}},
  author = {Ji, Z. and Liu, Q. and Xu, W. and Liu, Z. and Yao, B. and Xiong, B. and Zhou, Z.},
  date = {2020},
  volume = {2020-Augus},
  pages = {411--417},
  doi = {10.1109/CASE48305.2020.9217003},
  abstract = {Industrial human-robot collaboration (HRC) is a promising production mode that enables humans and robots complete a joint set of tasks in a shared workplace. In this context, to facilitate efficient and safe collaboration, an industrial robot needs to understand its human teammate's behavior and develop human-aware motion planning. However, the systematic theoretical explanation on this subject is limited. Shared autonomy allows the human intervention in the control loop of the autonomous robot to achieve human-robot common goals. In this paper, the framework of shared autonomy into industrial HRC context is presented. In the sight of shared autonomy, considering the intention of human behavior is partially observable, we formalize the human-aware motion planning as a Partially Observable Markov Decision Process (POMDP), where the robot addresses the sequential decision making problems under the uncertainty of human's intention. Moreover, the shared autonomy framework and its detailed systematic enabling approaches for human-aware motion planning is presented. The feasibility of the presented framework and approaches is also validated by the case study of a HRC assembly scenario, which could accomplish more fluent and safe collaboration.},
  isbn = {978-1-72816-904-0}
}

@article{jungRobotAssistedTowerConstruction2020,
  title = {Robot-{{Assisted Tower Construction}}—{{A Method}} to {{Study}} the {{Impact}} of a {{Robot}}'s {{Allocation Behavior}} on {{Interpersonal Dynamics}} and {{Collaboration}} in {{Groups}}},
  author = {Jung, Malte F. and Difranzo, Dominic and Shen, Solace and Stoll, Brett and Claure, Houston and Lawrence, Austin},
  date = {2020},
  journaltitle = {ACM Transactions on Human-Robot Interaction},
  volume = {10},
  number = {1},
  issn = {25739522},
  doi = {10.1145/3394287},
  abstract = {Research on human-robot collaboration or human-robot teaming, has focused predominantly on understanding and enabling collaboration between a single robot and a single human. Extending human-robot collaboration research beyond the dyad, raises novel questions about how a robot should allocate resources among group members and about what the consequences of such allocation are for a group's social dynamics and outcomes. Methodological advances are needed to answer these questions allow researchers to collect data about a robot's impact not only on interactions with the robot but also on interactions of people with each other. This paper presents Robot Assisted Tower Construction, a novel task that allows researchers to examine the impact of a robot's allocation behavior on the dynamics of a group or team collaborating on a task. By focusing on the question of whether and how a robot's allocation of resources (wooden blocks required for a building task) affects collaboration dynamics and outcomes, a case is provided of how this task can be applied in a laboratory study with 124 participants to collect data about human robot collaboration that involves a group of people. We highlight the kinds of insights the task can yield and how it can be adapted to various human robot collaboration contexts.},
  keywords = {and teams,groups,Human-robot collaboration,human-robot interaction,human-robot teaming,interpersonal dynamics,research method}
}

@article{jungRobotAssistedTowerConstruction2020a,
  title = {Robot-{{Assisted Tower Construction}}—{{A Method}} to {{Study}} the {{Impact}} of a {{Robot}}'s {{Allocation Behavior}} on {{Interpersonal Dynamics}} and {{Collaboration}} in {{Groups}}},
  author = {Jung, Malte F. and Difranzo, Dominic and Shen, Solace and Stoll, Brett and Claure, Houston and Lawrence, Austin},
  date = {2020},
  journaltitle = {ACM Transactions on Human-Robot Interaction},
  volume = {10},
  number = {1},
  issn = {25739522},
  doi = {10.1145/3394287},
  abstract = {Research on human-robot collaboration or human-robot teaming, has focused predominantly on understanding and enabling collaboration between a single robot and a single human. Extending human-robot collaboration research beyond the dyad, raises novel questions about how a robot should allocate resources among group members and about what the consequences of such allocation are for a group's social dynamics and outcomes. Methodological advances are needed to answer these questions allow researchers to collect data about a robot's impact not only on interactions with the robot but also on interactions of people with each other. This paper presents Robot Assisted Tower Construction, a novel task that allows researchers to examine the impact of a robot's allocation behavior on the dynamics of a group or team collaborating on a task. By focusing on the question of whether and how a robot's allocation of resources (wooden blocks required for a building task) affects collaboration dynamics and outcomes, a case is provided of how this task can be applied in a laboratory study with 124 participants to collect data about human robot collaboration that involves a group of people. We highlight the kinds of insights the task can yield and how it can be adapted to various human robot collaboration contexts.},
  keywords = {and teams,groups,Human-robot collaboration,human-robot interaction,human-robot teaming,interpersonal dynamics,research method},
  file = {C:\Users\leemar\Zotero\storage\2B9GJ5DP\Robot-Assisted Tower Construction—A Method to Study the Impact of a Robot’s Allocation Behavior on Interpersonal Dynamics and Collab.pdf}
}

@inproceedings{kadirDESIGNINGHUMANROBOTCOLLABORATIONS2018,
  title = {{{DESIGNING HUMAN-ROBOT COLLABORATIONS IN INDUSTRY}} 4.0: {{EXPLORATIVE CASE STUDIES}}},
  shorttitle = {{{DESIGNING HUMAN-ROBOT COLLABORATIONS IN INDUSTRY}} 4.0},
  author = {Kadir, Bzhwen A and Broberg, Ole and Souza Da Conceição, Carolina},
  date = {2018},
  pages = {601--610},
  doi = {10.21278/idc.2018.0319},
  url = {https://www.designsociety.org/publication/40476/DESIGNING+HUMAN-ROBOT+COLLABORATIONS+IN+INDUSTRY+4.0%3A+EXPLORATIVE+CASE+STUDIES},
  urldate = {2023-08-20},
  eventtitle = {15th {{International Design Conference}}},
  file = {C:\Users\leemar\Zotero\storage\9FHIJWCR\Kadir 等。 - 2018 - DESIGNING HUMAN-ROBOT COLLABORATIONS IN INDUSTRY 4.pdf}
}

@article{kahanowichRobustClassificationGrasped2021,
  title = {Robust {{Classification}} of {{Grasped Objects}} in {{Intuitive Human-Robot Collaboration Using}} a {{Wearable Force-Myography Device}}},
  author = {Kahanowich, Nadav D. and Sintov, Avishai},
  date = {2021-04},
  journaltitle = {IEEE Robotics and Automation Letters},
  shortjournal = {IEEE Robot. Autom. Lett.},
  volume = {6},
  number = {2},
  pages = {1192--1199},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2021.3057794},
  url = {https://ieeexplore.ieee.org/document/9350160/},
  urldate = {2023-11-13},
  abstract = {Feasible human-robot collaboration requires intuitive and fluent understanding of human motion in shared tasks. The object in hand provides the most valuable information about the intended task of a human. In this letter, we propose a simple and affordable approach where a wearable force-myography device is used to classify objects grasped by a human. The device worn on the forearm incorporates 15 force sensors that can imply about the configuration of the hand and fingers during grasping. Hence, a classifier is trained to easily identify various objects using data recorded while holding them. To augment the classifier, we propose an iterative approach in which additional signals are taken in realtime to increase certainty about the predicted object. We show that the approach provides robust classification where the device can be taken off and placed back while maintaining high accuracy. The approach also improves the performance of trained classifiers that initially produced low accuracy due to insufficient data or non-optimal hyper-parameters. Classification success rate of more than 97\% is reached in a short period of time. Furthermore, we analyze the key locations of sensors on the forearm that provide the most accurate and robust classification.},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\6YZ938LZ\Kahanowich 與 Sintov - 2021 - Robust Classification of Grasped Objects in Intuit.pdf}
}

@inproceedings{karayiannidisMappingHumanIntentions2014,
  title = {Mapping Human Intentions to Robot Motions via Physical Interaction through a Jointly-Held Object},
  booktitle = {{{IEEE RO-MAN}} 2014 - 23rd {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}: {{Human-Robot Co-Existence}}: {{Adaptive Interfaces}} and {{Systems}} for {{Daily Life}}, {{Therapy}}, {{Assistance}} and {{Socially Engaging Interactions}}},
  author = {Karayiannidis, Y. and Smith, C. and Kragic, D.},
  date = {2014},
  pages = {391--397},
  doi = {10.1109/ROMAN.2014.6926284},
  abstract = {In this paper we consider the problem of human-robot collaborative manipulation of an object, where the human is active in controlling the motion, and the robot is passively following the human's lead. Assuming that the human grasp of the object only allows for transfer of forces and not torques, there is a disambiguity as to whether the human desires translation or rotation. In this paper, we analyze different approaches to this problem both theoretically and in experiment. This leads to the proposal of a control methodology that uses switching between two different admittance control modes based on the magnitude of measured force to achieve disambiguation of the rotation/translation problem.},
  isbn = {978-1-4799-6763-6}
}

@inproceedings{karayiannidisMappingHumanIntentions2014a,
  title = {Mapping Human Intentions to Robot Motions via Physical Interaction through a Jointly-Held Object},
  booktitle = {{{IEEE RO-MAN}} 2014 - 23rd {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}: {{Human-Robot Co-Existence}}: {{Adaptive Interfaces}} and {{Systems}} for {{Daily Life}}, {{Therapy}}, {{Assistance}} and {{Socially Engaging Interactions}}},
  author = {Karayiannidis, Y. and Smith, C. and Kragic, D.},
  date = {2014},
  pages = {391--397},
  doi = {10.1109/ROMAN.2014.6926284},
  abstract = {In this paper we consider the problem of human-robot collaborative manipulation of an object, where the human is active in controlling the motion, and the robot is passively following the human's lead. Assuming that the human grasp of the object only allows for transfer of forces and not torques, there is a disambiguity as to whether the human desires translation or rotation. In this paper, we analyze different approaches to this problem both theoretically and in experiment. This leads to the proposal of a control methodology that uses switching between two different admittance control modes based on the magnitude of measured force to achieve disambiguation of the rotation/translation problem.},
  isbn = {978-1-4799-6763-6}
}

@article{kazerooniDesignAnalysisStatically1989,
  title = {Design and Analysis of the Statically Balanced Direct-Drive Robot Manipulator},
  author = {Kazerooni, H.},
  date = {1989},
  journaltitle = {Robotics and Computer Integrated Manufacturing},
  volume = {6},
  number = {4},
  pages = {287--293},
  doi = {10.1016/0736-5845(89)90118-X},
  abstract = {A practical architecture, using a four-bar linkage, is considered for the University of Minnesota direct-drive robot (Kazerooni, H., Kim, S.: A new architecture for direct drive robots. In Proc. IEEE International Conference on Robotics and Automation, Philadelphia, Pennsylvania, April 1988). This statically balanced direct-drive robot has been constructed for stability analysis of the robot in constrained manipulation (Kazerooni, H. et al.: Fundamentals of robust compliant motion for robot manipulators. IEEE J. Robotics Automation 2: 1986; Kazerooni, H.: On the robot compliant motion control. ASME J. Dynamic Systems Msmt Control; 111 (3): September 1989. Kazerooni, H. et al.: Theory and experiments on robot compliant motion control. ASME J. Dynamic Systems Msmt Control, June 1990). As a result of the elimination of the gravity forces (without any counterweights), smaller actuators and, consequently, smaller amplifiers were chosen. The motors yield acceleration of 5 g at the robot end point without overheating. High torque, low speed, brushless AC synchronous motors are used to power the robot. Graphite-epoxy composite material is used for construction of the robot links. A 4-node parallel processor has been used to control the robot. A compliant motion control method has been derived and experimentally verified to guarantee stable constrained maneuvers for the robot. As part of the research work, a general criterion has been derived to guarantee the stability of robot manipulators in constrained maneuvers. © 1989.}
}

@article{kazerooniDesignAnalysisStatically1989a,
  title = {Design and Analysis of the Statically Balanced Direct-Drive Robot Manipulator},
  author = {Kazerooni, H.},
  date = {1989},
  journaltitle = {Robotics and Computer Integrated Manufacturing},
  volume = {6},
  number = {4},
  pages = {287--293},
  doi = {10.1016/0736-5845(89)90118-X},
  abstract = {A practical architecture, using a four-bar linkage, is considered for the University of Minnesota direct-drive robot (Kazerooni, H., Kim, S.: A new architecture for direct drive robots. In Proc. IEEE International Conference on Robotics and Automation, Philadelphia, Pennsylvania, April 1988). This statically balanced direct-drive robot has been constructed for stability analysis of the robot in constrained manipulation (Kazerooni, H. et al.: Fundamentals of robust compliant motion for robot manipulators. IEEE J. Robotics Automation 2: 1986; Kazerooni, H.: On the robot compliant motion control. ASME J. Dynamic Systems Msmt Control; 111 (3): September 1989. Kazerooni, H. et al.: Theory and experiments on robot compliant motion control. ASME J. Dynamic Systems Msmt Control, June 1990). As a result of the elimination of the gravity forces (without any counterweights), smaller actuators and, consequently, smaller amplifiers were chosen. The motors yield acceleration of 5 g at the robot end point without overheating. High torque, low speed, brushless AC synchronous motors are used to power the robot. Graphite-epoxy composite material is used for construction of the robot links. A 4-node parallel processor has been used to control the robot. A compliant motion control method has been derived and experimentally verified to guarantee stable constrained maneuvers for the robot. As part of the research work, a general criterion has been derived to guarantee the stability of robot manipulators in constrained maneuvers. © 1989.}
}

@article{kazerooniHumanExtenders1993,
  title = {Human Extenders},
  author = {Kazerooni, H. and Guo, J.},
  date = {1993},
  journaltitle = {Journal of Dynamic Systems, Measurement and Control, Transactions of the ASME},
  volume = {115},
  pages = {281--290},
  doi = {10.1115/1.2899068},
  abstract = {A human’s ability to perform physical tasks is limited by physical strength, not by intelligence. We coined the word “extenders” as a class of robot manipulators worn by humans to augment human mechanical strength, while the wearer’s intellect remains the central control system for manipulating the extender. Our research objective is to determine the ground rules for the control of robotic systems worn by humans through the design, construction, and control of several prototype experimental direct-drive/non-direct-drive multi-degree-of-freedom hydraulic/electric extenders. The design of extenders is different from the design of conventional robots because the extender interfaces with the human on a physical level. The work discussed in this article involves the dynamics and control of a prototype hydraulic six-degree-of-freedom extender. This extender’s architecture is a direct drive system with all revalue joints. Its linkage consists of two identical subsystems, the arm and the hand, each having three degrees of freedom. Two sets of force sensors measure the forces imposed on the extender by the human and by the environment (i.e., the load). The extender’s compliances in response to such contact forces were designed by selecting appropriate force compensators. The stability of the system of human, extender, and object being manipulated was analyzed. A mathematical expression for the extender performance was determined to quantify the force augmentation. Experimental studies on the control and performance of the experimental extender were conducted to verify the theoretical predictions. © 1993 ASME.},
  issue = {2B}
}

@article{kazerooniHumanExtenders1993a,
  title = {Human Extenders},
  author = {Kazerooni, H. and Guo, J.},
  date = {1993},
  journaltitle = {Journal of Dynamic Systems, Measurement and Control, Transactions of the ASME},
  volume = {115},
  pages = {281--290},
  doi = {10.1115/1.2899068},
  abstract = {A human’s ability to perform physical tasks is limited by physical strength, not by intelligence. We coined the word “extenders” as a class of robot manipulators worn by humans to augment human mechanical strength, while the wearer’s intellect remains the central control system for manipulating the extender. Our research objective is to determine the ground rules for the control of robotic systems worn by humans through the design, construction, and control of several prototype experimental direct-drive/non-direct-drive multi-degree-of-freedom hydraulic/electric extenders. The design of extenders is different from the design of conventional robots because the extender interfaces with the human on a physical level. The work discussed in this article involves the dynamics and control of a prototype hydraulic six-degree-of-freedom extender. This extender’s architecture is a direct drive system with all revalue joints. Its linkage consists of two identical subsystems, the arm and the hand, each having three degrees of freedom. Two sets of force sensors measure the forces imposed on the extender by the human and by the environment (i.e., the load). The extender’s compliances in response to such contact forces were designed by selecting appropriate force compensators. The stability of the system of human, extender, and object being manipulated was analyzed. A mathematical expression for the extender performance was determined to quantify the force augmentation. Experimental studies on the control and performance of the experimental extender were conducted to verify the theoretical predictions. © 1993 ASME.},
  issue = {2B}
}

@article{keatingSitespecificSelfsufficientRobotic2017,
  title = {Toward Site-Specific and Self-Sufficient Robotic Fabrication on Architectural Scales},
  author = {Keating, Steven J. and Leland, Julian C. and Cai, Levi and Oxman, Neri},
  date = {2017-04-26},
  journaltitle = {Science Robotics},
  shortjournal = {Sci. Robot.},
  volume = {2},
  number = {5},
  pages = {eaam8986},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.aam8986},
  url = {https://www.science.org/doi/10.1126/scirobotics.aam8986},
  urldate = {2023-09-20},
  abstract = {An on-site mobile robotic platform autonomously constructed an open dome with complex curvature and variable wall thickness.           ,              Contemporary construction techniques are slow, labor-intensive, dangerous, expensive, and constrained to primarily rectilinear forms, often resulting in homogenous structures built using materials sourced from centralized factories. To begin to address these issues, we present the Digital Construction Platform (DCP), an automated construction system capable of customized on-site fabrication of architectural-scale structures using real-time environmental data for process control. The system consists of a compound arm system composed of hydraulic and electric robotic arms carried on a tracked mobile platform. An additive manufacturing technique for constructing insulated formwork with gradient properties from dynamic mixing was developed and implemented with the DCP. As a case study, a 14.6-m-diameter, 3.7-m-tall open dome formwork structure was successfully additively manufactured on site with a fabrication time under 13.5 hours. The DCP system was characterized and evaluated in comparison with traditional construction techniques and existing large-scale digital construction research projects. Benefits in safety, quality, customization, speed, cost, and functionality were identified and reported upon. Early exploratory steps toward self-sufficiency—including photovoltaic charging and the sourcing and use of local materials—are discussed along with proposed future applications for autonomous construction.},
  langid = {english}
}

@article{keiHardwareefficientSchemesLogarithmic2004,
  title = {Hardware-Efficient Schemes for Logarithmic Approximation and Binary Search with Application to Visibility Graph Construction},
  author = {Kei, L.S. and Sridharan, K. and Srikanthan, T.},
  date = {2004},
  journaltitle = {IEEE Transactions on Industrial Electronics},
  volume = {51},
  number = {6},
  pages = {1346--1348},
  doi = {10.1109/TIE.2004.837892},
  abstract = {Visibility graphs constitute a useful data structure for environment representation in the context of robot path planning. A central element in the construction of the basic visibility graph and its variants is tangent determination. This letter presents new schemes and hardware designs for key elements in tangent construction and identification of obstructed tangents. The designs have been synthesized using Synopsys Design Compiler 2001.08-SP1, and results show they are appropriate for development of a cost-effective and efficient visibility graph generation system. © 2004 IEEE.}
}

@article{keiHardwareefficientSchemesLogarithmic2004a,
  title = {Hardware-Efficient Schemes for Logarithmic Approximation and Binary Search with Application to Visibility Graph Construction},
  author = {Kei, L.S. and Sridharan, K. and Srikanthan, T.},
  date = {2004},
  journaltitle = {IEEE Transactions on Industrial Electronics},
  volume = {51},
  number = {6},
  pages = {1346--1348},
  doi = {10.1109/TIE.2004.837892},
  abstract = {Visibility graphs constitute a useful data structure for environment representation in the context of robot path planning. A central element in the construction of the basic visibility graph and its variants is tangent determination. This letter presents new schemes and hardware designs for key elements in tangent construction and identification of obstructed tangents. The designs have been synthesized using Synopsys Design Compiler 2001.08-SP1, and results show they are appropriate for development of a cost-effective and efficient visibility graph generation system. © 2004 IEEE.}
}

@article{khalifaDevelopmentNew3DOF2018,
  title = {Development of a New 3-{{DOF}} Parallel Manipulator for Minimally Invasive Surgery},
  author = {Khalifa, A. and Fanni, M. and Mohamed, A.M. and Miyashita, T.},
  date = {2018},
  journaltitle = {International Journal of Medical Robotics and Computer Assisted Surgery},
  volume = {14},
  number = {3},
  doi = {10.1002/rcs.1901},
  abstract = {This article proposes a novel dexterous endoscopic parallel manipulator for minimally invasive surgery. The proposed manipulator has 3 degrees of freedom (3-DOF), which consist of two rotational DOFs and one translational DOF (2R1T DOFs). The manipulator consists of 3 limbs exhibiting identical kinematic structure. Each limb contains an active prismatic joint followed by 2 consecutive passive universal joints. The proposed manipulator has a unique arrangement of its joints' axes. This unique arrangement permits large bending angles, ±90° in any direction, and a workspace almost free from interior singularities. These advantages allow the proposed manipulator to outperforms existing surgical manipulators. However, this unique arrangement makes the analysis of the robot extremely difficult. Therefore, a geometrical/analytical approach is used to facilitate its singularity analysis. Construction of the virtual prototype is accomplished using ADAMS software to validate the proposed manipulator and its bending capability. A closed-form solution for inverse kinematics is obtained analytically. Also, the forward kinematics solution is obtained numerically. Moreover, evaluation of the workspace is achieved using motion/force transmissibility indices. A practical experiment has been performed using a scaling technique and PID controller. The experimental results show the feasibility of the teleoperated surgical system using the proposed parallel manipulator as the slave.}
}

@article{khalifaDevelopmentNew3DOF2018a,
  title = {Development of a New 3-{{DOF}} Parallel Manipulator for Minimally Invasive Surgery},
  author = {Khalifa, A. and Fanni, M. and Mohamed, A.M. and Miyashita, T.},
  date = {2018},
  journaltitle = {International Journal of Medical Robotics and Computer Assisted Surgery},
  volume = {14},
  number = {3},
  doi = {10.1002/rcs.1901},
  abstract = {This article proposes a novel dexterous endoscopic parallel manipulator for minimally invasive surgery. The proposed manipulator has 3 degrees of freedom (3-DOF), which consist of two rotational DOFs and one translational DOF (2R1T DOFs). The manipulator consists of 3 limbs exhibiting identical kinematic structure. Each limb contains an active prismatic joint followed by 2 consecutive passive universal joints. The proposed manipulator has a unique arrangement of its joints' axes. This unique arrangement permits large bending angles, ±90° in any direction, and a workspace almost free from interior singularities. These advantages allow the proposed manipulator to outperforms existing surgical manipulators. However, this unique arrangement makes the analysis of the robot extremely difficult. Therefore, a geometrical/analytical approach is used to facilitate its singularity analysis. Construction of the virtual prototype is accomplished using ADAMS software to validate the proposed manipulator and its bending capability. A closed-form solution for inverse kinematics is obtained analytically. Also, the forward kinematics solution is obtained numerically. Moreover, evaluation of the workspace is achieved using motion/force transmissibility indices. A practical experiment has been performed using a scaling technique and PID controller. The experimental results show the feasibility of the teleoperated surgical system using the proposed parallel manipulator as the slave.}
}

@article{khanImplementationOptimizedFramework2019,
  title = {An Implementation of Optimized Framework for Action Classification Using Multilayers Neural Network on Selected Fused Features},
  author = {Khan, M. A. and Akram, T. and Sharif, M. and Javed, M. Y. and Muhammad, N. and Yasmin, M.},
  date = {2019},
  journaltitle = {Pattern Analysis and Applications},
  volume = {22},
  number = {4},
  pages = {1377--1397},
  doi = {10.1007/s10044-018-0688-1},
  abstract = {In video sequences, human action recognition is a challenging problem due to motion variation, in frame person difference, and setting of video recording in the field of computer vision. Since last few years, applications of human activity recognition have increased significantly. In the literature, many techniques are implemented for human action recognition, but still they face problem in contrast of foreground region, segmentation, feature extraction, and feature selection. This article contributes a novel human action recognition method by embedding the proposed frames fusion working on the principle of pixels similarity. An improved hybrid feature extraction increases the recognition rate and allows efficient classification in the complex environment. The design consists of four phases, (a) enhancement of video frames (b) threshold-based background subtraction and construction of saliency map (c) feature extraction and selection (d) neural network (NN) for human action classification. Results have been tested using five benchmark datasets including Weizmann, KTH, UIUC, Muhavi, and WVU and obtaining recognition rate 97.2, 99.8, 99.4, 99.9, and 99.9\%, respectively. Contingency table and graphical curves support our claims. Comparison with existent techniques identifies the recognition rate and trueness of our proposed method.}
}

@article{khanImplementationOptimizedFramework2019a,
  title = {An Implementation of Optimized Framework for Action Classification Using Multilayers Neural Network on Selected Fused Features},
  author = {Khan, M.A. and Akram, T. and Sharif, M. and Javed, M.Y. and Muhammad, N. and Yasmin, M.},
  date = {2019},
  journaltitle = {Pattern Analysis and Applications},
  volume = {22},
  number = {4},
  pages = {1377--1397},
  doi = {10.1007/s10044-018-0688-1},
  abstract = {In video sequences, human action recognition is a challenging problem due to motion variation, in frame person difference, and setting of video recording in the field of computer vision. Since last few years, applications of human activity recognition have increased significantly. In the literature, many techniques are implemented for human action recognition, but still they face problem in contrast of foreground region, segmentation, feature extraction, and feature selection. This article contributes a novel human action recognition method by embedding the proposed frames fusion working on the principle of pixels similarity. An improved hybrid feature extraction increases the recognition rate and allows efficient classification in the complex environment. The design consists of four phases, (a) enhancement of video frames (b) threshold-based background subtraction and construction of saliency map (c) feature extraction and selection (d) neural network (NN) for human action classification. Results have been tested using five benchmark datasets including Weizmann, KTH, UIUC, Muhavi, and WVU and obtaining recognition rate 97.2, 99.8, 99.4, 99.9, and 99.9\%, respectively. Contingency table and graphical curves support our claims. Comparison with existent techniques identifies the recognition rate and trueness of our proposed method.}
}

@article{khanIntegrationBIMImmersive2021,
  title = {Integration of {{BIM}} and {{Immersive Technologies}} for {{AEC}}: {{A Scientometric-SWOT Analysis}} and {{Critical Content Review}}},
  author = {Khan, Ayaz and Sepasgozar, Samad and Liu, Tingting and Yu, Rongrong},
  date = {2021-03-19},
  journaltitle = {Buildings},
  volume = {11},
  number = {3},
  pages = {126},
  issn = {2075-5309},
  doi = {10.3390/buildings11030126},
  url = {https://www.mdpi.com/2075-5309/11/3/126},
  abstract = {With the outset of Industrial Revolution 4.0 (IR 4.0), every sector is escalating to get enrichment out of it, whether they are research- or industry-oriented. The Architecture Engineering and Construction (AEC) industry lags a bit in adopting it because of its multi-faceted dependencies and unique nature of work. Despite this, a trend has been seen recently to hone the IR 4.0 multitudes in the AEC industry. The upsurge has been seen in the usage of Immersive Technologies (ImTs) as one of the disruptive techniques. This paper studies the literature based on ImTs, which are Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR) integrating with Building Information Modelling (BIM) in the AEC sector. A total number of 444 articles were selected from Scopus following the preferred reporting items for systematic reviews and meta-analysis (PRISMA) protocol of reviewing the literature. Among the selected database, 64 papers are identified as the result of following the protocol, and the articles are divided into eight domains relevant to the AEC industry, namely client/stakeholder, design exploration, design analysis, construction planning, construction monitoring, construction health/safety, facility/management, and education/training. This study adopts both a scientometric analysis for bibliometrics visualization and a critical review using Strength Weakness Opportunity Threat (SWOT) analysis for finding gaps and state of play. The novelty of this paper lies in the analysis techniques used in the literature to provide an insight into the literature, and it provides directions for the future with an emphasis on developing sustainable development goals (SDGs). In addition, research directions for the future growth on the adoption of ImTs are identified and presented based on categorization in immersive devices, graphical/non-graphical data and, responsive/integrative processes. In addition, five subcategories for each direction are listed, citing the limitations and future/needs. This study presents the roadmap for the successful adoption of ImTs for industry practitioners and stakeholders in the AEC industry for various domains. The paper shows that there are studies on ImTs with or without BIM; however, future studies should focus on the usage of ImTs in various sectors such as modular integrated construction (MiC) or emerging needs such as SDGs.}
}

@article{khanIntegrationBimImmersive2021,
  title = {Integration of Bim and Immersive Technologies for Aec: {{A}} Scientometric‐swot Analysis and Critical Content Review},
  author = {Khan, Ayaz and Sepasgozar, Samad and Liu, Tingting and Yu, Rongrong},
  date = {2021},
  journaltitle = {Buildings},
  volume = {11},
  number = {3},
  pages = {1--34},
  issn = {20755309},
  doi = {10.3390/buildings11030126},
  abstract = {With the outset of Industrial Revolution 4.0 (IR 4.0), every sector is escalating to get en-richment out of it, whether they are research‐ or industry‐oriented. The Architecture Engineering and Construction (AEC) industry lags a bit in adopting it because of its multi‐faceted dependencies and unique nature of work. Despite this, a trend has been seen recently to hone the IR 4.0 multitudes in the AEC industry. The upsurge has been seen in the usage of Immersive Technologies (ImTs) as one of the disruptive techniques. This paper studies the literature based on ImTs, which are Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR) integrating with Building Information Modelling (BIM) in the AEC sector. A total number of 444 articles were selected from Scopus following the preferred reporting items for systematic reviews and meta‐analysis (PRISMA) protocol of reviewing the literature. Among the selected database, 64 papers are identified as the result of following the protocol, and the articles are divided into eight domains relevant to the AEC indus-try, namely client/stakeholder, design exploration, design analysis, construction planning, construction monitoring, construction health/safety, facility/management, and education/training. This study adopts both a scientometric analysis for bibliometrics visualization and a critical review using Strength Weakness Opportunity Threat (SWOT) analysis for finding gaps and state of play. The novelty of this paper lies in the analysis techniques used in the literature to provide an insight into the literature, and it provides directions for the future with an emphasis on developing sustainable development goals (SDGs). In addition, research directions for the future growth on the adoption of ImTs are identified and presented based on categorization in immersive devices, graphical/non-graphical data and, responsive/integrative processes. In addition, five subcategories for each direc-tion are listed, citing the limitations and future/needs. This study presents the roadmap for the suc-cessful adoption of ImTs for industry practitioners and stakeholders in the AEC industry for various domains. The paper shows that there are studies on ImTs with or without BIM; however, future studies should focus on the usage of ImTs in various sectors such as modular integrated construction (MiC) or emerging needs such as SDGs.},
  keywords = {AEC/facility management (FM) in-dustry,Augmented re-ality,Building information modelling,Immersive technologies,Literature review,Mixed reality,PRISMA,Sustainable development goals,SWOT analysis,Virtual reality},
  file = {C:\Users\leemar\Zotero\storage\QHA5FHWG\buildings-11-00126-v2.pdf}
}

@inproceedings{khanUpperExtremityAssist2014,
  title = {Upper Extremity Assist Exoskeleton Robot},
  booktitle = {{{IEEE RO-MAN}} 2014 - 23rd {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}: {{Human-Robot Co-Existence}}: {{Adaptive Interfaces}} and {{Systems}} for {{Daily Life}}, {{Therapy}}, {{Assistance}} and {{Socially Engaging Interactions}}},
  author = {Khan, A. M. and Yun, D.-W. and Han, J.-S. and Shin, K. and Han, C.-S.},
  date = {2014},
  pages = {892--898},
  doi = {10.1109/ROMAN.2014.6926366},
  abstract = {Need to develop human body's posture supervised robots, gave the push to researchers to think over dexterous design of exoskeleton robots. It requires to develop quantitative techniques to assess motor function and generate the command for the robots to act accordingly with complex human structure. In this paper, we focus on developing new technique for the upper limb power exoskeleton in which load is handled by the human subject and not by the robot. Main challenge along with the design complexity is to find the desired human motion intention and to develop an algorithm to assist as needed accordingly. For this purpose, we used newly developed Muscle Circumference Sensor (MCS) instead of electromyogram (EMG) sensors. MCS together with the load cells is used to estimate the desired human intention by which desired trajectory is generated. The desired trajectory is then tracked by passivity based adaptive control technique. Developed Upper limb power exoskeleton has seven degrees of freedom (DOF) in which five are passive and two are active. Active joints include shoulder and elbow, powered by electric motors and move in Sagittal plane while abduction and adduction motion in shoulder joint is provided by the passive joint. Performance of the exoskeleton is evaluated experimentally by a neurologically intact subject. The results show that after adjusting the motion intention recognition algorithm for the subject, the robot assisted effectively and the subject only felt nominal load regardless of the weight in hand.},
  isbn = {978-1-4799-6763-6}
}

@inproceedings{khanUpperExtremityAssist2014a,
  title = {Upper Extremity Assist Exoskeleton Robot},
  booktitle = {{{IEEE RO-MAN}} 2014 - 23rd {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}: {{Human-Robot Co-Existence}}: {{Adaptive Interfaces}} and {{Systems}} for {{Daily Life}}, {{Therapy}}, {{Assistance}} and {{Socially Engaging Interactions}}},
  author = {Khan, A.M. and Yun, D.-W. and Han, J.-S. and Shin, K. and Han, C.-S.},
  date = {2014},
  pages = {892--898},
  doi = {10.1109/ROMAN.2014.6926366},
  abstract = {Need to develop human body's posture supervised robots, gave the push to researchers to think over dexterous design of exoskeleton robots. It requires to develop quantitative techniques to assess motor function and generate the command for the robots to act accordingly with complex human structure. In this paper, we focus on developing new technique for the upper limb power exoskeleton in which load is handled by the human subject and not by the robot. Main challenge along with the design complexity is to find the desired human motion intention and to develop an algorithm to assist as needed accordingly. For this purpose, we used newly developed Muscle Circumference Sensor (MCS) instead of electromyogram (EMG) sensors. MCS together with the load cells is used to estimate the desired human intention by which desired trajectory is generated. The desired trajectory is then tracked by passivity based adaptive control technique. Developed Upper limb power exoskeleton has seven degrees of freedom (DOF) in which five are passive and two are active. Active joints include shoulder and elbow, powered by electric motors and move in Sagittal plane while abduction and adduction motion in shoulder joint is provided by the passive joint. Performance of the exoskeleton is evaluated experimentally by a neurologically intact subject. The results show that after adjusting the motion intention recognition algorithm for the subject, the robot assisted effectively and the subject only felt nominal load regardless of the weight in hand.},
  isbn = {978-1-4799-6763-6}
}

@article{khareMultiresolutionApproachHuman2022,
  title = {Multi-Resolution Approach to Human Activity Recognition in Video Sequence Based on Combination of Complex Wavelet Transform, {{Local Binary Pattern}} and {{Zernike}} Moment},
  author = {Khare, M. and Jeon, M.},
  date = {2022},
  journaltitle = {Multimedia Tools and Applications},
  doi = {10.1007/s11042-021-11828-6},
  abstract = {Human activity recognition is a challenging problem of computer vision and it has different emerging applications. The task of recognizing human activities from video sequence exhibits more challenges because of its highly variable nature and requirement of real time processing of data. This paper proposes a combination of features in a multiresolution framework for human activity recognition. We exploit multiresolution analysis through Daubechies complex wavelet transform (DCxWT). We combine Local binary pattern (LBP) with Zernike moment (ZM) at multiple resolutions of Daubechies complex wavelet decomposition. First, LBP coefficients of DCxWT coefficients of image frames are computed to extract texture features of image, then ZM of these LBP coefficients are computed to extract the shape feature from texture feature for construction of final feature vector. The Multi-class support vector machine classifier is used for classifying the recognized human activities. The proposed method has been tested on various standard publicly available datasets. The experimental results demonstrate that the proposed method works well for multiview human activities as well as performs better than some of the other state-of-the-art methods in terms of different quantitative performance measures.}
}

@article{khareMultiresolutionApproachHuman2022a,
  title = {Multi-Resolution Approach to Human Activity Recognition in Video Sequence Based on Combination of Complex Wavelet Transform, {{Local Binary Pattern}} and {{Zernike}} Moment},
  author = {Khare, M. and Jeon, M.},
  date = {2022},
  journaltitle = {Multimedia Tools and Applications},
  doi = {10.1007/s11042-021-11828-6},
  abstract = {Human activity recognition is a challenging problem of computer vision and it has different emerging applications. The task of recognizing human activities from video sequence exhibits more challenges because of its highly variable nature and requirement of real time processing of data. This paper proposes a combination of features in a multiresolution framework for human activity recognition. We exploit multiresolution analysis through Daubechies complex wavelet transform (DCxWT). We combine Local binary pattern (LBP) with Zernike moment (ZM) at multiple resolutions of Daubechies complex wavelet decomposition. First, LBP coefficients of DCxWT coefficients of image frames are computed to extract texture features of image, then ZM of these LBP coefficients are computed to extract the shape feature from texture feature for construction of final feature vector. The Multi-class support vector machine classifier is used for classifying the recognized human activities. The proposed method has been tested on various standard publicly available datasets. The experimental results demonstrate that the proposed method works well for multiview human activities as well as performs better than some of the other state-of-the-art methods in terms of different quantitative performance measures.}
}

@article{khuongTensileStrengthFlexural2014,
  title = {Tensile Strength and Flexural Strength Testing of {{Acrylonitrile Butadiene Styrene}} ({{ABS}}) Materials for Biomimetic Robotic Applications},
  author = {Khuong, T.L. and Gang, Z. and Farid, M. and Yu, R. and Sun, Z.-Z. and Rizwan, M.},
  date = {2014},
  journaltitle = {Journal of Biomimetics, Biomaterials and Biomedical Engineering},
  volume = {20},
  pages = {11--21},
  doi = {10.4028/www.scientific.net/JBBBE.20.11},
  abstract = {Biomimetic robots borrow their structure, senses and behavior from animals, such as humans or insects, and plants. Biomimetic design is design of a machine, a robot or a system in engineering domain that mimics operational and/or behavioral model of a biological system in nature. 3D printing technology has another name as rapid prototyping technology. Currently it is being developed fastly and widely and is applied in many fields like the jewelry, footwear, industrial design, architecture, engineering and construction, automotive, aerospace, dental and medical industry, education, geographic information system, civil engineering, guns. 3D printing technology is able to manufacture complicated, sophisticated details that the traditional processing method cannot manufacture. Therefore, 3D printing technology can be seen as an effective tool in biomimetic, which can accurately simulate most of the biological structure. Fused Deposition Modeling (FDM) is a technology of the typical rapid prototyping. The main content of the article is the focusing on tensile strength test of the ABS-Acrylonitrile Butadiene Styrene material after using Fused Deposition Modeling (FDM) technology, concretization after it's printed by UP2! 3D printer. The article focuses on two basic features which are Tensile Strength and Determination of flexural properties. © (2014) Trans Tech Publications, Switzerland.}
}

@article{khuongTensileStrengthFlexural2014a,
  title = {Tensile Strength and Flexural Strength Testing of {{Acrylonitrile Butadiene Styrene}} ({{ABS}}) Materials for Biomimetic Robotic Applications},
  author = {Khuong, T.L. and Gang, Z. and Farid, M. and Yu, R. and Sun, Z.-Z. and Rizwan, M.},
  date = {2014},
  journaltitle = {Journal of Biomimetics, Biomaterials and Biomedical Engineering},
  volume = {20},
  pages = {11--21},
  doi = {10.4028/www.scientific.net/JBBBE.20.11},
  abstract = {Biomimetic robots borrow their structure, senses and behavior from animals, such as humans or insects, and plants. Biomimetic design is design of a machine, a robot or a system in engineering domain that mimics operational and/or behavioral model of a biological system in nature. 3D printing technology has another name as rapid prototyping technology. Currently it is being developed fastly and widely and is applied in many fields like the jewelry, footwear, industrial design, architecture, engineering and construction, automotive, aerospace, dental and medical industry, education, geographic information system, civil engineering, guns. 3D printing technology is able to manufacture complicated, sophisticated details that the traditional processing method cannot manufacture. Therefore, 3D printing technology can be seen as an effective tool in biomimetic, which can accurately simulate most of the biological structure. Fused Deposition Modeling (FDM) is a technology of the typical rapid prototyping. The main content of the article is the focusing on tensile strength test of the ABS-Acrylonitrile Butadiene Styrene material after using Fused Deposition Modeling (FDM) technology, concretization after it's printed by UP2! 3D printer. The article focuses on two basic features which are Tensile Strength and Determination of flexural properties. © (2014) Trans Tech Publications, Switzerland.}
}

@article{kildalPotentialUsersKey2018,
  title = {Potential Users' Key Concerns and Expectations for the Adoption of Cobots},
  author = {Kildal, Johan and Tellaeche, Alberto and Fernández, Izaskun and Maurtua, Iñaki},
  date = {2018},
  journaltitle = {Procedia CIRP},
  shortjournal = {Procedia CIRP},
  volume = {72},
  pages = {21--26},
  issn = {22128271},
  doi = {10.1016/j.procir.2018.03.104},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2212827118302592},
  urldate = {2023-08-20},
  langid = {english}
}

@article{kimDesignIntegratedParametric2012,
  title = {Design Integrated Parametric Modeling Methodology for {{Han-ok}}},
  author = {Kim, J. and Jeon, B.H.},
  date = {2012},
  journaltitle = {Journal of Asian Architecture and Building Engineering},
  volume = {11},
  number = {2},
  pages = {239--243},
  doi = {10.3130/jaabe.11.239},
  abstract = {Han-ok, the traditional Korean house, has the timber frame structure which is common in East Asia. Because the timber frame structure requires a vast amount of hand-cutting woodwork, prefabrication based on computer aided manufacturing (CAM) should be applied to reduce the construction cost of Han-ok. In order to implement them successfully, it is necessary to manage the building information in an organized system based on data handling technology, such as building information modeling (BIM) and parametric modeling. Three-dimensional, object-based parametric modeling technology not only enhances the construction process but also associates well with design study, especially when applying it to Han-ok. By applying the principle of Kan, the Korean traditional concept of a bay, this paper suggests a parametric modeling methodology that reduces modeling tasks and increases the efficiency of design study.}
}

@article{kimDesignIntegratedParametric2012a,
  title = {Design Integrated Parametric Modeling Methodology for {{Han-ok}}},
  author = {Kim, J. and Jeon, B.H.},
  date = {2012},
  journaltitle = {Journal of Asian Architecture and Building Engineering},
  volume = {11},
  number = {2},
  pages = {239--243},
  doi = {10.3130/jaabe.11.239},
  abstract = {Han-ok, the traditional Korean house, has the timber frame structure which is common in East Asia. Because the timber frame structure requires a vast amount of hand-cutting woodwork, prefabrication based on computer aided manufacturing (CAM) should be applied to reduce the construction cost of Han-ok. In order to implement them successfully, it is necessary to manage the building information in an organized system based on data handling technology, such as building information modeling (BIM) and parametric modeling. Three-dimensional, object-based parametric modeling technology not only enhances the construction process but also associates well with design study, especially when applying it to Han-ok. By applying the principle of Kan, the Korean traditional concept of a bay, this paper suggests a parametric modeling methodology that reduces modeling tasks and increases the efficiency of design study.}
}

@article{kimDevelopmentBIMintegratedConstruction2021,
  title = {Development of {{BIM-integrated}} Construction Robot Task Planning and Simulation System},
  author = {Kim, Sungjin and Peavy, Matthew and Huang, Pei Chi and Kim, Kyungki},
  date = {2021-07},
  journaltitle = {Automation in Construction},
  volume = {127},
  publisher = {{Elsevier B.V.}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2021.103720},
  abstract = {A major challenge toward construction robotization is a lack of a system that generates detailed behaviors of robots as part of the construction process based on information contained in building information modeling (BIM) and construction schedules. This study extends BIM to incorporate robot task planning and generate detailed motions conducting construction tasks. A prototype was built upon robot operating system (ROS), focusing on generating robot task plans for indoor wall painting. The prototype includes a converter that generates a ROS-compliant world file from industry foundation classes (IFC) file and sub-processes that conduct localization, navigation, and motion planning. A case study was conducted to demonstrate the system's capability to simulate behaviors of a painting robot and evaluate the performance within the context of the construction-related tasks. The case study demonstrates the proposed BIM-leveraged robot task planning can integrate construction and robotics domains to plan operations of autonomous robots in construction projects.},
  keywords = {Building information modeling (BIM),Construction robotics,Indoor wall painting,Robot task planning,Robotization}
}

@article{kimDevelopmentBIMintegratedConstruction2021a,
  title = {Development of {{BIM-integrated}} Construction Robot Task Planning and Simulation System},
  author = {Kim, Sungjin and Peavy, Matthew and Huang, Pei Chi and Kim, Kyungki},
  date = {2021-07-01},
  journaltitle = {Automation in Construction},
  volume = {127},
  publisher = {{Elsevier B.V.}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2021.103720},
  abstract = {A major challenge toward construction robotization is a lack of a system that generates detailed behaviors of robots as part of the construction process based on information contained in building information modeling (BIM) and construction schedules. This study extends BIM to incorporate robot task planning and generate detailed motions conducting construction tasks. A prototype was built upon robot operating system (ROS), focusing on generating robot task plans for indoor wall painting. The prototype includes a converter that generates a ROS-compliant world file from industry foundation classes (IFC) file and sub-processes that conduct localization, navigation, and motion planning. A case study was conducted to demonstrate the system's capability to simulate behaviors of a painting robot and evaluate the performance within the context of the construction-related tasks. The case study demonstrates the proposed BIM-leveraged robot task planning can integrate construction and robotics domains to plan operations of autonomous robots in construction projects.},
  keywords = {★,Building information modeling (BIM),Construction robotics,Indoor wall painting,Robot task planning,Robotization},
  file = {C:\Users\leemar\Zotero\storage\C6ZDLEUN\1-s2.0-S0926580521001710-main.pdf}
}

@article{kimDevelopmentBIMintegratedConstruction2021b,
  title = {Development of {{BIM-integrated}} Construction Robot Task Planning and Simulation System},
  author = {Kim, Sungjin and Peavy, Matthew and Huang, Pei-Chi and Kim, Kyungki},
  date = {2021-07},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {127},
  pages = {103720},
  issn = {09265805},
  doi = {10.1016/j.autcon.2021.103720},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0926580521001710},
  urldate = {2023-03-23},
  langid = {english}
}

@article{kimDevelopmentRealtimeControl2004,
  title = {Development of a Real-Time Control Architecture for a Semi-Autonomous Underwater Vehicle for Intervention Missions},
  author = {Kim, T.W. and Yuh, J.},
  date = {2004},
  journaltitle = {Control Engineering Practice},
  volume = {12},
  pages = {1521--1530},
  doi = {10.1016/j.conengprac.2003.12.015},
  abstract = {The need for autonomous underwater vehicles (AUVs) for intervention missions becomes greater as they can perform underwater tasks requiring physical contacts with the underwater environment, such as underwater plug-in/plug-out, construction and repair, cable streaming, mine hunting, munitions retrieval, and scientific sampling. This paper describes a semi-autonomous underwater vehicle for intervention missions that has multiple on-board CPUs, redundant sensors and actuators, on-board power source and a robotic manipulator for dextrous underwater performance. Such a complex robotic vehicle system requires advanced control software architecture for on-board intelligence with a wide range of sensors and actuators to carry out required missions. In this paper, AUV control architectures are reviewed and a sensor data bus based control architecture (SDBCA) is presented. SDBCA is a modified hierarchical architecture that offers good controllability and stability while sensor data bus increases flexibility of system design, making it possible to have a prompt response from high-level control with respect to low-level sensor data. The overall sensor input mechanism of SDBCA becomes similar to the sensor input mechanism of subsumption architecture. © 2004 Published by Elsevier Ltd.},
  issue = {12 SPEC. I}
}

@article{kimDevelopmentRealtimeControl2004a,
  title = {Development of a Real-Time Control Architecture for a Semi-Autonomous Underwater Vehicle for Intervention Missions},
  author = {Kim, T.W. and Yuh, J.},
  date = {2004},
  journaltitle = {Control Engineering Practice},
  volume = {12},
  pages = {1521--1530},
  doi = {10.1016/j.conengprac.2003.12.015},
  abstract = {The need for autonomous underwater vehicles (AUVs) for intervention missions becomes greater as they can perform underwater tasks requiring physical contacts with the underwater environment, such as underwater plug-in/plug-out, construction and repair, cable streaming, mine hunting, munitions retrieval, and scientific sampling. This paper describes a semi-autonomous underwater vehicle for intervention missions that has multiple on-board CPUs, redundant sensors and actuators, on-board power source and a robotic manipulator for dextrous underwater performance. Such a complex robotic vehicle system requires advanced control software architecture for on-board intelligence with a wide range of sensors and actuators to carry out required missions. In this paper, AUV control architectures are reviewed and a sensor data bus based control architecture (SDBCA) is presented. SDBCA is a modified hierarchical architecture that offers good controllability and stability while sensor data bus increases flexibility of system design, making it possible to have a prompt response from high-level control with respect to low-level sensor data. The overall sensor input mechanism of SDBCA becomes similar to the sensor input mechanism of subsumption architecture. © 2004 Published by Elsevier Ltd.},
  issue = {12 SPEC. I}
}

@article{kimInteractionAnalysisVisionbased2018,
  title = {Interaction Analysis for Vision-Based Activity Identification of Earthmoving Excavators and Dump Trucks},
  author = {Kim, J. and Chi, S. and Seo, J.},
  date = {2018},
  journaltitle = {Automation in Construction},
  volume = {87},
  pages = {297--308},
  doi = {10.1016/j.autcon.2017.12.016},
  abstract = {Activity identification is an essential step to measure and monitor the performance of earthmoving operations. Many vision-based methods that automatically capture and explain activity information from image data have been developed with economic advantages and analysis efficiency. However, the previous methods failed to consider the interactive operations among equipment, and thus limited the applicability to the operation time estimation for productivity analysis. To address the drawback, this research developed a vision-based activity identification framework that incorporates interactive aspects of earthmoving equipment's operation. This framework included four main processes: equipment tracking, action recognition of individual equipment, interaction analysis, and post-processing. The interactions between excavators and dump trucks were examined due to its significant impacts on earthmoving operations. TLD (Tracking-Learning-Detection) was adapted to track the heavy equipment. Spatio-temporal reasoning and image differencing techniques were then implemented to categorize individual actions. Third, interactions were interpreted based on a knowledge-based system that evaluates equipment actions and proximity between operating equipment. Lastly, outliers or noisy results were filtered out considering work continuity. To validate the proposed framework, two experiments were performed: one with the interaction analysis and the other without the analysis. 11,513 image frames from actual earthmoving sites in total were tested. The consequent average precision of activity analysis was enhanced from 75.68\% to 91.27\% after the interaction analysis was applied. In conclusion, this research contributes to identifying critical elements that explain interactive operations, characterize the vision-based activity identification framework, and improve the applicability of the vision-based method for the automated equipment operations analysis.}
}

@article{kimInteractionAnalysisVisionbased2018a,
  title = {Interaction Analysis for Vision-Based Activity Identification of Earthmoving Excavators and Dump Trucks},
  author = {Kim, J. and Chi, S. and Seo, J.},
  date = {2018},
  journaltitle = {Automation in Construction},
  volume = {87},
  pages = {297--308},
  doi = {10.1016/j.autcon.2017.12.016},
  abstract = {Activity identification is an essential step to measure and monitor the performance of earthmoving operations. Many vision-based methods that automatically capture and explain activity information from image data have been developed with economic advantages and analysis efficiency. However, the previous methods failed to consider the interactive operations among equipment, and thus limited the applicability to the operation time estimation for productivity analysis. To address the drawback, this research developed a vision-based activity identification framework that incorporates interactive aspects of earthmoving equipment's operation. This framework included four main processes: equipment tracking, action recognition of individual equipment, interaction analysis, and post-processing. The interactions between excavators and dump trucks were examined due to its significant impacts on earthmoving operations. TLD (Tracking-Learning-Detection) was adapted to track the heavy equipment. Spatio-temporal reasoning and image differencing techniques were then implemented to categorize individual actions. Third, interactions were interpreted based on a knowledge-based system that evaluates equipment actions and proximity between operating equipment. Lastly, outliers or noisy results were filtered out considering work continuity. To validate the proposed framework, two experiments were performed: one with the interaction analysis and the other without the analysis. 11,513 image frames from actual earthmoving sites in total were tested. The consequent average precision of activity analysis was enhanced from 75.68\% to 91.27\% after the interaction analysis was applied. In conclusion, this research contributes to identifying critical elements that explain interactive operations, characterize the vision-based activity identification framework, and improve the applicability of the vision-based method for the automated equipment operations analysis.}
}

@inproceedings{kimSEMGbasedStaticForce2020,
  title = {{{sEMG-based Static Force Estimation}} for {{Human-Robot Interaction}} Using {{Deep Learning}}},
  booktitle = {2020 17th {{International Conference}} on {{Ubiquitous Robots}}, {{UR}} 2020},
  author = {Kim, S. and Chung, W. K. and Kim, K.},
  date = {2020},
  pages = {81--86},
  doi = {10.1109/UR49135.2020.9144869},
  abstract = {Human-robot interaction (HRI) is a rapidly growing research area and it occurs in many applications including human-robot collaboration, human power augmentation, and rehabilitation robotics. As it is hard to exactly calculate intended motion trajectory, generally, interaction control is applied in HRI instead of pure motion control. To implement the interaction control, force information is necessary and force sensor is widely used in force feedback. However, force sensor has some limitations as 1) it is subject to breakdown, 2) it imposes additional volume and weight to the system, and 3) its applicable places are constrained. In this situation, force estimation can be a good solution. However, if force in static situation should be measured, using position and velocity is not sufficient because they are not influenced by the exerted force anymore. Therefore, we proposed sEMG-based static force estimation using deep learning. sEMG provides a useful information about human-exerting force because it reflects the human intention. Also, to extract the complex relationship between sEMG and force, deep learning approach is used. Experimental results show that when force with maximal value of 63.2 N is exerted, average force estimation error was 3.67 N. Also, the proposed method shows that force onset timing of estimated force is faster than force sensor signal. This result would be advantageous for faster human intention recognition.},
  isbn = {978-1-72815-715-3}
}

@inproceedings{kimSEMGbasedStaticForce2020a,
  title = {{{sEMG-based Static Force Estimation}} for {{Human-Robot Interaction}} Using {{Deep Learning}}},
  booktitle = {2020 17th {{International Conference}} on {{Ubiquitous Robots}}, {{UR}} 2020},
  author = {Kim, S. and Chung, W.K. and Kim, K.},
  date = {2020},
  pages = {81--86},
  doi = {10.1109/UR49135.2020.9144869},
  abstract = {Human-robot interaction (HRI) is a rapidly growing research area and it occurs in many applications including human-robot collaboration, human power augmentation, and rehabilitation robotics. As it is hard to exactly calculate intended motion trajectory, generally, interaction control is applied in HRI instead of pure motion control. To implement the interaction control, force information is necessary and force sensor is widely used in force feedback. However, force sensor has some limitations as 1) it is subject to breakdown, 2) it imposes additional volume and weight to the system, and 3) its applicable places are constrained. In this situation, force estimation can be a good solution. However, if force in static situation should be measured, using position and velocity is not sufficient because they are not influenced by the exerted force anymore. Therefore, we proposed sEMG-based static force estimation using deep learning. sEMG provides a useful information about human-exerting force because it reflects the human intention. Also, to extract the complex relationship between sEMG and force, deep learning approach is used. Experimental results show that when force with maximal value of 63.2 N is exerted, average force estimation error was 3.67 N. Also, the proposed method shows that force onset timing of estimated force is faster than force sensor signal. This result would be advantageous for faster human intention recognition.},
  isbn = {978-1-72815-715-3}
}

@inproceedings{kimVisionbasedActionRecognition2013,
  title = {Vision-Based Action Recognition in the Internal Construction Site Using Interactions between Worker Actions and Construction Objects},
  booktitle = {{{ISARC}} 2013 - 30th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} and {{Mining}}, {{Held}} in {{Conjunction}} with the 23rd {{World Mining Congress}}},
  author = {Kim, J. Y. and Caldas, C. H.},
  date = {2013},
  pages = {661--668},
  doi = {10.22260/isarc2013/0072},
  abstract = {This paper presents a novel action recognition method for observing human workers using interactions between actions and related objects on an internal construction site. This method can be used to measure work rates for labour productivity monitoring. This monitoring is critical because the performance of a construction project is significantly impacted by labour productivity. However, construction sites are generally crowded with a large number of workers and objects. Such congestion disrupts the accurate, automatic recognition of construction workers' actions. This congestion is one reason that existing automatic action recognition studies of construction areas mainly focus on workers' actions themselves. However, the crowded conditions mean that sites could offer a great deal of clues that could be used for automatic action recognition. According to psychological studies, interactions clearly take place between human actions and related objects, such as between hammering and a hammer. Humans use these interactions to recognize actions or objects more accurately. On the construction site, workers, materials, tools, and equipment are carefully planned out ahead of actual construction. The categories of workers and objects are pre-defined and, as noted, specific interactions define relations between worker actions and objects. In this paper, the interactions are limited to human workers and their hand-held objects. Action recognition results can be combined with hand-held object information to improve recognition accuracy. With the limited interactions, experiments in this paper show a significant improvement in action recognition. This paper describes the utilization of these interactions to improve construction action recognition accuracy based on human skeleton data and 2D color video from Microsoft KINECT sensor.}
}

@inproceedings{kimVisionbasedActionRecognition2013a,
  title = {Vision-Based Action Recognition in the Internal Construction Site Using Interactions between Worker Actions and Construction Objects},
  booktitle = {{{ISARC}} 2013 - 30th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} and {{Mining}}, {{Held}} in {{Conjunction}} with the 23rd {{World Mining Congress}}},
  author = {Kim, J.Y. and Caldas, C.H.},
  date = {2013},
  pages = {661--668},
  doi = {10.22260/isarc2013/0072},
  abstract = {This paper presents a novel action recognition method for observing human workers using interactions between actions and related objects on an internal construction site. This method can be used to measure work rates for labour productivity monitoring. This monitoring is critical because the performance of a construction project is significantly impacted by labour productivity. However, construction sites are generally crowded with a large number of workers and objects. Such congestion disrupts the accurate, automatic recognition of construction workers' actions. This congestion is one reason that existing automatic action recognition studies of construction areas mainly focus on workers' actions themselves. However, the crowded conditions mean that sites could offer a great deal of clues that could be used for automatic action recognition. According to psychological studies, interactions clearly take place between human actions and related objects, such as between hammering and a hammer. Humans use these interactions to recognize actions or objects more accurately. On the construction site, workers, materials, tools, and equipment are carefully planned out ahead of actual construction. The categories of workers and objects are pre-defined and, as noted, specific interactions define relations between worker actions and objects. In this paper, the interactions are limited to human workers and their hand-held objects. Action recognition results can be combined with hand-held object information to improve recognition accuracy. With the limited interactions, experiments in this paper show a significant improvement in action recognition. This paper describes the utilization of these interactions to improve construction action recognition accuracy based on human skeleton data and 2D color video from Microsoft KINECT sensor.}
}

@inproceedings{kimVisionBasedActivityAnalysis2017,
  title = {Vision-{{Based Activity Analysis Framework Considering Interactive Operation}} of {{Construction Equipment}}},
  booktitle = {Congress on {{Computing}} in {{Civil Engineering}}, {{Proceedings}}},
  author = {Kim, J. and Chi, S. and Hwang, B.-G.},
  date = {2017},
  volume = {2017-June},
  pages = {162--170},
  doi = {10.1061/9780784480830.021},
  abstract = {Automated activity analysis is vital for efficient productivity management on construction sites. A vision-based method has received attention due to its efficiency in identification and tracking. Although existing vision studies showed applicability, they did not consider interactive operations between equipment, and thus deteriorated analysis performance. To tackle the limitation, this paper proposes a vision-based activity analysis framework considering interactive operations of construction equipment. The framework includes four main processes: detection, tracking, individual action recognition, and interaction analysis. For the feasibility analysis, the individual actions of excavators were analyzed automatically using tracking-learning-detection and bags-of-features. This framework was validated with video images collected from earthmoving construction sites, and the average precisions of detection, tracking and action recognition were 88.0\%, 88.0\%, and 83.6\% respectively. The experimental results showed the developed approach was able to identify independent actions of equipment, but the interactive operations should be considered to be more reliable activity analysis.},
  isbn = {978-0-7844-8083-0}
}

@inproceedings{kimVisionBasedActivityAnalysis2017a,
  title = {Vision-{{Based Activity Analysis Framework Considering Interactive Operation}} of {{Construction Equipment}}},
  booktitle = {Congress on {{Computing}} in {{Civil Engineering}}, {{Proceedings}}},
  author = {Kim, J. and Chi, S. and Hwang, B.-G.},
  date = {2017},
  volume = {2017-June},
  pages = {162--170},
  doi = {10.1061/9780784480830.021},
  abstract = {Automated activity analysis is vital for efficient productivity management on construction sites. A vision-based method has received attention due to its efficiency in identification and tracking. Although existing vision studies showed applicability, they did not consider interactive operations between equipment, and thus deteriorated analysis performance. To tackle the limitation, this paper proposes a vision-based activity analysis framework considering interactive operations of construction equipment. The framework includes four main processes: detection, tracking, individual action recognition, and interaction analysis. For the feasibility analysis, the individual actions of excavators were analyzed automatically using tracking-learning-detection and bags-of-features. This framework was validated with video images collected from earthmoving construction sites, and the average precisions of detection, tracking and action recognition were 88.0\%, 88.0\%, and 83.6\% respectively. The experimental results showed the developed approach was able to identify independent actions of equipment, but the interactive operations should be considered to be more reliable activity analysis.},
  isbn = {978-0-7844-8083-0}
}

@inproceedings{kimWhoShouldBlame2006,
  title = {Who {{Should I Blame}}? {{Effects}} of {{Autonomy}} and {{Transparency}} on {{Attributions}} in {{Human-Robot Interaction}}},
  shorttitle = {Who {{Should I Blame}}?},
  booktitle = {{{ROMAN}} 2006 - {{The}} 15th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}},
  author = {Kim, Taemie and Hinds, Pamela},
  date = {2006-09},
  pages = {80--85},
  publisher = {{IEEE}},
  location = {{Univ. of Hertfordshire, Hatfield, UK}},
  doi = {10.1109/ROMAN.2006.314398},
  url = {http://ieeexplore.ieee.org/document/4107789/},
  urldate = {2023-08-20},
  eventtitle = {{{ROMAN}} 2006 - {{The}} 15th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}},
  isbn = {978-1-4244-0564-0 978-1-4244-0565-7}
}

@inproceedings{kincelovaBIMbasedCodeCompliance2019,
  title = {{{BIM-based}} Code Compliance Checking for Fire Safety in Timber Buildings: {{A}} Comparison of Existing Tools},
  booktitle = {Proceedings, {{Annual Conference}} - {{Canadian Society}} for {{Civil Engineering}}},
  author = {Kincelova, K. and Boton, C. and Blanchet, P. and Dagenais, C.},
  date = {2019},
  volume = {2019-June},
  abstract = {The nature and the complexity of building codes, including the fire regulations, result in mainly manual verification and, therefore, in subjective potential interpretations or errors. In the case of timber construction, the fire safety regulations are moreover a challenge due to the combustibility of the material. Further integration of fire safety is needed during the design process in order to increase the reliability of the designs in terms of fire safety. Building information modelling (BIM) technologies offer today new tools for automating different tasks in the construction process. The different approaches and available tools have been therefore compared in the context of fire protection code compliance. For that matter, criteria applicable to the tools have been identified based on literature review and on the National Building Code of Canada prescriptive provisions, but also based on a practical manipulation of the available tools. The potential of the different tools is therefore assessed based on their integration of the fire protection concepts and on their adaptability to BIM. This contextualized comparison has shown that the fire protection integration in BIM is limited. The tools for performance-based fire protection design are not exploring enough the information contained by the building model that is beyond the geometry. The BIM-based compliance checking tools, in turn, contain insufficient space for fire safety regulations checking as advanced spatial study is required for this purpose. Thus, this paper demonstrates the need for further development in terms of exploiting the building models� semantics in the fire protection context.}
}

@inproceedings{kincelovaBIMbasedCodeCompliance2019a,
  title = {{{BIM-based}} Code Compliance Checking for Fire Safety in Timber Buildings: {{A}} Comparison of Existing Tools},
  booktitle = {Proceedings, {{Annual Conference}} - {{Canadian Society}} for {{Civil Engineering}}},
  author = {Kincelova, K. and Boton, C. and Blanchet, P. and Dagenais, C.},
  date = {2019},
  volume = {2019-June},
  abstract = {The nature and the complexity of building codes, including the fire regulations, result in mainly manual verification and, therefore, in subjective potential interpretations or errors. In the case of timber construction, the fire safety regulations are moreover a challenge due to the combustibility of the material. Further integration of fire safety is needed during the design process in order to increase the reliability of the designs in terms of fire safety. Building information modelling (BIM) technologies offer today new tools for automating different tasks in the construction process. The different approaches and available tools have been therefore compared in the context of fire protection code compliance. For that matter, criteria applicable to the tools have been identified based on literature review and on the National Building Code of Canada prescriptive provisions, but also based on a practical manipulation of the available tools. The potential of the different tools is therefore assessed based on their integration of the fire protection concepts and on their adaptability to BIM. This contextualized comparison has shown that the fire protection integration in BIM is limited. The tools for performance-based fire protection design are not exploring enough the information contained by the building model that is beyond the geometry. The BIM-based compliance checking tools, in turn, contain insufficient space for fire safety regulations checking as advanced spatial study is required for this purpose. Thus, this paper demonstrates the need for further development in terms of exploiting the building models� semantics in the fire protection context.}
}

@article{kincelovaFireSafetyTall2020,
  title = {Fire Safety in Tall Timber Building: {{A BIM-based}} Automated Code-Checking Approach},
  author = {Kincelova, K. and Boton, C. and Blanchet, P. and Dagenais, C.},
  date = {2020},
  journaltitle = {Buildings},
  volume = {10},
  number = {10},
  doi = {10.3390/BUILDINGS10070121},
  abstract = {Fire safety regulations impose very strict requirements on building design, especially for buildings built with combustible materials. It is believed that it is possible to improve the management of these regulations with a better integration of fire protection aspects in the building information modeling (BIM) approach. A new BIM-based domain is emerging, the automated code checking, with its growing number of dedicated approaches. However, only very few of these works have been dedicated to managing the compliance to fire safety regulations in timber buildings. In this paper, the applicability to fire safety in the Canadian context is studied by constituting and executing a complete method from the regulations text through code-checking construction to result analysis. A design science approach is used to propose a code-checking method with a detailed analysis of the National Building Code of Canada (NBCC) in order to obtain the required information. The method starts by retrieving information from the regulation text, leading to a compliance check of an architectural building model. Then, the method is tested on a set of fire safety regulations and validated on a building model from a real project. The selected fire safety rules set a solid basis for further development of checking rules for the field of fire safety. This study shows that the main challenges for rule checking are the modeling standards and the elements' required levels of detail. The implementation of the method was successful for geometrical as well as non-geometrical requirements, although further work is needed for more advanced geometrical studies, such as sprinkler or fire dampers positioning.}
}

@article{kincelovaFireSafetyTall2020a,
  title = {Fire Safety in Tall Timber Building: {{A BIM-based}} Automated Code-Checking Approach},
  author = {Kincelova, K. and Boton, C. and Blanchet, P. and Dagenais, C.},
  date = {2020},
  journaltitle = {Buildings},
  volume = {10},
  number = {10},
  doi = {10.3390/BUILDINGS10070121},
  abstract = {Fire safety regulations impose very strict requirements on building design, especially for buildings built with combustible materials. It is believed that it is possible to improve the management of these regulations with a better integration of fire protection aspects in the building information modeling (BIM) approach. A new BIM-based domain is emerging, the automated code checking, with its growing number of dedicated approaches. However, only very few of these works have been dedicated to managing the compliance to fire safety regulations in timber buildings. In this paper, the applicability to fire safety in the Canadian context is studied by constituting and executing a complete method from the regulations text through code-checking construction to result analysis. A design science approach is used to propose a code-checking method with a detailed analysis of the National Building Code of Canada (NBCC) in order to obtain the required information. The method starts by retrieving information from the regulation text, leading to a compliance check of an architectural building model. Then, the method is tested on a set of fire safety regulations and validated on a building model from a real project. The selected fire safety rules set a solid basis for further development of checking rules for the field of fire safety. This study shows that the main challenges for rule checking are the modeling standards and the elements' required levels of detail. The implementation of the method was successful for geometrical as well as non-geometrical requirements, although further work is needed for more advanced geometrical studies, such as sprinkler or fire dampers positioning.}
}

@article{Knoblich20031006,
  title = {Action Coordination in Groups and Individuals: {{Learning}} Anticipatory Control},
  author = {Knoblich, G. and Jordan, J.S.},
  date = {2003},
  journaltitle = {Journal of Experimental Psychology: Learning Memory and Cognition},
  volume = {29},
  number = {5},
  pages = {1006--1016},
  doi = {10.1037/0278-7393.29.5.1006}
}

@article{Knoblich201159,
  title = {Psychological Research on Joint Action. {{Theory}} and Data},
  author = {Knoblich, G. and Butterfill, S. and Sebanz, N.},
  date = {2011},
  journaltitle = {Psychology of Learning and Motivation - Advances in Research and Theory},
  volume = {54},
  pages = {59--101},
  doi = {10.1016/B978-0-12-385527-5.00003-6}
}

@inproceedings{kollerRoboticDrinkingAssistance2019,
  title = {Towards Robotic Drinking Assistance: {{Low}} Cost Multi-Sensor System to Limit Forces in {{Human-Robot-Interaction}}},
  booktitle = {{{ACM International Conference Proceeding Series}}},
  author = {Koller, T. L. and Kyrarini, M. and Gräser, A.},
  date = {2019},
  pages = {243--246},
  doi = {10.1145/3316782.3321539},
  abstract = {Assistive robotic manipulators have the potential to support individuals with severe motor impairments at performing activities of daily life. With the help of robotic manipulators, the individuals may eat and drink independently of caregivers. The presented research work focuses on interactive drinking with a cup without a straw. The interaction exposes the user to potential harm due to the direct contact with the robot. In the presented work, a multi-sensor system is outlined, which ensures harmless contact forces between robot and human during an interactive drinking task. Tests on a healthy subject are performed and indicate pain-free interaction with the system. The sensor system is designed to allow the user an intuitive control of the task. The lip pressure is measured at the contact points and will be used in future work to control the tilting angle of the cup, which is grasped by the robot.},
  isbn = {978-1-4503-6232-0}
}

@inproceedings{kollerRoboticDrinkingAssistance2019a,
  title = {Towards Robotic Drinking Assistance: {{Low}} Cost Multi-Sensor System to Limit Forces in {{Human-Robot-Interaction}}},
  booktitle = {{{ACM International Conference Proceeding Series}}},
  author = {Koller, T.L. and Kyrarini, M. and Gräser, A.},
  date = {2019},
  pages = {243--246},
  doi = {10.1145/3316782.3321539},
  abstract = {Assistive robotic manipulators have the potential to support individuals with severe motor impairments at performing activities of daily life. With the help of robotic manipulators, the individuals may eat and drink independently of caregivers. The presented research work focuses on interactive drinking with a cup without a straw. The interaction exposes the user to potential harm due to the direct contact with the robot. In the presented work, a multi-sensor system is outlined, which ensures harmless contact forces between robot and human during an interactive drinking task. Tests on a healthy subject are performed and indicate pain-free interaction with the system. The sensor system is designed to allow the user an intuitive control of the task. The lip pressure is measured at the contact points and will be used in future work to control the tilting angle of the cup, which is grasped by the robot.},
  isbn = {978-1-4503-6232-0}
}

@article{konidarisSkillsSymbolsLearning2018,
  title = {From {{Skills}} to {{Symbols}}: {{Learning Symbolic Representations}} for {{Abstract High-Level Planning}}},
  shorttitle = {From {{Skills}} to {{Symbols}}},
  author = {Konidaris, George and Kaelbling, Leslie Pack and Lozano-Perez, Tomas},
  date = {2018-01-31},
  journaltitle = {Journal of Artificial Intelligence Research},
  shortjournal = {jair},
  volume = {61},
  pages = {215--289},
  issn = {1076-9757},
  doi = {10.1613/jair.5575},
  url = {https://jair.org/index.php/jair/article/view/11175},
  urldate = {2023-03-22},
  abstract = {We consider the problem of constructing abstract representations for planning in high-dimensional, continuous environments. We assume an agent equipped with a collection of high-level actions, and construct representations provably capable of evaluating plans composed of sequences of those actions.  We first consider the deterministic planning case, and  show that the relevant computation involves set operations performed over sets of states. We define the specific collection of sets that is necessary and sufficient for planning, and use them to construct a  grounded abstract symbolic representation that is provably suitable for deterministic planning. The resulting representation can be expressed in PDDL, a canonical high-level planning domain language; we construct such a representation for the Playroom domain and solve it in milliseconds using an off-the-shelf planner.  We then consider probabilistic planning, which we show requires generalizing from sets of states to distributions over states. We identify the specific distributions required for planning, and use them to construct a grounded abstract symbolic representation that correctly estimates the expected reward and probability of success of any plan. In addition, we show that learning the relevant probability distributions corresponds to specific instances of probabilistic density estimation and probabilistic classification. We construct an agent that autonomously learns the correct abstract representation of a computer game domain, and rapidly solves it.   Finally, we apply these techniques to create a physical robot system that autonomously learns its own symbolic representation of a mobile manipulation task directly from sensorimotor data---point clouds, map locations, and joint angles---and then plans using that representation. Together, these results establish a principled link between high-level actions and abstract representations, a concrete theoretical foundation for constructing abstract representations with provable properties, and a practical mechanism for autonomously learning abstract high-level representations.},
  file = {C:\Users\leemar\Zotero\storage\8LLR4H5B\Konidaris et al. - 2018 - From Skills to Symbols Learning Symbolic Represen.pdf}
}

@article{kontovourkisRoboticAdditiveManufacturing2020,
  title = {Robotic Additive Manufacturing ({{RAM}}) with Clay Using Topology Optimization Principles for Toolpath Planning: The Example of a Building Element},
  author = {Kontovourkis, O. and Tryfonos, G. and Georgiou, C.},
  date = {2020},
  journaltitle = {Architectural Science Review},
  volume = {63},
  number = {2},
  pages = {105--118},
  doi = {10.1080/00038628.2019.1620170},
  abstract = {The term Robotic Additive Manufacturing (RAM) describes the process of material deposition in layers, leading to solidified products using industrial robots. Similar processes like construction-scale 3D printing have gained considerable attention during the last few decades and today an increasing interest is observed. Despite their emerging trend, very early adoptions are visible today, with issues under further consideration to include construction time and cost, associated with material minimization and structural efficiency, but also ecological aspect of materials evolved. This paper discusses the current role of 3D printing in the architecture and construction and proposes a framework for implementation using Topology Optimization (TO) principles and clay-based materials. This is applied in a case study example where the design and fabrication of a building element is conducted. The results derived from this investigation are critically discussed and conclusions are drawn for a new and more effective application in the architecture and construction industry.}
}

@article{kontovourkisRoboticAdditiveManufacturing2020a,
  title = {Robotic Additive Manufacturing ({{RAM}}) with Clay Using Topology Optimization Principles for Toolpath Planning: The Example of a Building Element},
  author = {Kontovourkis, O. and Tryfonos, G. and Georgiou, C.},
  date = {2020},
  journaltitle = {Architectural Science Review},
  volume = {63},
  number = {2},
  pages = {105--118},
  doi = {10.1080/00038628.2019.1620170},
  abstract = {The term Robotic Additive Manufacturing (RAM) describes the process of material deposition in layers, leading to solidified products using industrial robots. Similar processes like construction-scale 3D printing have gained considerable attention during the last few decades and today an increasing interest is observed. Despite their emerging trend, very early adoptions are visible today, with issues under further consideration to include construction time and cost, associated with material minimization and structural efficiency, but also ecological aspect of materials evolved. This paper discusses the current role of 3D printing in the architecture and construction and proposes a framework for implementation using Topology Optimization (TO) principles and clay-based materials. This is applied in a case study example where the design and fabrication of a building element is conducted. The results derived from this investigation are critically discussed and conclusions are drawn for a new and more effective application in the architecture and construction industry.}
}

@article{Konvalinka20102220,
  title = {Follow You, Follow Me: {{Continuous}} Mutual Prediction and Adaptation in Joint Tapping},
  author = {Konvalinka, I. and Vuust, P. and Roepstorff, A. and Frith, C.D.},
  date = {2010},
  journaltitle = {Quarterly Journal of Experimental Psychology},
  volume = {63},
  number = {11},
  pages = {2220--2230},
  doi = {10.1080/17470218.2010.497843}
}

@article{Konvalinka20118514,
  title = {Synchronized Arousal between Performers and Related Spectators in a Fire-Walking Ritual},
  author = {Konvalinka, I. and Xygalatas, D. and Bulbulia, J. and Schjødt, U. and Jegindø, E.-M. and Wallot, S. and Van Orden, G. and Roepstorff, A.},
  date = {2011},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {108},
  number = {20},
  pages = {8514--8519},
  doi = {10.1073/pnas.1016955108}
}

@inproceedings{kootFrameworkSmartResilient2019,
  title = {Towards a Framework for Smart Resilient Logistics},
  booktitle = {Proceedings - {{IEEE International Enterprise Distributed Object Computing Workshop}}, {{EDOCW}}},
  author = {Koot, M.},
  date = {2019},
  volume = {2019-Octob},
  pages = {202--207},
  doi = {10.1109/EDOCW.2019.00043},
  abstract = {In order to remain competitive, logistics companies are forced to provide smart solutions within a network that is characterized by complexity and heterogeneity. The advancements of sensing and communication technologies stimulate logistics organizations to improve their business performances by using more advanced decision support tools. This research is devoted to improve logistics decision making by exploiting the enormous datasets originating from IoT networks in combination with Big Data Analytics. The main aim is to develop a resilient planning framework that stimulates logistics planners to combine both human experiences and pattern recognition mechanisms (e.g., machine learning, data mining, etc.). In this paper, four research deliverables are proposed to pursue this vision: (1) a state-of-the-art overview of modern decision support tools to enhance logistics resilience and efficiency; (2) the development of dynamic optimization algorithms using real-time data; (3) the construction of data-driven algorithms to identify, assess and resolve the presence of logistical disturbances and; (4) the formulation of resilient planning framework that enables real-life implementations of the algorithms developed. A brief overview of the required research activities is given as well, including a visualization of the activities' coherency. This paper concludes with a description of the preliminary results and some future research directions.},
  isbn = {978-1-72814-598-3}
}

@inproceedings{kootFrameworkSmartResilient2019a,
  title = {Towards a Framework for Smart Resilient Logistics},
  booktitle = {Proceedings - {{IEEE International Enterprise Distributed Object Computing Workshop}}, {{EDOCW}}},
  author = {Koot, M.},
  date = {2019},
  volume = {2019-Octob},
  pages = {202--207},
  doi = {10.1109/EDOCW.2019.00043},
  abstract = {In order to remain competitive, logistics companies are forced to provide smart solutions within a network that is characterized by complexity and heterogeneity. The advancements of sensing and communication technologies stimulate logistics organizations to improve their business performances by using more advanced decision support tools. This research is devoted to improve logistics decision making by exploiting the enormous datasets originating from IoT networks in combination with Big Data Analytics. The main aim is to develop a resilient planning framework that stimulates logistics planners to combine both human experiences and pattern recognition mechanisms (e.g., machine learning, data mining, etc.). In this paper, four research deliverables are proposed to pursue this vision: (1) a state-of-the-art overview of modern decision support tools to enhance logistics resilience and efficiency; (2) the development of dynamic optimization algorithms using real-time data; (3) the construction of data-driven algorithms to identify, assess and resolve the presence of logistical disturbances and; (4) the formulation of resilient planning framework that enables real-life implementations of the algorithms developed. A brief overview of the required research activities is given as well, including a visualization of the activities' coherency. This paper concludes with a description of the preliminary results and some future research directions.},
  isbn = {978-1-72814-598-3}
}

@article{Koppula2016453,
  title = {Anticipatory Planning for Human-Robot Teams},
  author = {Koppula, H.S. and Jain, A. and Saxena, A.},
  date = {2016},
  journaltitle = {Springer Tracts in Advanced Robotics},
  volume = {109},
  pages = {453--470},
  doi = {10.1007/978-3-319-23778-7_30}
}

@article{Koseoglu20181298,
  type = {Article},
  title = {Mobile {{BIM}} Implementation and Lean Interaction on Construction Site: {{A}} Case Study of a Complex Airport Project},
  author = {Koseoglu, Ozan and Nurtan-Gunes, Elif Tugce},
  date = {2018},
  journaltitle = {Engineering, Construction and Architectural Management},
  volume = {25},
  number = {10},
  pages = {1298--1321},
  doi = {10.1108/ECAM-08-2017-0188},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053243809&doi=10.1108%2fECAM-08-2017-0188&partnerID=40&md5=6182a1c8d968cbc2b1b7edbf23e91040},
  publication_stage = {Final},
  source = {Scopus}
}

@article{Koseoglu20181298,
  type = {Article},
  title = {Mobile {{BIM}} Implementation and Lean Interaction on Construction Site: {{A}} Case Study of a Complex Airport Project},
  author = {Koseoglu, Ozan and Nurtan-Gunes, Elif Tugce},
  date = {2018},
  journaltitle = {Engineering, Construction and Architectural Management},
  volume = {25},
  number = {10},
  pages = {1298--1321},
  doi = {10.1108/ECAM-08-2017-0188},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053243809&doi=10.1108%2fECAM-08-2017-0188&partnerID=40&md5=6182a1c8d968cbc2b1b7edbf23e91040},
  publication_stage = {Final},
  source = {Scopus}
}

@article{koutamanisFutureVisualDesign1993,
  title = {The Future of Visual Design Representations in Architecture},
  author = {Koutamanis, A.},
  date = {1993},
  journaltitle = {Automation in Construction},
  volume = {2},
  number = {1},
  pages = {47--56},
  doi = {10.1016/0926-5805(93)90034-U},
  abstract = {Visual representations form one of the most successful and yet most underrated-especially in the framework of the computerization of architecture-devices of architectural design. Recent advances in computer-aided design, as well as the emerging need to explore and utilize more extensively the cognitive aspects of architecture could lead to a reconsideration of the forms and roles of computer-based architectural visual representations. The paper outlines a number of forthcoming applications, mainly with respect to the relationships between computer graphics, computer vision and architectural design thinking. It is proposed that the capability of automated recognition transforms the computer into an efficient, knowledgeable design assistant who supports and anticipates the activities of the architect during designing and facilitates automation of building construction and supervision. © 1993.}
}

@article{koutamanisFutureVisualDesign1993a,
  title = {The Future of Visual Design Representations in Architecture},
  author = {Koutamanis, A.},
  date = {1993},
  journaltitle = {Automation in Construction},
  volume = {2},
  number = {1},
  pages = {47--56},
  doi = {10.1016/0926-5805(93)90034-U},
  abstract = {Visual representations form one of the most successful and yet most underrated-especially in the framework of the computerization of architecture-devices of architectural design. Recent advances in computer-aided design, as well as the emerging need to explore and utilize more extensively the cognitive aspects of architecture could lead to a reconsideration of the forms and roles of computer-based architectural visual representations. The paper outlines a number of forthcoming applications, mainly with respect to the relationships between computer graphics, computer vision and architectural design thinking. It is proposed that the capability of automated recognition transforms the computer into an efficient, knowledgeable design assistant who supports and anticipates the activities of the architect during designing and facilitates automation of building construction and supervision. © 1993.}
}

@inproceedings{kratzerAnticipatingHumanIntention2020,
  title = {Anticipating {{Human Intention}} for {{Full-Body Motion Prediction}} in {{Object Grasping}} and {{Placing Tasks}}},
  booktitle = {29th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}}, {{RO-MAN}} 2020},
  author = {Kratzer, P. and Midlagajni, N. B. and Toussaint, M. and Mainprice, J.},
  date = {2020},
  pages = {1157--1163},
  doi = {10.1109/RO-MAN47096.2020.9223547},
  abstract = {Motion prediction in unstructured environments is a difficult problem and is essential for safe and efficient human-robot space sharing and collaboration. In this work, we focus on manipulation movements in environments such as homes, workplaces or restaurants, where the overall task and environment can be leveraged to produce accurate motion prediction. For these cases we propose an algorithmic framework that accounts explicitly for the environment geometry based on a model of affordances and a model of short-term human dynamics both trained on motion capture data. We propose dedicated function networks for graspability and placebility affordances and we make use of a dedicated RNN [1] for short-term motion prediction. The prediction of grasp and placement probability densities are used by a constraint-based trajectory optimizer to produce a full-body motion prediction over the entire horizon. We show by comparing to ground truth data that we achieve similar performance for full-body motion predictions as using oracle grasp and place locations.},
  isbn = {978-1-72816-075-7}
}

@inproceedings{kratzerAnticipatingHumanIntention2020a,
  title = {Anticipating {{Human Intention}} for {{Full-Body Motion Prediction}} in {{Object Grasping}} and {{Placing Tasks}}},
  booktitle = {29th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}}, {{RO-MAN}} 2020},
  author = {Kratzer, P. and Midlagajni, N.B. and Toussaint, M. and Mainprice, J.},
  date = {2020},
  pages = {1157--1163},
  doi = {10.1109/RO-MAN47096.2020.9223547},
  abstract = {Motion prediction in unstructured environments is a difficult problem and is essential for safe and efficient human-robot space sharing and collaboration. In this work, we focus on manipulation movements in environments such as homes, workplaces or restaurants, where the overall task and environment can be leveraged to produce accurate motion prediction. For these cases we propose an algorithmic framework that accounts explicitly for the environment geometry based on a model of affordances and a model of short-term human dynamics both trained on motion capture data. We propose dedicated function networks for graspability and placebility affordances and we make use of a dedicated RNN [1] for short-term motion prediction. The prediction of grasp and placement probability densities are used by a constraint-based trajectory optimizer to produce a full-body motion prediction over the entire horizon. We show by comparing to ground truth data that we achieve similar performance for full-body motion predictions as using oracle grasp and place locations.},
  isbn = {978-1-72816-075-7}
}

@article{krichmarDesignPrinciplesBiologically2012,
  title = {Design Principles for Biologically Inspired Cognitive Robotics},
  author = {Krichmar, J.L.},
  date = {2012},
  journaltitle = {Biologically Inspired Cognitive Architectures},
  volume = {1},
  pages = {73--81},
  doi = {10.1016/j.bica.2012.04.003},
  abstract = {The goals of cognitive robotics are to better understand cognition through the construction of physical artifacts, and to create practical systems that demonstrate cognitive capabilities. I believe for cognitive robotics to move forward, a balanced approach that emphasizes the interaction of brain, body, and environment is necessary. In general, cognitive robots and cognitive architectures focus too much on brain control, and overlook the contributions of morphology to intelligent behavior. On the other hand, the behavior based robotics approach is unbalanced in the opposite direction. For cognitive robotics to move forward, these disparate research communities need to come into balance. The materials, morphology, sensors, actuators, and the nervous system should be balanced and coordinated in their action. In their book, "How the body shapes the way we think: A new view of intelligence" (MIT Press, 2007), Pfeifer and Bongard have suggested that intelligent agents should follow a set of design principles that highlight the importance of embodiment and physical interaction with the environment. In the present paper, I apply each of these principles to biologically inspired cognitive robotics and suggest how the field can shift toward better cognitive architectures by adherence to these principles. © 2012 Elsevier B.V.}
}

@article{krichmarDesignPrinciplesBiologically2012a,
  title = {Design Principles for Biologically Inspired Cognitive Robotics},
  author = {Krichmar, J.L.},
  date = {2012},
  journaltitle = {Biologically Inspired Cognitive Architectures},
  volume = {1},
  pages = {73--81},
  doi = {10.1016/j.bica.2012.04.003},
  abstract = {The goals of cognitive robotics are to better understand cognition through the construction of physical artifacts, and to create practical systems that demonstrate cognitive capabilities. I believe for cognitive robotics to move forward, a balanced approach that emphasizes the interaction of brain, body, and environment is necessary. In general, cognitive robots and cognitive architectures focus too much on brain control, and overlook the contributions of morphology to intelligent behavior. On the other hand, the behavior based robotics approach is unbalanced in the opposite direction. For cognitive robotics to move forward, these disparate research communities need to come into balance. The materials, morphology, sensors, actuators, and the nervous system should be balanced and coordinated in their action. In their book, "How the body shapes the way we think: A new view of intelligence" (MIT Press, 2007), Pfeifer and Bongard have suggested that intelligent agents should follow a set of design principles that highlight the importance of embodiment and physical interaction with the environment. In the present paper, I apply each of these principles to biologically inspired cognitive robotics and suggest how the field can shift toward better cognitive architectures by adherence to these principles. © 2012 Elsevier B.V.}
}

@article{kroemerReviewRobotLearning2019,
  title = {A {{Review}} of {{Robot Learning}} for {{Manipulation}}: {{Challenges}}, {{Representations}}, and {{Algorithms}}},
  shorttitle = {A {{Review}} of {{Robot Learning}} for {{Manipulation}}},
  author = {Kroemer, Oliver and Niekum, Scott and Konidaris, George},
  date = {2019},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1907.03146},
  url = {https://arxiv.org/abs/1907.03146},
  urldate = {2023-03-23},
  abstract = {A key challenge in intelligent robotics is creating robots that are capable of directly interacting with the world around them to achieve their goals. The last decade has seen substantial growth in research on the problem of robot manipulation, which aims to exploit the increasing availability of affordable robot arms and grippers to create robots capable of directly interacting with the world to achieve their goals. Learning will be central to such autonomous systems, as the real world contains too much variation for a robot to expect to have an accurate model of its environment, the objects in it, or the skills required to manipulate them, in advance. We aim to survey a representative subset of that research which uses machine learning for manipulation. We describe a formalization of the robot manipulation learning problem that synthesizes existing research into a single coherent framework and highlight the many remaining research opportunities and challenges.},
  version = {3},
  keywords = {FOS: Computer and information sciences,Robotics (cs.RO)}
}

@article{kroppInteriorConstructionState2018,
  title = {Interior Construction State Recognition with {{4D BIM}} Registered Image Sequences},
  author = {Kropp, C. and Koch, C. and König, M.},
  date = {2018},
  journaltitle = {Automation in Construction},
  volume = {86},
  pages = {11--32},
  doi = {10.1016/j.autcon.2017.10.027},
  abstract = {Deviations from planned schedules in construction projects frequently lead to unexpected financial disadvantages. However, early assessment of delays or accelerations during the phase of construction enables the adjustment of subsequent and dependent tasks. Manually performed, this involves many human resources if as-built information is not immediately available. This is particularly valid for indoor environments, where a general overview of tasks is not given. In this paper, we present a novel method that increases the degree of automation for indoor progress monitoring. The novel method recognizes the actual state of construction activities from as-built video data based on as-planned BIM data using computer vision algorithms. To achieve that, two main steps are incorporated. The first step registers the images with the underlying 4D BIM model. This means the discovery of the pose of each image of a sequence according to the coordinate system of the building model. Being aware of the image origin, it allows for the advanced interpretation of the content in consecutive processing. In the second step, the relevant tasks of the expected state of the 4D BIM model are projected onto the image space. The resulting image regions of interest are then taken as input for the determination of the activity state. The method is extensively tested in the experiment section of this paper. Since each consecutive process is based on the output of preceding steps, each process of the introduced method is tested for its standalone characteristics. In addition, the general manner of applicability is evaluated by means of two exemplary tasks as a concluding proof of the success of the novel method. All experiments show promising results and direct towards automatic indoor progress monitoring.}
}

@article{kroppInteriorConstructionState2018a,
  title = {Interior Construction State Recognition with {{4D BIM}} Registered Image Sequences},
  author = {Kropp, C. and Koch, C. and König, M.},
  date = {2018},
  journaltitle = {Automation in Construction},
  volume = {86},
  pages = {11--32},
  doi = {10.1016/j.autcon.2017.10.027},
  abstract = {Deviations from planned schedules in construction projects frequently lead to unexpected financial disadvantages. However, early assessment of delays or accelerations during the phase of construction enables the adjustment of subsequent and dependent tasks. Manually performed, this involves many human resources if as-built information is not immediately available. This is particularly valid for indoor environments, where a general overview of tasks is not given. In this paper, we present a novel method that increases the degree of automation for indoor progress monitoring. The novel method recognizes the actual state of construction activities from as-built video data based on as-planned BIM data using computer vision algorithms. To achieve that, two main steps are incorporated. The first step registers the images with the underlying 4D BIM model. This means the discovery of the pose of each image of a sequence according to the coordinate system of the building model. Being aware of the image origin, it allows for the advanced interpretation of the content in consecutive processing. In the second step, the relevant tasks of the expected state of the 4D BIM model are projected onto the image space. The resulting image regions of interest are then taken as input for the determination of the activity state. The method is extensively tested in the experiment section of this paper. Since each consecutive process is based on the output of preceding steps, each process of the introduced method is tested for its standalone characteristics. In addition, the general manner of applicability is evaluated by means of two exemplary tasks as a concluding proof of the success of the novel method. All experiments show promising results and direct towards automatic indoor progress monitoring.}
}

@inproceedings{kroppObjectRecognitionBIM2013,
  title = {Object Recognition in {{BIM}} Registered Videos for Indoor Progress Monitoring},
  booktitle = {European {{Group}} for {{Intelligent Computing}} in {{Engineering}}, {{EG-ICE}} 2013 - 20th {{International Workshop}}: {{Intelligent Computing}} in {{Engineering}}},
  author = {Kropp, C. and König, M. and Koch, C.},
  date = {2013},
  abstract = {Automatic progress monitoring in indoor scenes of construction projects is a great challenge due to complex environments. A first strategy to recognize higher level activities with computer vision and machine learning is to detect the presence of project related objects. In this paper, an approach is introduced that uses present data from schedule loaded BIM models and motion registered videos to gain information for enhanced object recognition. Image data is preprocessed by several filters to achieve simple 2D classification problems for unsupervised captured image data from indoor scenes. This approach is evaluated on a practical example, detecting heating devices using HOG features and a SVM classifier. It is shown that this approach requires only a low number of real and virtual model images to automatically create a training set for indoor object recognition with high accuracy.},
  isbn = {978-3-200-03145-6}
}

@inproceedings{kroppObjectRecognitionBIM2013a,
  title = {Object Recognition in {{BIM}} Registered Videos for Indoor Progress Monitoring},
  booktitle = {European {{Group}} for {{Intelligent Computing}} in {{Engineering}}, {{EG-ICE}} 2013 - 20th {{International Workshop}}: {{Intelligent Computing}} in {{Engineering}}},
  author = {Kropp, C. and König, M. and Koch, C.},
  date = {2013},
  abstract = {Automatic progress monitoring in indoor scenes of construction projects is a great challenge due to complex environments. A first strategy to recognize higher level activities with computer vision and machine learning is to detect the presence of project related objects. In this paper, an approach is introduced that uses present data from schedule loaded BIM models and motion registered videos to gain information for enhanced object recognition. Image data is preprocessed by several filters to achieve simple 2D classification problems for unsupervised captured image data from indoor scenes. This approach is evaluated on a practical example, detecting heating devices using HOG features and a SVM classifier. It is shown that this approach requires only a low number of real and virtual model images to automatically create a training set for indoor object recognition with high accuracy.},
  isbn = {978-3-200-03145-6}
}

@article{kulakowskiModelingIndoorLighting2014,
  title = {Modeling Indoor Lighting Inspection Robot Behavior Using {{Concurrent Communicating Lists}}},
  author = {Kułakowski, K. and Matyasik, P. and Ernst, S.},
  date = {2014},
  journaltitle = {Expert Systems with Applications},
  volume = {41},
  pages = {984--989},
  doi = {10.1016/j.eswa.2013.06.065},
  abstract = {Today, energy efficiency is one of the top priorities in building design and construction. A significant share of energy usage is due to indoor lighting. Although methods exist for design and control of intelligent lighting systems, the task of real-world lighting assessment and verification remains only partly addressed. This paper describes foundations for design of a robot to conduct regular and automated audits of lighting quality in office buildings, with emphasis on the modeling of its behavior. The proposed model uses the Concurrent Communicating Lists (CCL) notation, which allows it to be easily simulated, executed, and formally verified. The CCL behavior model is discussed in the context of Knowledge-Behavior-Platform (KBP) robotic architecture proposed as a practical model runtime environment. © 2013 Elsevier Ltd. All rights reserved.},
  issue = {4 PART 1}
}

@article{kulakowskiModelingIndoorLighting2014a,
  title = {Modeling Indoor Lighting Inspection Robot Behavior Using {{Concurrent Communicating Lists}}},
  author = {Kułakowski, K. and Matyasik, P. and Ernst, S.},
  date = {2014},
  journaltitle = {Expert Systems with Applications},
  volume = {41},
  pages = {984--989},
  doi = {10.1016/j.eswa.2013.06.065},
  abstract = {Today, energy efficiency is one of the top priorities in building design and construction. A significant share of energy usage is due to indoor lighting. Although methods exist for design and control of intelligent lighting systems, the task of real-world lighting assessment and verification remains only partly addressed. This paper describes foundations for design of a robot to conduct regular and automated audits of lighting quality in office buildings, with emphasis on the modeling of its behavior. The proposed model uses the Concurrent Communicating Lists (CCL) notation, which allows it to be easily simulated, executed, and formally verified. The CCL behavior model is discussed in the context of Knowledge-Behavior-Platform (KBP) robotic architecture proposed as a practical model runtime environment. © 2013 Elsevier Ltd. All rights reserved.},
  issue = {4 PART 1}
}

@article{kunicDesignAssemblyAutomation2021,
  title = {Design and Assembly Automation of the {{Robotic Reversible Timber Beam}}},
  author = {Kunic, A. and Naboni, R. and Kramberger, A. and Schlette, C.},
  date = {2021},
  journaltitle = {Automation in Construction},
  volume = {123},
  doi = {10.1016/j.autcon.2020.103531},
  abstract = {The field of architecture is more and more referring to wood as a sustainable solution for satisfying the need of new buildings while offsetting carbon emissions. In parallel, the research in Robotic Timber Construction (RTC) has evolved rapidly, focusing both on fabrication and assembly processes in order to improve the productivity of the construction industry and extend the production digital chain. This paper presents an original workflow for the automation from design to layered robotic assembly of reversible timber structures, aided by human-robot collaboration. An advanced digital design workflow for non-standard timber structures is established, shifting the focus towards the assembly of a kit of discrete wood elements into larger configurations that can be reconfigured in time. Linked to this, collaborative robots are employed for grasping, positioning and fixing of discrete timber elements, with the introduction of a multi-phase end effector that connects wood elements through reversible joinery. As such, the work introduces fundamental design and manufacturing concepts for an automated construction process that extends the material life cycle of wood, and consequently, its carbon store. The enhancement of robotic assembly is here achieved with the (1) integration of a feedback system based on location and force signals, and (2) human collaboration to provide immediate assistance to the robot in the case the signals do not match the defined assembly conditions. The various developments are applied to a research demonstrator which crystallizes the various design, constructional, and manufacturing inputs into a physical output, which is discussed from multiple viewpoints, in order to delineate relevant areas for future studies.}
}

@article{kunicDesignAssemblyAutomation2021a,
  title = {Design and Assembly Automation of the {{Robotic Reversible Timber Beam}}},
  author = {Kunic, A. and Naboni, R. and Kramberger, A. and Schlette, C.},
  date = {2021},
  journaltitle = {Automation in Construction},
  volume = {123},
  doi = {10.1016/j.autcon.2020.103531},
  abstract = {The field of architecture is more and more referring to wood as a sustainable solution for satisfying the need of new buildings while offsetting carbon emissions. In parallel, the research in Robotic Timber Construction (RTC) has evolved rapidly, focusing both on fabrication and assembly processes in order to improve the productivity of the construction industry and extend the production digital chain. This paper presents an original workflow for the automation from design to layered robotic assembly of reversible timber structures, aided by human-robot collaboration. An advanced digital design workflow for non-standard timber structures is established, shifting the focus towards the assembly of a kit of discrete wood elements into larger configurations that can be reconfigured in time. Linked to this, collaborative robots are employed for grasping, positioning and fixing of discrete timber elements, with the introduction of a multi-phase end effector that connects wood elements through reversible joinery. As such, the work introduces fundamental design and manufacturing concepts for an automated construction process that extends the material life cycle of wood, and consequently, its carbon store. The enhancement of robotic assembly is here achieved with the (1) integration of a feedback system based on location and force signals, and (2) human collaboration to provide immediate assistance to the robot in the case the signals do not match the defined assembly conditions. The various developments are applied to a research demonstrator which crystallizes the various design, constructional, and manufacturing inputs into a physical output, which is discussed from multiple viewpoints, in order to delineate relevant areas for future studies.}
}

@article{kuoDevelopmentModularbasedLarge2008,
  title = {Development of Modular-Based Large Size Humanoid Robots},
  author = {Kuo, C.-H. and Chen, C.-C. and Siao, J.-W. and Chen, C.-T.},
  date = {2008},
  journaltitle = {Journal of Harbin Institute of Technology (New Series)},
  volume = {15},
  pages = {190--194},
  abstract = {The humanoid robot is a fast growing research field. Humanoid robots are interdisciplinary studies of engineering related techniques such as mechanical design, electrical driving, and soft-computing based intelligent sensing, reasoning and control. Currently, developments of humanoid robots are focusing on small size humanoid robots. Due to challenges of high cost and advanced technical concerns, the building of large size humanoid robots (LSHR) is not popular, especially in Taiwan. In general, the small size humanoid robot uses the RC servo to construct the joints. Such control architectures are simple, and they are easy to plan and to synchronize all joint motors. Contrarily, constructions and controls of LSHR are complicated. Because there existed no popular RC servos for the LSHR, the LSHR builders have to deal with very detailed mechanical and control interfaces of a LSHR with around 20 degrees of control freedoms. To reduce the cost, time and efforts of constructing LSHR, this paper proposed a modular-based approach to construct humanoid robotic joint modules (HRJM). The proposed joint modules are constructed based on uniform mechanical interface when the same torque is surveyed. In addition, the position servo controller is also developed to control the joint angles of the LSHR. In this manner, the proposed HRJM behaves similar roles with the RC servo, while the HRJM provides larger torques and higher control performance. In addition to the development of the HRJM, a multiple-joint synchronization controller is also developed to coordinate the motion patterns of individual HRJM. Furthermore, a PC based gait training program is also developed to train various motions. Finally, a 19 DOF LSHR with 175 cm in height and 70 kg in weight (excluding batteries) was built in laboratory based on the proposed architecture, named DCA-LSHR-V1. In addition to the implementations of the robot body and control system, this paper also demonstrates the first trial of walking.},
  issue = {SUPPL. 2}
}

@article{kuoDevelopmentModularbasedLarge2008a,
  title = {Development of Modular-Based Large Size Humanoid Robots},
  author = {Kuo, C.-H. and Chen, C.-C. and Siao, J.-W. and Chen, C.-T.},
  date = {2008},
  journaltitle = {Journal of Harbin Institute of Technology (New Series)},
  volume = {15},
  pages = {190--194},
  abstract = {The humanoid robot is a fast growing research field. Humanoid robots are interdisciplinary studies of engineering related techniques such as mechanical design, electrical driving, and soft-computing based intelligent sensing, reasoning and control. Currently, developments of humanoid robots are focusing on small size humanoid robots. Due to challenges of high cost and advanced technical concerns, the building of large size humanoid robots (LSHR) is not popular, especially in Taiwan. In general, the small size humanoid robot uses the RC servo to construct the joints. Such control architectures are simple, and they are easy to plan and to synchronize all joint motors. Contrarily, constructions and controls of LSHR are complicated. Because there existed no popular RC servos for the LSHR, the LSHR builders have to deal with very detailed mechanical and control interfaces of a LSHR with around 20 degrees of control freedoms. To reduce the cost, time and efforts of constructing LSHR, this paper proposed a modular-based approach to construct humanoid robotic joint modules (HRJM). The proposed joint modules are constructed based on uniform mechanical interface when the same torque is surveyed. In addition, the position servo controller is also developed to control the joint angles of the LSHR. In this manner, the proposed HRJM behaves similar roles with the RC servo, while the HRJM provides larger torques and higher control performance. In addition to the development of the HRJM, a multiple-joint synchronization controller is also developed to coordinate the motion patterns of individual HRJM. Furthermore, a PC based gait training program is also developed to train various motions. Finally, a 19 DOF LSHR with 175 cm in height and 70 kg in weight (excluding batteries) was built in laboratory based on the proposed architecture, named DCA-LSHR-V1. In addition to the implementations of the robot body and control system, this paper also demonstrates the first trial of walking.},
  issue = {SUPPL. 2}
}

@article{kwonPlanningProactiveBehaviors2014,
  title = {Planning of Proactive Behaviors for Human-Robot Cooperative Tasks under Uncertainty},
  author = {Kwon, W. Y. and Suh, I. H.},
  date = {2014},
  journaltitle = {Knowledge-Based Systems},
  volume = {72},
  pages = {81--95},
  doi = {10.1016/j.knosys.2014.08.021},
  abstract = {For seamless human-robot cooperation, a robot may need to take several steps proactively to minimize unnecessary delays between the human's intention and the robot's corresponding reactions. By predicting exogenous events from human intention and generating proactive plans based on the predicted events, a robot can reduce delays and significantly improve interaction. In this paper, we propose a decision-theoretic proactive planning framework that selects best proactive actions and the best times for those actions as a means to improving human-robot interactions. To this end, we developed a composite node temporal Bayesian network as an extension to handle both the nature of an event and its time of occurrence within a single framework. We also developed a composite node temporal influence diagram that combines a composite node temporal Bayesian network with a limited memory influence diagram to solve proactive planning problems. Experimental results obtained using a robot assistant in a manual assembly task demonstrate the effectiveness of our proposed framework.}
}

@article{kwonPlanningProactiveBehaviors2014a,
  title = {Planning of Proactive Behaviors for Human-Robot Cooperative Tasks under Uncertainty},
  author = {Kwon, W.Y. and Suh, I.H.},
  date = {2014},
  journaltitle = {Knowledge-Based Systems},
  volume = {72},
  pages = {81--95},
  doi = {10.1016/j.knosys.2014.08.021},
  abstract = {For seamless human-robot cooperation, a robot may need to take several steps proactively to minimize unnecessary delays between the human's intention and the robot's corresponding reactions. By predicting exogenous events from human intention and generating proactive plans based on the predicted events, a robot can reduce delays and significantly improve interaction. In this paper, we propose a decision-theoretic proactive planning framework that selects best proactive actions and the best times for those actions as a means to improving human-robot interactions. To this end, we developed a composite node temporal Bayesian network as an extension to handle both the nature of an event and its time of occurrence within a single framework. We also developed a composite node temporal influence diagram that combines a composite node temporal Bayesian network with a limited memory influence diagram to solve proactive planning problems. Experimental results obtained using a robot assistant in a manual assembly task demonstrate the effectiveness of our proposed framework.}
}

@article{laboDesignDiagridExoskeletons2020,
  title = {Design of Diagrid Exoskeletons for the Retrofit of Existing {{RC}} Buildings},
  author = {Labò, S. and Passoni, C. and Marini, A. and Belleri, A.},
  date = {2020},
  journaltitle = {Engineering Structures},
  volume = {220},
  doi = {10.1016/j.engstruct.2020.110899},
  abstract = {The pursuit of a sustainable society requires an extensive intervention on the existing buildings, which are responsible for the major share of greenhouse gas (GHG) emissions. In addition, such constructions have exhausted their nominal structural service life and are vulnerable to seismic hazard. In such a scenario, new integrated retrofit techniques have been proposed to foster the holistic and sustainable renovation of the European obsolete building stock, thereby boosting the current renovation rate. In this paper, diagrids are proposed as structural exoskeletons for the renovation of existing reinforced concrete (RC) buildings. The diagrid system is an inclined structural grid withstanding both vertical and horizontal loads to which a building is subjected. Such a system was initially proposed and is usually adopted in tall new buildings with the aim of creating structures with strong architectural identity, without vertical columns. Diagrids are suitable solutions for the integrated renovation (energy, architecture and structure) of existing buildings, and they may be applied from outside to avoid the occupants’ relocation. They may be assembled in different steps over an extended period of time by adopting an incremental rehabilitation strategy, thereby increasing the economic sustainability of the interventions; finally, they may be designed in full compliance with the principles of Life Cycle Thinking. In this paper, two methods for the design of elastic diagrids as retrofit intervention are proposed. The first method is an analytical design method which can be regarded as the extension of previous studies on diagrid systems for tall new buildings. The second method entails the definition of design spectra from which both stiffness and strength of the diagrid exoskeleton can be obtained. The latter is obtained from sensitivity analyses carried out on a simplified SDOF system, and it stems as the extension of existing procedures for the design of bracing systems. Both methods are then applied for the design of the structural retrofit of a RC building typical of the post-WWII European building stock. Theoretical results have been compared with results obtained with nonlinear time history analyses, showing the effectiveness of the proposed design methods.}
}

@article{laboDesignDiagridExoskeletons2020a,
  title = {Design of Diagrid Exoskeletons for the Retrofit of Existing {{RC}} Buildings},
  author = {Labò, S. and Passoni, C. and Marini, A. and Belleri, A.},
  date = {2020},
  journaltitle = {Engineering Structures},
  volume = {220},
  doi = {10.1016/j.engstruct.2020.110899},
  abstract = {The pursuit of a sustainable society requires an extensive intervention on the existing buildings, which are responsible for the major share of greenhouse gas (GHG) emissions. In addition, such constructions have exhausted their nominal structural service life and are vulnerable to seismic hazard. In such a scenario, new integrated retrofit techniques have been proposed to foster the holistic and sustainable renovation of the European obsolete building stock, thereby boosting the current renovation rate. In this paper, diagrids are proposed as structural exoskeletons for the renovation of existing reinforced concrete (RC) buildings. The diagrid system is an inclined structural grid withstanding both vertical and horizontal loads to which a building is subjected. Such a system was initially proposed and is usually adopted in tall new buildings with the aim of creating structures with strong architectural identity, without vertical columns. Diagrids are suitable solutions for the integrated renovation (energy, architecture and structure) of existing buildings, and they may be applied from outside to avoid the occupants’ relocation. They may be assembled in different steps over an extended period of time by adopting an incremental rehabilitation strategy, thereby increasing the economic sustainability of the interventions; finally, they may be designed in full compliance with the principles of Life Cycle Thinking. In this paper, two methods for the design of elastic diagrids as retrofit intervention are proposed. The first method is an analytical design method which can be regarded as the extension of previous studies on diagrid systems for tall new buildings. The second method entails the definition of design spectra from which both stiffness and strength of the diagrid exoskeleton can be obtained. The latter is obtained from sensitivity analyses carried out on a simplified SDOF system, and it stems as the extension of existing procedures for the design of bracing systems. Both methods are then applied for the design of the structural retrofit of a RC building typical of the post-WWII European building stock. Theoretical results have been compared with results obtained with nonlinear time history analyses, showing the effectiveness of the proposed design methods.}
}

@article{laceyApplicationRoboticsMobility1998,
  title = {The Application of Robotics to a Mobility Aid for the Elderly Blind},
  author = {Lacey, G. and Dawson-Howe, K.M.},
  date = {1998},
  journaltitle = {Robotics and Autonomous Systems},
  volume = {23},
  number = {4},
  pages = {245--252},
  doi = {10.1016/S0921-8890(98)00011-6},
  abstract = {In this paper we describe a novel application of mobile robot technology to the construction of a mobility for the frail blind. The robot mobility aid discussed in this paper physically supports the person walking behind it and provides obstacle avoidance to ensure safer travel. As in all Assistive Technology projects, a clear understanding of the user's needs is vital and we summarise the main user requirements for our device. We then describe the mechanical design, the user interface, the software and hardware architectures of our robot. We describe the results of evaluations carried out by both mobility experts and users and finally we outline our plans for further development. © 1998 Elsevier Science B.V. All rights reserved.}
}

@article{laceyApplicationRoboticsMobility1998a,
  title = {The Application of Robotics to a Mobility Aid for the Elderly Blind},
  author = {Lacey, G. and Dawson-Howe, K.M.},
  date = {1998},
  journaltitle = {Robotics and Autonomous Systems},
  volume = {23},
  number = {4},
  pages = {245--252},
  doi = {10.1016/S0921-8890(98)00011-6},
  abstract = {In this paper we describe a novel application of mobile robot technology to the construction of a mobility for the frail blind. The robot mobility aid discussed in this paper physically supports the person walking behind it and provides obstacle avoidance to ensure safer travel. As in all Assistive Technology projects, a clear understanding of the user's needs is vital and we summarise the main user requirements for our device. We then describe the mechanical design, the user interface, the software and hardware architectures of our robot. We describe the results of evaluations carried out by both mobility experts and users and finally we outline our plans for further development. © 1998 Elsevier Science B.V. All rights reserved.}
}

@inproceedings{lamartinaStructuralPreanalysisImplementing2019,
  title = {Structural Pre-Analysis through Implementing Revit Structures and Robot to Develop and Compare Engineered Timber Structural Families},
  booktitle = {{{WIT Transactions}} on the {{Built Environment}}},
  author = {Lamartina, L. and Sa, J.},
  date = {2019},
  volume = {192},
  pages = {229--243},
  doi = {10.2495/BIM190201},
  abstract = {The structural pre-analysis is a teaching technique based on the implementation of BIM for structural design and finds its theoretical didactical background on the theory of didactical situations and designs intended learning outcomes. It provides a problem-based learning approach and wish to shape future professional handling techniques in constant development. The implementation is focused on two main aspects combined together: Structural performance (sizing for load bearing capacity) and the sustainability of engineered timber structures. The aim is to test the effect of structural loads and verify both performance compliance (overall dimension and ratio of a load bearing section) and sustainability (CO2 footprint in relation of the material involved in the lean processes) combining BIM tools and fine elements analysis software. The system implements Autodesk® Revit® Structure with the bidirectional interoperability with Autodesk® Robot™ Structural Analysis Professional to develop structure generated by modified, built-in families according to manufacturer’s mechanical properties. Models can be compared within the analytical results of structural performance and CO2 footprint. The competence of the students can be enhanced in a way to make them able to develop a 3D virtual structural model from a low to high level of development, to choose correctly pre-dimensioned elements from manufacturer’s catalogs or, eventually, to dimension realistically a load bearing engineered timber element, always with an eye on sustainability. This teaching procedure provides a second final set of student’s outcomes: Shop drawings, generated and drawn with a high level of accuracy. This is in conjunction with problem-owners from the international construction and building industry. In this way, the number of iterations during the design phases can be minimized and the role of an architectural technologist can be more interlocked with both structural engineering and production procedures.},
  isbn = {978-1-78466-361-2}
}

@inproceedings{lamartinaStructuralPreanalysisImplementing2019a,
  title = {Structural Pre-Analysis through Implementing Revit Structures and Robot to Develop and Compare Engineered Timber Structural Families},
  booktitle = {{{WIT Transactions}} on the {{Built Environment}}},
  author = {Lamartina, L. and Sa, J.},
  date = {2019},
  volume = {192},
  pages = {229--243},
  doi = {10.2495/BIM190201},
  abstract = {The structural pre-analysis is a teaching technique based on the implementation of BIM for structural design and finds its theoretical didactical background on the theory of didactical situations and designs intended learning outcomes. It provides a problem-based learning approach and wish to shape future professional handling techniques in constant development. The implementation is focused on two main aspects combined together: Structural performance (sizing for load bearing capacity) and the sustainability of engineered timber structures. The aim is to test the effect of structural loads and verify both performance compliance (overall dimension and ratio of a load bearing section) and sustainability (CO2 footprint in relation of the material involved in the lean processes) combining BIM tools and fine elements analysis software. The system implements Autodesk® Revit® Structure with the bidirectional interoperability with Autodesk® Robot™ Structural Analysis Professional to develop structure generated by modified, built-in families according to manufacturer’s mechanical properties. Models can be compared within the analytical results of structural performance and CO2 footprint. The competence of the students can be enhanced in a way to make them able to develop a 3D virtual structural model from a low to high level of development, to choose correctly pre-dimensioned elements from manufacturer’s catalogs or, eventually, to dimension realistically a load bearing engineered timber element, always with an eye on sustainability. This teaching procedure provides a second final set of student’s outcomes: Shop drawings, generated and drawn with a high level of accuracy. This is in conjunction with problem-owners from the international construction and building industry. In this way, the number of iterations during the design phases can be minimized and the role of an architectural technologist can be more interlocked with both structural engineering and production procedures.},
  isbn = {978-1-78466-361-2}
}

@article{langBioinformaticsAnalysisMountain2021,
  title = {Bioinformatics Analysis of Mountain Plant Characteristics and Ginsenoside Glycosyltransferase Based on Image Recognition},
  author = {Lang, C. and Sui, X.},
  date = {2021},
  journaltitle = {Arabian Journal of Geosciences},
  volume = {14},
  number = {17},
  doi = {10.1007/s12517-021-08174-0},
  abstract = {With the rapid development of software and hardware technology and the advent of the era of big data, deep learning has made breakthroughs in more and more fields. Convolutional neural network is based on the biological vision system, combined with the characteristics of the image itself, and discusses the construction method, optimization algorithm, and classification recognition performance of the convolutional neural network model for image classification and recognition problems. Through image recognition and other technologies, it is understood that vegetation is the most important part of the ecosystem and is susceptible to human interference. Moreover, the decrease in species diversity of mountain plants is usually the most obvious manifestation of population degradation, and it also affects the changes in the ecological environment of mountain plants, which is the most important factor for changes in species diversity. Therefore, this article uses a typical sampling method to collect and study cultural heritage, plant species composition, and habitat factors in mountainous areas, and analyze their correlation. In recent years, with the development of high-throughput sequencing technology, a large number of genome and transcriptome sequences of medicinal plants have been analyzed, and more and more UGT genes have been discovered. Among them, glycosyltransferase is a key enzyme in the biosynthesis of ginsenosides, which can catalyze the transfer of sugar groups from donor molecules to acceptor molecules, thereby forming various glycoside compounds with biological activity. Common methods for detecting UGT genes include differential expression analysis, homologous sequence screening, gene cluster screening, and chemical proteomics screening. Therefore, this article uses image recognition technology to study the characteristics of mountain plants and the biological information of ginsenoside glycosyltransferase.}
}

@article{langBioinformaticsAnalysisMountain2021a,
  title = {Bioinformatics Analysis of Mountain Plant Characteristics and Ginsenoside Glycosyltransferase Based on Image Recognition},
  author = {Lang, C. and Sui, X.},
  date = {2021},
  journaltitle = {Arabian Journal of Geosciences},
  volume = {14},
  number = {17},
  doi = {10.1007/s12517-021-08174-0},
  abstract = {With the rapid development of software and hardware technology and the advent of the era of big data, deep learning has made breakthroughs in more and more fields. Convolutional neural network is based on the biological vision system, combined with the characteristics of the image itself, and discusses the construction method, optimization algorithm, and classification recognition performance of the convolutional neural network model for image classification and recognition problems. Through image recognition and other technologies, it is understood that vegetation is the most important part of the ecosystem and is susceptible to human interference. Moreover, the decrease in species diversity of mountain plants is usually the most obvious manifestation of population degradation, and it also affects the changes in the ecological environment of mountain plants, which is the most important factor for changes in species diversity. Therefore, this article uses a typical sampling method to collect and study cultural heritage, plant species composition, and habitat factors in mountainous areas, and analyze their correlation. In recent years, with the development of high-throughput sequencing technology, a large number of genome and transcriptome sequences of medicinal plants have been analyzed, and more and more UGT genes have been discovered. Among them, glycosyltransferase is a key enzyme in the biosynthesis of ginsenosides, which can catalyze the transfer of sugar groups from donor molecules to acceptor molecules, thereby forming various glycoside compounds with biological activity. Common methods for detecting UGT genes include differential expression analysis, homologous sequence screening, gene cluster screening, and chemical proteomics screening. Therefore, this article uses image recognition technology to study the characteristics of mountain plants and the biological information of ginsenoside glycosyltransferase.}
}

@report{laptevSpacetimeInterestPoints2003,
  title = {Space-Time {{Interest Points}}},
  author = {Laptev, Ivan and Lindeberg, Tony},
  date = {2003},
  abstract = {Local image features or interest points provide compact and abstract representations of patterns in an image. In this paper, we propose to extend the notion of spatial interest points into the spatio-temporal domain and show how the resulting features often reflect interesting events that can be used for a compact representation of video data as well as for its interpretation. To detect spatio-temporal events, we build on the idea of the Harris and F ¨ orstner interest point operators and detect local structures in space-time where the image values have significant local variations in both space and time. We then estimate the spatio-temporal extents of the detected events and compute their scale-invariant spatio-temporal descrip-tors. Using such descriptors, we classify events and construct video representation in terms of labeled space-time points. For the problem of human motion analysis, we illustrate how the proposed method allows for detection of walking people in scenes with occlusions and dynamic backgrounds .}
}

@report{laptevSpacetimeInterestPoints2003a,
  title = {Space-Time {{Interest Points}}},
  author = {Laptev, Ivan and Lindeberg, Tony},
  date = {2003},
  abstract = {Local image features or interest points provide compact and abstract representations of patterns in an image. In this paper, we propose to extend the notion of spatial interest points into the spatio-temporal domain and show how the resulting features often reflect interesting events that can be used for a compact representation of video data as well as for its interpretation. To detect spatio-temporal events, we build on the idea of the Harris and F ¨ orstner interest point operators and detect local structures in space-time where the image values have significant local variations in both space and time. We then estimate the spatio-temporal extents of the detected events and compute their scale-invariant spatio-temporal descrip-tors. Using such descriptors, we classify events and construct video representation in terms of labeled space-time points. For the problem of human motion analysis, we illustrate how the proposed method allows for detection of walking people in scenes with occlusions and dynamic backgrounds .},
  file = {C:\Users\leemar\Zotero\storage\7IKQWZ6J\2003_iccv_laptev.pdf}
}

@article{larsenSurveyingDigitalWorkflow2011,
  title = {Surveying and Digital Workflow in Energy Performance Retrofit Projects Using Prefabricated Elements},
  author = {Larsen, K.E. and Lattke, F. and Ott, S. and Winter, S.},
  date = {2011},
  journaltitle = {Automation in Construction},
  volume = {20},
  number = {8},
  pages = {999--1011},
  doi = {10.1016/j.autcon.2011.04.001},
  abstract = {Due to the need for improving the energy efficiency of existing buildings, various methods for energy retrofitting are being developed. One such initiative is the TES Energy Façade project, a joint European academia and industry project under the umbrella of the WoodWisdom Net research platform. The project has developed a systematic approach for using prefabricated timber-framed elements that can be assembled in front of an existing façade. The TES approach requires a detailed and precise documentation of the as-built/as-maintained conditions of the existing façade. This paper discusses the approach for the surveying and documentation of a building's existing state and the need to establish a continuous digital chain that encompasses the various project stages from the survey to the site assembly of the elements. Technologies such as 3D laser scanning and BIM are efficient tools in the process but are not yet sufficiently developed to handle all of the challenges in renewal and retrofit projects. © 2011 Elsevier B.V. All rights reserved.}
}

@article{larsenSurveyingDigitalWorkflow2011a,
  title = {Surveying and Digital Workflow in Energy Performance Retrofit Projects Using Prefabricated Elements},
  author = {Larsen, K.E. and Lattke, F. and Ott, S. and Winter, S.},
  date = {2011},
  journaltitle = {Automation in Construction},
  volume = {20},
  number = {8},
  pages = {999--1011},
  doi = {10.1016/j.autcon.2011.04.001},
  abstract = {Due to the need for improving the energy efficiency of existing buildings, various methods for energy retrofitting are being developed. One such initiative is the TES Energy Façade project, a joint European academia and industry project under the umbrella of the WoodWisdom Net research platform. The project has developed a systematic approach for using prefabricated timber-framed elements that can be assembled in front of an existing façade. The TES approach requires a detailed and precise documentation of the as-built/as-maintained conditions of the existing façade. This paper discusses the approach for the surveying and documentation of a building's existing state and the need to establish a continuous digital chain that encompasses the various project stages from the survey to the site assembly of the elements. Technologies such as 3D laser scanning and BIM are efficient tools in the process but are not yet sufficiently developed to handle all of the challenges in renewal and retrofit projects. © 2011 Elsevier B.V. All rights reserved.}
}

@article{lassenEnhancingLearningOutcomes2018,
  title = {Enhancing Learning Outcomes by Introducing Bim in Civil Engineering Studies – Experiences from a University College in {{Norway}}},
  author = {Lassen, A.K. and Hjelseth, E. and Tollnes, T.},
  date = {2018},
  journaltitle = {International Journal of Sustainable Development and Planning},
  volume = {13},
  number = {1},
  pages = {62--72},
  doi = {10.2495/SDP-V13-N1-62-72},
  abstract = {It is a challenge to introduce building information modeling (BIM), as demanded from the industry, in an already packed curriculum for higher engineering education. There is therefore a need for alternative ways to include BIM in the curriculum, while at the same time strengthening – rather than supplanting – the traditional engineering subjects. The purpose of this study is increased understanding of how BIM can be integrated as part of an engineering curriculum in an efficient way. The study is based on an evaluation of the ‘Introduction to Building Professions’ course given to all civil engineering students in their first semester of the bachelor’s degree programme at Oslo and Akershus University College of Applied Sciences in Norway. Autodesk Revit was used as BIM-based software in the designing of a two-family timber dwelling, a compulsory group project in the course. Data for this paper are collected from multiple sources: a net-based questionnaire, course evaluations, interviews with students and teachers, and assessment of students’ project work. Selected factors in Active Learning theories are used as a theoretical lens for analyzing the data in a systematic way. BIM enabled a design and ‘virtual construction’ process where students held professional roles in a design team, and contributed with their expertise toward a holistic solution. The students reported that the hands-on modeling with BIM-based software led to increased understanding of design parameters, load distribution, and construction detailing, as well as information requirements for collaboration within a design team. We conclude that BIM in higher engineering education can support understanding of professional content, which is the primary learning outcome. Software proficiency is seen as a necessary yet subordinate skill in higher education and should not be graded as a separate task. Use of BIM-based software should, however, be integrated to enhance problem understanding and relevant information processing. This integrated approach can lead to a more widespread implementation of BIM to support active learning in higher education.},
  file = {C:\Users\leemar\Zotero\storage\4NGEHL5U\Enhancing-learning-outcomes-by-introducing-bim-in-civil-engineering-studies--experiences-from-a-university-college-in-NorwayInternational-Journal-of-Sustainable-Development-and-Planning.pdf}
}

@article{lassenEnhancingLearningOutcomes2018a,
  title = {Enhancing Learning Outcomes by Introducing Bim in Civil Engineering Studies – Experiences from a University College in {{Norway}}},
  author = {Lassen, A.K. and Hjelseth, E. and Tollnes, T.},
  date = {2018},
  journaltitle = {International Journal of Sustainable Development and Planning},
  volume = {13},
  number = {1},
  pages = {62--72},
  doi = {10.2495/SDP-V13-N1-62-72},
  abstract = {It is a challenge to introduce building information modeling (BIM), as demanded from the industry, in an already packed curriculum for higher engineering education. There is therefore a need for alternative ways to include BIM in the curriculum, while at the same time strengthening – rather than supplanting – the traditional engineering subjects. The purpose of this study is increased understanding of how BIM can be integrated as part of an engineering curriculum in an efficient way. The study is based on an evaluation of the ‘Introduction to Building Professions’ course given to all civil engineering students in their first semester of the bachelor’s degree programme at Oslo and Akershus University College of Applied Sciences in Norway. Autodesk Revit was used as BIM-based software in the designing of a two-family timber dwelling, a compulsory group project in the course. Data for this paper are collected from multiple sources: a net-based questionnaire, course evaluations, interviews with students and teachers, and assessment of students’ project work. Selected factors in Active Learning theories are used as a theoretical lens for analyzing the data in a systematic way. BIM enabled a design and ‘virtual construction’ process where students held professional roles in a design team, and contributed with their expertise toward a holistic solution. The students reported that the hands-on modeling with BIM-based software led to increased understanding of design parameters, load distribution, and construction detailing, as well as information requirements for collaboration within a design team. We conclude that BIM in higher engineering education can support understanding of professional content, which is the primary learning outcome. Software proficiency is seen as a necessary yet subordinate skill in higher education and should not be graded as a separate task. Use of BIM-based software should, however, be integrated to enhance problem understanding and relevant information processing. This integrated approach can lead to a more widespread implementation of BIM to support active learning in higher education.},
  file = {C:\Users\leemar\Zotero\storage\46MGT4X7\Enhancing-learning-outcomes-by-introducing-bim-in-civil-engineering-studies--experiences-from-a-university-college-in-NorwayInternational-Journal-of-Sustainable-Development-and-Planning.pdf}
}

@inproceedings{lattkeLeanWOODAdvancingPerformance2016,
  title = {{{LeanWOOD}} - {{Advancing}} Performance of Design Teams in Timber Construction},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Lattke, F. and Hernandez-Maetschl, S.},
  date = {2016},
  abstract = {LeanWOOD tackles process innovation at the interface of design and production planning. Against the background of a growing complexity of timber building construction the paper discusses main constraints and potentials influencing the performance of design teams and demonstrates a strategy to streamline planning processes and thus increases the effect of collaboration of architects, engineers, special planners and timber production planners and manufacturers. leanWOOD presents a strategy for the documentation of the decision-making process in execution planning and represents a way to map plan format and specification of contents according to the hierarchy of building elements and components. The study aims at a checklist to support the planning process and management of expert planer teams. An optimized planning process in timber construction according to the recommendations of leanWOOD will significantly improve team performance and is an important contribution to the current development of BIM processes. Full collaboration through sharing information at the beginning of a project will most likely deliver the expected outcome: fast, efficient, effective, and cost bound buildings.},
  isbn = {978-3-903039-00-1}
}

@inproceedings{lattkeLeanWOODAdvancingPerformance2016a,
  title = {{{LeanWOOD}} - {{Advancing}} Performance of Design Teams in Timber Construction},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Lattke, F. and Hernandez-Maetschl, S.},
  date = {2016},
  abstract = {LeanWOOD tackles process innovation at the interface of design and production planning. Against the background of a growing complexity of timber building construction the paper discusses main constraints and potentials influencing the performance of design teams and demonstrates a strategy to streamline planning processes and thus increases the effect of collaboration of architects, engineers, special planners and timber production planners and manufacturers. leanWOOD presents a strategy for the documentation of the decision-making process in execution planning and represents a way to map plan format and specification of contents according to the hierarchy of building elements and components. The study aims at a checklist to support the planning process and management of expert planer teams. An optimized planning process in timber construction according to the recommendations of leanWOOD will significantly improve team performance and is an important contribution to the current development of BIM processes. Full collaboration through sharing information at the beginning of a project will most likely deliver the expected outcome: fast, efficient, effective, and cost bound buildings.},
  isbn = {978-3-903039-00-1}
}

@article{leeDMModularSolution1996,
  title = {({{DM}}){\textsuperscript{2}}: {{A}} Modular Solution for Robotic Lunar Missions},
  author = {Lee, C. and Xu, Y.},
  date = {1996},
  journaltitle = {Space Technology},
  volume = {16},
  number = {1},
  pages = {49--58},
  doi = {10.1016/0892-9270(95)00052-6},
  abstract = {This paper describes the Dual-Use Mobile Detachable Manipulator, (DM)2, which is a mobile manipulator designed to operate in a lunar station scenario. (DM)2 is designed to perform two very different kinds of tasks: exploration on the lunar terrain, and maintenance work in lunar manufacturing plants. Both tasks are essential during the early construction of a lunar station. In order to be able to competently perform both tasks, (DM)2 embodies a modular hardware design - namely a mobile base, and a detachable, symmetric manipulator arm with exchangeable grippers at each end. (DM)2 can work with a number of possibly different arms, each of which may use several kinds of specialized detachable end-effectors. This flexible hardware configuration enables the robot to be useful for many different kinds of operations on a lunar base. In turn, this flexibility of hardware configuration necessitates a software control architecture that is equally flexible - allowing for on-the-fly reconfiguration, and independence of high-level functionality from the details of the current hardware configuration. (DM)2 is designed to perform its tasks either autonomously based on a task model and realtime vision system, or under the supervision of a human operator through a custom realtime teleoperation interface. Copyright © 1996 Elsevier Science Ltd.}
}

@article{leeDMModularSolution1996a,
  title = {({{DM}}){\textsuperscript{2}}: {{A}} Modular Solution for Robotic Lunar Missions},
  author = {Lee, C. and Xu, Y.},
  date = {1996},
  journaltitle = {Space Technology},
  volume = {16},
  number = {1},
  pages = {49--58},
  doi = {10.1016/0892-9270(95)00052-6},
  abstract = {This paper describes the Dual-Use Mobile Detachable Manipulator, (DM)2, which is a mobile manipulator designed to operate in a lunar station scenario. (DM)2 is designed to perform two very different kinds of tasks: exploration on the lunar terrain, and maintenance work in lunar manufacturing plants. Both tasks are essential during the early construction of a lunar station. In order to be able to competently perform both tasks, (DM)2 embodies a modular hardware design - namely a mobile base, and a detachable, symmetric manipulator arm with exchangeable grippers at each end. (DM)2 can work with a number of possibly different arms, each of which may use several kinds of specialized detachable end-effectors. This flexible hardware configuration enables the robot to be useful for many different kinds of operations on a lunar base. In turn, this flexibility of hardware configuration necessitates a software control architecture that is equally flexible - allowing for on-the-fly reconfiguration, and independence of high-level functionality from the details of the current hardware configuration. (DM)2 is designed to perform its tasks either autonomously based on a task model and realtime vision system, or under the supervision of a human operator through a custom realtime teleoperation interface. Copyright © 1996 Elsevier Science Ltd.}
}

@article{leeEvidencedrivenSoundDetection2020,
  title = {Evidence-Driven Sound Detection for Prenotification and Identification of Construction Safety Hazards and Accidents},
  author = {Lee, Y.-C. and Shariatfar, M. and Rashidi, A. and Lee, H. W.},
  date = {2020},
  journaltitle = {Automation in Construction},
  volume = {113},
  doi = {10.1016/j.autcon.2020.103127},
  abstract = {As the construction industry experiences a high rate of casualties and significant economic loss associated with accidents, safety has always been a primary concern. In response, several studies have attempted to develop new approaches and state-of-the-art technology for conducting autonomous safety surveillance of construction work zones such as vision-based monitoring. The current and proposed methods including human inspection, however, are limited to consistent and real-time monitoring and rapid event recognition of construction safety issues. In addition, the health and safety risks inherent in construction projects make it challenging for construction workers to be aware of possible safety risks and hazards according to daily planned work activities. To address the urgent demand of the industry to improve worker safety, this study involves the development of an audio-based event detection system to provide daily safety issues to laborers and through the rapid identification of construction accidents. As an evidence-driven approach, the proposed framework incorporates the occupational injury and illness manual data, consisting of historical construction accident data classified by types of sources and events, into an audio-based safety event detection framework. This evidence-driven framework integrated with a daily project schedule can automatically provide construction workers with prenotifications regarding safety hazards at a pertinent work zone as well as consistently contribute to enhanced construction safety monitoring by audio-based event detection. By using a machine learning algorithm, the framework can clearly categorize the narrowed-down sound training data according to a daily project schedule and dynamically restrict sound classification types in advance. The proposed framework is expected to contribute to an emerging knowledge base for integrating an automated safety surveillance system into occupational accident data, significantly improving the accuracy of audio-based event detection.}
}

@article{leeEvidencedrivenSoundDetection2020a,
  title = {Evidence-Driven Sound Detection for Prenotification and Identification of Construction Safety Hazards and Accidents},
  author = {Lee, Y.-C. and Shariatfar, M. and Rashidi, A. and Lee, H.W.},
  date = {2020},
  journaltitle = {Automation in Construction},
  volume = {113},
  doi = {10.1016/j.autcon.2020.103127},
  abstract = {As the construction industry experiences a high rate of casualties and significant economic loss associated with accidents, safety has always been a primary concern. In response, several studies have attempted to develop new approaches and state-of-the-art technology for conducting autonomous safety surveillance of construction work zones such as vision-based monitoring. The current and proposed methods including human inspection, however, are limited to consistent and real-time monitoring and rapid event recognition of construction safety issues. In addition, the health and safety risks inherent in construction projects make it challenging for construction workers to be aware of possible safety risks and hazards according to daily planned work activities. To address the urgent demand of the industry to improve worker safety, this study involves the development of an audio-based event detection system to provide daily safety issues to laborers and through the rapid identification of construction accidents. As an evidence-driven approach, the proposed framework incorporates the occupational injury and illness manual data, consisting of historical construction accident data classified by types of sources and events, into an audio-based safety event detection framework. This evidence-driven framework integrated with a daily project schedule can automatically provide construction workers with prenotifications regarding safety hazards at a pertinent work zone as well as consistently contribute to enhanced construction safety monitoring by audio-based event detection. By using a machine learning algorithm, the framework can clearly categorize the narrowed-down sound training data according to a daily project schedule and dynamically restrict sound classification types in advance. The proposed framework is expected to contribute to an emerging knowledge base for integrating an automated safety surveillance system into occupational accident data, significantly improving the accuracy of audio-based event detection.}
}

@article{leeSpecifyingParametricBuilding2006,
  title = {Specifying Parametric Building Object Behavior ({{BOB}}) for a Building Information Modeling System},
  author = {Lee, Ghang and Sacks, Rafael and Eastman, Charles M.},
  date = {2006},
  journaltitle = {Automation in Construction},
  volume = {15},
  number = {6},
  pages = {758--776},
  issn = {09265805},
  doi = {10.1016/j.autcon.2005.09.009},
  abstract = {Parametric modeling has been proposed as an effective means to embed domain expertise in models of buildings. As information technology becomes more powerful in terms of the ability to manipulate large parametric models, the potential grows to build increasingly sophisticated functional systems for designing, modeling and fabricating buildings. Implementing more powerful systems implies greater functional specificity, which requires elicitation and capture of increasingly detailed and complex domain-specific semantics and knowledge. This paper explores the extent to which design and engineering knowledge can be practically embedded in production software for building information modeling (BIM). It focuses on a building object behavior (BOB) description notation and method, developed as a shorthand protocol for designing, validating and sharing the design intent of parametric objects. Examples are drawn from an advanced BIM system development project for precast concrete. © 2005 Elsevier B.V. All rights reserved.},
  keywords = {Building object behavior,Expert knowledge,Parametric modeling}
}

@article{leeSpecifyingParametricBuilding2006a,
  title = {Specifying Parametric Building Object Behavior ({{BOB}}) for a Building Information Modeling System},
  author = {Lee, Ghang and Sacks, Rafael and Eastman, Charles M.},
  date = {2006},
  journaltitle = {Automation in Construction},
  volume = {15},
  number = {6},
  pages = {758--776},
  issn = {09265805},
  doi = {10.1016/j.autcon.2005.09.009},
  abstract = {Parametric modeling has been proposed as an effective means to embed domain expertise in models of buildings. As information technology becomes more powerful in terms of the ability to manipulate large parametric models, the potential grows to build increasingly sophisticated functional systems for designing, modeling and fabricating buildings. Implementing more powerful systems implies greater functional specificity, which requires elicitation and capture of increasingly detailed and complex domain-specific semantics and knowledge. This paper explores the extent to which design and engineering knowledge can be practically embedded in production software for building information modeling (BIM). It focuses on a building object behavior (BOB) description notation and method, developed as a shorthand protocol for designing, validating and sharing the design intent of parametric objects. Examples are drawn from an advanced BIM system development project for precast concrete. © 2005 Elsevier B.V. All rights reserved.},
  keywords = {Building object behavior,Expert knowledge,Parametric modeling},
  file = {C:\Users\leemar\Zotero\storage\WWAXET8R\1-s2.0-S0926580505001445-main.pdf}
}

@book{legebyUrbanSegregationUrban2010,
  title = {Urban Segregation and Urban Form from Residential Segregation to Segregation in Public Space},
  author = {Legeby, Ann},
  date = {2010},
  publisher = {{Skolan för arkitektur och samhällsbyggnad, Kungliga Tekniska högskolan}},
  location = {{Stockholm}},
  isbn = {978-91-7415-730-7},
  langid = {english},
  annotation = {OCLC: 698343471},
  file = {C:\Users\leemar\Zotero\storage\L265ZR2Y\Legeby - 2010 - Urban segregation and urban form from residential .pdf}
}

@article{leicaSwitchedControlRobotHuman2015,
  title = {Switched {{Control}} to {{Robot-Human Bilateral Interaction}} for {{Guiding People}}},
  author = {Leica, P. and Toibero, J. M. and Roberti, F. and Carelli, R.},
  date = {2015},
  journaltitle = {Journal of Intelligent and Robotic Systems: Theory and Applications},
  volume = {77},
  number = {1},
  pages = {73--93},
  doi = {10.1007/s10846-014-0098-6},
  abstract = {This paper presents a switched control strategy to interpret and design a human-robot bilateral interaction when a human follows a non-holonomic mobile robot at a desired distance while the robot is already following a known path. Furthermore, it proposes and experimentally validates a model that mathematically describes the human behavior when performing the specific task of tracking a mobile robot. This model is useful for the purposes of the control system design and its associated stability analysis. A switched system is proposed to model the complete human-robot behavior. The switching strategy is based on the human-robot relative position and on the human intention to follow the robot. Control errors are defined in terms of human to robot and robot to path instantaneous distances. Stability analyses for the individual controllers, as well as for the complete switching system, are provided by considering Lyapunov theory. Real human-robot interaction experiments show the good performance of the proposed control strategy.}
}

@article{leicaSwitchedControlRobotHuman2015a,
  title = {Switched {{Control}} to {{Robot-Human Bilateral Interaction}} for {{Guiding People}}},
  author = {Leica, P. and Toibero, J.M. and Roberti, F. and Carelli, R.},
  date = {2015},
  journaltitle = {Journal of Intelligent and Robotic Systems: Theory and Applications},
  volume = {77},
  number = {1},
  pages = {73--93},
  doi = {10.1007/s10846-014-0098-6},
  abstract = {This paper presents a switched control strategy to interpret and design a human-robot bilateral interaction when a human follows a non-holonomic mobile robot at a desired distance while the robot is already following a known path. Furthermore, it proposes and experimentally validates a model that mathematically describes the human behavior when performing the specific task of tracking a mobile robot. This model is useful for the purposes of the control system design and its associated stability analysis. A switched system is proposed to model the complete human-robot behavior. The switching strategy is based on the human-robot relative position and on the human intention to follow the robot. Control errors are defined in terms of human to robot and robot to path instantaneous distances. Stability analyses for the individual controllers, as well as for the complete switching system, are provided by considering Lyapunov theory. Real human-robot interaction experiments show the good performance of the proposed control strategy.}
}

@inproceedings{Leite2012367,
  title = {Modelling Empathic Behaviour in a Robotic Game Companion for Children: {{An}} Ethnographic Study in Real-World Settings},
  author = {Leite, I. and Castellano, G. and Pereira, A. and Martinho, C. and Paiva, A.},
  date = {2012},
  series = {{{HRI}}'12 - {{Proceedings}} of the 7th {{Annual ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  pages = {367--374},
  doi = {10.1145/2157689.2157811}
}

@inproceedings{lennartssonFrameworkDigitalDevelopment2020,
  title = {Framework for {{Digital Development}} in {{Industrialized Housebuilding}}},
  booktitle = {Advances in {{Transdisciplinary Engineering}}},
  author = {Lennartsson, M. and Yitmen, I. and Movaffaghi, H. and Linderoth, H.},
  date = {2020},
  volume = {13},
  pages = {335--345},
  doi = {10.3233/ATDE200171},
  abstract = {Building Information Modelling (BIM) is claimed to transform the Architecture, Engineering and Construction (AEC) industry, whereas current research has argued that diffusion of BIM use proceeds at a slower rate than the optimistic predictions. Despite that potential of BIM is higher in industrialized housebuilding, the trade express similar characteristics as traditional construction both in terms of BIM sue but also organization of assets. The aim of this paper is to present a conceptual framework for digital development in industrialized timber housing. Data were gathered from eight industrialized housebuilding companies in a mixed approach with interviews, focus groups and a survey. The analysis presents the current use of BIM and digital tools and prioritized development areas within this domain. By adding a theoretical overview of current research for industrialized housebuilding with focus on platform strategies and digital development a framework is drawn. Problems with transfer in the interfaces between software were emphasized. Current research on developing a system for Product Lifecycle Management (PLM) in industrialized housebuilding indicate a path forward. A PLM system facilitates the development of digital developments such as digital twins and smart products, which possess the potentials to generate crucial feedback, which is crucial for the competitiveness and efficiency of industrialized housebuilding. Thus, for a trade with high levels of complexity, a move towards a fully functional PLM system might not only be desirable but decisive.},
  isbn = {978-1-61499-439-8},
  file = {C:\Users\leemar\Zotero\storage\B3FX2GMN\FrameworkforDigitalDevelopmentinIndustrializedHousebuilding.pdf}
}

@inproceedings{lennartssonFrameworkDigitalDevelopment2020a,
  title = {Framework for {{Digital Development}} in {{Industrialized Housebuilding}}},
  booktitle = {Advances in {{Transdisciplinary Engineering}}},
  author = {Lennartsson, M. and Yitmen, I. and Movaffaghi, H. and Linderoth, H.},
  date = {2020},
  volume = {13},
  pages = {335--345},
  doi = {10.3233/ATDE200171},
  abstract = {Building Information Modelling (BIM) is claimed to transform the Architecture, Engineering and Construction (AEC) industry, whereas current research has argued that diffusion of BIM use proceeds at a slower rate than the optimistic predictions. Despite that potential of BIM is higher in industrialized housebuilding, the trade express similar characteristics as traditional construction both in terms of BIM sue but also organization of assets. The aim of this paper is to present a conceptual framework for digital development in industrialized timber housing. Data were gathered from eight industrialized housebuilding companies in a mixed approach with interviews, focus groups and a survey. The analysis presents the current use of BIM and digital tools and prioritized development areas within this domain. By adding a theoretical overview of current research for industrialized housebuilding with focus on platform strategies and digital development a framework is drawn. Problems with transfer in the interfaces between software were emphasized. Current research on developing a system for Product Lifecycle Management (PLM) in industrialized housebuilding indicate a path forward. A PLM system facilitates the development of digital developments such as digital twins and smart products, which possess the potentials to generate crucial feedback, which is crucial for the competitiveness and efficiency of industrialized housebuilding. Thus, for a trade with high levels of complexity, a move towards a fully functional PLM system might not only be desirable but decisive.},
  isbn = {978-1-61499-439-8},
  file = {C:\Users\leemar\Zotero\storage\FINBLCQJ\FrameworkforDigitalDevelopmentinIndustrializedHousebuilding.pdf}
}

@inproceedings{lerouxInvestigatingInteractionBuilding2016,
  title = {Investigating the Interaction of Building Information Modelling and Lean Construction in the Timber Industry},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Le Roux, S. and Bannier, F. and Bossanne, E. and Stieglmeier, M.},
  date = {2016},
  abstract = {Building Information Modelling (BIM) is expanding very quickly in the construction industry and offers new opportunities to redefine and optimize the construction process. This paper collects insight from software developers, BIM users in the timber industry, architects and engineers, timber manufacturers, contractors and property developers, to collect an overview across the entire value chain. This paper is based on the analysis of different case studies. Experts have been interviewed on the current and coming issues of BIM applied to the timber industry in three different countries (Finland, France and Germany) where the global maturity about the use of BIM and the BIM thinking are significantly different. First results reveal that the timber industry needs to invest in open source BIM guidance to designers, and to experiment in collaborative pilot projects together with BIM developers and lean construction practitioners in order to identify the potential improvements of the BIM ecosystem.},
  isbn = {978-3-903039-00-1}
}

@inproceedings{lerouxInvestigatingInteractionBuilding2016a,
  title = {Investigating the Interaction of Building Information Modelling and Lean Construction in the Timber Industry},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Le Roux, S. and Bannier, F. and Bossanne, E. and Stieglmeier, M.},
  date = {2016},
  abstract = {Building Information Modelling (BIM) is expanding very quickly in the construction industry and offers new opportunities to redefine and optimize the construction process. This paper collects insight from software developers, BIM users in the timber industry, architects and engineers, timber manufacturers, contractors and property developers, to collect an overview across the entire value chain. This paper is based on the analysis of different case studies. Experts have been interviewed on the current and coming issues of BIM applied to the timber industry in three different countries (Finland, France and Germany) where the global maturity about the use of BIM and the BIM thinking are significantly different. First results reveal that the timber industry needs to invest in open source BIM guidance to designers, and to experiment in collaborative pilot projects together with BIM developers and lean construction practitioners in order to identify the potential improvements of the BIM ecosystem.},
  isbn = {978-3-903039-00-1}
}

@article{leyhExperiencesConstructionBuilding1995,
  title = {Experiences with the Construction of a Building Assembly Robot},
  author = {Leyh, W.},
  date = {1995},
  journaltitle = {Automation in Construction},
  volume = {4},
  number = {1},
  pages = {45--60},
  doi = {10.1016/0926-5805(94)00034-K},
  abstract = {The aim of the development was the construction of a freely programmable handling system for use as an experimental plant for various tasks in research and development in the field of overground workings where freely programmable movement and force patterns are important. The system should be suitable for building assembly work in particular. With regard to the robot technology and the assembly operations, plans which are worked out theoretically are checked here and developed further by practical experience. The handling system constructed will be called "experimental building assembly robot". © 1995.}
}

@article{leyhExperiencesConstructionBuilding1995a,
  title = {Experiences with the Construction of a Building Assembly Robot},
  author = {Leyh, W.},
  date = {1995},
  journaltitle = {Automation in Construction},
  volume = {4},
  number = {1},
  pages = {45--60},
  doi = {10.1016/0926-5805(94)00034-K},
  abstract = {The aim of the development was the construction of a freely programmable handling system for use as an experimental plant for various tasks in research and development in the field of overground workings where freely programmable movement and force patterns are important. The system should be suitable for building assembly work in particular. With regard to the robot technology and the assembly operations, plans which are worked out theoretically are checked here and developed further by practical experience. The handling system constructed will be called "experimental building assembly robot". © 1995.}
}

@article{Li2020,
  type = {Article},
  title = {Smart Work Packaging-Enabled Constraint-Free Path Re-Planning for Tower Crane in Prefabricated Products Assembly Process},
  author = {Li, Xiao and Chi, Hung-lin and Wu, Peng and Shen, Geoffrey Qiping},
  date = {2020},
  journaltitle = {Advanced Engineering Informatics},
  volume = {43},
  doi = {10.1016/j.aei.2019.101008},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074894959&doi=10.1016%2fj.aei.2019.101008&partnerID=40&md5=f58956154122349ed44b6758c88f6182},
  publication_stage = {Final},
  source = {Scopus}
}

@article{liangHumanRobotCollaboration2021,
  title = {Human–{{Robot Collaboration}} in {{Construction}}: {{Classification}} and {{Research Trends}}},
  author = {Liang, Ci-Jyun and Wang, Xi and Kamat, Vineet R. and Menassa, Carol C.},
  date = {2021},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {147},
  number = {10},
  pages = {1--23},
  issn = {0733-9364},
  doi = {10.1061/(asce)co.1943-7862.0002154},
  abstract = {AbstractConstruction robots continue to be increasingly deployed on construction sites to assist human workers in various tasks to improve safety, efficiency, and productivity. Due to the recent an...},
  isbn = {0000000202138}
}

@article{liangHumanRobotCollaboration2021a,
  title = {Human–{{Robot Collaboration}} in {{Construction}}: {{Classification}} and {{Research Trends}}},
  author = {Liang, Ci-Jyun and Wang, Xi and Kamat, Vineet R. and Menassa, Carol C.},
  date = {2021},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {147},
  number = {10},
  pages = {1--23},
  issn = {0733-9364},
  doi = {10.1061/(asce)co.1943-7862.0002154},
  abstract = {AbstractConstruction robots continue to be increasingly deployed on construction sites to assist human workers in various tasks to improve safety, efficiency, and productivity. Due to the recent an...},
  isbn = {0000000202138},
  file = {C:\Users\leemar\Zotero\storage\C2BVAWA8\%28ASCE%29CO.1943-7862.0002154.pdf}
}

@inproceedings{liaoFormalFrameworkRobot2021,
  title = {A Formal Framework for Robot to Understand Compound Concepts},
  booktitle = {Journal of {{Physics}}: {{Conference Series}}},
  author = {Liao, Y. and Yan, M. and Li, X.},
  date = {2021},
  volume = {1846},
  number = {1},
  doi = {10.1088/1742-6596/1846/1/012035},
  abstract = {Social robots are playing an important role in assisting humans in shopping, caring for the elderly and educating children. However, to accomplish these tasks with high quality, social robots still face huge challenges. One of the main challenges is how robots understand the intentions of human behavior and predict human needs in order to respond appropriately. Most existing social robots determine the intentions and needs of humans based on the postures and actions in a specific scene. We know that it is not enough to understand human intentions and needs based on gestures and actions. It will be more perfect to understand human intentions and needs through natural language communication. To this end, we propose a formal framework for describing robots' understanding of simple and compound concepts. Once the robot has the ability to understand compound concepts, it has the ability to understand some simple knowledge. We first introduce the formal methods of expressing the connotation and extension of simple concepts, and then propose a framework for robots to understand simple concepts, and finally build a formal framework for robots to understand complex concepts. This framework provides a formal method for robots to understand knowledge.}
}

@inproceedings{liaoFormalFrameworkRobot2021a,
  title = {A Formal Framework for Robot to Understand Compound Concepts},
  booktitle = {Journal of {{Physics}}: {{Conference Series}}},
  author = {Liao, Y. and Yan, M. and Li, X.},
  date = {2021},
  volume = {1846},
  number = {1},
  doi = {10.1088/1742-6596/1846/1/012035},
  abstract = {Social robots are playing an important role in assisting humans in shopping, caring for the elderly and educating children. However, to accomplish these tasks with high quality, social robots still face huge challenges. One of the main challenges is how robots understand the intentions of human behavior and predict human needs in order to respond appropriately. Most existing social robots determine the intentions and needs of humans based on the postures and actions in a specific scene. We know that it is not enough to understand human intentions and needs based on gestures and actions. It will be more perfect to understand human intentions and needs through natural language communication. To this end, we propose a formal framework for describing robots' understanding of simple and compound concepts. Once the robot has the ability to understand compound concepts, it has the ability to understand some simple knowledge. We first introduce the formal methods of expressing the connotation and extension of simple concepts, and then propose a framework for robots to understand simple concepts, and finally build a formal framework for robots to understand complex concepts. This framework provides a formal method for robots to understand knowledge.}
}

@article{liauTaskAllocationHumanRobot2020,
  title = {Task {{Allocation}} in {{Human-Robot Collaboration}} ({{HRC}}) {{Based}} on {{Task Characteristics}} and {{Agent Capability}} for {{Mold Assembly}}},
  author = {Liau, Yee Yeng and Ryu, Kwangyeol},
  date = {2020},
  journaltitle = {Procedia Manufacturing},
  shortjournal = {Procedia Manufacturing},
  volume = {51},
  pages = {179--186},
  issn = {23519789},
  doi = {10.1016/j.promfg.2020.10.026},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2351978920318813},
  urldate = {2023-05-29},
  abstract = {The involvement of repetitive motion with force and heavy component handling during the manual mold assembly causes an ergonomic problem that harms the musculoskeletal system on the human worker. This ergonomic problem can be eliminated using a robot. However, the traditional automation system is impractical to be implemented in the mold assembly because of the complexity of the customized mold structure. Hence, human-robot collaboration (HRC) systems became the potential solution to improve the working conditions with the assistance of a robot while adapting to the frequent change over in the mold assembly operation. In this paper, we propose a task allocation model for the HRC system that consists of three agents who are one human and two robots to cope with heavy part handling and the diversity of tasks in the mold assembly. First, we decompose the assembly operation into functional actions. Second, we evaluate the action assignment using the Analytic Network Process (ANP) based on the action characteristics and agent capability. Third, we allocate the functional action to the agents in the HRC work cell using the Genetic Algorithm (GA) to minimize the operation cycle time and maximize the agent capability. The outcome of this paper is to contribute to the expansion of the HRC system with one human and two robots in the mold assembly operation. In addition to the improvement in the ergonomic condition, the proposed task allocation model can achieve a wider variety of tasks assigned to robots with minimum tool change.},
  langid = {english},
  file = {/Volumes/WIP/library/1-s2.0-S2351978920318813-main.pdf}
}

@article{liBarriersComputerVision2022,
  title = {Barriers to Computer Vision Applications in Pig Production Facilities},
  author = {Li, J. and Green-Miller, A. R. and Hu, X. and Lucic, A. and Mohan, M. R. Mahesh and Dilger, R. N. and Condotta, I. C. F. S. and Aldridge, B. and Hart, J. M. and Ahuja, N.},
  date = {2022},
  journaltitle = {Computers and Electronics in Agriculture},
  volume = {200},
  doi = {10.1016/j.compag.2022.107227},
  abstract = {Surveillance and analysis of behavior can be used to detect and characterize health disruption and welfare status in animals. The accurate identification of changes in behavior is a time-consuming task for caretakers in large, commercial pig production systems and requires strong observational skills and a working knowledge of animal husbandry and livestock systems operations. In recent years, many studies have explored the use of various technologies and sensors to assist animal caretakers in monitoring animal activity and behavior. Of these technologies, computer vision offers the most consistent promise as an effective aid in animal care, and yet, a systematic review of the state of application of this technology indicates that there are many significant barriers to its widespread adoption and successful utilization in commercial production system settings. One of the most important of these barriers is the recognition of the sources of errors from objective behavior labeling that are not measurable by current algorithm performance evaluations. Additionally, there is a significant disconnect between the remarkable advances in computer vision research interests and the integration of advances and practical needs being instituted by scientific experts working in commercial animal production partnerships. This lack of synergy between experts in the computer vision and animal health and production sectors means that existing and emerging datasets tend to have a very particular focus that cannot be easily pivoted or extended for use in other contexts, resulting in a generality versus particularity conundrum. This goal of this paper is to help catalogue and consider the major obstacles and impediments to the effective use of computer vision associated technologies in the swine industry by offering a systematic analysis of computer vision applications specific to commercial pig management by reviewing and summarizing the following: (i) the purpose and associated challenges of computer vision applications in pig behavior analysis; (ii) the use of computer vision algorithms and datasets for pig husbandry and management tasks; (iii) the process of dataset construction for computer vision algorithm development. In this appraisal, we outline common difficulties and challenges associated with each of these themes and suggest possible solutions. Finally, we highlight the opportunities for future research in computer vision applications that can build upon existing knowledge of pig management by extending our capability to interpret pig behaviors and thereby overcome the current barriers to applying computer vision technologies to pig production systems. In conclusion, we believe productive collaboration between animal-based scientists and computer-based scientists may accelerate animal behavior studies and lead the computer vision technologies to commercial applications in pig production facilities.}
}

@article{liBarriersComputerVision2022a,
  title = {Barriers to Computer Vision Applications in Pig Production Facilities},
  author = {Li, J. and Green-Miller, A.R. and Hu, X. and Lucic, A. and Mahesh Mohan, M.R. and Dilger, R.N. and Condotta, I.C.F.S. and Aldridge, B. and Hart, J.M. and Ahuja, N.},
  date = {2022},
  journaltitle = {Computers and Electronics in Agriculture},
  volume = {200},
  doi = {10.1016/j.compag.2022.107227},
  abstract = {Surveillance and analysis of behavior can be used to detect and characterize health disruption and welfare status in animals. The accurate identification of changes in behavior is a time-consuming task for caretakers in large, commercial pig production systems and requires strong observational skills and a working knowledge of animal husbandry and livestock systems operations. In recent years, many studies have explored the use of various technologies and sensors to assist animal caretakers in monitoring animal activity and behavior. Of these technologies, computer vision offers the most consistent promise as an effective aid in animal care, and yet, a systematic review of the state of application of this technology indicates that there are many significant barriers to its widespread adoption and successful utilization in commercial production system settings. One of the most important of these barriers is the recognition of the sources of errors from objective behavior labeling that are not measurable by current algorithm performance evaluations. Additionally, there is a significant disconnect between the remarkable advances in computer vision research interests and the integration of advances and practical needs being instituted by scientific experts working in commercial animal production partnerships. This lack of synergy between experts in the computer vision and animal health and production sectors means that existing and emerging datasets tend to have a very particular focus that cannot be easily pivoted or extended for use in other contexts, resulting in a generality versus particularity conundrum. This goal of this paper is to help catalogue and consider the major obstacles and impediments to the effective use of computer vision associated technologies in the swine industry by offering a systematic analysis of computer vision applications specific to commercial pig management by reviewing and summarizing the following: (i) the purpose and associated challenges of computer vision applications in pig behavior analysis; (ii) the use of computer vision algorithms and datasets for pig husbandry and management tasks; (iii) the process of dataset construction for computer vision algorithm development. In this appraisal, we outline common difficulties and challenges associated with each of these themes and suggest possible solutions. Finally, we highlight the opportunities for future research in computer vision applications that can build upon existing knowledge of pig management by extending our capability to interpret pig behaviors and thereby overcome the current barriers to applying computer vision technologies to pig production systems. In conclusion, we believe productive collaboration between animal-based scientists and computer-based scientists may accelerate animal behavior studies and lead the computer vision technologies to commercial applications in pig production facilities.}
}

@book{liciottiPersonReidentificationDataset2017,
  title = {Person Re-Identification Dataset with {{RGB-D}} Camera in a Top-View Configuration},
  author = {Liciotti, D. and Paolanti, M. and Frontoni, E. and Mancini, A. and Zingaretti, P.},
  date = {2017},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {10165 LNCS},
  doi = {10.1007/978-3-319-56687-0_1},
  abstract = {Video analytics, involves a variety of techniques to monitor, analyse, and extract meaningful information from video streams. In this light, person re-identification is an important topic in scene monitoring, human computer interaction, retail, people counting, ambient assisted living and many other computer vision research. The existing datasets are not suitable for activity monitoring and human behaviour analysis. For this reason we build a novel dataset for person re-identification that uses an RGB-D camera in a top-view configuration. This setup choice is primarily due to the reduction of occlusions and it has also the advantage of being privacy preserving, because faces are not recorded by the camera. The use of an RGB-D camera allows to extract anthropometric features for the recognition of people passing under the camera. The paper describes in details the collection and construction modalities of the dataset TVPR. This is composed by 100 people and for each video frame nine depth and colour features are computed and provided together with key descriptive statistics.},
  isbn = {978-3-319-56686-3},
  pagetotal = {1-11}
}

@book{liciottiPersonReidentificationDataset2017a,
  title = {Person Re-Identification Dataset with {{RGB-D}} Camera in a Top-View Configuration},
  author = {Liciotti, D. and Paolanti, M. and Frontoni, E. and Mancini, A. and Zingaretti, P.},
  date = {2017},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {10165 LNCS},
  doi = {10.1007/978-3-319-56687-0_1},
  abstract = {Video analytics, involves a variety of techniques to monitor, analyse, and extract meaningful information from video streams. In this light, person re-identification is an important topic in scene monitoring, human computer interaction, retail, people counting, ambient assisted living and many other computer vision research. The existing datasets are not suitable for activity monitoring and human behaviour analysis. For this reason we build a novel dataset for person re-identification that uses an RGB-D camera in a top-view configuration. This setup choice is primarily due to the reduction of occlusions and it has also the advantage of being privacy preserving, because faces are not recorded by the camera. The use of an RGB-D camera allows to extract anthropometric features for the recognition of people passing under the camera. The paper describes in details the collection and construction modalities of the dataset TVPR. This is composed by 100 people and for each video frame nine depth and colour features are computed and provided together with key descriptive statistics.},
  isbn = {978-3-319-56686-3},
  pagetotal = {1-11}
}

@article{liContinuousRoleAdaptation2015,
  title = {Continuous {{Role Adaptation}} for {{Human-Robot Shared Control}}},
  author = {Li, Yanan and Tee, Keng Peng and Chan, Wei Liang and Yan, Rui and Chua, Yuanwei and Limbu, Dilip Kumar},
  date = {2015},
  journaltitle = {IEEE Transactions on Robotics},
  volume = {31},
  number = {3},
  pages = {672--681},
  publisher = {{IEEE}},
  issn = {15523098},
  doi = {10.1109/TRO.2015.2419873},
  abstract = {In this paper, we propose a role adaptation method for human-robot shared control. Game theory is employed for fundamental analysis of this two-agent system. An adaptation law is developed such that the robot is able to adjust its own role according to the human's intention to lead or follow, which is inferred through the measured interaction force. In the absence of human interaction forces, the adaptive scheme allows the robot to take the lead and complete the task by itself. On the other hand, when the human persistently exerts strong forces that signal an unambiguous intent to lead, the robot yields and becomes the follower. Additionally, the full spectrum of mixed roles between these extreme scenarios is afforded by continuous online update of the control that is shared between both agents. Theoretical analysis shows that the resulting shared control is optimal with respect to a two-agent coordination game. Experimental results illustrate better overall performance, in terms of both error and effort, compared with fixed-role interactions.},
  keywords = {Adaptive control,physical human-robot interaction,shared control}
}

@article{liContinuousRoleAdaptation2015a,
  title = {Continuous {{Role Adaptation}} for {{Human-Robot Shared Control}}},
  author = {Li, Yanan and Tee, Keng Peng and Chan, Wei Liang and Yan, Rui and Chua, Yuanwei and Limbu, Dilip Kumar},
  date = {2015},
  journaltitle = {IEEE Transactions on Robotics},
  volume = {31},
  number = {3},
  pages = {672--681},
  publisher = {{IEEE}},
  issn = {15523098},
  doi = {10.1109/TRO.2015.2419873},
  abstract = {In this paper, we propose a role adaptation method for human-robot shared control. Game theory is employed for fundamental analysis of this two-agent system. An adaptation law is developed such that the robot is able to adjust its own role according to the human's intention to lead or follow, which is inferred through the measured interaction force. In the absence of human interaction forces, the adaptive scheme allows the robot to take the lead and complete the task by itself. On the other hand, when the human persistently exerts strong forces that signal an unambiguous intent to lead, the robot yields and becomes the follower. Additionally, the full spectrum of mixed roles between these extreme scenarios is afforded by continuous online update of the control that is shared between both agents. Theoretical analysis shows that the resulting shared control is optimal with respect to a two-agent coordination game. Experimental results illustrate better overall performance, in terms of both error and effort, compared with fixed-role interactions.},
  keywords = {Adaptive control,physical human-robot interaction,shared control},
  file = {C:\Users\leemar\Zotero\storage\2RZR8W4H\Continuous_Role_Adaptation_for_HumanRobot_Shared_Control.pdf}
}

@article{liHumanRobotCollaboration2014,
  title = {Human–{{Robot Collaboration Based}} on {{Motion Intention Estimation}}},
  author = {Li, Yanan and Ge, Shuzhi Sam},
  date = {2014-06},
  journaltitle = {IEEE/ASME Transactions on Mechatronics},
  shortjournal = {IEEE/ASME Trans. Mechatron.},
  volume = {19},
  number = {3},
  pages = {1007--1014},
  issn = {1083-4435, 1941-014X},
  doi = {10.1109/TMECH.2013.2264533},
  url = {http://ieeexplore.ieee.org/document/6545352/},
  urldate = {2023-04-23},
  file = {C:\Users\leemar\Zotero\storage\ECXEY7FZ\Li and Ge - 2014 - Human–Robot Collaboration Based on Motion Intentio.pdf}
}

@article{liInfluenceSandstormAir2021,
  title = {Influence of Sandstorm on Air Pollution Based on {{Gaussian}} Mixture Model and Sports Detection},
  author = {Li, X.},
  date = {2021},
  journaltitle = {Arabian Journal of Geosciences},
  volume = {14},
  number = {15},
  doi = {10.1007/s12517-021-07953-z},
  abstract = {Gaussian mixture model (GMM) is widely used in pattern recognition, computer vision, machine learning, data mining, and bioinformatics. In these areas, it is used to perform tasks such as image segmentation, grouping, and probability density function construction. At the same time, the research on the air pollution caused by sandstorm has also been widely concerned and recognized. The atmospheric boundary layer is an important environment for the exchange of material and energy between the earth’s surface and the atmosphere. The formation of storms is closely related to the boundary layer process. Dust weather is a disastrous climate closely related to the boundary layer, which has a significant impact on human life, production, and ecological environment. The arid and semi-arid area of Northwest China has become one of the dustiest areas in China due to its special geographical location and climatic conditions and has very unique atmospheric boundary layer characteristics. The characteristics of boundary layer height and its influence on dust emission time are studied. Gene testing technology can evaluate the scientific basis and current state of sports ability and discuss how to standardize the gene testing of sports ability from the moral point of view. Put forward and improve the relevant legal and ethical standards to protect genetic privacy; improve the system and industry standard of gene detection; through the genetic test of sports ability, we can prevent the misjudgment of sports potential and influence the choice of sports. In this paper, through the research of Gaussian mixture model technology, it is applied to the air pollution in sandstorm and sports activities, which greatly improves the pollution situation of sandstorm weather.}
}

@article{liInfluenceSandstormAir2021a,
  title = {Influence of Sandstorm on Air Pollution Based on {{Gaussian}} Mixture Model and Sports Detection},
  author = {Li, X.},
  date = {2021},
  journaltitle = {Arabian Journal of Geosciences},
  volume = {14},
  number = {15},
  doi = {10.1007/s12517-021-07953-z},
  abstract = {Gaussian mixture model (GMM) is widely used in pattern recognition, computer vision, machine learning, data mining, and bioinformatics. In these areas, it is used to perform tasks such as image segmentation, grouping, and probability density function construction. At the same time, the research on the air pollution caused by sandstorm has also been widely concerned and recognized. The atmospheric boundary layer is an important environment for the exchange of material and energy between the earth’s surface and the atmosphere. The formation of storms is closely related to the boundary layer process. Dust weather is a disastrous climate closely related to the boundary layer, which has a significant impact on human life, production, and ecological environment. The arid and semi-arid area of Northwest China has become one of the dustiest areas in China due to its special geographical location and climatic conditions and has very unique atmospheric boundary layer characteristics. The characteristics of boundary layer height and its influence on dust emission time are studied. Gene testing technology can evaluate the scientific basis and current state of sports ability and discuss how to standardize the gene testing of sports ability from the moral point of view. Put forward and improve the relevant legal and ethical standards to protect genetic privacy; improve the system and industry standard of gene detection; through the genetic test of sports ability, we can prevent the misjudgment of sports potential and influence the choice of sports. In this paper, through the research of Gaussian mixture model technology, it is applied to the air pollution in sandstorm and sports activities, which greatly improves the pollution situation of sandstorm weather.}
}

@article{liIntegratedApproachRobotic2021,
  title = {An Integrated Approach for Robotic {{Sit-To-Stand}} Assistance: {{Control}} Framework Design and Human Intention Recognition},
  author = {Li, J. and Lu, L. and Zhao, L. and Wang, C. and Li, J.},
  date = {2021},
  journaltitle = {Control Engineering Practice},
  volume = {107},
  doi = {10.1016/j.conengprac.2020.104680},
  abstract = {In this paper, the problem of robotic Sit-To-Stand (STS) assistance is studied. The objective is to effectively assist individuals in need to stand up from a seated position using a robot manipulator. To achieve the goal, we propose an integrated method which encompasses traditional model-based control and optimization, as well as AI-based human intention recognition. Specifically, a number of demonstrations of human-to-human STS assistance are first performed and recorded using motion capture system. On the account of the observation and recorded data, the average intended motion trajectories for the joints of lower limbs are obtained. Based on these intended motion trajectories as well as the constructed human body dynamics and control in different STS phases, an optimal nominal trajectory of the robot end-effector is generated off-line that minimizes the human joint loads while satisfying additional physical constraints. In actual STS assistance, the human who is being assisted is likely to move faster or slower from the nominal trajectories, or even sit back down. Therefore, we develop a Long Short-Term Memory (LSTM) network to estimate the ever-changing human's intention in STS assistance, and then adjust the velocity of the robot end-effector on the basis of the predicted human intention on the nominal trajectory. Simulations and experiments are conducted, demonstrating that the proposed algorithm is indeed capable of minimizing joint load of human while following his/her intention during the course of STS motion. The algorithm can potentially be applied to future home robots that assist elderly and disabled people with daily activities.}
}

@article{liIntegratedApproachRobotic2021a,
  title = {An Integrated Approach for Robotic {{Sit-To-Stand}} Assistance: {{Control}} Framework Design and Human Intention Recognition},
  author = {Li, J. and Lu, L. and Zhao, L. and Wang, C. and Li, J.},
  date = {2021},
  journaltitle = {Control Engineering Practice},
  volume = {107},
  doi = {10.1016/j.conengprac.2020.104680},
  abstract = {In this paper, the problem of robotic Sit-To-Stand (STS) assistance is studied. The objective is to effectively assist individuals in need to stand up from a seated position using a robot manipulator. To achieve the goal, we propose an integrated method which encompasses traditional model-based control and optimization, as well as AI-based human intention recognition. Specifically, a number of demonstrations of human-to-human STS assistance are first performed and recorded using motion capture system. On the account of the observation and recorded data, the average intended motion trajectories for the joints of lower limbs are obtained. Based on these intended motion trajectories as well as the constructed human body dynamics and control in different STS phases, an optimal nominal trajectory of the robot end-effector is generated off-line that minimizes the human joint loads while satisfying additional physical constraints. In actual STS assistance, the human who is being assisted is likely to move faster or slower from the nominal trajectories, or even sit back down. Therefore, we develop a Long Short-Term Memory (LSTM) network to estimate the ever-changing human's intention in STS assistance, and then adjust the velocity of the robot end-effector on the basis of the predicted human intention on the nominal trajectory. Simulations and experiments are conducted, demonstrating that the proposed algorithm is indeed capable of minimizing joint load of human while following his/her intention during the course of STS motion. The algorithm can potentially be applied to future home robots that assist elderly and disabled people with daily activities.}
}

@article{liIntentionUnderstandingHuman2021,
  title = {Intention {{Understanding}} in {{Human}}–{{Robot Interaction Based}} on {{Visual-NLP Semantics}}},
  author = {Li, Zhihao and Mu, Yishan and Sun, Zhenglong and Song, Sifan and Su, Jionglong and Zhang, Jiaming},
  date = {2021-02},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {14},
  issn = {1662-5218},
  doi = {10.3389/fnbot.2020.610139},
  url = {https://www.frontiersin.org/articles/10.3389/fnbot.2020.610139/full},
  abstract = {With the rapid development of robotic and AI technology in recent years, human–robot interaction has made great advancement, making practical social impact. Verbal commands are one of the most direct and frequently used means for human–robot interaction. Currently, such technology can enable robots to execute pre-defined tasks based on simple and direct and explicit language instructions, e.g., certain keywords must be used and detected. However, that is not the natural way for human to communicate. In this paper, we propose a novel task-based framework to enable the robot to comprehend human intentions using visual semantics information, such that the robot is able to satisfy human intentions based on natural language instructions (total three types, namely clear, vague, and feeling, are defined and tested). The proposed framework includes a language semantics module to extract the keywords despite the explicitly of the command instruction, a visual object recognition module to identify the objects in front of the robot, and a similarity computation algorithm to infer the intention based on the given task. The task is then translated into the commands for the robot accordingly. Experiments are performed and validated on a humanoid robot with a defined task: to pick the desired item out of multiple objects on the table, and hand over to one desired user out of multiple human participants. The results show that our algorithm can interact with different types of instructions, even with unseen sentence structures.}
}

@article{liIntentionUnderstandingHuman2021a,
  title = {Intention {{Understanding}} in {{Human}}–{{Robot Interaction Based}} on {{Visual-NLP Semantics}}},
  author = {Li, Zhihao and Mu, Yishan and Sun, Zhenglong and Song, Sifan and Su, Jionglong and Zhang, Jiaming},
  date = {2021-02-02},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {14},
  issn = {1662-5218},
  doi = {10.3389/fnbot.2020.610139},
  url = {https://www.frontiersin.org/articles/10.3389/fnbot.2020.610139/full},
  abstract = {With the rapid development of robotic and AI technology in recent years, human–robot interaction has made great advancement, making practical social impact. Verbal commands are one of the most direct and frequently used means for human–robot interaction. Currently, such technology can enable robots to execute pre-defined tasks based on simple and direct and explicit language instructions, e.g., certain keywords must be used and detected. However, that is not the natural way for human to communicate. In this paper, we propose a novel task-based framework to enable the robot to comprehend human intentions using visual semantics information, such that the robot is able to satisfy human intentions based on natural language instructions (total three types, namely clear, vague, and feeling, are defined and tested). The proposed framework includes a language semantics module to extract the keywords despite the explicitly of the command instruction, a visual object recognition module to identify the objects in front of the robot, and a similarity computation algorithm to infer the intention based on the given task. The task is then translated into the commands for the robot accordingly. Experiments are performed and validated on a humanoid robot with a defined task: to pick the desired item out of multiple objects on the table, and hand over to one desired user out of multiple human participants. The results show that our algorithm can interact with different types of instructions, even with unseen sentence structures.},
  file = {C:\Users\leemar\Zotero\storage\2G9G98DS\fnbot-14-610139.pdf}
}

@article{limOntologybasedUnifiedRobot2011,
  title = {Ontology-Based Unified Robot Knowledge for Service Robots in Indoor Environments},
  author = {Lim, Gi Hyun and Suh, Il Hong and Suh, Hyowon},
  date = {2011},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics Part A:Systems and Humans},
  volume = {41},
  number = {3},
  pages = {492--509},
  publisher = {{IEEE}},
  issn = {10834427},
  doi = {10.1109/TSMCA.2010.2076404},
  abstract = {A significant obstacle for service robots is the execution of complex tasks in real environments. For example, it is not easy for service robots to find objects that are partially observable and are located at a place which is not identical but near the place where the robots saw them previously. To overcome the challenge effectively, robot knowledge represented as a semantic network can be extremely useful. This paper presents an ontology-based unified robot knowledge framework that integrates low-level data with high-level knowledge for robot intelligence. This framework consists of two sections: knowledge description and knowledge association. Knowledge description includes comprehensively integrated robot knowledge derived from low-level knowledge regarding perceptual features, part objects, metric maps, and primitive behaviors, as well as high-level knowledge about perceptual concepts, objects, semantic maps, tasks, and contexts. Knowledge association uses logical inference with both unidirectional and bidirectional rules. This characteristic enables reasoning to be performed even when only a partial information is available. The experimental results that demonstrate the advantages of using the proposed knowledge framework are also presented. © 2006 IEEE.},
  keywords = {Intelligent service robot,knowledge association,knowledge description,ontology-based knowledge,unified robot knowledge}
}

@article{limOntologybasedUnifiedRobot2011a,
  title = {Ontology-Based Unified Robot Knowledge for Service Robots in Indoor Environments},
  author = {Lim, Gi Hyun and Suh, Il Hong and Suh, Hyowon},
  date = {2011},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics Part A:Systems and Humans},
  volume = {41},
  number = {3},
  pages = {492--509},
  publisher = {{IEEE}},
  issn = {10834427},
  doi = {10.1109/TSMCA.2010.2076404},
  abstract = {A significant obstacle for service robots is the execution of complex tasks in real environments. For example, it is not easy for service robots to find objects that are partially observable and are located at a place which is not identical but near the place where the robots saw them previously. To overcome the challenge effectively, robot knowledge represented as a semantic network can be extremely useful. This paper presents an ontology-based unified robot knowledge framework that integrates low-level data with high-level knowledge for robot intelligence. This framework consists of two sections: knowledge description and knowledge association. Knowledge description includes comprehensively integrated robot knowledge derived from low-level knowledge regarding perceptual features, part objects, metric maps, and primitive behaviors, as well as high-level knowledge about perceptual concepts, objects, semantic maps, tasks, and contexts. Knowledge association uses logical inference with both unidirectional and bidirectional rules. This characteristic enables reasoning to be performed even when only a partial information is available. The experimental results that demonstrate the advantages of using the proposed knowledge framework are also presented. © 2006 IEEE.},
  keywords = {Intelligent service robot,knowledge association,knowledge description,ontology-based knowledge,unified robot knowledge},
  file = {C:\Users\leemar\Zotero\storage\HMDDQWXI\Ontology-Based_Unified_Robot_Knowledge_for_Service_Robots_in_Indoor_Environments.pdf}
}

@article{Lin2015,
  type = {Article},
  title = {Motion Planning and Coordination for Mobile Construction Machinery},
  author = {Lin, Jacob Je-Chian and Hung, Wei-Han and Kang, Shih-Chung},
  date = {2015},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {29},
  number = {6},
  doi = {10.1061/(ASCE)CP.1943-5487.0000408},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945137297&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000408&partnerID=40&md5=d53df575e1b0cf68f748c5d7ddf41b77},
  publication_stage = {Final},
  source = {Scopus}
}

@online{linContextbasedOntologyModelling2023,
  title = {Context-Based {{Ontology Modelling}} for {{Database}}: {{Enabling ChatGPT}} for {{Semantic Database Management}}},
  shorttitle = {Context-Based {{Ontology Modelling}} for {{Database}}},
  author = {Lin, Wenjun and Babyn, Paul and {yan}, Yan and Zhang, Wenjun},
  date = {2023-03-11},
  eprint = {2303.07351},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2303.07351},
  urldate = {2023-11-19},
  abstract = {This research paper explores the use of ChatGPT in database management. ChatGPT, an AI-powered chatbot, has limitations in performing tasks related to database management due to the lack of standardized vocabulary and grammar for representing database semantics. To address this limitation, the paper proposes a solution that involves developing a set of syntaxes that can represent database semantics in natural language. The syntax is used to convert database schemas into natural language formats, providing a new application of ChatGPT in database management. The proposed solution is demonstrated through a case study where ChatGPT is used to perform two tasks, semantic integration, and tables joining. Results demonstrate that the use of semantic database representations produces more precise outcomes and avoids common mistakes compared to cases with no semantic representation. The proposed method has the potential to speed up the database management process, reduce the level of understanding required for database domain knowledge, and enable automatic database operations without accessing the actual data, thus illuminating privacy protection concerns when using AI. This paper provides a promising new direction for research in the field of AI-based database management.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Databases},
  file = {C:\Users\leemar\Zotero\storage\247E6WA6\Lin 等。 - 2023 - Context-based Ontology Modelling for Database Ena.pdf}
}

@article{liProactiveHumanRobot2021,
  title = {Towards Proactive Human–Robot Collaboration: {{A}} Foreseeable Cognitive Manufacturing Paradigm},
  shorttitle = {Towards Proactive Human–Robot Collaboration},
  author = {Li, Shufei and Wang, Ruobing and Zheng, Pai and Wang, Lihui},
  date = {2021-07},
  journaltitle = {Journal of Manufacturing Systems},
  shortjournal = {Journal of Manufacturing Systems},
  volume = {60},
  pages = {547--552},
  issn = {02786125},
  doi = {10.1016/j.jmsy.2021.07.017},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0278612521001540},
  urldate = {2023-06-07},
  langid = {english},
  file = {/Volumes/WIP/library/1-s2.0-S0278612521001540-main.pdf}
}

@article{liRecognizingWorkersConstruction2022,
  title = {Recognizing Workers' Construction Activities on a Reinforcement Processing Area through the Position Relationship of Objects Detected by Faster {{R-CNN}}},
  author = {Li, J. and Zhou, G. and Li, D. and Zhang, M. and Zhao, X.},
  date = {2022},
  journaltitle = {Engineering, Construction and Architectural Management},
  doi = {10.1108/ECAM-04-2021-0312},
  abstract = {Purpose: Recognizing every worker's working status instead of only describing the existing construction activities in static images or videos as most computer vision-based approaches do; identifying workers and their activities simultaneously; establishing a connection between workers and their behaviors. Design/methodology/approach: Taking a reinforcement processing area as a research case, a new method for recognizing each different worker's activity through the position relationship of objects detected by Faster R-CNN is proposed. Firstly, based on four workers and four kinds of high-frequency activities, a Faster R-CNN model is trained. Then, by inputting the video into the model, with the coordinate of the boxes at each moment, the status of each worker can be judged. Findings: The Faster R-CNN detector shows a satisfying performance with an mAP of 0.9654; with the detected boxes, a connection between the workers and activities is established; Through this connection, the average accuracy of activity recognition reached 0.92; with the proposed method, the labor consumption of each worker can be viewed more intuitively on the visualization graphics. Originality/value: With this proposed method, the visualization graphics generated will help managers to evaluate the labor consumption of each worker more intuitively. Furthermore, human resources can be allocated more efficiently according to the information obtained. It is especially suitable for some small construction scenarios, in which the recognition model can work for a long time after it is established. This is potentially beneficial for the healthy operation of the entire project, and can also have a positive indirect impact on structural health and safety.}
}

@article{liRecognizingWorkersConstruction2022a,
  title = {Recognizing Workers' Construction Activities on a Reinforcement Processing Area through the Position Relationship of Objects Detected by Faster {{R-CNN}}},
  author = {Li, J. and Zhou, G. and Li, D. and Zhang, M. and Zhao, X.},
  date = {2022},
  journaltitle = {Engineering, Construction and Architectural Management},
  doi = {10.1108/ECAM-04-2021-0312},
  abstract = {Purpose: Recognizing every worker's working status instead of only describing the existing construction activities in static images or videos as most computer vision-based approaches do; identifying workers and their activities simultaneously; establishing a connection between workers and their behaviors. Design/methodology/approach: Taking a reinforcement processing area as a research case, a new method for recognizing each different worker's activity through the position relationship of objects detected by Faster R-CNN is proposed. Firstly, based on four workers and four kinds of high-frequency activities, a Faster R-CNN model is trained. Then, by inputting the video into the model, with the coordinate of the boxes at each moment, the status of each worker can be judged. Findings: The Faster R-CNN detector shows a satisfying performance with an mAP of 0.9654; with the detected boxes, a connection between the workers and activities is established; Through this connection, the average accuracy of activity recognition reached 0.92; with the proposed method, the labor consumption of each worker can be viewed more intuitively on the visualization graphics. Originality/value: With this proposed method, the visualization graphics generated will help managers to evaluate the labor consumption of each worker more intuitively. Furthermore, human resources can be allocated more efficiently according to the information obtained. It is especially suitable for some small construction scenarios, in which the recognition model can work for a long time after it is established. This is potentially beneficial for the healthy operation of the entire project, and can also have a positive indirect impact on structural health and safety.}
}

@article{liuActionRecognitionModel2017,
  title = {Action Recognition Model Construction Based on Multi-Scale Deep Convolution Neural Network},
  author = {Liu, Z. and Huang, J.-T. and Feng, X.},
  date = {2017},
  journaltitle = {Guangxue Jingmi Gongcheng/Optics and Precision Engineering},
  volume = {25},
  number = {3},
  pages = {799--805},
  doi = {10.3788/OPE.20172503.0799},
  abstract = {In order to simplify the feature extracting process of Human Activity Recognition (HAR) and improve the generalization of extracted feature, an algorithm based on multi-scale deep convolution neural network was proposed. In this algorithm, the depth video was selected as research object and a parallel CNN (Convolution Neural Network) based deep network was constructed to process coarse global information of the action and fine-grained local information of hand part simultaneously. Experiments were executed on MSRDailyActivity3D dataset. The average recognition accuracy on actions ranging from No.11 to No.16 was 98\%, while that on all actions was 60.625\%. The experimental results showed that proposed algorithm could take effective recognition for human activity. Almost all of the actions with obvious movements and most of actions with local movements just in hands could be recognized effectively.}
}

@article{liuActionRecognitionModel2017a,
  title = {Action Recognition Model Construction Based on Multi-Scale Deep Convolution Neural Network},
  author = {Liu, Z. and Huang, J.-T. and Feng, X.},
  date = {2017},
  journaltitle = {Guangxue Jingmi Gongcheng/Optics and Precision Engineering},
  volume = {25},
  number = {3},
  pages = {799--805},
  doi = {10.3788/OPE.20172503.0799},
  abstract = {In order to simplify the feature extracting process of Human Activity Recognition (HAR) and improve the generalization of extracted feature, an algorithm based on multi-scale deep convolution neural network was proposed. In this algorithm, the depth video was selected as research object and a parallel CNN (Convolution Neural Network) based deep network was constructed to process coarse global information of the action and fine-grained local information of hand part simultaneously. Experiments were executed on MSRDailyActivity3D dataset. The average recognition accuracy on actions ranging from No.11 to No.16 was 98\%, while that on all actions was 60.625\%. The experimental results showed that proposed algorithm could take effective recognition for human activity. Almost all of the actions with obvious movements and most of actions with local movements just in hands could be recognized effectively.}
}

@article{liuCrowdsourcingConstructionActivity2015,
  title = {Crowdsourcing {{Construction Activity Analysis}} from {{Jobsite Video Streams}}},
  author = {Liu, K. and Golparvar-Fard, M.},
  date = {2015},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {141},
  number = {11},
  doi = {10.1061/(ASCE)CO.1943-7862.0001010},
  abstract = {The advent of affordable jobsite cameras is reshaping the way on-site construction activities are monitored. To facilitate the analysis of large collections of videos, research has focused on addressing the problem of manual workface assessment by recognizing worker and equipment activities using computer-vision algorithms. Despite the explosion of these methods, the ability to automatically recognize and understand worker and equipment activities from videos is still rather limited. The current algorithms require large-scale annotated workface assessment video data to learn models that can deal with the high degree of intraclass variability among activity categories. To address current limitations, this study proposes crowdsourcing the task of workface assessment from jobsite video streams. By introducing an intuitive web-based platform for massive marketplaces such as Amazon Mechanical Turk (AMT) and several automated methods, the intelligence of the crowd is engaged for interpreting jobsite videos. The goal is to overcome the limitations of the current practices of workface assessment and also provide significantly large empirical data sets together with their ground truth that can serve as the basis for developing video-based activity recognition methods. Six extensive experiments have shown that engaging nonexperts on AMT to annotate construction activities in jobsite videos can provide complete and detailed workface assessment results with 85\% accuracy. It has been demonstrated that crowdsourcing has the potential to minimize time needed for workface assessment, provides ground truth for algorithmic developments, and most importantly allows on-site professionals to focus their time on the more important task of root-cause analysis and performance improvements.}
}

@article{liuCrowdsourcingConstructionActivity2015a,
  title = {Crowdsourcing {{Construction Activity Analysis}} from {{Jobsite Video Streams}}},
  author = {Liu, K. and Golparvar-Fard, M.},
  date = {2015},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {141},
  number = {11},
  doi = {10.1061/(ASCE)CO.1943-7862.0001010},
  abstract = {The advent of affordable jobsite cameras is reshaping the way on-site construction activities are monitored. To facilitate the analysis of large collections of videos, research has focused on addressing the problem of manual workface assessment by recognizing worker and equipment activities using computer-vision algorithms. Despite the explosion of these methods, the ability to automatically recognize and understand worker and equipment activities from videos is still rather limited. The current algorithms require large-scale annotated workface assessment video data to learn models that can deal with the high degree of intraclass variability among activity categories. To address current limitations, this study proposes crowdsourcing the task of workface assessment from jobsite video streams. By introducing an intuitive web-based platform for massive marketplaces such as Amazon Mechanical Turk (AMT) and several automated methods, the intelligence of the crowd is engaged for interpreting jobsite videos. The goal is to overcome the limitations of the current practices of workface assessment and also provide significantly large empirical data sets together with their ground truth that can serve as the basis for developing video-based activity recognition methods. Six extensive experiments have shown that engaging nonexperts on AMT to annotate construction activities in jobsite videos can provide complete and detailed workface assessment results with 85\% accuracy. It has been demonstrated that crowdsourcing has the potential to minimize time needed for workface assessment, provides ground truth for algorithmic developments, and most importantly allows on-site professionals to focus their time on the more important task of root-cause analysis and performance improvements.}
}

@inproceedings{liuCrowdsourcingVideobasedWorkface2015,
  title = {Crowdsourcing Video-Based Workface Assessment for Construction Activity Analysis},
  booktitle = {32nd {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} and {{Mining}}: {{Connected}} to the {{Future}}, {{Proceedings}}},
  author = {Liu, K. and Golparvar-Fard, M.},
  date = {2015},
  doi = {10.22260/isarc2015/0009},
  abstract = {Today, the availability of multiple cameras on every jobsite is reshaping the way construction activities are being monitored. Research has focused on addressing the limitations of manual workface assessment from these videos via computer vision algorithms. Despite the rapid explosion of these algorithms, the ability to automatically recognize worker and equipment activities from videos is still limited. By crowd-sourcing the task of workface assessment from jobsite videos, this paper aims to overcome the limitations of the current practice and provides a large empirical dataset that can serve as the basis for developing video-based activity recognition methods. As such, an intuitive web-based platform for massive marketplaces such as Amazon Mechanical Turk (AMT) is introduced that engages the intelligence of non-expert crowd for interpretations of selected group of frames from these videos and then it automates remaining workface assessment tasks based on the initial interpretations. To validate, several experiments are conducted on videos from concrete placement operations. The results show that engaging AMT non-experts together with computer vision algorithms can provide assessment results with an accuracy of 85\%. This minimizes the time needed for workface assessment, and allows the practitioners to focus their time on the more important task of root-cause analysis for performance improvements. This platform also provides significantly large datasets with ground truth for algorithmic development purposes.},
  isbn = {978-951-758-597-2}
}

@inproceedings{liuCrowdsourcingVideobasedWorkface2015a,
  title = {Crowdsourcing Video-Based Workface Assessment for Construction Activity Analysis},
  booktitle = {32nd {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} and {{Mining}}: {{Connected}} to the {{Future}}, {{Proceedings}}},
  author = {Liu, K. and Golparvar-Fard, M.},
  date = {2015},
  doi = {10.22260/isarc2015/0009},
  abstract = {Today, the availability of multiple cameras on every jobsite is reshaping the way construction activities are being monitored. Research has focused on addressing the limitations of manual workface assessment from these videos via computer vision algorithms. Despite the rapid explosion of these algorithms, the ability to automatically recognize worker and equipment activities from videos is still limited. By crowd-sourcing the task of workface assessment from jobsite videos, this paper aims to overcome the limitations of the current practice and provides a large empirical dataset that can serve as the basis for developing video-based activity recognition methods. As such, an intuitive web-based platform for massive marketplaces such as Amazon Mechanical Turk (AMT) is introduced that engages the intelligence of non-expert crowd for interpretations of selected group of frames from these videos and then it automates remaining workface assessment tasks based on the initial interpretations. To validate, several experiments are conducted on videos from concrete placement operations. The results show that engaging AMT non-experts together with computer vision algorithms can provide assessment results with an accuracy of 85\%. This minimizes the time needed for workface assessment, and allows the practitioners to focus their time on the more important task of root-cause analysis for performance improvements. This platform also provides significantly large datasets with ground truth for algorithmic development purposes.},
  isbn = {978-951-758-597-2}
}

@misc{LiuFengZhifeng-chihliuYingYongYuBanGongShiQingJingZhiRenJiHuDongYiHuDongQiangHuaFangShiDaChengJiQiRenXingWeiDiaoShiZhiXueXi2013,
  title = {應用於辦公室情境之人機互動：以互動強化方式達成機器人行為調適之學習},
  author = {{劉峯志(Feng-Chih Liu)}},
  year = {1 月 1, 2013},
  langid = {english},
  organization = {{國立台灣大學學位論文}}
}

@thesis{LiuFengZhiYingYongYuBanGongShiQingJingZhiRenJiHuDongYiHuDongQiangHuaFangShiDaChengJiQiRenXingWeiDiaoShiZhiXueXi2013,
  type = {mathesis},
  title = {應用於辦公室情境之人機互動：以互動強化方式達成機器人行為調適之學習},
  author = {{劉峯志}},
  date = {2013-01},
  journaltitle = {國立臺灣大學電機工程學研究所學位論文},
  institution = {{國立臺灣大學}},
  doi = {10.6342/NTU.2013.11138},
  abstract = {This thesis proposes an approach that is applied to human-robot interaction domain to learn the user needs and preferences and adjust robot behaviors. Accordingly, as robots are put into use in humans’ daily life, the assigned tasks to robots are miscellaneous, and the quantity of people to be interacted by robots is immense. As a result, when facing different users, it is important for robots to personalize the interactions and provide user-desired services. For occupational people, staying at working places takes a large amount of time. In this thesis, we study the service robot with application to the office environment. The research content in this work is distinct from traditional machine learning. In human-robot interaction, the training data can be collected only or largely from real experiments. Besides, different individuals possess different preferences, and his/her preferences may even vary with many internal or external factors. Last but not the least, natural human communication and interactive behaviors add additional uncertainties to the learning of robots. This thesis has three principal contributions. First, we propose an approach under which the robot adjusts its behaviors to adapt to user preferences while it is interacting with users. The method of action selection can effectively explore actions based on past human responses. Moreover, the method of approximating the reward functions and transition functions are especially designed for human-robot interaction. Second, due to the fact that human preference can vary and reactions to the same robot behaviors are different from person to person, the rewards produced from the pre-constructed model should be modified online. To achieve this, we examine the correlation between the robot action and the human response, and then fine-tune the reward of the predictive model for adaptive learning. Third, natural human responses and the human’s interaction with the environment are considered in our work. In this way, the learning efficiency can be enhanced and the required human efforts for robot learning can be reduced.},
  issue = {2013年},
  langid = {英文},
  pagetotal = {1-69},
  keywords = {human-robot interaction,office robot,reinforcement learning,user adaptation,人機互動,使用者調適,加強式學習,辦公室機器人}
}

@inproceedings{liuImitationObservationLearning2018,
  title = {Imitation from {{Observation}}: {{Learning}} to {{Imitate Behaviors}} from {{Raw Video}} via {{Context Translation}}},
  shorttitle = {Imitation from {{Observation}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Liu, YuXuan and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  date = {2018-05},
  pages = {1118--1125},
  publisher = {{IEEE}},
  location = {{Brisbane, QLD}},
  doi = {10.1109/ICRA.2018.8462901},
  url = {https://ieeexplore.ieee.org/document/8462901/},
  urldate = {2023-03-23},
  eventtitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-5386-3081-5},
  file = {C:\Users\leemar\Zotero\storage\GZ8254V8\Liu et al. - 2018 - Imitation from Observation Learning to Imitate Be.pdf}
}

@article{liuImpedanceControlledVariableStiffness2020,
  title = {Impedance-{{Controlled Variable Stiffness Actuator}} for {{Lower Limb Robot Applications}}},
  author = {Liu, L. and Leonhardt, S. and Ngo, C. and Misgeld, B.J.E.},
  date = {2020},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {17},
  number = {2},
  pages = {991--1004},
  doi = {10.1109/TASE.2019.2954769},
  abstract = {We present a novel application of the variable stiffness actuator (VSA)-based assistance/rehabilitation robot-featured impedance control using a cascaded position torque control loop. The robot follows the adaptive impedance control paradigm, thereby achieving an adaptive assistance level according to human joint torque. The feedforward human joint torque command is used to cooperatively adjust the impedance controller and the stiffness trajectory of the VSA (this functional architecture is referred to as the cooperative control framework). In this way, the task performance during movement training can be improved regarding: 1) safety-for example, when the subject intends to contribute considerable effort, low-gain impedance control is activated with a low stiffness actuator to further decrease output impedance and 2) tracking performance-for example, for the subject with less effort, high-gain impedance control is used while pursuing high stiffness to enhance the torque bandwidth. Regarding the safety aspect, we demonstrate that the torque controller designed at low stiffness can be sensitive to the disturbance for low output impedance while maintaining tracking performance. A precondition for this is to treat the input disturbance separately. This is guaranteed by our previously proposed torque control of the VSA using the linear quadratic Gaussian technique. This approach is also employed here, but with additional discussion on the observer design to serve the proposed cooperative control approach. Here, the effectiveness of the proposed control system is experimentally verified using a VSA prototype and a one-degree-of-freedom lower limb exoskeleton worn by a human test person. Note to Practitioners-Control of 'physical human-robot interaction' can be achieved by the mechanical parts of the variable stiffness actuator (VSA). However, the mechanical construction for stiffness variation may limit the capacity to achieve low output stiffness and fast stiffness variation in speed. These limitations may become more evident in the assistance/rehabilitation robot applications. To overcome these limitations, the impedance control scheme can be employed to achieve a programmable impedance range and impedance variation speed. This control scheme has been widely applied on the fixed-compliance joint but lacks a way to be implemented on the VSA joint because of its existing capacity to control the impedance with the mechanical construction. This article presents a novel application of the impedance-controlled VSA used on a lower limb robot. We describe how to adjust the actuator stiffness to cooperatively work with the adaptive impedance control scheme. Based on our approach, the robot with the impedance-controlled VSA joint can extend the capacity of bandwidth and low output impedance. This is an improvement on the impedance-controlled fixed-compliance joint. The cooperative control framework presented here was tested on an exoskeleton system with two healthy test persons and is also applicable to other actuator prototypes. Future research aims to employ this system for actual patient training.}
}

@article{liuImpedanceControlledVariableStiffness2020a,
  title = {Impedance-{{Controlled Variable Stiffness Actuator}} for {{Lower Limb Robot Applications}}},
  author = {Liu, L. and Leonhardt, S. and Ngo, C. and Misgeld, B.J.E.},
  date = {2020},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {17},
  number = {2},
  pages = {991--1004},
  doi = {10.1109/TASE.2019.2954769},
  abstract = {We present a novel application of the variable stiffness actuator (VSA)-based assistance/rehabilitation robot-featured impedance control using a cascaded position torque control loop. The robot follows the adaptive impedance control paradigm, thereby achieving an adaptive assistance level according to human joint torque. The feedforward human joint torque command is used to cooperatively adjust the impedance controller and the stiffness trajectory of the VSA (this functional architecture is referred to as the cooperative control framework). In this way, the task performance during movement training can be improved regarding: 1) safety-for example, when the subject intends to contribute considerable effort, low-gain impedance control is activated with a low stiffness actuator to further decrease output impedance and 2) tracking performance-for example, for the subject with less effort, high-gain impedance control is used while pursuing high stiffness to enhance the torque bandwidth. Regarding the safety aspect, we demonstrate that the torque controller designed at low stiffness can be sensitive to the disturbance for low output impedance while maintaining tracking performance. A precondition for this is to treat the input disturbance separately. This is guaranteed by our previously proposed torque control of the VSA using the linear quadratic Gaussian technique. This approach is also employed here, but with additional discussion on the observer design to serve the proposed cooperative control approach. Here, the effectiveness of the proposed control system is experimentally verified using a VSA prototype and a one-degree-of-freedom lower limb exoskeleton worn by a human test person. Note to Practitioners-Control of 'physical human-robot interaction' can be achieved by the mechanical parts of the variable stiffness actuator (VSA). However, the mechanical construction for stiffness variation may limit the capacity to achieve low output stiffness and fast stiffness variation in speed. These limitations may become more evident in the assistance/rehabilitation robot applications. To overcome these limitations, the impedance control scheme can be employed to achieve a programmable impedance range and impedance variation speed. This control scheme has been widely applied on the fixed-compliance joint but lacks a way to be implemented on the VSA joint because of its existing capacity to control the impedance with the mechanical construction. This article presents a novel application of the impedance-controlled VSA used on a lower limb robot. We describe how to adjust the actuator stiffness to cooperatively work with the adaptive impedance control scheme. Based on our approach, the robot with the impedance-controlled VSA joint can extend the capacity of bandwidth and low output impedance. This is an improvement on the impedance-controlled fixed-compliance joint. The cooperative control framework presented here was tested on an exoskeleton system with two healthy test persons and is also applicable to other actuator prototypes. Future research aims to employ this system for actual patient training.}
}

@article{liuRecognizingHumanActions2018,
  title = {Recognizing {{Human Actions}} as the {{Evolution}} of {{Pose Estimation Maps}}},
  author = {Liu, Mengyuan and Yuan, Junsong},
  date = {2018},
  journaltitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages = {1159--1168},
  publisher = {{IEEE}},
  issn = {10636919},
  doi = {10.1109/CVPR.2018.00127},
  abstract = {Most video-based action recognition approaches choose to extract features from the whole video to recognize actions. The cluttered background and non-action motions limit the performances of these methods, since they lack the explicit modeling of human body movements. With recent advances of human pose estimation, this work presents a novel method to recognize human action as the evolution of pose estimation maps. Instead of relying on the inaccurate human poses estimated from videos, we observe that pose estimation maps, the byproduct of pose estimation, preserve richer cues of human body to benefit action recognition. Specifically, the evolution of pose estimation maps can be decomposed as an evolution of heatmaps, e.g., probabilistic maps, and an evolution of estimated 2D human poses, which denote the changes of body shape and body pose, respectively. Considering the sparse property of heatmap, we develop spatial rank pooling to aggregate the evolution of heatmaps as a body shape evolution image. As body shape evolution image does not differentiate body parts, we design body guided sampling to aggregate the evolution of poses as a body pose evolution image. The complementary properties between both types of images are explored by deep convolutional neural networks to predict action label. Experiments on NTU RGB+D, UTD-MHAD and PennAction datasets verify the effectiveness of our method, which outperforms most state-of-the-art methods.},
  isbn = {9781538664209}
}

@article{liuRecognizingHumanActions2018a,
  title = {Recognizing {{Human Actions}} as the {{Evolution}} of {{Pose Estimation Maps}}},
  author = {Liu, Mengyuan and Yuan, Junsong},
  date = {2018},
  journaltitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages = {1159--1168},
  publisher = {{IEEE}},
  issn = {10636919},
  doi = {10.1109/CVPR.2018.00127},
  abstract = {Most video-based action recognition approaches choose to extract features from the whole video to recognize actions. The cluttered background and non-action motions limit the performances of these methods, since they lack the explicit modeling of human body movements. With recent advances of human pose estimation, this work presents a novel method to recognize human action as the evolution of pose estimation maps. Instead of relying on the inaccurate human poses estimated from videos, we observe that pose estimation maps, the byproduct of pose estimation, preserve richer cues of human body to benefit action recognition. Specifically, the evolution of pose estimation maps can be decomposed as an evolution of heatmaps, e.g., probabilistic maps, and an evolution of estimated 2D human poses, which denote the changes of body shape and body pose, respectively. Considering the sparse property of heatmap, we develop spatial rank pooling to aggregate the evolution of heatmaps as a body shape evolution image. As body shape evolution image does not differentiate body parts, we design body guided sampling to aggregate the evolution of poses as a body pose evolution image. The complementary properties between both types of images are explored by deep convolutional neural networks to predict action label. Experiments on NTU RGB+D, UTD-MHAD and PennAction datasets verify the effectiveness of our method, which outperforms most state-of-the-art methods.},
  isbn = {9781538664209},
  file = {C:\Users\leemar\Zotero\storage\XXBJX7A8\Recognizing_Human_Actions_as_the_Evolution_of_Pose_Estimation_Maps.pdf}
}

@inproceedings{liuRecognizingHumanActions2018b,
  title = {Recognizing {{Human Actions}} as the {{Evolution}} of {{Pose Estimation Maps}}},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Liu, Mengyuan and Yuan, Junsong},
  date = {2018-06},
  pages = {1159--1168},
  publisher = {{IEEE}},
  location = {{Salt Lake City, UT, USA}},
  doi = {10.1109/CVPR.2018.00127},
  url = {https://ieeexplore.ieee.org/document/8578225/},
  urldate = {2023-03-15},
  abstract = {Most video-based action recognition approaches choose to extract features from the whole video to recognize actions. The cluttered background and non-action motions limit the performances of these methods, since they lack the explicit modeling of human body movements. With recent advances of human pose estimation, this work presents a novel method to recognize human action as the evolution of pose estimation maps. Instead of relying on the inaccurate human poses estimated from videos, we observe that pose estimation maps, the byproduct of pose estimation, preserve richer cues of human body to benefit action recognition. Specifically, the evolution of pose estimation maps can be decomposed as an evolution of heatmaps, e.g., probabilistic maps, and an evolution of estimated 2D human poses, which denote the changes of body shape and body pose, respectively. Considering the sparse property of heatmap, we develop spatial rank pooling to aggregate the evolution of heatmaps as a body shape evolution image. As body shape evolution image does not differentiate body parts, we design body guided sampling to aggregate the evolution of poses as a body pose evolution image. The complementary properties between both types of images are explored by deep convolutional neural networks to predict action label. Experiments on NTU RGB+D, UTD-MHAD and PennAction datasets verify the effectiveness of our method, which outperforms most state-of-the-art methods.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-6420-9},
  langid = {english}
}

@article{liuUnifiedIntentionInference2022,
  title = {Unified {{Intention Inference}} and {{Learning}} for {{Human}}–{{Robot Cooperative Assembly}}},
  author = {Liu, Tingting and Lyu, Erli and Wang, Jiaole and Meng, Max Q.-H.},
  date = {2022-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {19},
  number = {3},
  pages = {2256--2266},
  issn = {1545-5955},
  doi = {10.1109/TASE.2021.3077255},
  url = {https://ieeexplore.ieee.org/document/9432792/},
  abstract = {Collaborative robots are widely utilized in intelligent manufacturing to cooperate with the human to accomplish different assembly tasks. To improve the efficiency of human-robot cooperation, robots should be able to recognize human intentions and provide necessary assistance proactively. The major challenge for current human intention recognition methods is that they only deal with known human intentions of predefined tasks and lack of ability to learn unknown intentions corresponding to new tasks. This article introduces an evolving hidden Markov model (EHMM)-based approach to learn new human intentions incrementally by carrying out structure and parameter updating based on the observed sequence, in parallel with the recognition. The incremental learning ability makes it applicable in dynamic environments with changing tasks. A set of assistive execution policies has been developed for the robot to provide appropriate assistance to the human partner based on the intention recognition results in real time. Experiments have been carried out to verify the effectiveness of our approach in human-robot cooperative assembly tasks. The results show very high recognition accuracy (≥95.45\%), and the human subjects show their high satisfaction with the intention learning ability of the proposed approach. Note to Practitioners - This article aims to effectively improve the productivity of human-robot cooperation by exploiting human adaptability and robot repeatability. Smooth cooperation requires the peer robot to provide proactive assistance to humans by inferring human intention after training. Moreover, the robot should also be able to learn untrained intentions online by human demonstrations. This is made possible by our proposed evolving hidden Markov model (EHMM) that unifies intention inference and incremental learning. Simplified cooperative assembly tasks have been designed to verify the proposed unified intention inference and learning model. A robotic assembly platform has been introduced to integrate the proposed EHMM with a perception module and a collaborative manipulation module. We have demonstrated, through experiments and surveys, that the proposed approach can promote efficacy and acceptance of human-robot cooperative assembly.}
}

@article{liuUnifiedIntentionInference2022a,
  title = {Unified {{Intention Inference}} and {{Learning}} for {{Human}}–{{Robot Cooperative Assembly}}},
  author = {Liu, Tingting and Lyu, Erli and Wang, Jiaole and Meng, Max Q.-H.},
  date = {2022-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {19},
  number = {3},
  pages = {2256--2266},
  issn = {1545-5955},
  doi = {10.1109/TASE.2021.3077255},
  url = {https://ieeexplore.ieee.org/document/9432792/},
  abstract = {Collaborative robots are widely utilized in intelligent manufacturing to cooperate with the human to accomplish different assembly tasks. To improve the efficiency of human-robot cooperation, robots should be able to recognize human intentions and provide necessary assistance proactively. The major challenge for current human intention recognition methods is that they only deal with known human intentions of predefined tasks and lack of ability to learn unknown intentions corresponding to new tasks. This article introduces an evolving hidden Markov model (EHMM)-based approach to learn new human intentions incrementally by carrying out structure and parameter updating based on the observed sequence, in parallel with the recognition. The incremental learning ability makes it applicable in dynamic environments with changing tasks. A set of assistive execution policies has been developed for the robot to provide appropriate assistance to the human partner based on the intention recognition results in real time. Experiments have been carried out to verify the effectiveness of our approach in human-robot cooperative assembly tasks. The results show very high recognition accuracy (≥95.45\%), and the human subjects show their high satisfaction with the intention learning ability of the proposed approach. Note to Practitioners - This article aims to effectively improve the productivity of human-robot cooperation by exploiting human adaptability and robot repeatability. Smooth cooperation requires the peer robot to provide proactive assistance to humans by inferring human intention after training. Moreover, the robot should also be able to learn untrained intentions online by human demonstrations. This is made possible by our proposed evolving hidden Markov model (EHMM) that unifies intention inference and incremental learning. Simplified cooperative assembly tasks have been designed to verify the proposed unified intention inference and learning model. A robotic assembly platform has been introduced to integrate the proposed EHMM with a perception module and a collaborative manipulation module. We have demonstrated, through experiments and surveys, that the proposed approach can promote efficacy and acceptance of human-robot cooperative assembly.},
  file = {C:\Users\leemar\Zotero\storage\6XKCM7VT\Unified_Intention_Inference_and_Learning_for_HumanRobot_Cooperative_Assembly.pdf}
}

@inproceedings{livingstoneCaseMassCustomisation2015,
  title = {The Case for Mass Customisation of Structural Timber Design},
  booktitle = {Structures {{Congress}} 2015 - {{Proceedings}} of the 2015 {{Structures Congress}}},
  author = {Livingstone, A. and Menendez, J. and Leitch, K. and Hairstans, R.},
  date = {2015},
  pages = {2804--2814},
  doi = {10.1061/9780784479117.243},
  abstract = {This paper reports on the potential of timber for structural applications in the international construction market, particularly in the light of its environmental credentials and the advances being made in engineered timber products. The UK market is examined with a specific emphasis on the residential sector, given the target of the UK Government to deliver three million new energy-efficient zero carbon and sustainably built homes by 2020, with a 33\% reduction in combined initial and whole life cost of the constructed asset. The paper also reports on the work being undertaken to remove the barriers to timber specification for such applications, through the provision of structural design and detailing tools. These new tools allow a mass customised approach to be taken, facilitate research into practice and improve design efficiency through simplification.},
  isbn = {978-0-7844-7911-7}
}

@inproceedings{livingstoneCaseMassCustomisation2015a,
  title = {The Case for Mass Customisation of Structural Timber Design},
  booktitle = {Structures {{Congress}} 2015 - {{Proceedings}} of the 2015 {{Structures Congress}}},
  author = {Livingstone, A. and Menendez, J. and Leitch, K. and Hairstans, R.},
  date = {2015},
  pages = {2804--2814},
  doi = {10.1061/9780784479117.243},
  abstract = {This paper reports on the potential of timber for structural applications in the international construction market, particularly in the light of its environmental credentials and the advances being made in engineered timber products. The UK market is examined with a specific emphasis on the residential sector, given the target of the UK Government to deliver three million new energy-efficient zero carbon and sustainably built homes by 2020, with a 33\% reduction in combined initial and whole life cost of the constructed asset. The paper also reports on the work being undertaken to remove the barriers to timber specification for such applications, through the provision of structural design and detailing tools. These new tools allow a mass customised approach to be taken, facilitate research into practice and improve design efficiency through simplification.},
  isbn = {978-0-7844-7911-7}
}

@inproceedings{livingstoneMultidimensionalDataFitting2016,
  title = {Multi-Dimensional Data Fitting for the Structural Design of a Simple Timber Connection},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Livingstone, A. and Patlakas, P. and Milne, M. and Smith, S. and Hairstans, R.},
  date = {2016},
  abstract = {This paper presents a novel method of automating the structural design of timber connections and ensuring code compliance within a Building Information Modelling (BIM) context. The mathematical method of Multi-Dimensional Data Fitting (MDDF) is presented and applied in a proof-of-concept example of a simple timber connection. The requirements of MDDF for this example are presented, together with a custom software environment built within Matlab to generate the fitting equation. Issues of dataset selection and high dimensionality are discussed and the fitting process is described in detail. The validation and verification of the resulting equation are presented, drawing on existing laboratory work. A proof-of-concept integration in a BIM environment is presented, demonstrating the benefits MDDF can have for Automatic Code Compliance (ACC). The paper closes by discussing the future potential of MDDF/BIM integration.},
  isbn = {978-3-903039-00-1}
}

@inproceedings{livingstoneMultidimensionalDataFitting2016a,
  title = {Multi-Dimensional Data Fitting for the Structural Design of a Simple Timber Connection},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Livingstone, A. and Patlakas, P. and Milne, M. and Smith, S. and Hairstans, R.},
  date = {2016},
  abstract = {This paper presents a novel method of automating the structural design of timber connections and ensuring code compliance within a Building Information Modelling (BIM) context. The mathematical method of Multi-Dimensional Data Fitting (MDDF) is presented and applied in a proof-of-concept example of a simple timber connection. The requirements of MDDF for this example are presented, together with a custom software environment built within Matlab to generate the fitting equation. Issues of dataset selection and high dimensionality are discussed and the fitting process is described in detail. The validation and verification of the resulting equation are presented, drawing on existing laboratory work. A proof-of-concept integration in a BIM environment is presented, demonstrating the benefits MDDF can have for Automatic Code Compliance (ACC). The paper closes by discussing the future potential of MDDF/BIM integration.},
  isbn = {978-3-903039-00-1}
}

@inproceedings{lobosBIMWoodIntegration2018,
  title = {{{BIM}} and Wood Integration. {{New}} Possibilities for {{AEC}} Industry},
  booktitle = {{{WCTE}} 2018 - {{World Conference}} on {{Timber Engineering}}},
  author = {Lobos, D. and Pino, F. and Codron, C. and Nuñez, V. and Sierra, A.},
  date = {2018},
  abstract = {This research conducts several literature reviews (book, journals, and congresses) and extensive software tests (BIM software: Revit, Archicad, Tekla, and Wood plug-ins: AGACAD, Archiframe, Timber Framing 2015, WoodStud Frame, etc.), the state-of-the-art was assessed in both fields, several cases linking BIM and wood are shown in detail and discussed, various theoretical samples are modelled and shown, and the advantages and disadvantages of each technique and stage are explained. It discusses the question about the usability of BIM methodologies for wood design and construction. Several academic and research initiatives are reviewed, and the paper aims to establish an appropriate link between two agendas that the architecture, engineering, and construction (AEC) industry, academia, and governments normally handle separately. Final conclusions are that BIM for Wood has been used more frequently in academia and that both fields have several common processes and, in many cases, only a few BIM-wood tools have been used, disregarding the high potential of these methodologies for the complete building life cycle (design, construction, and operation).}
}

@inproceedings{lobosBIMWoodIntegration2018a,
  title = {{{BIM}} and Wood Integration. {{New}} Possibilities for {{AEC}} Industry},
  booktitle = {{{WCTE}} 2018 - {{World Conference}} on {{Timber Engineering}}},
  author = {Lobos, D. and Pino, F. and Codron, C. and Nuñez, V. and Sierra, A.},
  date = {2018},
  abstract = {This research conducts several literature reviews (book, journals, and congresses) and extensive software tests (BIM software: Revit, Archicad, Tekla, and Wood plug-ins: AGACAD, Archiframe, Timber Framing 2015, WoodStud Frame, etc.), the state-of-the-art was assessed in both fields, several cases linking BIM and wood are shown in detail and discussed, various theoretical samples are modelled and shown, and the advantages and disadvantages of each technique and stage are explained. It discusses the question about the usability of BIM methodologies for wood design and construction. Several academic and research initiatives are reviewed, and the paper aims to establish an appropriate link between two agendas that the architecture, engineering, and construction (AEC) industry, academia, and governments normally handle separately. Final conclusions are that BIM for Wood has been used more frequently in academia and that both fields have several common processes and, in many cases, only a few BIM-wood tools have been used, disregarding the high potential of these methodologies for the complete building life cycle (design, construction, and operation).}
}

@book{lohmeierHumanoidWalkingRobot2008,
  title = {Humanoid Walking Robot {{LOLA}}},
  author = {Lohmeier, S. and Buschmann, T. and Ulbrich, H. and Pfeiffer, F.},
  date = {2008},
  journaltitle = {VDI Berichte},
  number = {2012},
  abstract = {This paper presents the performance enhanced humanoid robot LOLA. The goal of the project is the realization of a fast, human-like walking motion. The robot has 22 degrees of freedom, including 7-DoF legs with actively driven toe joints. It is characterized by its lightweight construction, a modular, multi-sensory joint design with AC servo motors and an electronics architecture using decentralized joint controllers. Special emphasis was paid on an improved mass distribution of the leg apparatus to achieve good dynamic performance. The sensor system comprises absolute angular sensors in all links, two custom-made force/torque sensors in the feet and a high-precision inertial sensor on the upper body. The trajectory generation and control system currently being developed aim at faster, more flexible, and more robust walking patterns.},
  isbn = {978-3-18-092012-2},
  pagetotal = {291-292}
}

@book{lohmeierHumanoidWalkingRobot2008a,
  title = {Humanoid Walking Robot {{LOLA}}},
  author = {Lohmeier, S. and Buschmann, T. and Ulbrich, H. and Pfeiffer, F.},
  date = {2008},
  journaltitle = {VDI Berichte},
  number = {2012},
  abstract = {This paper presents the performance enhanced humanoid robot LOLA. The goal of the project is the realization of a fast, human-like walking motion. The robot has 22 degrees of freedom, including 7-DoF legs with actively driven toe joints. It is characterized by its lightweight construction, a modular, multi-sensory joint design with AC servo motors and an electronics architecture using decentralized joint controllers. Special emphasis was paid on an improved mass distribution of the leg apparatus to achieve good dynamic performance. The sensor system comprises absolute angular sensors in all links, two custom-made force/torque sensors in the feet and a high-precision inertial sensor on the upper body. The trajectory generation and control system currently being developed aim at faster, more flexible, and more robust walking patterns.},
  isbn = {978-3-18-092012-2},
  pagetotal = {291-292}
}

@article{loiannoAutonomousFlightCooperative2018,
  title = {Autonomous Flight and Cooperative Control for Reconstruction Using Aerial Robots Powered by Smartphones},
  author = {Loianno, G. and Mulgaonkar, Y. and Brunner, C. and Ahuja, D. and Ramanandan, A. and Chari, M. and Diaz, S. and Kumar, V.},
  date = {2018},
  journaltitle = {International Journal of Robotics Research},
  volume = {37},
  number = {11},
  pages = {1341--1358},
  doi = {10.1177/0278364918774136},
  abstract = {Advances in consumer electronics products and the technology seen in personal computers, digital cameras, and smartphones phones have led to the price/performance ratio of sensors and processors falling dramatically over the last decade. In particular, many consumer products are packaged with small cameras, gyroscopes, and accelerometers, all sensors that are needed for autonomous robots in GPS-denied environments. The low mass and small form factor make them particularly well suited for autonomous flight with small flying robots. In this work, we present the first fully autonomous smartphone-based system for quadrotors. We show how multiple quadrotors can be stabilized and controlled to achieve autonomous flight in indoor buildings with application to smart homes, search and rescue, monitoring construction projects, and developing models for architecture design. In our work, the computation for sensing and control runs on an off-the-shelf smartphone, with all the software functionality embedded in a smartphone app. No additional sensors or processors are required for autonomous flight. We are also able to use multiple, coordinated autonomous aerial vehicles to improve the efficiency of our mission. In our framework, multiple vehicles are able to plan safe trajectories avoiding inter-robot collisions, while concurrently building in a cooperative manner a three-dimensional map of the environment. The work allows any consumer with any number of robots equipped with smartphones to autonomously drive a team of quadrotor robots, even without GPS, by downloading our app and cooperatively build three-dimensional maps.}
}

@article{loiannoAutonomousFlightCooperative2018a,
  title = {Autonomous Flight and Cooperative Control for Reconstruction Using Aerial Robots Powered by Smartphones},
  author = {Loianno, G. and Mulgaonkar, Y. and Brunner, C. and Ahuja, D. and Ramanandan, A. and Chari, M. and Diaz, S. and Kumar, V.},
  date = {2018},
  journaltitle = {International Journal of Robotics Research},
  volume = {37},
  number = {11},
  pages = {1341--1358},
  doi = {10.1177/0278364918774136},
  abstract = {Advances in consumer electronics products and the technology seen in personal computers, digital cameras, and smartphones phones have led to the price/performance ratio of sensors and processors falling dramatically over the last decade. In particular, many consumer products are packaged with small cameras, gyroscopes, and accelerometers, all sensors that are needed for autonomous robots in GPS-denied environments. The low mass and small form factor make them particularly well suited for autonomous flight with small flying robots. In this work, we present the first fully autonomous smartphone-based system for quadrotors. We show how multiple quadrotors can be stabilized and controlled to achieve autonomous flight in indoor buildings with application to smart homes, search and rescue, monitoring construction projects, and developing models for architecture design. In our work, the computation for sensing and control runs on an off-the-shelf smartphone, with all the software functionality embedded in a smartphone app. No additional sensors or processors are required for autonomous flight. We are also able to use multiple, coordinated autonomous aerial vehicles to improve the efficiency of our mission. In our framework, multiple vehicles are able to plan safe trajectories avoiding inter-robot collisions, while concurrently building in a cooperative manner a three-dimensional map of the environment. The work allows any consumer with any number of robots equipped with smartphones to autonomously drive a team of quadrotor robots, even without GPS, by downloading our app and cooperatively build three-dimensional maps.}
}

@book{longakerRhetoricRepublicPolitics2007,
  title = {Rhetoric and the Republic: {{Politics}}, Civic Discourse and Education in Early {{America}}},
  author = {Longaker, M. G.},
  date = {2007},
  journaltitle = {Rhetoric and The Republic: Politics, Civic Discourse and Education in Early America},
  abstract = {Contemporary efforts to revitalize the civic mission of higher education in America have revived an age-old republican tradition of teaching students to be responsible citizens, particularly through the study of rhetoric, composition, and oratory. This book examines the political, cultural, economic, and religious agendas that drove the various-and often conflicting-curricula and contrasting visions of what good citizenship entails. Mark Garrett Longaker argues that higher education more than 200 years ago allowed actors with differing political and economic interests to wrestle over the fate of American citizenship. Then, as today, there was widespread agreement that civic training was essential in higher education, but there were also sharp differences in the various visions of what proper republic citizenship entailed and how to prepare for it. Longaker studies in detail the specific trends in rhetorical education offered at various early institutions-such as Yale, Columbia, Pennsylvania, and William and Mary-with analyses of student lecture notes, classroom activities, disputation exercises, reading lists, lecture outlines, and literary society records. These documents reveal an extraordinary range of economic and philosophical interests and allegiances-agrarian, commercial, spiritual, communal, and belletristic-specific to each institution. The findings challenge and complicate a widely held belief that early-American civic education occurred in a halcyon era of united democratic republicanism. Recognition that there are multiple ways to practice democratic citizenship and to enact democratic discourse, historically as well as today, best serves the goal of civic education, Longaker argues. Rhetoric and the Republic illuminates an important historical moment in the history of American education and dramatically highlights rhetorical education as a key site in the construction of democracy. © 2007 by University of Alabama Press. All rights reserved.},
  isbn = {978-0-8173-1547-4},
  pagetotal = {1-266}
}

@book{longakerRhetoricRepublicPolitics2007a,
  title = {Rhetoric and the Republic: {{Politics}}, Civic Discourse and Education in Early {{America}}},
  author = {Longaker, M.G.},
  date = {2007},
  journaltitle = {Rhetoric and The Republic: Politics, Civic Discourse and Education in Early America},
  abstract = {Contemporary efforts to revitalize the civic mission of higher education in America have revived an age-old republican tradition of teaching students to be responsible citizens, particularly through the study of rhetoric, composition, and oratory. This book examines the political, cultural, economic, and religious agendas that drove the various-and often conflicting-curricula and contrasting visions of what good citizenship entails. Mark Garrett Longaker argues that higher education more than 200 years ago allowed actors with differing political and economic interests to wrestle over the fate of American citizenship. Then, as today, there was widespread agreement that civic training was essential in higher education, but there were also sharp differences in the various visions of what proper republic citizenship entailed and how to prepare for it. Longaker studies in detail the specific trends in rhetorical education offered at various early institutions-such as Yale, Columbia, Pennsylvania, and William and Mary-with analyses of student lecture notes, classroom activities, disputation exercises, reading lists, lecture outlines, and literary society records. These documents reveal an extraordinary range of economic and philosophical interests and allegiances-agrarian, commercial, spiritual, communal, and belletristic-specific to each institution. The findings challenge and complicate a widely held belief that early-American civic education occurred in a halcyon era of united democratic republicanism. Recognition that there are multiple ways to practice democratic citizenship and to enact democratic discourse, historically as well as today, best serves the goal of civic education, Longaker argues. Rhetoric and the Republic illuminates an important historical moment in the history of American education and dramatically highlights rhetorical education as a key site in the construction of democracy. © 2007 by University of Alabama Press. All rights reserved.},
  isbn = {978-0-8173-1547-4},
  pagetotal = {1-266}
}

@inproceedings{lopezParticipatoryActionResearch2018,
  title = {Participatory Action Research as a Methodology for the Development of Appropriate Technologies by Communities},
  booktitle = {Proceedings of the 60th {{Annual Meeting}} of the {{International Society}} for the {{Systems Sciences}}, {{ISSS}} 2016},
  author = {López, A. E. A. and Cajiao, M. C. R. and Mejía, M. P. and Durán, L. F. P. and Díaz, E. E. E.},
  date = {2018},
  abstract = {The social and environmental development potential of countries like Colombia shows the need to articulate right from the communities, the processes and projects relevant to their territories. Furthermore when vital aspects of human health, such as access to clean water and water consumption, are also opportunities for the development of innovative technological solutions, stemming from the relationship between society and natural systems. In this context, a group of researchers together with a community of about 1,500 children and 15 teachers from schools of several towns in Cundinamarca department (Colombia) has been developing a technological platform founded on the community-based action research proposal of Ernest Stringer. This interactive technological platform, based on the use of SMS and the web, is called “La Liga del Agua”. It is a jointly constructed space where synergies between the different stakeholders around the proper use of water resources can arise, based on the self-recognition of wastewater problems on each of the participants’ homes. Thus, the problem approaches from the daily practices and the technological inefficiency, generating an empowerment of the water importance. The main theoretical foundation of this technological co-construction is based on the spirit of participatory and democratic systemic intervention, from the soft systems methodology of Peter Checkland, as well as the sociocultural vision of the community that, voluntarily, intend to solve a problem collectively, as suggested by Rusell Ackoff. In this article, we will show the jointly design process of “La Liga del Agua” platform and the incidence on the increase of the good practices of water resources usage. In addition, the results of the teaching strategies and recreational activities that seek to increase the empowerment by the actors and their interaction with the technology will be presented. To conclude, all the learnings of the proposal will be introduced, so it can be replicated on other contexts with environmental concerns.},
  isbn = {978-1-906740-14-6}
}

@inproceedings{lopezParticipatoryActionResearch2018a,
  title = {Participatory Action Research as a Methodology for the Development of Appropriate Technologies by Communities},
  booktitle = {Proceedings of the 60th {{Annual Meeting}} of the {{International Society}} for the {{Systems Sciences}}, {{ISSS}} 2016},
  author = {López, A.E.A. and Cajiao, M.C.R. and Mejía, M.P. and Durán, L.F.P. and Díaz, E.E.E.},
  date = {2018},
  abstract = {The social and environmental development potential of countries like Colombia shows the need to articulate right from the communities, the processes and projects relevant to their territories. Furthermore when vital aspects of human health, such as access to clean water and water consumption, are also opportunities for the development of innovative technological solutions, stemming from the relationship between society and natural systems. In this context, a group of researchers together with a community of about 1,500 children and 15 teachers from schools of several towns in Cundinamarca department (Colombia) has been developing a technological platform founded on the community-based action research proposal of Ernest Stringer. This interactive technological platform, based on the use of SMS and the web, is called “La Liga del Agua”. It is a jointly constructed space where synergies between the different stakeholders around the proper use of water resources can arise, based on the self-recognition of wastewater problems on each of the participants’ homes. Thus, the problem approaches from the daily practices and the technological inefficiency, generating an empowerment of the water importance. The main theoretical foundation of this technological co-construction is based on the spirit of participatory and democratic systemic intervention, from the soft systems methodology of Peter Checkland, as well as the sociocultural vision of the community that, voluntarily, intend to solve a problem collectively, as suggested by Rusell Ackoff. In this article, we will show the jointly design process of “La Liga del Agua” platform and the incidence on the increase of the good practices of water resources usage. In addition, the results of the teaching strategies and recreational activities that seek to increase the empowerment by the actors and their interaction with the technology will be presented. To conclude, all the learnings of the proposal will be introduced, so it can be replicated on other contexts with environmental concerns.},
  isbn = {978-1-906740-14-6}
}

@inproceedings{Lorenz2011198,
  title = {Synchronization in a Goal-Directed Task: {{Human}} Movement Coordination with Each Other and Robotic Partners},
  author = {Lorenz, T. and Mortl, A. and Vlaskamp, B. and Schubo, A. and Hirche, S.},
  date = {2011},
  series = {Proceedings - {{IEEE International Workshop}} on {{Robot}} and {{Human Interactive Communication}}},
  pages = {198--203},
  doi = {10.1109/ROMAN.2011.6005253},
  art_number = {6005253}
}

@article{loseyReviewIntentDetection2018,
  title = {A Review of Intent Detection, Arbitration, and Communication Aspects of Shared Control for Physical Human–Robot Interaction},
  author = {Losey, Dylan P. and McDonald, Craig G. and Battaglia, Edoardo and O’Malley, Marcia K.},
  date = {2018},
  journaltitle = {Applied Mechanics Reviews},
  volume = {70},
  number = {1},
  pages = {1--19},
  issn = {00036900},
  doi = {10.1115/1.4039145},
  abstract = {As robotic devices are applied to problems beyond traditional manufacturing and industrial settings, we find that interaction between robots and humans, especially physical interaction, has become a fast developing field. Consider the application of robotics in healthcare, where we find telerobotic devices in the operating room facilitating dexterous surgical procedures, exoskeletons in the rehabilitation domain as walking aids and upper-limb movement assist devices, and even robotic limbs that are physically integrated with amputees who seek to restore their independence and mobility. In each of these scenarios, the physical coupling between human and robot, often termed physical human robot interaction (pHRI), facilitates new human performance capabilities and creates an opportunity to explore the sharing of task execution and control between humans and robots. In this review, we provide a unifying view of human and robot sharing task execution in scenarios where collaboration and cooperation between the two entities are necessary, and where the physical coupling of human and robot is a vital aspect. We define three key themes that emerge in these shared control scenarios, namely, intent detection, arbitration, and feedback. First, we explore methods for how the coupled pHRI system can detect what the human is trying to do, and how the physical coupling itself can be leveraged to detect intent. Second, once the human intent is known, we explore techniques for sharing and modulating control of the coupled system between robot and human operator. Finally, we survey methods for informing the human operator of the state of the coupled system, or the characteristics of the environment with which the pHRI system is interacting. At the conclusion of the survey, we present two case studies that exemplify shared control in pHRI systems, and specifically highlight the approaches used for the three key themes of intent detection, arbitration, and feedback for applications of upper limb robotic rehabilitation and haptic feedback from a robotic prosthesis for the upper limb.}
}

@article{loseyReviewIntentDetection2018a,
  title = {A Review of Intent Detection, Arbitration, and Communication Aspects of Shared Control for Physical Human–Robot Interaction},
  author = {Losey, Dylan P. and McDonald, Craig G. and Battaglia, Edoardo and O’Malley, Marcia K.},
  date = {2018},
  journaltitle = {Applied Mechanics Reviews},
  volume = {70},
  number = {1},
  pages = {1--19},
  issn = {00036900},
  doi = {10.1115/1.4039145},
  abstract = {As robotic devices are applied to problems beyond traditional manufacturing and industrial settings, we find that interaction between robots and humans, especially physical interaction, has become a fast developing field. Consider the application of robotics in healthcare, where we find telerobotic devices in the operating room facilitating dexterous surgical procedures, exoskeletons in the rehabilitation domain as walking aids and upper-limb movement assist devices, and even robotic limbs that are physically integrated with amputees who seek to restore their independence and mobility. In each of these scenarios, the physical coupling between human and robot, often termed physical human robot interaction (pHRI), facilitates new human performance capabilities and creates an opportunity to explore the sharing of task execution and control between humans and robots. In this review, we provide a unifying view of human and robot sharing task execution in scenarios where collaboration and cooperation between the two entities are necessary, and where the physical coupling of human and robot is a vital aspect. We define three key themes that emerge in these shared control scenarios, namely, intent detection, arbitration, and feedback. First, we explore methods for how the coupled pHRI system can detect what the human is trying to do, and how the physical coupling itself can be leveraged to detect intent. Second, once the human intent is known, we explore techniques for sharing and modulating control of the coupled system between robot and human operator. Finally, we survey methods for informing the human operator of the state of the coupled system, or the characteristics of the environment with which the pHRI system is interacting. At the conclusion of the survey, we present two case studies that exemplify shared control in pHRI systems, and specifically highlight the approaches used for the three key themes of intent detection, arbitration, and feedback for applications of upper limb robotic rehabilitation and haptic feedback from a robotic prosthesis for the upper limb.},
  file = {C:\Users\leemar\Zotero\storage\BZCLWX7K\amr_070_01_010804.pdf}
}

@article{lublasserRoboticApplicationFoam2018,
  title = {Robotic Application of Foam Concrete onto Bare Wall Elements - {{Analysis}}, Concept and Robotic Experiments},
  author = {Lublasser, E. and Adams, T. and Vollpracht, A. and Brell-Cokcan, S.},
  date = {2018},
  journaltitle = {Automation in Construction},
  volume = {89},
  pages = {299--306},
  doi = {10.1016/j.autcon.2018.02.005},
  abstract = {In the course of frequently altering energy saving regulations, numerous buildings have to be comprehensively refurbished to meet the rising energy-efficiency standards in order to protect the global environment and to save resources. However, available materials as well as adaptable design concepts for additional energy-saving insulation layers are not yet convincing in terms of their long term recyclability or variation of shape. Therefore, we investigate the application of foam concrete onto bare walls of existing buildings to gain a façade finish which is highly insulating, easily recyclable and at the same time promises to be individually designable due to the properties of the raw material mixture. To ensure controllable as well as reproducible application and to react to changing working methods in architecture and construction, the research focuses on the automatized application of foam concrete using a robotic setup. We analyzed manual application strategies of foam concrete, considering parameters of handcraft, used tools as well as the reaction on varying material characteristics during application. Based on the analysis results, we present a concept for the robotic application of foam concrete, including suggestions regarding end effectors, robot programming and surface design planning.}
}

@article{lublasserRoboticApplicationFoam2018a,
  title = {Robotic Application of Foam Concrete onto Bare Wall Elements - {{Analysis}}, Concept and Robotic Experiments},
  author = {Lublasser, E. and Adams, T. and Vollpracht, A. and Brell-Cokcan, S.},
  date = {2018},
  journaltitle = {Automation in Construction},
  volume = {89},
  pages = {299--306},
  doi = {10.1016/j.autcon.2018.02.005},
  abstract = {In the course of frequently altering energy saving regulations, numerous buildings have to be comprehensively refurbished to meet the rising energy-efficiency standards in order to protect the global environment and to save resources. However, available materials as well as adaptable design concepts for additional energy-saving insulation layers are not yet convincing in terms of their long term recyclability or variation of shape. Therefore, we investigate the application of foam concrete onto bare walls of existing buildings to gain a façade finish which is highly insulating, easily recyclable and at the same time promises to be individually designable due to the properties of the raw material mixture. To ensure controllable as well as reproducible application and to react to changing working methods in architecture and construction, the research focuses on the automatized application of foam concrete using a robotic setup. We analyzed manual application strategies of foam concrete, considering parameters of handcraft, used tools as well as the reaction on varying material characteristics during application. Based on the analysis results, we present a concept for the robotic application of foam concrete, including suggestions regarding end effectors, robot programming and surface design planning.}
}

@article{lucasPermanentVisualWork2020,
  title = {Permanent Visual Work Disabilities: 321 Cases Review | {{Incapacidades}} Laborales Permanentes de Causas Visuales. {{Revisión}} de 321 Casos},
  author = {family=Lucas, given=J. A. Menéndez, prefix=de, useprefix=false and Navarro, A. Castell},
  date = {2020},
  journaltitle = {Archivos de la Sociedad Espanola de Oftalmologia},
  volume = {95},
  number = {3},
  pages = {130--137},
  doi = {10.1016/j.oftal.2019.12.013},
  abstract = {Introduction: Visual diseases are the fifth more frequent cause of labour permanent disability, what represents 4\% of the total of them. In order to assess these cases we must take into account on one hand the visual requirements of each profession, and on the other hand the visual functional impairments that the worker is suffering. Special attention must be paid to situations of legal blindness and low vision, as a cause of serious disabilities. Despite the importance of the matter, we have hardly found any reviews about it in the consulted bibliography. Materials and methods: We have carried out a retrospective research of 321 disability claims due to ocular causes, assessed at the Ophthalmology Section of the Forensic Medical Clinic of Madrid, in the last 18 years. They account for 3\% of the total disability claims raised in our field. Results: The most frequent professions involved have been administrative services, construction, hotel workers, cleaning and professional drivers. In 90\% of cases these professional activities had medium or low visual requirements. The plaintiff in 40\% of cases was unemployed. The most frequent visual pathologies we found out were myopic complications (especially myopic maculopathy) 17\%, and eye trauma (16\%). To a lesser extent: retinal detachment (12\%), optic neuritis (7\%), glaucoma (6\%), diabetic retinopathy (6\%), pigmentary retinitis (4\%), non-myopic maculopathies (2\%) and melanomas (2\%). In 23\% of cases no significant visual limitation was found (it was lower than 33\%). Out of these, 9\% were diagnosed as NOVL (non-organic visual loss), 3\% of them being very obvious cases of simulation. Conclusions: In 82\% of the cases the expert's report pointed out a significant global (visual and non-visual) functional limitation (greater than 33\%) of their work capacity. In the previous administrative phase of all these cases the recognition fo disability had not been granted. From the results obtained it turns out the importance of an ophthalmologist acting as an expert in this type of demands.}
}

@inproceedings{luczkowskiDigitalWorkflowsVs2019,
  title = {Digital Workflows vs. Spatial Structures Design},
  booktitle = {{{IABSE Symposium}}, {{Guimaraes}} 2019: {{Towards}} a {{Resilient Built Environment Risk}} and {{Asset Management}} - {{Report}}},
  author = {Luczkowski, M. and Dyvik, S.H. and Mork, J.H. and Rønnquist, A.N.},
  date = {2019},
  pages = {563--569},
  abstract = {Digital workflows are already widely used by the designers (architects and engineers) in creating a better Building Information Modelling (BIM) data flow. In the core of this design method is a parametric model, which thanks to open source software can be easily customized according to the project or user needs. Shell or gridshell structures are very sensitive on the external loads, due to the low weight and big span. The accuracy and reliability are therefore a crucial point in design. More and more architects are using parametrical models, based on visual programing (like Grasshopper or Dynamo) to develop form of spatial structure. The parametric model in shell design gives a high precision in creating BIM model and is the starting point for the structural analysis. In this paper we will present a design method, in which the parametric model is not only the starting point for structural analysis. Thanks to a well-established digital workflow it can occur, that structural analysis is made simultaneously with architectural form finding of the shell. The digital workflow, developed by our research group is based on the Finite Element Method (FEM). The design methodology is to create two kind of structural analyses. The first one, called global, is using beam elements to investigate the general forces and deformations. The second one, called local, is using solid/volume elements to investigate the connection solution. Thanks to fast information transfer between this two analysis and automation of this process, the architect can achieve information about feasibility of the whole designed structure in real time. To validate our approach the timber gridshell was designed. The structure with nontrivial shape and customized each of the 61 nodes, was build in 2016 in Trondheim. The nodes were manufactured with usage of the 3D printing technology.},
  isbn = {978-3-85748-163-5}
}

@inproceedings{luczkowskiDigitalWorkflowsVs2019a,
  title = {Digital Workflows vs. Spatial Structures Design},
  booktitle = {{{IABSE Symposium}}, {{Guimaraes}} 2019: {{Towards}} a {{Resilient Built Environment Risk}} and {{Asset Management}} - {{Report}}},
  author = {Luczkowski, M. and Dyvik, S.H. and Mork, J.H. and Rønnquist, A.N.},
  date = {2019},
  pages = {563--569},
  abstract = {Digital workflows are already widely used by the designers (architects and engineers) in creating a better Building Information Modelling (BIM) data flow. In the core of this design method is a parametric model, which thanks to open source software can be easily customized according to the project or user needs. Shell or gridshell structures are very sensitive on the external loads, due to the low weight and big span. The accuracy and reliability are therefore a crucial point in design. More and more architects are using parametrical models, based on visual programing (like Grasshopper or Dynamo) to develop form of spatial structure. The parametric model in shell design gives a high precision in creating BIM model and is the starting point for the structural analysis. In this paper we will present a design method, in which the parametric model is not only the starting point for structural analysis. Thanks to a well-established digital workflow it can occur, that structural analysis is made simultaneously with architectural form finding of the shell. The digital workflow, developed by our research group is based on the Finite Element Method (FEM). The design methodology is to create two kind of structural analyses. The first one, called global, is using beam elements to investigate the general forces and deformations. The second one, called local, is using solid/volume elements to investigate the connection solution. Thanks to fast information transfer between this two analysis and automation of this process, the architect can achieve information about feasibility of the whole designed structure in real time. To validate our approach the timber gridshell was designed. The structure with nontrivial shape and customized each of the 61 nodes, was build in 2016 in Trondheim. The nodes were manufactured with usage of the 3D printing technology.},
  isbn = {978-3-85748-163-5}
}

@inproceedings{luHumanRobotCollaborationUsing2020,
  title = {Human-{{Robot Collaboration}} Using {{Variable Admittance Control}} and {{Human Intention Prediction}}},
  booktitle = {{{IEEE International Conference}} on {{Automation Science}} and {{Engineering}}},
  author = {Lu, W. and Hu, Z. and Pan, J.},
  date = {2020},
  volume = {2020-Augus},
  pages = {1116--1121},
  doi = {10.1109/CASE48305.2020.9217040},
  abstract = {Due to the difficulty of modeling human limb, it is very challenging to design the controller for human-robot collaboration. In this paper, we present a novel controller combining the variable admittance control and assistant control. In particular, the reinforcement learning is used to obtain the optimal damping value of the admittance controller by minimizing the reward function. In addition, we use the long short-term memory networks (LSTMs) to predict human intention based on the human limb dynamics and then an assistant controller is proposed to help human complete collaboration tasks. We validate the performance of our prediction algorithm and controller on a 7 d.o.f Franka Emika robot equipped with joint torque sensors. The proposed controller can both achieve minimum-jerk trajectory and low-effort cost.},
  isbn = {978-1-72816-904-0}
}

@inproceedings{luHumanRobotCollaborationUsing2020a,
  title = {Human-{{Robot Collaboration}} Using {{Variable Admittance Control}} and {{Human Intention Prediction}}},
  booktitle = {{{IEEE International Conference}} on {{Automation Science}} and {{Engineering}}},
  author = {Lu, W. and Hu, Z. and Pan, J.},
  date = {2020},
  volume = {2020-Augus},
  pages = {1116--1121},
  doi = {10.1109/CASE48305.2020.9217040},
  abstract = {Due to the difficulty of modeling human limb, it is very challenging to design the controller for human-robot collaboration. In this paper, we present a novel controller combining the variable admittance control and assistant control. In particular, the reinforcement learning is used to obtain the optimal damping value of the admittance controller by minimizing the reward function. In addition, we use the long short-term memory networks (LSTMs) to predict human intention based on the human limb dynamics and then an assistant controller is proposed to help human complete collaboration tasks. We validate the performance of our prediction algorithm and controller on a 7 d.o.f Franka Emika robot equipped with joint torque sensors. The proposed controller can both achieve minimum-jerk trajectory and low-effort cost.},
  isbn = {978-1-72816-904-0}
}

@article{lundModularBehaviorbasedControl2004,
  title = {Modular Behavior-Based Control for Team Humanoids},
  author = {Lund, H.H. and Pagliarini, L.},
  date = {2004},
  journaltitle = {Advanced Robotics},
  volume = {18},
  number = {7},
  pages = {659--676},
  doi = {10.1163/1568553041719483},
  abstract = {When developing teams of humanoids - rather than an individual humanoid -there are a number of issues that become important to consider, including robustness, scalability, versatility, and also development and production costs. Therefore, we used a modern approach to AI that puts emphasis on the balance between control, electronic hardware, material, sensory system and energy in order to develop the team of Viki humanoid robots. In contrast to the top-down approach of equipping a humanoid with as many sensors, motors, power, etc., as possible, we developed a bottom-up approach to the construction of humanoids, regarding both hardware and software (modular behavior-based control). The approach is shown with the development of the Viki humanoid team that won the RoboCup Humanoids Free Style World Championship 2002. In this paper, we focus on the main result of the behavior-based architecture with many layers of behaviors at different levels, which make it easy for both engineers to design new behaviors and for end-users to develop humanoid behaviors at different levels of complexity, dependent on the competencies of the individual end-user. With this architecture, it becomes possible to develop simple user interfaces with a user-guided implementation of our modular behavior-based approach, in order to allow any user to design performances with the humanoid robots.}
}

@article{lundModularBehaviorbasedControl2004a,
  title = {Modular Behavior-Based Control for Team Humanoids},
  author = {Lund, H.H. and Pagliarini, L.},
  date = {2004},
  journaltitle = {Advanced Robotics},
  volume = {18},
  number = {7},
  pages = {659--676},
  doi = {10.1163/1568553041719483},
  abstract = {When developing teams of humanoids - rather than an individual humanoid -there are a number of issues that become important to consider, including robustness, scalability, versatility, and also development and production costs. Therefore, we used a modern approach to AI that puts emphasis on the balance between control, electronic hardware, material, sensory system and energy in order to develop the team of Viki humanoid robots. In contrast to the top-down approach of equipping a humanoid with as many sensors, motors, power, etc., as possible, we developed a bottom-up approach to the construction of humanoids, regarding both hardware and software (modular behavior-based control). The approach is shown with the development of the Viki humanoid team that won the RoboCup Humanoids Free Style World Championship 2002. In this paper, we focus on the main result of the behavior-based architecture with many layers of behaviors at different levels, which make it easy for both engineers to design new behaviors and for end-users to develop humanoid behaviors at different levels of complexity, dependent on the competencies of the individual end-user. With this architecture, it becomes possible to develop simple user interfaces with a user-guided implementation of our modular behavior-based approach, in order to allow any user to design performances with the humanoid robots.}
}

@article{luoCombiningDeepFeatures2020,
  title = {Combining Deep Features and Activity Context to Improve Recognition of Activities of Workers in Groups},
  author = {Luo, Xiaochun and Li, Heng and Yu, Yantao and Zhou, Cheng and Cao, Dongping},
  date = {2020-09},
  journaltitle = {Computer-Aided Civil and Infrastructure Engineering},
  volume = {35},
  number = {9},
  pages = {965--978},
  issn = {1093-9687},
  doi = {10.1111/mice.12538},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/mice.12538},
  abstract = {Automatic activity recognition plays an important role in addressing the efficiency issue of site management. In recent years, there has been an increasing interest in vision-based activity recognition, while its relatively low recognition accuracy and speed impede the practical application. This paper introduces a discriminative model to combine deep activity features and contextual information to improve the recognition of activities of workers on foot in site surveillance videos. Specifically, a conditional random field (CRF) model is designed based on deep activity features, which are extracted with a single-stream deep activity recognition network, and spatial relevance, which are obtained with a tracking-by-detection multiple-object tracking method. We have evaluated various deep activity features, including action features, activity features, and joint features. Also, we have parameterized the contextual information of activities in terms of spatial relevance and represent the context with graphs of K-nearest neighbors. The experimental results show that the CRF model based on deep activity features and activity context can significantly improve activity recognition performance to 98.77\% average accuracy by 22.10\% from the baseline 77.67\%, which is obtained using the single-stream deep activity recognition network, with a small computational overhead of 0.025 ms per segment.}
}

@article{luoCombiningDeepFeatures2020a,
  title = {Combining Deep Features and Activity Context to Improve Recognition of Activities of Workers in Groups},
  author = {Luo, Xiaochun and Li, Heng and Yu, Yantao and Zhou, Cheng and Cao, Dongping},
  date = {2020-09-05},
  journaltitle = {Computer-Aided Civil and Infrastructure Engineering},
  volume = {35},
  number = {9},
  pages = {965--978},
  issn = {1093-9687},
  doi = {10.1111/mice.12538},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/mice.12538},
  abstract = {Automatic activity recognition plays an important role in addressing the efficiency issue of site management. In recent years, there has been an increasing interest in vision-based activity recognition, while its relatively low recognition accuracy and speed impede the practical application. This paper introduces a discriminative model to combine deep activity features and contextual information to improve the recognition of activities of workers on foot in site surveillance videos. Specifically, a conditional random field (CRF) model is designed based on deep activity features, which are extracted with a single-stream deep activity recognition network, and spatial relevance, which are obtained with a tracking-by-detection multiple-object tracking method. We have evaluated various deep activity features, including action features, activity features, and joint features. Also, we have parameterized the contextual information of activities in terms of spatial relevance and represent the context with graphs of K-nearest neighbors. The experimental results show that the CRF model based on deep activity features and activity context can significantly improve activity recognition performance to 98.77\% average accuracy by 22.10\% from the baseline 77.67\%, which is obtained using the single-stream deep activity recognition network, with a small computational overhead of 0.025 ms per segment.},
  keywords = {★},
  file = {C:\Users\leemar\Zotero\storage\EP6FBAV5\Computer aided Civil Eng - 2020 - Luo - Combining deep features and activity context to improve recognition of activities.pdf}
}

@inproceedings{luoElementsConstructionSports2021,
  title = {Elements and Construction of Sports Visual Image Action Recognition System Based on Visual Attention Analysis},
  booktitle = {2021 {{IEEE International Conference}} on {{Advances}} in {{Electrical Engineering}} and {{Computer Applications}}, {{AEECA}} 2021},
  author = {Luo, K.},
  date = {2021},
  pages = {411--414},
  doi = {10.1109/AEECA52519.2021.9574383},
  abstract = {With the rapid development of computer vision technology, human action recognition technology has occupied an important position in this field. It has important practical value and research value in security protection, advanced human-computer interaction, video search analysis and sports analysis. Due to the non rigid body characteristics of human body, the change of illumination, and the influence of the changeable surrounding environment, human action recognition is more challenging. Virtual reality technology is an important subject in computer field. It simulates real scenes by means of computer software and hardware technology. Observe students' learning situation dynamically according to the scene. At present, this technology is still in the research and development stage, and there are still many problems in the application process. However, the exchange of students' learning information and simulated scenes is of great help to teaching activities. Moreover, the data obtained by virtual technology also provides guidance for teaching and research.},
  isbn = {978-1-66543-561-1}
}

@inproceedings{luoElementsConstructionSports2021a,
  title = {Elements and Construction of Sports Visual Image Action Recognition System Based on Visual Attention Analysis},
  booktitle = {2021 {{IEEE International Conference}} on {{Advances}} in {{Electrical Engineering}} and {{Computer Applications}}, {{AEECA}} 2021},
  author = {Luo, K.},
  date = {2021},
  pages = {411--414},
  doi = {10.1109/AEECA52519.2021.9574383},
  abstract = {With the rapid development of computer vision technology, human action recognition technology has occupied an important position in this field. It has important practical value and research value in security protection, advanced human-computer interaction, video search analysis and sports analysis. Due to the non rigid body characteristics of human body, the change of illumination, and the influence of the changeable surrounding environment, human action recognition is more challenging. Virtual reality technology is an important subject in computer field. It simulates real scenes by means of computer software and hardware technology. Observe students' learning situation dynamically according to the scene. At present, this technology is still in the research and development stage, and there are still many problems in the application process. However, the exchange of students' learning information and simulated scenes is of great help to teaching activities. Moreover, the data obtained by virtual technology also provides guidance for teaching and research.},
  isbn = {978-1-66543-561-1}
}

@article{luoRecognizingDiverseConstruction2018,
  title = {Recognizing {{Diverse Construction Activities}} in {{Site Images}} via {{Relevance Networks}} of {{Construction-Related Objects Detected}} by {{Convolutional Neural Networks}}},
  author = {Luo, X. and Li, H. and Cao, D. and Dai, F. and Seo, J. and Lee, S.},
  date = {2018},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {32},
  number = {3},
  doi = {10.1061/(ASCE)CP.1943-5487.0000756},
  abstract = {Timely and overall knowledge of the states and resource allocation of diverse activities on construction sites is critical to resource leveling, progress tracking, and productivity analysis. Despite its importance, this task is still performed manually. Previous studies have taken a significant step forward in introducing computer vision technologies, although they have been oriented toward limited classes of objects or limited types of activities. Furthermore, they especially focus on single activity recognition, where an image contains only the execution of an activity by one or a few objects. This paper introduces a two-step method for recognizing diverse construction activities in still site images. It detects 22 classes of construction-related objects using convolutional neural networks. With objects detected, semantic relevance representing the likelihood of the cooperation or coexistence between two objects in a construction activity, spatial relevance representing the two-dimensional pixel proximity in the image coordinates, and activity patterns are defined to recognize 17 types of construction activities. The advantage of the proposed method is its potential to recognize diverse concurrent construction activities in a fully automatic way. Therefore, it is possible to save managers' valuable time in manual data collection and concentrate their attention on solving problems that necessarily demand their expertise.}
}

@article{luoRecognizingDiverseConstruction2018a,
  title = {Recognizing {{Diverse Construction Activities}} in {{Site Images}} via {{Relevance Networks}} of {{Construction-Related Objects Detected}} by {{Convolutional Neural Networks}}},
  author = {Luo, X. and Li, H. and Cao, D. and Dai, F. and Seo, J. and Lee, S.},
  date = {2018},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {32},
  number = {3},
  doi = {10.1061/(ASCE)CP.1943-5487.0000756},
  abstract = {Timely and overall knowledge of the states and resource allocation of diverse activities on construction sites is critical to resource leveling, progress tracking, and productivity analysis. Despite its importance, this task is still performed manually. Previous studies have taken a significant step forward in introducing computer vision technologies, although they have been oriented toward limited classes of objects or limited types of activities. Furthermore, they especially focus on single activity recognition, where an image contains only the execution of an activity by one or a few objects. This paper introduces a two-step method for recognizing diverse construction activities in still site images. It detects 22 classes of construction-related objects using convolutional neural networks. With objects detected, semantic relevance representing the likelihood of the cooperation or coexistence between two objects in a construction activity, spatial relevance representing the two-dimensional pixel proximity in the image coordinates, and activity patterns are defined to recognize 17 types of construction activities. The advantage of the proposed method is its potential to recognize diverse concurrent construction activities in a fully automatic way. Therefore, it is possible to save managers' valuable time in manual data collection and concentrate their attention on solving problems that necessarily demand their expertise.}
}

@misc{LuZaiFuZaHuanJingZhongZhenCeCanYuDuBingJianLiRenJiHuDongLuXinRuImplementation2020,
  title = {在複雜環境中偵測參與度並建立人機互動 / 呂昕儒 = {{Implementation}} of Pre-Engagement Detection on Human-Robot Interaction in Complex Environments / {{Sin-Ru Lu}}},
  author = {family=呂, given=昕儒., given-i={{昕儒}}},
  date = {2020},
  journaltitle = {在複雜環境中偵測參與度並建立人機互動},
  abstract = {人機互動是一門研究人類與機器人互動的領域, 其必須被引入以規範人類與機器人之間的互動行為. 因此本論文探討機器人與人類的互動行為, 並提出人機互動四層架構和人機模型, 規範機器人在人類社會中做出符合人類行為的決策. 為了使機器擁有與人類相似的決策行為, 此篇文章整合了實驗室已經發展的深度學習模組──SRWGAN.情緒辨識模型和眼神追蹤模型, 與現有的深度學習模組──FSA-Net.SlowFast和Google API, 並且使用自行改良的隱藏式馬可夫模型進行資訊整合與預測, 進而提出一個整合性的架構──機器人認知系統, 能讓機器人在複雜環境中, 找出互動對象, 並且給予回應. 為了使機器人能夠從人類頭部姿態與眼神, 推斷出適合開啟對話的時間, 我們提出了參與度的舒適指標, 讓機器人知道互動者處在的參與度狀態, 且防止過長時間凝視對方造成的焦慮. 另外, 為了使機器人可以偵測使用者的回饋(語音與表情), 我們提出了自然性指標, 讓機器人可以針對其數值採取適合的措施. 最後, 所發展的雙臂服務型機器人──莫比, 共20個自由度: 雙手臂12.雙手掌4.輪子2和頭部2, 並且可以完成舉起2公斤負載的任務. 所提出的接近模型.企圖模型.及人機互動模型, 均在莫比機器人身上實現, 實驗結果相當不錯.},
  langid = {english},
  organization = {{國立臺灣大學機械工程學研究所}},
  keywords = {HRI}
}

@incollection{lvRecognitionSegmentation3D2006,
  title = {Recognition and {{Segmentation}} of 3-{{D Human Action Using HMM}} and {{Multi-class AdaBoost}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2006},
  author = {Lv, Fengjun and Nevatia, Ramakant},
  editor = {Leonardis, Aleš and Bischof, Horst and Pinz, Axel},
  date = {2006},
  volume = {3954},
  pages = {359--372},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11744085_28},
  url = {http://link.springer.com/10.1007/11744085_28},
  urldate = {2023-03-15},
  abstract = {Our goal is to automatically segment and recognize basic human actions, such as stand, walk and wave hands, from a sequence of joint positions or pose angles. Such recognition is difficult due to high dimensionality of the data and large spatial and temporal variations in the same action. We decompose the high dimensional 3-D joint space into a set of feature spaces where each feature corresponds to the motion of a single joint or combination of related multiple joints. For each feature, the dynamics of each action class is learned with one HMM. Given a sequence, the observation probability is computed in each HMM and a weak classifier for that feature is formed based on those probabilities. The weak classifiers with strong discriminative power are then combined by the Multi-Class AdaBoost (AdaBoost.M2) algorithm. A dynamic programming algorithm is applied to segment and recognize actions simultaneously. Results of recognizing 22 actions on a large number of motion capture sequences as well as several annotated and automatically tracked sequences show the effectiveness of the proposed algorithms.},
  isbn = {978-3-540-33838-3 978-3-540-33839-0},
  langid = {english},
  file = {/Volumes/WIP/library/11744085_28.pdf}
}

@article{mackenzieMultiagentMissionSpecification1997,
  title = {Multiagent {{Mission Specification}} and {{Execution}}},
  author = {Mackenzie, D.C. and Arkin, R.C. and Cameron, J.M.},
  date = {1997},
  journaltitle = {Autonomous Robots},
  volume = {4},
  number = {1},
  pages = {29--52},
  doi = {10.1023/A:1008807102993},
  abstract = {Specifying a reactive behavioral configuration for use by a multiagent team requires both a careful choice of the behavior set and the creation of a temporal chain of behaviors which executes the mission. This difficult task is simplified by applying an object-oriented approach to the design of the mission using a construction called an assemblage and a methodology called temporal sequencing. The assemblage construct allows building high level primitives which provide abstractions for the designer. Assemblages consist of groups of basic behaviors and coordination mechanisms that allow the group to be treated as a new coherent behavior. Upon instantiation, the assemblage is parameterized based on the specific mission requirements. Assemblages can be re-parameterized and used in other states within a mission or archived as high level primitives for use in subsequent projects. Temporal sequencing partitions the mission into discrete operating states with perceptual triggers causing transitions between those states. Several smaller independent configurations (assemblages) can then be created which each implement one state. The Societal Agent theory is presented as a basis for constructions of this form. The Configuration Description Language (CDL) is developed to capture the recursive composition of configurations in an architecture-and robot-independent fashion. The MissionLab system 1, an implementation based on CDL, supports the graphical construction of configurations using a visual editor. Various multiagent missions are demonstrated in simulation and on our Denning robots using these tools.}
}

@article{mackenzieMultiagentMissionSpecification1997a,
  title = {Multiagent {{Mission Specification}} and {{Execution}}},
  author = {Mackenzie, D.C. and Arkin, R.C. and Cameron, J.M.},
  date = {1997},
  journaltitle = {Autonomous Robots},
  volume = {4},
  number = {1},
  pages = {29--52},
  doi = {10.1023/A:1008807102993},
  abstract = {Specifying a reactive behavioral configuration for use by a multiagent team requires both a careful choice of the behavior set and the creation of a temporal chain of behaviors which executes the mission. This difficult task is simplified by applying an object-oriented approach to the design of the mission using a construction called an assemblage and a methodology called temporal sequencing. The assemblage construct allows building high level primitives which provide abstractions for the designer. Assemblages consist of groups of basic behaviors and coordination mechanisms that allow the group to be treated as a new coherent behavior. Upon instantiation, the assemblage is parameterized based on the specific mission requirements. Assemblages can be re-parameterized and used in other states within a mission or archived as high level primitives for use in subsequent projects. Temporal sequencing partitions the mission into discrete operating states with perceptual triggers causing transitions between those states. Several smaller independent configurations (assemblages) can then be created which each implement one state. The Societal Agent theory is presented as a basis for constructions of this form. The Configuration Description Language (CDL) is developed to capture the recursive composition of configurations in an architecture-and robot-independent fashion. The MissionLab system 1, an implementation based on CDL, supports the graphical construction of configurations using a visual editor. Various multiagent missions are demonstrated in simulation and on our Denning robots using these tools.}
}

@inproceedings{Mainprice2013299,
  title = {Human-Robot Collaborative Manipulation Planning Using Early Prediction of Human Motion},
  author = {Mainprice, J. and Berenson, D.},
  date = {2013},
  series = {{{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  pages = {299--306},
  doi = {10.1109/IROS.2013.6696368},
  art_number = {6696368}
}

@article{martoneAnatomyFacialExpression1962,
  title = {Anatomy of Facial Expression and Its Prosthodontic Significance},
  author = {Martone, A. L.},
  date = {1962},
  journaltitle = {The Journal of Prosthetic Dentistry},
  volume = {12},
  number = {6},
  pages = {1020--1042},
  doi = {10.1016/0022-3913(62)90158-0},
  abstract = {An understanding of the muscles of facial expression is important to successful complete denture construction. These muscles may be observed at work by the dentist when he first views his patient and that patient begins to speak. I have termed this muscular activity the fourth dimension or vitality factor of a patient. An understanding of its prosthodontic significance enables the dentist to employ postoperative vision in the treatment planning stage which can minimize denture failures. Prosthodontic treatment must be in terms of all of the functions performed within the mouth region. In recognition of this, the present study was conducted to (1) consider the role which the facial muscles play in expression, (2) analyze these muscles in terms of the expressions of various emotions, and (3) evaluate their prosthodontic significance. As a result of this study, certain suggestions have been made as to the role muscles of facial expression may play in nonmasticatory movements of the mandible. In this review of the anatomy of facial expression, it is apparent that the polyfunctional pyramid previously mentioned as being the most important to the dentist suffers severe changes through the aging process. Thus, the dentist deals with a balance sheet primarily composed of losses-loss of teeth, alveolar processes, tonicity of musculature, and elasticity of skin, as well as loss or impairment of functions. His task is to attempt a restoration to offset these losses, at least in part. The beginning of prosthodontic treatment for a patient must start with an evaluation of the total loss incurred by that patient and cannot be limited to a consideration of only lost teeth or ridges. Success of prosthodontic treatment is in direct proportion to the dentist's knowledge of functioning anatomy and his application of this knowledge to denture construction. © 1962.}
}

@article{martoneAnatomyFacialExpression1962a,
  title = {Anatomy of Facial Expression and Its Prosthodontic Significance},
  author = {Martone, A.L.},
  date = {1962},
  journaltitle = {The Journal of Prosthetic Dentistry},
  volume = {12},
  number = {6},
  pages = {1020--1042},
  doi = {10.1016/0022-3913(62)90158-0},
  abstract = {An understanding of the muscles of facial expression is important to successful complete denture construction. These muscles may be observed at work by the dentist when he first views his patient and that patient begins to speak. I have termed this muscular activity the fourth dimension or vitality factor of a patient. An understanding of its prosthodontic significance enables the dentist to employ postoperative vision in the treatment planning stage which can minimize denture failures. Prosthodontic treatment must be in terms of all of the functions performed within the mouth region. In recognition of this, the present study was conducted to (1) consider the role which the facial muscles play in expression, (2) analyze these muscles in terms of the expressions of various emotions, and (3) evaluate their prosthodontic significance. As a result of this study, certain suggestions have been made as to the role muscles of facial expression may play in nonmasticatory movements of the mandible. In this review of the anatomy of facial expression, it is apparent that the polyfunctional pyramid previously mentioned as being the most important to the dentist suffers severe changes through the aging process. Thus, the dentist deals with a balance sheet primarily composed of losses-loss of teeth, alveolar processes, tonicity of musculature, and elasticity of skin, as well as loss or impairment of functions. His task is to attempt a restoration to offset these losses, at least in part. The beginning of prosthodontic treatment for a patient must start with an evaluation of the total loss incurred by that patient and cannot be limited to a consideration of only lost teeth or ridges. Success of prosthodontic treatment is in direct proportion to the dentist's knowledge of functioning anatomy and his application of this knowledge to denture construction. © 1962.}
}

@inproceedings{mastinoMethodsAcousticClassification2019,
  title = {Methods for Acoustic Classification in Buildings: {{An}} Example of Application of {{BIM}} Procedures on Wooden Buildings},
  booktitle = {{{INTER-NOISE}} 2019 {{MADRID}} - 48th {{International Congress}} and {{Exhibition}} on {{Noise Control Engineering}}},
  author = {Mastino, C.C. and Concu, G. and Baccoli, R. and Frattolillo, A. and Di Bella, A.},
  date = {2019},
  abstract = {Recently private buildings built with wooden structures in the Mediterranean area have been subjected to an increasing spread. In particular, construction of new buildings made with Cross Laminated Timber (CLT) technology, which has considerable advantages in terms of construction times and several excellent performance among which mechanical, acoustic and energy saving properties. However, this technology requires a high level of design and project management, because many elements being prefabricated far away from the construction site. This is combined with an increasing demand of comfort and advanced performance for the building. The acoustic performances, that have been for long time neglected or at least underestimated, are now a basic requirement and increasingly requested with attention to detail and cost effectiveness by the customers. The aim of this work is to analyse the standards currently available on the market for the acoustic classification of buildings by applying them to a case study, pointing out the potential of Building Information Modelling (BIM), highlighting on the one hand the performance achieved by the case study according to the different procedures and on the other the peculiarities of the applied standards.},
  isbn = {978-84-87985-31-7}
}

@inproceedings{mastinoMethodsAcousticClassification2019a,
  title = {Methods for Acoustic Classification in Buildings: {{An}} Example of Application of {{BIM}} Procedures on Wooden Buildings},
  booktitle = {{{INTER-NOISE}} 2019 {{MADRID}} - 48th {{International Congress}} and {{Exhibition}} on {{Noise Control Engineering}}},
  author = {Mastino, C.C. and Concu, G. and Baccoli, R. and Frattolillo, A. and Di Bella, A.},
  date = {2019},
  abstract = {Recently private buildings built with wooden structures in the Mediterranean area have been subjected to an increasing spread. In particular, construction of new buildings made with Cross Laminated Timber (CLT) technology, which has considerable advantages in terms of construction times and several excellent performance among which mechanical, acoustic and energy saving properties. However, this technology requires a high level of design and project management, because many elements being prefabricated far away from the construction site. This is combined with an increasing demand of comfort and advanced performance for the building. The acoustic performances, that have been for long time neglected or at least underestimated, are now a basic requirement and increasingly requested with attention to detail and cost effectiveness by the customers. The aim of this work is to analyse the standards currently available on the market for the acoustic classification of buildings by applying them to a case study, pointing out the potential of Building Information Modelling (BIM), highlighting on the one hand the performance achieved by the case study according to the different procedures and on the other the peculiarities of the applied standards.},
  isbn = {978-84-87985-31-7}
}

@inproceedings{matignonModelVerbalNonverbal2010,
  title = {A Model for Verbal and Non-Verbal Human-Robot Collaboration},
  booktitle = {{{AAAI Fall Symposium}} - {{Technical Report}}},
  author = {Matignon, L. and Karami, A.-B. and Mouaddib, A.-I.},
  date = {2010},
  volume = {FS-10-05},
  pages = {62--67},
  abstract = {We are motivated by building a system for an autonomous robot companion that collaborates with a human partner for achieving a common mission. The objective of the robot is to infer the human's preferences upon the tasks of the mission so as to collaborate with the human by achieving human's non-favorite tasks. Inspired by recent researches about the recognition of human's intention, we propose a unified model that allows the robot to switch accurately between verbal and non-verbal interactions. Our system unifies an epistemic partially observable Markov decision process (POMDP) that is a human-robot spoken dialog system aiming at disambiguating the human's preferences and an intuitive human-robot collaboration consisting in inferring human's intention based on the observed human actions. The beliefs over human's preferences computed during the dialog are then reinforced in the course of the task execution by the intuitive interaction. Our unified model helps the robot inferring the human's preferences and deciding which tasks to perform to effectively satisfy these preferences. The robot is also able to adjust its plan rapidly in case of sudden changes in the human's preferences and to switch between both kind of interactions. Experimental results on a scenario inspired from robocup@home outline various specific behaviors of the robot during the collaborative mission. Copyright ©2010, Association for the Advancement of Artificial Intelligence. All rights reserved.},
  isbn = {978-1-57735-487-1}
}

@inproceedings{matignonModelVerbalNonverbal2010a,
  title = {A Model for Verbal and Non-Verbal Human-Robot Collaboration},
  booktitle = {{{AAAI Fall Symposium}} - {{Technical Report}}},
  author = {Matignon, L. and Karami, A.-B. and Mouaddib, A.-I.},
  date = {2010},
  volume = {FS-10-05},
  pages = {62--67},
  abstract = {We are motivated by building a system for an autonomous robot companion that collaborates with a human partner for achieving a common mission. The objective of the robot is to infer the human's preferences upon the tasks of the mission so as to collaborate with the human by achieving human's non-favorite tasks. Inspired by recent researches about the recognition of human's intention, we propose a unified model that allows the robot to switch accurately between verbal and non-verbal interactions. Our system unifies an epistemic partially observable Markov decision process (POMDP) that is a human-robot spoken dialog system aiming at disambiguating the human's preferences and an intuitive human-robot collaboration consisting in inferring human's intention based on the observed human actions. The beliefs over human's preferences computed during the dialog are then reinforced in the course of the task execution by the intuitive interaction. Our unified model helps the robot inferring the human's preferences and deciding which tasks to perform to effectively satisfy these preferences. The robot is also able to adjust its plan rapidly in case of sudden changes in the human's preferences and to switch between both kind of interactions. Experimental results on a scenario inspired from robocup@home outline various specific behaviors of the robot during the collaborative mission. Copyright ©2010, Association for the Advancement of Artificial Intelligence. All rights reserved.},
  isbn = {978-1-57735-487-1}
}

@article{mcwhiteCVNXExpandedCapability2000,
  title = {{{CVNX}} - Expanded Capability Baseline Aircraft Carrier Design Study},
  author = {McWhite, J.D.},
  date = {2000},
  journaltitle = {Naval Engineers Journal},
  volume = {112},
  number = {3},
  pages = {47--57},
  doi = {10.1111/j.1559-3584.2000.tb03303.x},
  abstract = {Aircraft Carrier ship design study number 5, entitled 'Expanded Capability Baseline', of the CVNX Analysis of Alternatives (AoA) (Part 3) ship design studies, represents the Navy's most capable and cost effective design to meet all of the Operational Requirements Document (ORD) objectives for CVNX. This paper describes the overall ship design and provides insight into its key technologies and design innovations. With significant attention being placed on new manning reduction methods and in total life cycle cost (LCC) reduction efforts. It includes descriptions of key technology improvements like: 'Pit Stop' aircraft servicing, improved below deck weapons movement, electric aircraft and weapon elevators, modular electronic spaces, centralized food service, and robotic inventory and storage systems. Also covered are increased crew habitability, and optimized hull form and survivability features. Results address increased Flight Deck performance and construction and cost limitations.}
}

@article{mcwhiteCVNXExpandedCapability2000a,
  title = {{{CVNX}} - Expanded Capability Baseline Aircraft Carrier Design Study},
  author = {McWhite, J.D.},
  date = {2000},
  journaltitle = {Naval Engineers Journal},
  volume = {112},
  number = {3},
  pages = {47--57},
  doi = {10.1111/j.1559-3584.2000.tb03303.x},
  abstract = {Aircraft Carrier ship design study number 5, entitled 'Expanded Capability Baseline', of the CVNX Analysis of Alternatives (AoA) (Part 3) ship design studies, represents the Navy's most capable and cost effective design to meet all of the Operational Requirements Document (ORD) objectives for CVNX. This paper describes the overall ship design and provides insight into its key technologies and design innovations. With significant attention being placed on new manning reduction methods and in total life cycle cost (LCC) reduction efforts. It includes descriptions of key technology improvements like: 'Pit Stop' aircraft servicing, improved below deck weapons movement, electric aircraft and weapon elevators, modular electronic spaces, centralized food service, and robotic inventory and storage systems. Also covered are increased crew habitability, and optimized hull form and survivability features. Results address increased Flight Deck performance and construction and cost limitations.}
}

@inproceedings{mediavillaRenobimCollaborationPlatform2018,
  title = {Renobim: {{Collaboration}} Platform Based on Open Bim Workflows for Energy Renovation of Buildings Using Timber Prefabricated Products},
  booktitle = {{{eWork}} and {{eBusiness}} in {{Architecture}}, {{Engineering}} and {{Construction}} - {{Proceedings}} of the 12th {{European Conference}} on {{Product}} and {{Process Modelling}}, {{ECPPM}} 2018},
  author = {Mediavilla, A. and Arenaza, X. and Sánchez, V. and Sebesi, Y. and Philipps, P.},
  date = {2018},
  pages = {281--288},
  doi = {10.1201/9780429506215-35},
  abstract = {AEC industry is by far one of the most fragmented industries, with still important data and process silos. This paper presents an innovative platform developed in H2020 funded BERTIM project to overcome this barrier in the field of building energy renovation using timber prefabricated products. It supports the overall process from BIM creation using laser scanning techniques, assessment of the renovation project feasibility and selection of the most cost-effective alternative to be then produced by CNC machines. It follows the decision-making methodology developed in the project, involving several stakeholders (service provider, designer, manufacturer and potential client of the renovation process), as support their collaboration, with relevant time savings and better knowledge sharing. The platform implements Open BIM workflows through the interoperability of tools using IFC files, linking custom developed decision support tools, existing energy simulation engines (Energy Plus) and CAD/CAM tools, with secondary objectives like running cloud energy simulations by non-expert users. Simulation models are automatically created in two approaches: procedurally created models from user inputs (for early deci-sions), as well as an advanced IFC to Energy Plus conversion in detailed phases. Additionally, the user can quickly define the façade splitting configuration to be added to the existing IFC and conveyed to the CAD/CAM tool for manufacturing. 3D model visualization is supported using Web3D technologies. The final platform is easily adaptable to different manufacturers’ processes and products.},
  isbn = {978-1-138-58413-6}
}

@inproceedings{mediavillaRenobimCollaborationPlatform2018a,
  title = {Renobim: {{Collaboration}} Platform Based on Open Bim Workflows for Energy Renovation of Buildings Using Timber Prefabricated Products},
  booktitle = {{{eWork}} and {{eBusiness}} in {{Architecture}}, {{Engineering}} and {{Construction}} - {{Proceedings}} of the 12th {{European Conference}} on {{Product}} and {{Process Modelling}}, {{ECPPM}} 2018},
  author = {Mediavilla, A. and Arenaza, X. and Sánchez, V. and Sebesi, Y. and Philipps, P.},
  date = {2018},
  pages = {281--288},
  doi = {10.1201/9780429506215-35},
  abstract = {AEC industry is by far one of the most fragmented industries, with still important data and process silos. This paper presents an innovative platform developed in H2020 funded BERTIM project to overcome this barrier in the field of building energy renovation using timber prefabricated products. It supports the overall process from BIM creation using laser scanning techniques, assessment of the renovation project feasibility and selection of the most cost-effective alternative to be then produced by CNC machines. It follows the decision-making methodology developed in the project, involving several stakeholders (service provider, designer, manufacturer and potential client of the renovation process), as support their collaboration, with relevant time savings and better knowledge sharing. The platform implements Open BIM workflows through the interoperability of tools using IFC files, linking custom developed decision support tools, existing energy simulation engines (Energy Plus) and CAD/CAM tools, with secondary objectives like running cloud energy simulations by non-expert users. Simulation models are automatically created in two approaches: procedurally created models from user inputs (for early deci-sions), as well as an advanced IFC to Energy Plus conversion in detailed phases. Additionally, the user can quickly define the façade splitting configuration to be added to the existing IFC and conveyed to the CAD/CAM tool for manufacturing. 3D model visualization is supported using Web3D technologies. The final platform is easily adaptable to different manufacturers’ processes and products.},
  isbn = {978-1-138-58413-6}
}

@article{meiOvertimeWarningConcrete2021,
  title = {Overtime Warning of Concrete Pouring Interval Based on Object Detection Model | 基于目标检测模型的混凝土坯层覆盖间歇时间超时预警},
  author = {Mei, J. and Li, Q. and Chen, W. and Wu, K. and Tan, Y. and Liu, C. and Wang, D. and Hu, Y.},
  date = {2021},
  journaltitle = {Qinghua Daxue Xuebao/Journal of Tsinghua University},
  volume = {61},
  number = {7},
  pages = {688--693},
  doi = {10.16511/j.cnki.qhdxxb.2021.26.016},
  abstract = {Timely, comprehensive and accurate access to the status and progress of various activities on the construction site is essential for quality control, progress tracking and productivity analysis, and is also necessary for the full realization of fine management and intelligent construction. At present, the progress recording and quality control under the concrete pouring construction scenario are still mostly done manually, leading to problems such as insufficient timeliness, misreporting and omission. In this study, the semantic segmentation and object detection technology in the field of deep learning computer vision are applied to the field of engineering construction. Real-time construction progress is obtained by identifying formwork cover ratios and the unloading event of the bucket, and the overtime warning of layer coverage time with second-level accuracy is realized.}
}

@article{meiOvertimeWarningConcrete2021a,
  title = {Overtime Warning of Concrete Pouring Interval Based on Object Detection Model | 基于目标检测模型的混凝土坯层覆盖间歇时间超时预警},
  author = {Mei, J. and Li, Q. and Chen, W. and Wu, K. and Tan, Y. and Liu, C. and Wang, D. and Hu, Y.},
  date = {2021},
  journaltitle = {Qinghua Daxue Xuebao/Journal of Tsinghua University},
  volume = {61},
  number = {7},
  pages = {688--693},
  doi = {10.16511/j.cnki.qhdxxb.2021.26.016},
  abstract = {Timely, comprehensive and accurate access to the status and progress of various activities on the construction site is essential for quality control, progress tracking and productivity analysis, and is also necessary for the full realization of fine management and intelligent construction. At present, the progress recording and quality control under the concrete pouring construction scenario are still mostly done manually, leading to problems such as insufficient timeliness, misreporting and omission. In this study, the semantic segmentation and object detection technology in the field of deep learning computer vision are applied to the field of engineering construction. Real-time construction progress is obtained by identifying formwork cover ratios and the unloading event of the bucket, and the overtime warning of layer coverage time with second-level accuracy is realized.}
}

@article{menendezdelucasPermanentVisualWork2020,
  title = {Permanent Visual Work Disabilities: 321 Cases Review | {{Incapacidades}} Laborales Permanentes de Causas Visuales. {{Revisión}} de 321 Casos},
  author = {Menéndez de Lucas, J.A. and Castell Navarro, A.},
  date = {2020},
  journaltitle = {Archivos de la Sociedad Espanola de Oftalmologia},
  volume = {95},
  number = {3},
  pages = {130--137},
  doi = {10.1016/j.oftal.2019.12.013},
  abstract = {Introduction: Visual diseases are the fifth more frequent cause of labour permanent disability, what represents 4\% of the total of them. In order to assess these cases we must take into account on one hand the visual requirements of each profession, and on the other hand the visual functional impairments that the worker is suffering. Special attention must be paid to situations of legal blindness and low vision, as a cause of serious disabilities. Despite the importance of the matter, we have hardly found any reviews about it in the consulted bibliography. Materials and methods: We have carried out a retrospective research of 321 disability claims due to ocular causes, assessed at the Ophthalmology Section of the Forensic Medical Clinic of Madrid, in the last 18 years. They account for 3\% of the total disability claims raised in our field. Results: The most frequent professions involved have been administrative services, construction, hotel workers, cleaning and professional drivers. In 90\% of cases these professional activities had medium or low visual requirements. The plaintiff in 40\% of cases was unemployed. The most frequent visual pathologies we found out were myopic complications (especially myopic maculopathy) 17\%, and eye trauma (16\%). To a lesser extent: retinal detachment (12\%), optic neuritis (7\%), glaucoma (6\%), diabetic retinopathy (6\%), pigmentary retinitis (4\%), non-myopic maculopathies (2\%) and melanomas (2\%). In 23\% of cases no significant visual limitation was found (it was lower than 33\%). Out of these, 9\% were diagnosed as NOVL (non-organic visual loss), 3\% of them being very obvious cases of simulation. Conclusions: In 82\% of the cases the expert's report pointed out a significant global (visual and non-visual) functional limitation (greater than 33\%) of their work capacity. In the previous administrative phase of all these cases the recognition fo disability had not been granted. From the results obtained it turns out the importance of an ophthalmologist acting as an expert in this type of demands.}
}

@article{mengWebcamBasedEyeMovement2017,
  title = {Webcam-{{Based Eye Movement Analysis Using CNN}}},
  author = {Meng, C. and Zhao, X.},
  date = {2017},
  journaltitle = {IEEE Access},
  volume = {5},
  pages = {19581--19587},
  doi = {10.1109/ACCESS.2017.2754299},
  abstract = {Due to its low price, webcam has become one of the most promising sensors with the rapid development of computer vision. However, the accuracies of eye tracking and eye movement analysis are largely limited by the quality of the webcam videos. To solve this issue, a novel eye movement analysis model is proposed based on five eye feature points rather than a single point (such as the iris center). First, a single convolutional neural network (CNN) is trained for eye feature point detection, and five eye feature points are detected for obtaining more useful eye movement information. Subsequently, six types of original time-varying eye movement signals can be constructed by feature points of each frame, which can reduce the dependency of the iris center in low quality videos. Finally, behaviors-CNN can be trained by the time-varying eye movement signals for recognizing different eye movement patterns, which is capable of avoiding the influence of errors from the basic eye movement type detection and artificial eye movement feature construction. To validate the performance, a webcam-based visual activity data set was constructed, which contained almost 0.5 million frames collected from 38 subjects. The experimental results on this database have demonstrated that the proposed model can obtain promising results for natural and convenient eye movement-based applications.}
}

@article{mengWebcamBasedEyeMovement2017a,
  title = {Webcam-{{Based Eye Movement Analysis Using CNN}}},
  author = {Meng, C. and Zhao, X.},
  date = {2017},
  journaltitle = {IEEE Access},
  volume = {5},
  pages = {19581--19587},
  doi = {10.1109/ACCESS.2017.2754299},
  abstract = {Due to its low price, webcam has become one of the most promising sensors with the rapid development of computer vision. However, the accuracies of eye tracking and eye movement analysis are largely limited by the quality of the webcam videos. To solve this issue, a novel eye movement analysis model is proposed based on five eye feature points rather than a single point (such as the iris center). First, a single convolutional neural network (CNN) is trained for eye feature point detection, and five eye feature points are detected for obtaining more useful eye movement information. Subsequently, six types of original time-varying eye movement signals can be constructed by feature points of each frame, which can reduce the dependency of the iris center in low quality videos. Finally, behaviors-CNN can be trained by the time-varying eye movement signals for recognizing different eye movement patterns, which is capable of avoiding the influence of errors from the basic eye movement type detection and artificial eye movement feature construction. To validate the performance, a webcam-based visual activity data set was constructed, which contained almost 0.5 million frames collected from 38 subjects. The experimental results on this database have demonstrated that the proposed model can obtain promising results for natural and convenient eye movement-based applications.}
}

@article{meoniDesignNonoverconstrainedEnergyEfficient2016,
  title = {Design of {{Nonoverconstrained Energy-Efficient Multi-Axis Servo Presses}} for {{Deep-Drawing Applications1}}},
  author = {Meoni, F. and Carricato, M.},
  date = {2016},
  journaltitle = {Journal of Mechanical Design, Transactions of the ASME},
  volume = {138},
  number = {6},
  doi = {10.1115/1.4033085},
  abstract = {Servo-actuated presses may provide maximum pressing force at any ram position in the same manner that hydraulic presses do, while offering several benefits in terms of precision, energy-conversion efficiency, and simplicity, due to their lack of hydraulic circuitry and oil. Several press builders have developed servo-actuated presses; however, issues relating to overconstrained multi-axis architecture have been disregarded. This study proposes an innovative method to avoid overconstrained architectures in multi-axis presses, by implementing a family of modular parallel mechanisms that connect multiple servo-axes to the press ram. Parallel mechanisms, which can be applied in several fields of robotics and industrial automation, exhibit important benefits for the application at hand, including high-load capacity, stiffness, and compactness. A biaxial industrial servo press prototype with a nonoverconstrained and modular architecture was built and presented as a proof of concept. Each axis comprises a servomotor, a gearbox reducer, and a ball-screw transmission. It is shown that such a press may be constructed from commercially available components, achieving high energy efficiency and high press force with relatively simple construction. A direct comparison with an equivalent hydraulic-press model is carried out, thus highlighting the servo press energy efficiency.}
}

@article{meoniDesignNonoverconstrainedEnergyEfficient2016a,
  title = {Design of {{Nonoverconstrained Energy-Efficient Multi-Axis Servo Presses}} for {{Deep-Drawing Applications1}}},
  author = {Meoni, F. and Carricato, M.},
  date = {2016},
  journaltitle = {Journal of Mechanical Design, Transactions of the ASME},
  volume = {138},
  number = {6},
  doi = {10.1115/1.4033085},
  abstract = {Servo-actuated presses may provide maximum pressing force at any ram position in the same manner that hydraulic presses do, while offering several benefits in terms of precision, energy-conversion efficiency, and simplicity, due to their lack of hydraulic circuitry and oil. Several press builders have developed servo-actuated presses; however, issues relating to overconstrained multi-axis architecture have been disregarded. This study proposes an innovative method to avoid overconstrained architectures in multi-axis presses, by implementing a family of modular parallel mechanisms that connect multiple servo-axes to the press ram. Parallel mechanisms, which can be applied in several fields of robotics and industrial automation, exhibit important benefits for the application at hand, including high-load capacity, stiffness, and compactness. A biaxial industrial servo press prototype with a nonoverconstrained and modular architecture was built and presented as a proof of concept. Each axis comprises a servomotor, a gearbox reducer, and a ball-screw transmission. It is shown that such a press may be constructed from commercially available components, achieving high energy efficiency and high press force with relatively simple construction. A direct comparison with an equivalent hydraulic-press model is carried out, thus highlighting the servo press energy efficiency.}
}

@inproceedings{mermaInnovationManagementApproach2020,
  title = {An Innovation Management Approach for the Digital Transformation of Industries Maturity Assessment: {{Case}} Studies in the Peruvian Mining},
  booktitle = {Towards the {{Digital World}} and {{Industry X}}.0 - {{Proceedings}} of the 29th {{International Conference}} of the {{International Association}} for {{Management}} of {{Technology}}, {{IAMOT}} 2020},
  author = {Merma, Y. P. C.},
  date = {2020},
  pages = {641--652},
  abstract = {Mining is one of the main sectors of global industry; its considerable contribution to GDP, its exploration and integration projects with other economic sectors get attraction in many knowledge fields. Accurately the strategic vision for the Bicentennial looks for the consolidation of this activity in Peru. Although in recent years it has traditionally been understood that production processes miners result in commodities; there are a series of stages in the mining operation where there are various changes, reductions and transformations based on the extracted land; and that many times are not considered as an aspect of value aggregate. Thus, a key factor in understanding the technological assimilation of this activity is the recognition of Key Process Areas (KPAs) from Digital Transformation. The objective of this work is to propose a Maturity Model (MM) for Digital Transformation of Industries (IDX) according to the principles of Innovation Management (IM) and its respective applications in a specific sector. The research methodology has a character descriptive and qualitative, based on Case Studies in seven Peruvian mining companies. The unit of analysis of the study is the maturity assessment of IDX in Peruvian mining. The main research questions are: What kind of KPAs related to IM was necessary to include for the construction of the IDX MM? In what maturity level of IDX are the Peruvian mining companies? As results, the additional KPAs for the MM involved innovative capabilities instead of an innovation management framework such as: Resource Efficiency, Operational efficiency and Shared Value. On the other hand, mostly mining companies have developed different maturity levels during its IDX process.},
  isbn = {978-1-77592-195-0}
}

@inproceedings{mermaInnovationManagementApproach2020a,
  title = {An Innovation Management Approach for the Digital Transformation of Industries Maturity Assessment: {{Case}} Studies in the Peruvian Mining},
  booktitle = {Towards the {{Digital World}} and {{Industry X}}.0 - {{Proceedings}} of the 29th {{International Conference}} of the {{International Association}} for {{Management}} of {{Technology}}, {{IAMOT}} 2020},
  author = {Merma, Y.P.C.},
  date = {2020},
  pages = {641--652},
  abstract = {Mining is one of the main sectors of global industry; its considerable contribution to GDP, its exploration and integration projects with other economic sectors get attraction in many knowledge fields. Accurately the strategic vision for the Bicentennial looks for the consolidation of this activity in Peru. Although in recent years it has traditionally been understood that production processes miners result in commodities; there are a series of stages in the mining operation where there are various changes, reductions and transformations based on the extracted land; and that many times are not considered as an aspect of value aggregate. Thus, a key factor in understanding the technological assimilation of this activity is the recognition of Key Process Areas (KPAs) from Digital Transformation. The objective of this work is to propose a Maturity Model (MM) for Digital Transformation of Industries (IDX) according to the principles of Innovation Management (IM) and its respective applications in a specific sector. The research methodology has a character descriptive and qualitative, based on Case Studies in seven Peruvian mining companies. The unit of analysis of the study is the maturity assessment of IDX in Peruvian mining. The main research questions are: What kind of KPAs related to IM was necessary to include for the construction of the IDX MM? In what maturity level of IDX are the Peruvian mining companies? As results, the additional KPAs for the MM involved innovative capabilities instead of an innovation management framework such as: Resource Efficiency, Operational efficiency and Shared Value. On the other hand, mostly mining companies have developed different maturity levels during its IDX process.},
  isbn = {978-1-77592-195-0}
}

@online{meyerLLMassistedKnowledgeGraph2023,
  title = {{{LLM-assisted Knowledge Graph Engineering}}: {{Experiments}} with {{ChatGPT}}},
  shorttitle = {{{LLM-assisted Knowledge Graph Engineering}}},
  author = {Meyer, Lars-Peter and Stadler, Claus and Frey, Johannes and Radtke, Norman and Junghanns, Kurt and Meissner, Roy and Dziwis, Gordian and Bulert, Kirill and Martin, Michael},
  date = {2023-07-13},
  eprint = {2307.06917},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.06917},
  urldate = {2023-11-19},
  abstract = {Knowledge Graphs (KG) provide us with a structured, flexible, transparent, cross-system, and collaborative way of organizing our knowledge and data across various domains in society and industrial as well as scientific disciplines. KGs surpass any other form of representation in terms of effectiveness. However, Knowledge Graph Engineering (KGE) requires in-depth experiences of graph structures, web technologies, existing models and vocabularies, rule sets, logic, as well as best practices. It also demands a significant amount of work.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases},
  file = {C:\Users\leemar\Zotero\storage\WIFT8X99\Meyer 等。 - 2023 - LLM-assisted Knowledge Graph Engineering Experime.pdf}
}

@misc{ministerforplanningandpublicspacesResearchConfirmsDensity,
  title = {Research Confirms Density Close to {{CBD}}, Lowers Infrastructure Costs},
  author = {Minister for Planning {and} Public Spaces},
  url = {https://www.nsw.gov.au/media-releases/research-confirms-density-close-to-cbd-lowers-costs}
}

@article{mitterbergerDigitalSoilRobotically2020,
  title = {Digital Soil: {{Robotically 3D-printed}} Granular Bio-Composites},
  author = {Mitterberger, D. and Derme, T.},
  date = {2020},
  journaltitle = {International Journal of Architectural Computing},
  volume = {18},
  number = {2},
  pages = {194--211},
  doi = {10.1177/1478077120924996},
  abstract = {Organic granular materials offer a valid alternative for non-biodegradable composites widely adopted in building construction and digital fabrication. Despite the need to find alternatives to fuel-based solutions, current material research in architecture mostly supports strategies that favour predictable, durable and homogeneous solutions. Materials such as soil, due to their physical properties and volatile nature, present new challenges and potentials to change the way we manufacture, built and integrate material systems and environmental factors into the design process. This article proposes a novel fabrication framework that combines high-resolution three-dimensional-printed biodegradable materials with a novel robotic-additive manufacturing process for soil structures. Furthermore, the research reflects on concepts such as affordance and tolerance within the field of digital fabrication, especially in regards to bio-materials and robotic fabrication. Soil as a building material has a long tradition. New developments in earth construction show how earthen buildings can create novel, adaptive and sustainable structures. Nevertheless, existing large-scale earthen construction methods can only produce highly simplified shapes with rough geometrical articulations. This research proposes to use a robotic binder-jetting process that creates novel organic bio-composites to overcome such limitations of common earth constructions. In addition, this article shows how biological polymers, such as polysaccharides-based hydrogels, can be used as sustainable, biodegradable binding agents for soil aggregates. This article is divided into four main sections: architecture and affordance; tolerance versus precision; water-based binders; and robotic fabrication parameters. Digital Soil envisions a shift in the design practice and digital fabrication that builds on methods for tolerance handling. In this context, material and geometrical properties such as material porosity, hydraulic conductivity and natural evaporation rate affect the architectural resolution, introducing a design process driven by matter. Digital Soil shows the potential of a fully reversible biodegradable manufacturing process for load-bearing architectural elements, opening up new fields of application for sustainable material systems that can enhance the ecological potential of architectural construction.}
}

@article{mitterbergerDigitalSoilRobotically2020a,
  title = {Digital Soil: {{Robotically 3D-printed}} Granular Bio-Composites},
  author = {Mitterberger, D. and Derme, T.},
  date = {2020},
  journaltitle = {International Journal of Architectural Computing},
  volume = {18},
  number = {2},
  pages = {194--211},
  doi = {10.1177/1478077120924996},
  abstract = {Organic granular materials offer a valid alternative for non-biodegradable composites widely adopted in building construction and digital fabrication. Despite the need to find alternatives to fuel-based solutions, current material research in architecture mostly supports strategies that favour predictable, durable and homogeneous solutions. Materials such as soil, due to their physical properties and volatile nature, present new challenges and potentials to change the way we manufacture, built and integrate material systems and environmental factors into the design process. This article proposes a novel fabrication framework that combines high-resolution three-dimensional-printed biodegradable materials with a novel robotic-additive manufacturing process for soil structures. Furthermore, the research reflects on concepts such as affordance and tolerance within the field of digital fabrication, especially in regards to bio-materials and robotic fabrication. Soil as a building material has a long tradition. New developments in earth construction show how earthen buildings can create novel, adaptive and sustainable structures. Nevertheless, existing large-scale earthen construction methods can only produce highly simplified shapes with rough geometrical articulations. This research proposes to use a robotic binder-jetting process that creates novel organic bio-composites to overcome such limitations of common earth constructions. In addition, this article shows how biological polymers, such as polysaccharides-based hydrogels, can be used as sustainable, biodegradable binding agents for soil aggregates. This article is divided into four main sections: architecture and affordance; tolerance versus precision; water-based binders; and robotic fabrication parameters. Digital Soil envisions a shift in the design practice and digital fabrication that builds on methods for tolerance handling. In this context, material and geometrical properties such as material porosity, hydraulic conductivity and natural evaporation rate affect the architectural resolution, introducing a design process driven by matter. Digital Soil shows the potential of a fully reversible biodegradable manufacturing process for load-bearing architectural elements, opening up new fields of application for sustainable material systems that can enhance the ecological potential of architectural construction.}
}

@article{moAttentionImpedesNeural2022,
  title = {Attention Impedes Neural Representation of Interpolated Orientation during Perceptual Completion},
  author = {Mo, C. and Zhang, S. and Lu, J. and Yu, M. and Yao, Y.},
  date = {2022},
  journaltitle = {Psychophysiology},
  volume = {59},
  number = {8},
  doi = {10.1111/psyp.14031},
  abstract = {One of the most remarkable functional feats accomplished by visual system is the interpolation of missing retinal inputs based on surrounding information, a process known as perceptual completion. Perceptual completion enables the active construction of coherent, vivid percepts from spatially discontinuous visual information that is prevalent in real-life visual scenes. Despite mounting evidence linking sensory activity enhancement and perceptual completion, surprisingly little is known about whether and how attention, a fundamental modulator of sensory activities, affects perceptual completion. Using EEG-based time-resolved inverted encoding model (IEM), we reconstructed the moment-to-moment representation of the illusory grating that resulted from spatially interpolating the orientation of surrounding inducers. We found that, despite manipulation of observers' attentional focus, the illusory grating representation unfolded in time in a similar manner. Critically, attention to the surrounding inducers simultaneously attenuated the illusory grating representation and delayed its temporal development. Our findings disclosed, for the first time, the suppressive role of selective attention in perceptual completion and were suggestive of a fast, automatic neural machinery that implements the interpolation of missing visual information.}
}

@article{moAttentionImpedesNeural2022a,
  title = {Attention Impedes Neural Representation of Interpolated Orientation during Perceptual Completion},
  author = {Mo, C. and Zhang, S. and Lu, J. and Yu, M. and Yao, Y.},
  date = {2022},
  journaltitle = {Psychophysiology},
  volume = {59},
  number = {8},
  doi = {10.1111/psyp.14031},
  abstract = {One of the most remarkable functional feats accomplished by visual system is the interpolation of missing retinal inputs based on surrounding information, a process known as perceptual completion. Perceptual completion enables the active construction of coherent, vivid percepts from spatially discontinuous visual information that is prevalent in real-life visual scenes. Despite mounting evidence linking sensory activity enhancement and perceptual completion, surprisingly little is known about whether and how attention, a fundamental modulator of sensory activities, affects perceptual completion. Using EEG-based time-resolved inverted encoding model (IEM), we reconstructed the moment-to-moment representation of the illusory grating that resulted from spatially interpolating the orientation of surrounding inducers. We found that, despite manipulation of observers' attentional focus, the illusory grating representation unfolded in time in a similar manner. Critically, attention to the surrounding inducers simultaneously attenuated the illusory grating representation and delayed its temporal development. Our findings disclosed, for the first time, the suppressive role of selective attention in perceptual completion and were suggestive of a fast, automatic neural machinery that implements the interpolation of missing visual information.}
}

@article{molfinoAutonomousDrillingRobot2008,
  title = {Autonomous Drilling Robot for Landslide Monitoring and Consolidation},
  author = {Molfino, R.M. and Razzoli, R.P. and Zoppi, M.},
  date = {2008},
  journaltitle = {Automation in Construction},
  volume = {17},
  number = {2},
  pages = {111--121},
  doi = {10.1016/j.autcon.2006.12.004},
  abstract = {The paper proposes a new highly automated drilling system able to create holes up to 20~m depth in rocky walls using standard 1.5~m length rods. The drilling system, to be used to automate rocky walls consolidation, has to be positioned in the points of the map earlier defined by the geologist; for this reason it is hosted onto a semiautonomous climbing platform, with rods stored on-board. An automatic system is also required to feed the drilling head with new rods while the hole progresses and to recover the rods once the hole is up. The drilling system mainly consists of: a commercial drilling rig with the requested modifications for the interfacing to an automatic feeding system; a manipulator (endowed with a suitable gripper) for the loading/unloading of the rods; a storage buffer for allocating the rods. In the paper, the alternatives considered for the design of the whole drilling system are shortly recalled, explaining the guidelines which led to the final architecture, as well. © 2006 Elsevier B.V. All rights reserved.}
}

@article{molfinoAutonomousDrillingRobot2008a,
  title = {Autonomous Drilling Robot for Landslide Monitoring and Consolidation},
  author = {Molfino, R.M. and Razzoli, R.P. and Zoppi, M.},
  date = {2008},
  journaltitle = {Automation in Construction},
  volume = {17},
  number = {2},
  pages = {111--121},
  doi = {10.1016/j.autcon.2006.12.004},
  abstract = {The paper proposes a new highly automated drilling system able to create holes up to 20~m depth in rocky walls using standard 1.5~m length rods. The drilling system, to be used to automate rocky walls consolidation, has to be positioned in the points of the map earlier defined by the geologist; for this reason it is hosted onto a semiautonomous climbing platform, with rods stored on-board. An automatic system is also required to feed the drilling head with new rods while the hole progresses and to recover the rods once the hole is up. The drilling system mainly consists of: a commercial drilling rig with the requested modifications for the interfacing to an automatic feeding system; a manipulator (endowed with a suitable gripper) for the loading/unloading of the rods; a storage buffer for allocating the rods. In the paper, the alternatives considered for the design of the whole drilling system are shortly recalled, explaining the guidelines which led to the final architecture, as well. © 2006 Elsevier B.V. All rights reserved.}
}

@article{molHBIMStoringLifecycle2020,
  title = {{{HBIM}} for Storing Life-Cycle Data Regarding Decay and Damage in Existing Timber Structures},
  author = {Mol, A. and Cabaleiro, M. and Sousa, H.S. and Branco, J.M.},
  date = {2020},
  journaltitle = {Automation in Construction},
  volume = {117},
  doi = {10.1016/j.autcon.2020.103262},
  abstract = {The conservation and maintenance of the historical heritage is an issue of great importance, especially when dealing with elements that can easily suffer damage along the time, either to intrinsic materials properties or by exposure conditions, like often happen for timber structures. For the management and maintenance of historic timber structures, HBIM (Historic Building Information Modeling) is here presented as a fundamental tool. This work presents the application of a methodology that uses common HBIM software in combination with results obtained from non-destructive testing and geometric surveying, allowing it to perform modeling, analysis and storage of geometric data, levels of decay and lack of material of timber structures within a tridimensional space. Moreover, the proposed framework incorporates different time stages, thus allowing to make periodic comparisons along time, that substantiate a decision making process to take decisions about maintenance and intervention actions. In this work two case studies are used to validate this methodology and present its possible use. The case studies are: (i) the timber structure of the roof of the key tower of the Castle of Guimarães, and (ii) the timber structure of the ceiling and roof of the room of the Knight's Room in the Convent of Christ, Tomar, both Portuguese buildings listed as UNESCO World Heritage Sites.}
}

@article{molHBIMStoringLifecycle2020a,
  title = {{{HBIM}} for Storing Life-Cycle Data Regarding Decay and Damage in Existing Timber Structures},
  author = {Mol, A. and Cabaleiro, M. and Sousa, H.S. and Branco, J.M.},
  date = {2020},
  journaltitle = {Automation in Construction},
  volume = {117},
  doi = {10.1016/j.autcon.2020.103262},
  abstract = {The conservation and maintenance of the historical heritage is an issue of great importance, especially when dealing with elements that can easily suffer damage along the time, either to intrinsic materials properties or by exposure conditions, like often happen for timber structures. For the management and maintenance of historic timber structures, HBIM (Historic Building Information Modeling) is here presented as a fundamental tool. This work presents the application of a methodology that uses common HBIM software in combination with results obtained from non-destructive testing and geometric surveying, allowing it to perform modeling, analysis and storage of geometric data, levels of decay and lack of material of timber structures within a tridimensional space. Moreover, the proposed framework incorporates different time stages, thus allowing to make periodic comparisons along time, that substantiate a decision making process to take decisions about maintenance and intervention actions. In this work two case studies are used to validate this methodology and present its possible use. The case studies are: (i) the timber structure of the roof of the key tower of the Castle of Guimarães, and (ii) the timber structure of the ceiling and roof of the room of the Knight's Room in the Convent of Christ, Tomar, both Portuguese buildings listed as UNESCO World Heritage Sites.}
}

@book{mollerOntologybasedReasoningTechniques2008,
  title = {Ontology-Based Reasoning Techniques for Multimedia Interpretation and Retrieval},
  author = {Möller, R. and Neumann, B.},
  date = {2008},
  journaltitle = {Semantic Multimedia and Ontologies: Theory and Applications},
  doi = {10.1007/978-1-84800-076-6_3},
  abstract = {In this chapter, we show how formal knowledge representation and reasoning techniques can be used for the retrieval and interpretation of multimedia data. This section explains what we mean by an "interpretation"using examples of audio and video interpretation. Intuitively, interpretations are descriptions of media data at a high abstraction level, exposing interrelations and coherencies. In Section 3.2.3, we introduce description logics (DLs) as the formal basis for ontology languages of the OWL (web ontology language) family and for the interpretation framework described in subsequent sections. As a concrete example, we consider the interpretation of images describing a sports event in Section 3.3. It is shown that interpretations can be obtained by abductive reasoning, and a general interpretation framework is presented. Stepwise construction of an interpretation can be viewed as navigation in the compositional and taxonomical hierarchies spanned by a conceptual knowledge base. What do we mean by "interpretation"of media objects Consider the image shown in Fig. 3.1. One can think of the image as a set of primitive objects such as persons, garbage containers, a garbage truck, a bicycle, traffic signs, trees, etc. An interpretation of the image is a description which "makes sense"of these primitive objects. In our example, the interpretation could include the assertions "two workers empty garbage containers into a garbage truck"and "a mailman distributes mail"expressed in some knowledge representation language. When including the figure caption into the interpretation process, we have a multimodal interpretation task which in this case involves visual and textual media objects. The result could be a refinement of the assertions above in terms of the location "in Hamburg. Note that the interpretation describes activities extending in time although it is only based on a snapshot. Interpretations may generally include An interpretation is a "high-level"description of media data in the sense that it involves terms which abstract from details at lower representation levels. This is typical for meaningful descriptions in human language and hence also a desirable goal for machine interpretation. Media interpretation is therefore often structured as a process computing higher level representations from lower level ones. Figure 3.2 shows the level structure of two early interpretation systems, the speech recognition system HEARSAY-II (Erman, Hayes-Roth, Lesser and Reddy 1980) and the image interpretation system VISIONS (Hanson and Riseman 1978). The basic structure exemplified by each of the two systems also applies to interpretation systems in general: signal processing procedures first transform raw media data into primitive media objects by low-level processing steps. Then higher level descriptions are determined based on the primitive media objects. The low-level processing steps are often called "analysis"(e.g. image analysis, speech analysis), the high-level steps constitute the interpretation process. It is useful to view interpretation as a process which is both based on the general conceptual knowledge and the concrete contextual knowledge which an agent may possess. The term "contextual knowledge"covers specific prior knowledge relevant for the interpretation which the agent may possess (e.g. spatial and temporal context of a video clip) as well as the knowledge about the current task of the agent (e.g. recognizing criminal acts vs. recognizing sports events). The knowledge-based structure of an image sequence interpretation system is shown in Fig. 3.3. The concepts represented in the conceptual knowledge base typically describe configurations of lower level entities forming some interesting higher level entity, for example a configuration of an athlete and a horizontal bar forming a "high jump"event. We call such concepts "aggregates"as they combine several components to a larger whole. Aggregates form a compositional hierarchy, in addition to the taxonomical hierarchy induced by logic-based concept definitions. In a description logic setting, an aggregate has the generic structure shown in Fig. 3.4 (Neumann and Moller 2006). An aggregate is defined by (1) inheritance from parent concepts, (2) roles relating the aggregate to parts, and (3) constraints relating parts to each other. Instantiations of aggregates are at the core of media interpretations. In summary, interpretations have the following characteristics: they involve several objects; depend on the temporal or spatial relations between parts; describe the data in qualitative terms, omitting detail; exploit contextual information; include inferred facts, not explicit in the data; are based on conceptual knowledge about the application domain. The chapter is structured as follows.We first describe how ontology-based information retrieval can be formalised using description-logic inference problems (Section 3.2). Introducing the necessary technical background, we demonstrate for what purpose the output of media interpretation can be used, and, thereby, derive requirements for the media interpretation process. Then, in Section 3.3, the automatic construction of media interpretations is investigated. Techniques for dealing with uncertain and ambiguous interpretations are presented in Section 3.4. We conclude in Section 3.5. In summary it is the purpose of this chapter to show that interpretations can be computed in a formal knowledge representation framework using various reasoning processes. This has multiple potential benefits. First, the complex computational process "media interpretation"is realised via standardised reasoning procedures, i.e. by programs which have been conceptually shown to meet correctness and completeness conditions, and have been implemented as reusable tools for a wide range of applications. Second, the terms by which interpretations are expressed are embedded in a sharable ontology which provides a transparent declarative representation with well-defined semantics. Furthermore, ontologies constitute resources not only for media interpretation but also for other tasks dealing with semantic content, such as information retrieval, communication, documentation, and various engineering processes.},
  isbn = {978-1-84800-075-9},
  pagetotal = {55-98}
}

@book{mollerOntologybasedReasoningTechniques2008a,
  title = {Ontology-Based Reasoning Techniques for Multimedia Interpretation and Retrieval},
  author = {Möller, R. and Neumann, B.},
  date = {2008},
  journaltitle = {Semantic Multimedia and Ontologies: Theory and Applications},
  doi = {10.1007/978-1-84800-076-6_3},
  abstract = {In this chapter, we show how formal knowledge representation and reasoning techniques can be used for the retrieval and interpretation of multimedia data. This section explains what we mean by an "interpretation"using examples of audio and video interpretation. Intuitively, interpretations are descriptions of media data at a high abstraction level, exposing interrelations and coherencies. In Section 3.2.3, we introduce description logics (DLs) as the formal basis for ontology languages of the OWL (web ontology language) family and for the interpretation framework described in subsequent sections. As a concrete example, we consider the interpretation of images describing a sports event in Section 3.3. It is shown that interpretations can be obtained by abductive reasoning, and a general interpretation framework is presented. Stepwise construction of an interpretation can be viewed as navigation in the compositional and taxonomical hierarchies spanned by a conceptual knowledge base. What do we mean by "interpretation"of media objects Consider the image shown in Fig. 3.1. One can think of the image as a set of primitive objects such as persons, garbage containers, a garbage truck, a bicycle, traffic signs, trees, etc. An interpretation of the image is a description which "makes sense"of these primitive objects. In our example, the interpretation could include the assertions "two workers empty garbage containers into a garbage truck"and "a mailman distributes mail"expressed in some knowledge representation language. When including the figure caption into the interpretation process, we have a multimodal interpretation task which in this case involves visual and textual media objects. The result could be a refinement of the assertions above in terms of the location "in Hamburg. Note that the interpretation describes activities extending in time although it is only based on a snapshot. Interpretations may generally include An interpretation is a "high-level"description of media data in the sense that it involves terms which abstract from details at lower representation levels. This is typical for meaningful descriptions in human language and hence also a desirable goal for machine interpretation. Media interpretation is therefore often structured as a process computing higher level representations from lower level ones. Figure 3.2 shows the level structure of two early interpretation systems, the speech recognition system HEARSAY-II (Erman, Hayes-Roth, Lesser and Reddy 1980) and the image interpretation system VISIONS (Hanson and Riseman 1978). The basic structure exemplified by each of the two systems also applies to interpretation systems in general: signal processing procedures first transform raw media data into primitive media objects by low-level processing steps. Then higher level descriptions are determined based on the primitive media objects. The low-level processing steps are often called "analysis"(e.g. image analysis, speech analysis), the high-level steps constitute the interpretation process. It is useful to view interpretation as a process which is both based on the general conceptual knowledge and the concrete contextual knowledge which an agent may possess. The term "contextual knowledge"covers specific prior knowledge relevant for the interpretation which the agent may possess (e.g. spatial and temporal context of a video clip) as well as the knowledge about the current task of the agent (e.g. recognizing criminal acts vs. recognizing sports events). The knowledge-based structure of an image sequence interpretation system is shown in Fig. 3.3. The concepts represented in the conceptual knowledge base typically describe configurations of lower level entities forming some interesting higher level entity, for example a configuration of an athlete and a horizontal bar forming a "high jump"event. We call such concepts "aggregates"as they combine several components to a larger whole. Aggregates form a compositional hierarchy, in addition to the taxonomical hierarchy induced by logic-based concept definitions. In a description logic setting, an aggregate has the generic structure shown in Fig. 3.4 (Neumann and Moller 2006). An aggregate is defined by (1) inheritance from parent concepts, (2) roles relating the aggregate to parts, and (3) constraints relating parts to each other. Instantiations of aggregates are at the core of media interpretations. In summary, interpretations have the following characteristics: they involve several objects; depend on the temporal or spatial relations between parts; describe the data in qualitative terms, omitting detail; exploit contextual information; include inferred facts, not explicit in the data; are based on conceptual knowledge about the application domain. The chapter is structured as follows.We first describe how ontology-based information retrieval can be formalised using description-logic inference problems (Section 3.2). Introducing the necessary technical background, we demonstrate for what purpose the output of media interpretation can be used, and, thereby, derive requirements for the media interpretation process. Then, in Section 3.3, the automatic construction of media interpretations is investigated. Techniques for dealing with uncertain and ambiguous interpretations are presented in Section 3.4. We conclude in Section 3.5. In summary it is the purpose of this chapter to show that interpretations can be computed in a formal knowledge representation framework using various reasoning processes. This has multiple potential benefits. First, the complex computational process "media interpretation"is realised via standardised reasoning procedures, i.e. by programs which have been conceptually shown to meet correctness and completeness conditions, and have been implemented as reusable tools for a wide range of applications. Second, the terms by which interpretations are expressed are embedded in a sharable ontology which provides a transparent declarative representation with well-defined semantics. Furthermore, ontologies constitute resources not only for media interpretation but also for other tasks dealing with semantic content, such as information retrieval, communication, documentation, and various engineering processes.},
  isbn = {978-1-84800-075-9},
  pagetotal = {55-98}
}

@inproceedings{monizTechnologyAssessmentApproach2014,
  title = {Technology Assessment Approach to Human-Robot Interactions in Work Environments},
  booktitle = {2014 7th {{International Conference}} on {{Human System Interactions}} ({{HSI}})},
  author = {Moniz, Antonio and Krings, Bettina-Johanna},
  date = {2014-06},
  pages = {282--289},
  publisher = {{IEEE}},
  location = {{Costa da Caparica}},
  doi = {10.1109/HSI.2014.6860490},
  url = {http://ieeexplore.ieee.org/document/6860490/},
  urldate = {2023-08-20},
  eventtitle = {2014 7th {{International Conference}} on {{Human System Interactions}} ({{HSI}})},
  isbn = {978-1-4799-4714-0}
}

@article{Moon2014,
  title = {Meet Me Where i'm Gazing: {{How}} Shared Attention Gaze Affects Human-Robot Handover Timing},
  author = {Moon, A. and Troniak, D.M. and Gleeson, B. and Pan, M.K.X.J. and Zeng, M. and Blumer, B.A. and MacLean, K. and Croft, E.A.},
  date = {2014},
  journaltitle = {Proc. HRI'14}
}

@article{morrealeIntegrationExternalInternal2001,
  title = {Integration of External and Internal School Activities: {{Support}} from New Technologies},
  author = {Morreale, E.},
  date = {2001},
  journaltitle = {Educational Technology and Society},
  volume = {4},
  number = {2},
  pages = {66--78},
  abstract = {The paper examines some of the ways new technologies can be used to integrate external experiences (eg museums, natural parks) into traditional school activities. For this purpose, we present the main design approaches adopted in the design of: a) a system for highlighting the role of a museum in teaching natural sciences in primary schools; b) the technological infrastructure INformatic- TElematic- RObotic (IN.TE.RO.) for a Geopaleon-tology Museum; c) a methodology and a development system for presenting Cultural Heritage collections through "traditional" data (texts, images, films and animations) as well as through interactive 3D graphics. Both the methodology and the development system have been tested on widely different applications (historic buildings and architectures on the one hand, and natural fauna and paleontological examples on the other). From these experiences the most relevant choices and results on technical, organizational and didactic aspects are presented together with the rationale behind this approach.}
}

@article{morrealeIntegrationExternalInternal2001a,
  title = {Integration of External and Internal School Activities: {{Support}} from New Technologies},
  author = {Morreale, E.},
  date = {2001},
  journaltitle = {Educational Technology and Society},
  volume = {4},
  number = {2},
  pages = {66--78},
  abstract = {The paper examines some of the ways new technologies can be used to integrate external experiences (eg museums, natural parks) into traditional school activities. For this purpose, we present the main design approaches adopted in the design of: a) a system for highlighting the role of a museum in teaching natural sciences in primary schools; b) the technological infrastructure INformatic- TElematic- RObotic (IN.TE.RO.) for a Geopaleon-tology Museum; c) a methodology and a development system for presenting Cultural Heritage collections through "traditional" data (texts, images, films and animations) as well as through interactive 3D graphics. Both the methodology and the development system have been tested on widely different applications (historic buildings and architectures on the one hand, and natural fauna and paleontological examples on the other). From these experiences the most relevant choices and results on technical, organizational and didactic aspects are presented together with the rationale behind this approach.}
}

@article{Mörtl2014,
  title = {Rhythm Patterns Interaction - {{Synchronization}} Behavior for Human-Robot Joint Action},
  author = {Mörtl, A. and Lorenz, T. and Hirche, S.},
  date = {2014},
  journaltitle = {PLoS ONE},
  volume = {9},
  number = {4},
  doi = {10.1371/journal.pone.0095195},
  art_number = {e95195}
}

@article{mortlRoleRolesPhysical2012,
  title = {The Role of Roles: {{Physical}} Cooperation between Humans and Robots},
  author = {Mörtl, Alexander and Lawitzky, Martin and Kucukyilmaz, Ayse and Sezgin, Metin and Basdogan, Cagatay and Hirche, Sandra},
  date = {2012},
  journaltitle = {International Journal of Robotics Research},
  volume = {31},
  number = {13},
  pages = {1656--1674},
  issn = {02783649},
  doi = {10.1177/0278364912455366},
  abstract = {Since the strict separation of working spaces of humans and robots has experienced a softening due to recent robotics research achievements, close interaction of humans and robots comes rapidly into reach. In this context, physical human-robot interaction raises a number of questions regarding a desired intuitive robot behavior. The continuous bilateral information and energy exchange requires an appropriate continuous robot feedback. Investigating a cooperative manipulation task, the desired behavior is a combination of an urge to fulfill the task, a smooth instant reactive behavior to human force inputs and an assignment of the task effort to the cooperating agents. In this paper, a formal analysis of human-robot cooperative load transport is presented. Three different possibilities for the assignment of task effort are proposed. Two proposed dynamic role exchange mechanisms adjust the robot's urge to complete the task based on the human feedback. For comparison, a static role allocation strategy not relying on the human agreement feedback is investigated as well. All three role allocation mechanisms are evaluated in a user study that involves large-scale kinesthetic interaction and full-body human motion. Results show tradeoffs between subjective and objective performance measures stating a clear objective advantage of the proposed dynamic role allocation scheme. © The Author(s) 2012.},
  isbn = {0278364912455},
  keywords = {Cooperative manipulation,human feedback,input decomposition,kinesthetic interaction,load sharing}
}

@article{mortlRoleRolesPhysical2012a,
  title = {The Role of Roles: {{Physical}} Cooperation between Humans and Robots},
  author = {Mörtl, Alexander and Lawitzky, Martin and Kucukyilmaz, Ayse and Sezgin, Metin and Basdogan, Cagatay and Hirche, Sandra},
  date = {2012},
  journaltitle = {International Journal of Robotics Research},
  volume = {31},
  number = {13},
  pages = {1656--1674},
  issn = {02783649},
  doi = {10.1177/0278364912455366},
  abstract = {Since the strict separation of working spaces of humans and robots has experienced a softening due to recent robotics research achievements, close interaction of humans and robots comes rapidly into reach. In this context, physical human-robot interaction raises a number of questions regarding a desired intuitive robot behavior. The continuous bilateral information and energy exchange requires an appropriate continuous robot feedback. Investigating a cooperative manipulation task, the desired behavior is a combination of an urge to fulfill the task, a smooth instant reactive behavior to human force inputs and an assignment of the task effort to the cooperating agents. In this paper, a formal analysis of human-robot cooperative load transport is presented. Three different possibilities for the assignment of task effort are proposed. Two proposed dynamic role exchange mechanisms adjust the robot's urge to complete the task based on the human feedback. For comparison, a static role allocation strategy not relying on the human agreement feedback is investigated as well. All three role allocation mechanisms are evaluated in a user study that involves large-scale kinesthetic interaction and full-body human motion. Results show tradeoffs between subjective and objective performance measures stating a clear objective advantage of the proposed dynamic role allocation scheme. © The Author(s) 2012.},
  isbn = {0278364912455},
  keywords = {Cooperative manipulation,human feedback,input decomposition,kinesthetic interaction,load sharing},
  file = {C:\Users\leemar\Zotero\storage\S4DMWA7G\Human_Robot_Haptic_Collaboration_IJRR_2012.pdf}
}

@article{mullinerAssessmentSustainableHousing2013,
  title = {An Assessment of Sustainable Housing Affordability Using a Multiple Criteria Decision Making Method},
  author = {Mulliner, Emma and Smallbone, Kieran and Maliene, Vida},
  date = {2013-04},
  journaltitle = {Omega},
  shortjournal = {Omega},
  volume = {41},
  number = {2},
  pages = {270--279},
  issn = {03050483},
  doi = {10.1016/j.omega.2012.05.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0305048312000928},
  urldate = {2023-09-17},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\H7YQ5RWA\Mulliner 等。 - 2013 - An assessment of sustainable housing affordability.pdf}
}

@article{mutisObjectDetectorsConstruction2021,
  title = {Object {{Detectors}} for {{Construction Resources Using Unmanned Aerial Vehicles}}},
  author = {Mutis, I. and Joshi, V. A. and Singh, A.},
  date = {2021},
  journaltitle = {Practice Periodical on Structural Design and Construction},
  volume = {26},
  number = {4},
  doi = {10.1061/(ASCE)SC.1943-5576.0000598},
  abstract = {Project control operations in construction are mostly executed via direct observations and the manual monitoring of progress and performance of construction tasks on the job site. Project engineers move physically within job-site areas to ensure activities are executed as planned. Such physical displacements are error-prone and ineffective in cost and time, particularly in larger construction zones. It is critical to explore new methods and technologies to effectively assist performance control operations by rapidly capturing data from materials and equipment on the job site. Motivated by the ubiquitous use of unmanned aerial vehicles (UAVs) in construction projects and the maturity of computer-vision-based machine-learning (ML) techniques, this research investigates the challenges of object detection - the process of predicting classes of objects (specified construction materials and equipment) - in real time. The study addresses the challenges of data collection and predictions for remote monitoring in project control activities. It uses these two proven and robust technologies by exploring factors that impact the use of UAV aerial images to design and implement object detectors through an analytical conceptualization and a showcase demonstration. The approach sheds light on the applications of deep-learning techniques to access and rapidly identify and classify resources in real-time. It paves the way to shift from costly and time-consuming job-site walkthroughs that are coupled with manual data processing and input to more automated, streamlined operations. The research found that the critical factor to develop object detectors with acceptable levels of accuracy is collecting aerial images with for adequate scales with high frequencies from different positions of the same construction areas.}
}

@article{mutisObjectDetectorsConstruction2021a,
  title = {Object {{Detectors}} for {{Construction Resources Using Unmanned Aerial Vehicles}}},
  author = {Mutis, I. and Joshi, V.A. and Singh, A.},
  date = {2021},
  journaltitle = {Practice Periodical on Structural Design and Construction},
  volume = {26},
  number = {4},
  doi = {10.1061/(ASCE)SC.1943-5576.0000598},
  abstract = {Project control operations in construction are mostly executed via direct observations and the manual monitoring of progress and performance of construction tasks on the job site. Project engineers move physically within job-site areas to ensure activities are executed as planned. Such physical displacements are error-prone and ineffective in cost and time, particularly in larger construction zones. It is critical to explore new methods and technologies to effectively assist performance control operations by rapidly capturing data from materials and equipment on the job site. Motivated by the ubiquitous use of unmanned aerial vehicles (UAVs) in construction projects and the maturity of computer-vision-based machine-learning (ML) techniques, this research investigates the challenges of object detection - the process of predicting classes of objects (specified construction materials and equipment) - in real time. The study addresses the challenges of data collection and predictions for remote monitoring in project control activities. It uses these two proven and robust technologies by exploring factors that impact the use of UAV aerial images to design and implement object detectors through an analytical conceptualization and a showcase demonstration. The approach sheds light on the applications of deep-learning techniques to access and rapidly identify and classify resources in real-time. It paves the way to shift from costly and time-consuming job-site walkthroughs that are coupled with manual data processing and input to more automated, streamlined operations. The research found that the critical factor to develop object detectors with acceptable levels of accuracy is collecting aerial images with for adequate scales with high frequencies from different positions of the same construction areas.}
}

@book{naboniAdvancedMachinery2015,
  title = {Advanced Machinery},
  author = {Naboni, R. and Paoletti, I.},
  date = {2015},
  journaltitle = {SpringerBriefs in Applied Sciences and Technology},
  number = {9783319044},
  doi = {10.1007/978-3-319-04423-1_3},
  abstract = {Advanced Machinery focuses on one fundamental driver of the customization process in the construction sector: the use of advanced digitally controlled fabrication tools. Custom-made architectural systems require tailored fabrication processes, which are described in order to help the designer, with the use of parametric tools to integrate fabrication characteristics in a design. Three main typologies are analyzed: CNC machinery, Robotic Fabrication and Additive ManufacturingManufacturing. This categorization reflects a different approach that the design team should interpret within a project, while recognizing the different technologies of production. In particular, with the employment of robots, there is a shift from specialized industrial means of production like CNC, to versatile machines. This has the potential to revolutionize the current understanding of mass customizationMass customization, allowing architects to experiment limitlessly with a wide range of technical and aesthetic solutions. Moreover, Additive ManufacturingManufacturing has been developing quickly through the last years to accommodate the AEC needs, essentially in two ways: to produce components and sub-components to be assembled and joined to create larger structures, and to “print” large-scale and self-standing architectural elements as a whole. Important research is underway to develop large-scale 3D printersAdditive Manufacturing (AM)3D Printer, along with the simultaneous experimentation of different materials and tectonics with suitable properties to operate on the built environment.},
  pagetotal = {29-75}
}

@book{naboniAdvancedMachinery2015a,
  title = {Advanced Machinery},
  author = {Naboni, R. and Paoletti, I.},
  date = {2015},
  journaltitle = {SpringerBriefs in Applied Sciences and Technology},
  number = {9783319044},
  doi = {10.1007/978-3-319-04423-1_3},
  abstract = {Advanced Machinery focuses on one fundamental driver of the customization process in the construction sector: the use of advanced digitally controlled fabrication tools. Custom-made architectural systems require tailored fabrication processes, which are described in order to help the designer, with the use of parametric tools to integrate fabrication characteristics in a design. Three main typologies are analyzed: CNC machinery, Robotic Fabrication and Additive ManufacturingManufacturing. This categorization reflects a different approach that the design team should interpret within a project, while recognizing the different technologies of production. In particular, with the employment of robots, there is a shift from specialized industrial means of production like CNC, to versatile machines. This has the potential to revolutionize the current understanding of mass customizationMass customization, allowing architects to experiment limitlessly with a wide range of technical and aesthetic solutions. Moreover, Additive ManufacturingManufacturing has been developing quickly through the last years to accommodate the AEC needs, essentially in two ways: to produce components and sub-components to be assembled and joined to create larger structures, and to “print” large-scale and self-standing architectural elements as a whole. Important research is underway to develop large-scale 3D printersAdditive Manufacturing (AM)3D Printer, along with the simultaneous experimentation of different materials and tectonics with suitable properties to operate on the built environment.},
  pagetotal = {29-75}
}

@article{nansaiNovelNestedReconfigurable2017,
  title = {A Novel Nested Reconfigurable Approach for a Glass Façade Cleaning Robot},
  author = {Nansai, S. and Elara, M.R. and Tun, T.T. and Veerajagadheswar, P. and Pathmakumar, T.},
  date = {2017},
  journaltitle = {Inventions},
  volume = {2},
  number = {3},
  doi = {10.3390/inventions2030018},
  abstract = {The façade cleaning of high rise buildings is one of the hazardous tasks that is performed by human operators. Even after a significant advancement in construction technologies, several newfangled skyscrapers are still using the manual method for cleaning the glass panels. This research is aimed at the development of a glass façade cleaning robot, capable of adapting to any kind of building architecture. A robotic system capable of cleaning vertical glass surfaces demands a transformable morphology. A self-reconfigurable robot is one of the potential solutions to realize high degrees of adaptability. Following the design principles we derived, we propose a nested reconfigurable design approach for glass façade cleaning and develope a system of robot modules that performs glass façade cleaning. Throughout this research article, we discuss the brief concept and scheme of nested reconfigurable design principle and the hardware-software challenges associated with it. This article also discusses the capability to maximize the flexibility and modularity of the robot by using intra-and inter-reconfigurations. The effectiveness of the designed system is verified by experimental means.}
}

@article{nansaiNovelNestedReconfigurable2017a,
  title = {A Novel Nested Reconfigurable Approach for a Glass Façade Cleaning Robot},
  author = {Nansai, S. and Elara, M.R. and Tun, T.T. and Veerajagadheswar, P. and Pathmakumar, T.},
  date = {2017},
  journaltitle = {Inventions},
  volume = {2},
  number = {3},
  doi = {10.3390/inventions2030018},
  abstract = {The façade cleaning of high rise buildings is one of the hazardous tasks that is performed by human operators. Even after a significant advancement in construction technologies, several newfangled skyscrapers are still using the manual method for cleaning the glass panels. This research is aimed at the development of a glass façade cleaning robot, capable of adapting to any kind of building architecture. A robotic system capable of cleaning vertical glass surfaces demands a transformable morphology. A self-reconfigurable robot is one of the potential solutions to realize high degrees of adaptability. Following the design principles we derived, we propose a nested reconfigurable design approach for glass façade cleaning and develope a system of robot modules that performs glass façade cleaning. Throughout this research article, we discuss the brief concept and scheme of nested reconfigurable design principle and the hardware-software challenges associated with it. This article also discusses the capability to maximize the flexibility and modularity of the robot by using intra-and inter-reconfigurations. The effectiveness of the designed system is verified by experimental means.}
}

@article{nawrothTissueengineeredJellyfishBiomimetic2012,
  title = {A Tissue-Engineered Jellyfish with Biomimetic Propulsion},
  author = {Nawroth, J.C. and Lee, H. and Feinberg, A.W. and Ripplinger, C.M. and McCain, M.L. and Grosberg, A. and Dabiri, J.O. and Parker, K.K.},
  date = {2012},
  journaltitle = {Nature Biotechnology},
  volume = {30},
  number = {8},
  pages = {792--797},
  doi = {10.1038/nbt.2269},
  abstract = {Reverse engineering of biological form and function requires hierarchical design over several orders of space and time. Recent advances in the mechanistic understanding of biosynthetic compound materials, computer-aided design approaches in molecular synthetic biology and traditional soft robotics, and increasing aptitude in generating structural and chemical microenvironments that promote cellular self-organization have enhanced the ability to recapitulate such hierarchical architecture in engineered biological systems. Here we combined these capabilities in a systematic design strategy to reverse engineer a muscular pump. We report the construction of a freely swimming jellyfish from chemically dissociated rat tissue and silicone polymer as a proof of concept. The constructs, termed 'medusoids', were designed with computer simulations and experiments to match key determinants of jellyfish propulsion and feeding performance by quantitatively mimicking structural design, stroke kinematics and animal-fluid interactions. The combination of the engineering design algorithm with quantitative benchmarks of physiological performance suggests that our strategy is broadly applicable to reverse engineering of muscular organs or simple life forms that pump to survive. © 2012 Nature America, Inc. All rights reserved.}
}

@article{nawrothTissueengineeredJellyfishBiomimetic2012a,
  title = {A Tissue-Engineered Jellyfish with Biomimetic Propulsion},
  author = {Nawroth, J.C. and Lee, H. and Feinberg, A.W. and Ripplinger, C.M. and McCain, M.L. and Grosberg, A. and Dabiri, J.O. and Parker, K.K.},
  date = {2012},
  journaltitle = {Nature Biotechnology},
  volume = {30},
  number = {8},
  pages = {792--797},
  doi = {10.1038/nbt.2269},
  abstract = {Reverse engineering of biological form and function requires hierarchical design over several orders of space and time. Recent advances in the mechanistic understanding of biosynthetic compound materials, computer-aided design approaches in molecular synthetic biology and traditional soft robotics, and increasing aptitude in generating structural and chemical microenvironments that promote cellular self-organization have enhanced the ability to recapitulate such hierarchical architecture in engineered biological systems. Here we combined these capabilities in a systematic design strategy to reverse engineer a muscular pump. We report the construction of a freely swimming jellyfish from chemically dissociated rat tissue and silicone polymer as a proof of concept. The constructs, termed 'medusoids', were designed with computer simulations and experiments to match key determinants of jellyfish propulsion and feeding performance by quantitatively mimicking structural design, stroke kinematics and animal-fluid interactions. The combination of the engineering design algorithm with quantitative benchmarks of physiological performance suggests that our strategy is broadly applicable to reverse engineering of muscular organs or simple life forms that pump to survive. © 2012 Nature America, Inc. All rights reserved.}
}

@article{Néda2000849,
  title = {The Sound of Many Hands Clapping},
  author = {Néda, Z. and Ravasz, E. and Brechet, Y. and Vicsek, T. and Barabási, A.-L.},
  date = {2000},
  journaltitle = {Nature},
  volume = {403},
  number = {6772},
  pages = {849--850},
  doi = {10.1038/35002660}
}

@inproceedings{nessaParametrizationBrIMLarge2019,
  title = {Parametrization and {{BrIM}} in Large Infrastructure Projects - Project Study from {{RV3}}/25 {{Norway}}},
  booktitle = {20th {{Congress}} of {{IABSE}}, {{New York City}} 2019: {{The Evolving Metropolis}} - {{Report}}},
  author = {Nessa, K. and Eggen, T.E. and Jakobsen, S.E.},
  date = {2019},
  pages = {1867--1873},
  abstract = {RV 3/25 is a large infrastructure project consisting of a new 25 km highway in Hedmark County in Norway. The project is organized as a PPP-project and includes 20 concrete bridges and 8 timber glulam arch bridges. In the project the use of BIM-models and parameterization has been significant and has evolved greatly throughout the project. The work ranged from macro BIM with large coordination models with all disciplines included, to micro BIM-models for bridges including all details needed for construction. For 5 concrete bridges, the BIM-model was the only product delivered to the contractor without producing design or construction drawings. For the 8 glulam arch bridges in timber, parameterization was employed for establishing both the BIM-models and the analysis models. This was vital to achieving the goal of following the strict design schedule with a small design team. It also proved very valuable in the shaping phase of the bridges. Between 80\% and 90\% of the objects in the finalized BIM-models were included in the parameterization. The product delivered to the contractor was design drawings, most of which were generated directly from the BIM-model, thus benefiting from its advantages. The use of BIM has proved to be cost and time-efficient during design. This paper presents the challenges and benefits of using parameterization and BIM in a large infrastructure project with focus on bridge design.},
  isbn = {978-3-85748-165-9}
}

@inproceedings{nessaParametrizationBrIMLarge2019a,
  title = {Parametrization and {{BrIM}} in Large Infrastructure Projects - Project Study from {{RV3}}/25 {{Norway}}},
  booktitle = {20th {{Congress}} of {{IABSE}}, {{New York City}} 2019: {{The Evolving Metropolis}} - {{Report}}},
  author = {Nessa, K. and Eggen, T.E. and Jakobsen, S.E.},
  date = {2019},
  pages = {1867--1873},
  abstract = {RV 3/25 is a large infrastructure project consisting of a new 25 km highway in Hedmark County in Norway. The project is organized as a PPP-project and includes 20 concrete bridges and 8 timber glulam arch bridges. In the project the use of BIM-models and parameterization has been significant and has evolved greatly throughout the project. The work ranged from macro BIM with large coordination models with all disciplines included, to micro BIM-models for bridges including all details needed for construction. For 5 concrete bridges, the BIM-model was the only product delivered to the contractor without producing design or construction drawings. For the 8 glulam arch bridges in timber, parameterization was employed for establishing both the BIM-models and the analysis models. This was vital to achieving the goal of following the strict design schedule with a small design team. It also proved very valuable in the shaping phase of the bridges. Between 80\% and 90\% of the objects in the finalized BIM-models were included in the parameterization. The product delivered to the contractor was design drawings, most of which were generated directly from the BIM-model, thus benefiting from its advantages. The use of BIM has proved to be cost and time-efficient during design. This paper presents the challenges and benefits of using parameterization and BIM in a large infrastructure project with focus on bridge design.},
  isbn = {978-3-85748-165-9}
}

@article{Newman-Norlund200748,
  title = {Exploring the Brain Basis of Joint Action: {{Co-ordination}} of Actions, Goals and Intentions},
  author = {Newman-Norlund, R. and Noordzij, M. and Meulenbroek, R. and Bekkering, H.},
  date = {2007},
  journaltitle = {Social Neuroscience},
  volume = {2},
  number = {1},
  pages = {48--65},
  doi = {10.1080/17470910701224623}
}

@article{ngDesignDigitalFabrication2020,
  title = {Design for {{Digital Fabrication}}: {{An Industry}} Needs {{Analysis}} of {{Collaboration Platforms}} and {{Integrated Management Processes}}},
  author = {Ng, Ming Shan and Bonanomi, Marcella M. and Hall, Daniel M. and Hackl, Jürgen},
  date = {2020},
  journaltitle = {Proceedings of the 37th International Symposium on Automation and Robotics in Construction, ISARC 2020: From Demonstration to Practical Use - To New Stage of Construction Robot},
  pages = {318--325},
  doi = {10.22260/isarc2020/0046},
  abstract = {Digital Fabrication is an emerging systemic innovation in the architecture, engineering and construction sector. However, the design process for digital fabrication lacks an integrated management process or digital collaboration platform. One reason may be a lack of industry stakeholder needs for such processes and platforms. To explore and facilitate such solution in the current practice, more information about the socio-technical industry requirements on such solution and its implementation to support and manage the BIM-based design process of digital fabrication is needed. To fill this gap, this work conducts an industry-needs analysis through content analysis and an online survey of 144 project stakeholders. Based on the results, this work identifies the most needed fabrication-related information, tools and roles at different design stages and the requirements of platform-based management, which include a common virtual environment for collaboration and a common data environment for data management. Moreover, this work shows that fabrication-related information and new roles are required by project stakeholders since the early design stage. The paper concludes by proposing a conceptual management framework for BIM-platform-based integration for design for digital fabrication in construction projects and identifying potential future research directions on the topic.},
  isbn = {9789529436347},
  issue = {Isarc},
  keywords = {Bim,Design process,Digital fabrication,Platforms,Project management,Survey}
}

@article{ngDesignDigitalFabrication2020a,
  title = {Design for {{Digital Fabrication}}: {{An Industry}} Needs {{Analysis}} of {{Collaboration Platforms}} and {{Integrated Management Processes}}},
  author = {Ng, Ming Shan and Bonanomi, Marcella M. and Hall, Daniel M. and Hackl, Jürgen},
  date = {2020},
  journaltitle = {Proceedings of the 37th International Symposium on Automation and Robotics in Construction, ISARC 2020: From Demonstration to Practical Use - To New Stage of Construction Robot},
  pages = {318--325},
  doi = {10.22260/isarc2020/0046},
  abstract = {Digital Fabrication is an emerging systemic innovation in the architecture, engineering and construction sector. However, the design process for digital fabrication lacks an integrated management process or digital collaboration platform. One reason may be a lack of industry stakeholder needs for such processes and platforms. To explore and facilitate such solution in the current practice, more information about the socio-technical industry requirements on such solution and its implementation to support and manage the BIM-based design process of digital fabrication is needed. To fill this gap, this work conducts an industry-needs analysis through content analysis and an online survey of 144 project stakeholders. Based on the results, this work identifies the most needed fabrication-related information, tools and roles at different design stages and the requirements of platform-based management, which include a common virtual environment for collaboration and a common data environment for data management. Moreover, this work shows that fabrication-related information and new roles are required by project stakeholders since the early design stage. The paper concludes by proposing a conceptual management framework for BIM-platform-based integration for design for digital fabrication in construction projects and identifying potential future research directions on the topic.},
  isbn = {9789529436347},
  issue = {Isarc},
  keywords = {Bim,Design process,Digital fabrication,Platforms,Project management,Survey},
  file = {C:\Users\leemar\Zotero\storage\L5EWY8P5\ISARC_2020_Paper_250.pdf}
}

@article{ngDigitalFabricationBIM2021,
  title = {Digital Fabrication, {{BIM}} and Early Contractor Involvement in Design in Construction Projects: A Comparative Case Study},
  author = {Ng, Ming Shan and Graser, Konrad and Hall, Daniel Mark},
  date = {2021},
  journaltitle = {Architectural Engineering and Design Management},
  volume = {0},
  number = {0},
  pages = {1--17},
  publisher = {{Taylor \& Francis}},
  issn = {17527589},
  doi = {10.1080/17452007.2021.1956417},
  url = {https://doi.org/10.1080/17452007.2021.1956417},
  abstract = {Digital Fabrication (DFAB) is a systemic innovation with low adoption rates in architecture, engineering and construction (AEC) projects. Managing requirements of a new design process is one major challenge for the increased DFAB adoption. For other types of innovations, practices such as Building Information Modelling (BIM) and Early Contractor Involvement (ECI) improve design management by integrating process, information and organisation in construction projects. In theory, BIM and ECI could improve design management and increase the adoption of DFAB. However, the relationship between DFAB, BIM and ECI has not yet been studied thoroughly. There is a need to understand new paradigms of DFAB design management in regard to process integration, information integration and organisational integration. This study undertakes a comparative study of four DFAB adoptions in AEC projects with varying levels of BIM and ECI implementation. The design processes of DFAB are traced using swimlane process diagrams. From this, relationships between DFAB, BIM, and ECI are derived using a quadripartite interrelationship diagram. This work illustrates the proposed relationships in DFAB adoption in design using a fishbone diagram. This work concludes with potential future research in design management for digital fabrication, including five takeaways for practitioners to adopt and manage DFAB in the design process of construction projects.},
  keywords = {BIM,comparative case study,design management,Digital fabrication,early contractor involvement}
}

@article{ngDigitalFabricationBIM2021a,
  title = {Digital Fabrication, {{BIM}} and Early Contractor Involvement in Design in Construction Projects: A Comparative Case Study},
  author = {Ng, Ming Shan and Graser, Konrad and Hall, Daniel Mark},
  date = {2021},
  journaltitle = {Architectural Engineering and Design Management},
  volume = {0},
  number = {0},
  pages = {1--17},
  publisher = {{Taylor \& Francis}},
  issn = {17527589},
  doi = {10.1080/17452007.2021.1956417},
  url = {https://doi.org/10.1080/17452007.2021.1956417},
  abstract = {Digital Fabrication (DFAB) is a systemic innovation with low adoption rates in architecture, engineering and construction (AEC) projects. Managing requirements of a new design process is one major challenge for the increased DFAB adoption. For other types of innovations, practices such as Building Information Modelling (BIM) and Early Contractor Involvement (ECI) improve design management by integrating process, information and organisation in construction projects. In theory, BIM and ECI could improve design management and increase the adoption of DFAB. However, the relationship between DFAB, BIM and ECI has not yet been studied thoroughly. There is a need to understand new paradigms of DFAB design management in regard to process integration, information integration and organisational integration. This study undertakes a comparative study of four DFAB adoptions in AEC projects with varying levels of BIM and ECI implementation. The design processes of DFAB are traced using swimlane process diagrams. From this, relationships between DFAB, BIM, and ECI are derived using a quadripartite interrelationship diagram. This work illustrates the proposed relationships in DFAB adoption in design using a fishbone diagram. This work concludes with potential future research in design management for digital fabrication, including five takeaways for practitioners to adopt and manage DFAB in the design process of construction projects.},
  keywords = {BIM,comparative case study,design management,Digital fabrication,early contractor involvement},
  file = {C:\Users\leemar\Zotero\storage\7GWWIHTR\17452007.2021.1956417.pdf}
}

@inproceedings{niedertDesignSimulationControl2012,
  title = {Design, Simulation, and Control of a Teleoperated Omnidirectional Ground Vehicle},
  booktitle = {{{ASME}} 2012 5th {{Annual Dynamic Systems}} and {{Control Conference Joint}} with the {{JSME}} 2012 11th {{Motion}} and {{Vibration Conference}}, {{DSCC}} 2012-{{MOVIC}} 2012},
  author = {Niedert, A.D. and Hill, R.C. and Rayess, N.E.},
  date = {2012},
  volume = {1},
  pages = {243--251},
  doi = {10.1115/DSCC2012-MOVIC2012-8640},
  abstract = {This paper describes the design, construction, and sim-ulation of a prototype, teleoperated, omnidirectional robotic ground vehicle. The design of a dynamic control system to assist the human operator of the vehicle is also presented. This work sought to test the feasibility of a novel vehicle architecture and to develop a dynamic multi-body simula-tion tool to assist in the development of future iterations of such a vehicle. The vehicle design seeks to achieve high-speed, omnidirectional mobility, and modest o ®-road capa-bility. This paper presents results from the physical operation and simulation of the vehicle as well as describing some future work to achieve improved performance of the vehicle system. Copyright © 2012 by ASME.},
  isbn = {978-0-7918-4529-5}
}

@inproceedings{niedertDesignSimulationControl2012a,
  title = {Design, Simulation, and Control of a Teleoperated Omnidirectional Ground Vehicle},
  booktitle = {{{ASME}} 2012 5th {{Annual Dynamic Systems}} and {{Control Conference Joint}} with the {{JSME}} 2012 11th {{Motion}} and {{Vibration Conference}}, {{DSCC}} 2012-{{MOVIC}} 2012},
  author = {Niedert, A.D. and Hill, R.C. and Rayess, N.E.},
  date = {2012},
  volume = {1},
  pages = {243--251},
  doi = {10.1115/DSCC2012-MOVIC2012-8640},
  abstract = {This paper describes the design, construction, and sim-ulation of a prototype, teleoperated, omnidirectional robotic ground vehicle. The design of a dynamic control system to assist the human operator of the vehicle is also presented. This work sought to test the feasibility of a novel vehicle architecture and to develop a dynamic multi-body simula-tion tool to assist in the development of future iterations of such a vehicle. The vehicle design seeks to achieve high-speed, omnidirectional mobility, and modest o ®-road capa-bility. This paper presents results from the physical operation and simulation of the vehicle as well as describing some future work to achieve improved performance of the vehicle system. Copyright © 2012 by ASME.},
  isbn = {978-0-7918-4529-5}
}

@article{Niekum2013,
  title = {Incremental Semantically Grounded Learning from Demonstration},
  author = {Niekum, S. and Chitta, S. and Barto, A.G. and Marthi, B. and Osentoski, S.},
  date = {2013},
  journaltitle = {Robotics: Science and Systems},
  volume = {9}
}

@inproceedings{Nigam20153621,
  title = {Social Context Perception for Mobile Robots},
  author = {Nigam, A. and Riek, L.D.},
  date = {2015},
  series = {{{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  volume = {2015-December},
  pages = {3621--3627},
  doi = {10.1109/IROS.2015.7353883},
  art_number = {7353883}
}

@inproceedings{Nikolaidis2015189,
  title = {Efficient Model Learning from Joint-Action Demonstrations for Human-Robot Collaborative Tasks},
  author = {Nikolaidis, S. and Ramakrishnan, R. and Gu, K. and Shah, J.},
  date = {2015},
  series = {{{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  volume = {2015-March},
  pages = {189--196},
  doi = {10.1145/2696454.2696455}
}

@inproceedings{nikolaidisEfficientModelLearning2015,
  title = {Efficient {{Model Learning}} from {{Joint-Action Demonstrations}} for {{Human-Robot Collaborative Tasks}}},
  booktitle = {Proceedings of the {{Tenth Annual ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Nikolaidis, Stefanos and Ramakrishnan, Ramya and Gu, Keren and Shah, Julie},
  date = {2015-03-02},
  pages = {189--196},
  publisher = {{ACM}},
  location = {{Portland Oregon USA}},
  doi = {10.1145/2696454.2696455},
  url = {https://dl.acm.org/doi/10.1145/2696454.2696455},
  urldate = {2023-08-19},
  eventtitle = {{{HRI}} '15: {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  isbn = {978-1-4503-2883-8},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\Q668E8R2\Nikolaidis 等。 - 2015 - Efficient Model Learning from Joint-Action Demonst.pdf}
}

@article{nonakaGeneratingAlternativeProcess2013,
  title = {Generating Alternative Process Plans for Complex Parts},
  author = {Nonaka, Youichi and Erdős, Gábor and Kis, Tamás and Kovács, András and Monostori, László and Nakano, Takahiro and Váncza, József},
  date = {2013},
  journaltitle = {CIRP Annals},
  shortjournal = {CIRP Annals},
  volume = {62},
  number = {1},
  pages = {453--458},
  issn = {00078506},
  doi = {10.1016/j.cirp.2013.03.048},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0007850613000498},
  urldate = {2023-08-20},
  langid = {english}
}

@article{Novembre20141062,
  title = {Motor Simulation and the Coordination of Self and Other in Real-Time Joint Action},
  author = {Novembre, G. and Ticini, L.F. and Schütz-Bosbach, S. and Keller, P.E.},
  date = {2014},
  journaltitle = {Social Cognitive and Affective Neuroscience},
  volume = {9},
  number = {8},
  pages = {1062--1068},
  doi = {10.1093/scan/nst086},
  art_number = {nst086}
}

@article{nuutinenChallengesDevelopingComplex2007,
  title = {Challenges of Developing the Complex Socio-Technical System: {{Realising}} the Present, Acknowledging the Past, and Envisaging the Future of Vessel Traffic Services},
  author = {Nuutinen, M. and Savioja, P. and Sonninen, S.},
  date = {2007},
  journaltitle = {Applied Ergonomics},
  volume = {38},
  number = {5},
  pages = {513--524},
  doi = {10.1016/j.apergo.2006.10.004},
  abstract = {This paper raises the question of how to guide the development of an emerging complex socio-technical system. The empirical basis for the discussion is a study of Vessel Traffic Services (VTS). We analysed the current state and the history of the service in Finland in four studies and identified several development needs. The results showed that there are differences between the outcome, practices and conceptions of the core task across different experts in the VTS centres, which can be explained by the current state of the constituents and the history of the activity system. Qualitatively different development phases characterised either by a top-down standardisation or bottom-up construction process were recognised. A combination of these processes was suggested for the future development strategy of the VTS. This could allow both continuous development within VTS and recognition of the need for a new system. A promising way to achieve continuous development is by creating reflective practices supported for instance with annual simulator exercises aimed at procedure development. We conclude that solving the current problems and promoting the development of the complex system call for a dynamic, open vision of the target future of the system, in which the pressures from the social, political and technological environments are taken into account. The results of ergonomics studies can help in self-reflecting, envisaging and developing supportive methods for the system but the persons within the system create the will to develop and find their way towards the development horizon. © 2006 Elsevier Ltd. All rights reserved.}
}

@article{nuutinenChallengesDevelopingComplex2007a,
  title = {Challenges of Developing the Complex Socio-Technical System: {{Realising}} the Present, Acknowledging the Past, and Envisaging the Future of Vessel Traffic Services},
  author = {Nuutinen, M. and Savioja, P. and Sonninen, S.},
  date = {2007},
  journaltitle = {Applied Ergonomics},
  volume = {38},
  number = {5},
  pages = {513--524},
  doi = {10.1016/j.apergo.2006.10.004},
  abstract = {This paper raises the question of how to guide the development of an emerging complex socio-technical system. The empirical basis for the discussion is a study of Vessel Traffic Services (VTS). We analysed the current state and the history of the service in Finland in four studies and identified several development needs. The results showed that there are differences between the outcome, practices and conceptions of the core task across different experts in the VTS centres, which can be explained by the current state of the constituents and the history of the activity system. Qualitatively different development phases characterised either by a top-down standardisation or bottom-up construction process were recognised. A combination of these processes was suggested for the future development strategy of the VTS. This could allow both continuous development within VTS and recognition of the need for a new system. A promising way to achieve continuous development is by creating reflective practices supported for instance with annual simulator exercises aimed at procedure development. We conclude that solving the current problems and promoting the development of the complex system call for a dynamic, open vision of the target future of the system, in which the pressures from the social, political and technological environments are taken into account. The results of ergonomics studies can help in self-reflecting, envisaging and developing supportive methods for the system but the persons within the system create the will to develop and find their way towards the development horizon. © 2006 Elsevier Ltd. All rights reserved.}
}

@inproceedings{O’Connor2015,
  title = {Detecting Social Context: {{A}} Method for Social Event Classification Using Naturalistic Multimodal Data},
  author = {O’Connor, M.F. and Riek, L.D.},
  date = {2015},
  series = {2015 11th {{IEEE International Conference}} and {{Workshops}} on {{Automatic Face}} and {{Gesture Recognition}}, {{FG}} 2015},
  volume = {2015-January},
  doi = {10.1109/FG.2015.7284843},
  art_number = {7284843}
}

@inproceedings{ojeladeConstructionWorkerPosture2020,
  title = {Construction Worker Posture Estimation Using Openpose},
  booktitle = {Construction {{Research Congress}} 2020: {{Safety}}, {{Workforce}}, and {{Education}} - {{Selected Papers}} from the {{Construction Research Congress}} 2020},
  author = {Ojelade, A. and Paige, F.},
  date = {2020},
  pages = {556--564},
  doi = {10.1061/9780784482872.060},
  abstract = {Visual field observations are critical in construction project management. Cost reduction and increases in data usability have made RGB cameras more prevalent on construction sites, expanding capabilities of the modern construction manager. The eyes of a construction manager are irreplaceable tools which monitor and subjectively evaluate construction activities. The variety of "right"and "wrong"ways to complete a construction task make the automation of visual field operations a difficult task. Existing vision-based methods are limited to RGB-depth cameras which are rarely used on construction sites. This paper presents a method for using deep learning techniques to aid the automatic recognition of construction worker activities from RGB camera footage and to what extent can computer vision accurately detect construction worker activity. OpenPose human estimation algorithm was used to create 2D human pose samples of construction activities using RGB cameras. The samples are used to train and test a time distributed feed forward neural network with LSTM Keras model classifier. The results of this work in progress set the stage for improving the usefulness of visual data for project management in a variety of construction scenarios and other labor-intensive sectors. Monitoring the safety and productivity of construction workers will become more efficient allowing much-needed increases in our capacity to develop and maintain infrastructure.},
  isbn = {978-0-7844-8287-2}
}

@inproceedings{ojeladeConstructionWorkerPosture2020a,
  title = {Construction Worker Posture Estimation Using Openpose},
  booktitle = {Construction {{Research Congress}} 2020: {{Safety}}, {{Workforce}}, and {{Education}} - {{Selected Papers}} from the {{Construction Research Congress}} 2020},
  author = {Ojelade, A. and Paige, F.},
  date = {2020},
  pages = {556--564},
  doi = {10.1061/9780784482872.060},
  abstract = {Visual field observations are critical in construction project management. Cost reduction and increases in data usability have made RGB cameras more prevalent on construction sites, expanding capabilities of the modern construction manager. The eyes of a construction manager are irreplaceable tools which monitor and subjectively evaluate construction activities. The variety of "right"and "wrong"ways to complete a construction task make the automation of visual field operations a difficult task. Existing vision-based methods are limited to RGB-depth cameras which are rarely used on construction sites. This paper presents a method for using deep learning techniques to aid the automatic recognition of construction worker activities from RGB camera footage and to what extent can computer vision accurately detect construction worker activity. OpenPose human estimation algorithm was used to create 2D human pose samples of construction activities using RGB cameras. The samples are used to train and test a time distributed feed forward neural network with LSTM Keras model classifier. The results of this work in progress set the stage for improving the usefulness of visual data for project management in a variety of construction scenarios and other labor-intensive sectors. Monitoring the safety and productivity of construction workers will become more efficient allowing much-needed increases in our capacity to develop and maintain infrastructure.},
  isbn = {978-0-7844-8287-2}
}

@article{oleshkoAnalysisPossibilitiesApplying2021,
  title = {Analysis of the {{Possibilities}} of {{Applying Mobile Robotic Platforms Using Machine Vision}} in {{Industry}}},
  author = {Oleshko, T. and Heiets, I. and Kvashuk, D.},
  date = {2021},
  journaltitle = {Periodica Polytechnica Transportation Engineering},
  volume = {49},
  number = {4},
  pages = {309--316},
  doi = {10.3311/PPTR.17043},
  abstract = {The article considers the possibilities of automated use of robotic equipment in order to form an infrastructure for moving goods at enterprises. Areas of application of algorithmic programming languages of object-oriented type in robotics are investigated. The algorithm of operation of a transport vehicle, the movement, which is based on the recognition of the line of motion, describing the route of movement, is presented. The analysis of the peculiarities of the implementation of such problems with the use of OpenCv software library was carried out. The structure of the vehicle is proposed, in particular: its driving mechanisms, control scheme, engines and wheelbase. Further development was made to the algorithms for the management of crawler lorries and the ways of their program realization in various spheres of entrepreneurial activity, where there is a need for the transfer of cargoes in the ordinary areas (construction sites, forest lands, open warehouses, airports, etc.). Based on the proposals for creating a cargo robot that can be moved according to a given route, the model of control system of conveyor systems, which solve the issues of automation of technological processes in the part of the addition of conveyor systems, is presented. The analysis of literary sources describing the necessity of creating mobile conveyor systems in production, which enables to quickly re-equip production processes to unforeseen needs, was carried out.}
}

@article{oleshkoAnalysisPossibilitiesApplying2021a,
  title = {Analysis of the {{Possibilities}} of {{Applying Mobile Robotic Platforms Using Machine Vision}} in {{Industry}}},
  author = {Oleshko, T. and Heiets, I. and Kvashuk, D.},
  date = {2021},
  journaltitle = {Periodica Polytechnica Transportation Engineering},
  volume = {49},
  number = {4},
  pages = {309--316},
  doi = {10.3311/PPTR.17043},
  abstract = {The article considers the possibilities of automated use of robotic equipment in order to form an infrastructure for moving goods at enterprises. Areas of application of algorithmic programming languages of object-oriented type in robotics are investigated. The algorithm of operation of a transport vehicle, the movement, which is based on the recognition of the line of motion, describing the route of movement, is presented. The analysis of the peculiarities of the implementation of such problems with the use of OpenCv software library was carried out. The structure of the vehicle is proposed, in particular: its driving mechanisms, control scheme, engines and wheelbase. Further development was made to the algorithms for the management of crawler lorries and the ways of their program realization in various spheres of entrepreneurial activity, where there is a need for the transfer of cargoes in the ordinary areas (construction sites, forest lands, open warehouses, airports, etc.). Based on the proposals for creating a cargo robot that can be moved according to a given route, the model of control system of conveyor systems, which solve the issues of automation of technological processes in the part of the addition of conveyor systems, is presented. The analysis of literary sources describing the necessity of creating mobile conveyor systems in production, which enables to quickly re-equip production processes to unforeseen needs, was carried out.}
}

@article{olivares-alarcosReviewComparisonOntologybased2019,
  title = {A Review and Comparison of Ontology-Based Approaches to Robot Autonomy},
  author = {Olivares-Alarcos, Alberto and Beßler, Daniel and Khamis, Alaa and Goncalves, Paulo and Habib, Maki K. and Bermejo-Alonso, Julita and Barreto, Marcos and Diab, Mohammed and Rosell, Jan and Quintas, Joaõ and Olszewska, Joanna and Nakawala, Hirenkumar and Pignaton, Edison and Gyrard, Amelie and Borgo, Stefano and Alenyà, Guillem and Beetz, Michael and Li, Howard},
  date = {2019},
  journaltitle = {Knowledge Engineering Review},
  publisher = {{Cambridge University Press}},
  issn = {14698005},
  doi = {10.1017/S0269888919000237},
  abstract = {Within the next decades, robots will need to be able to execute a large variety of tasks autonomously in a large variety of environments. To relax the resulting programming effort, a knowledge-enabled approach to robot programming can be adopted to organize information in re-usable knowledge pieces. However, for the ease of reuse, there needs to be an agreement on the meaning of terms. A common approach is to represent these terms using ontology languages that conceptualize the respective domain. In this work, we will review projects that use ontologies to support robot autonomy. We will systematically search for projects that fulfill a set of inclusion criteria and compare them with each other with respect to the scope of their ontology, what types of cognitive capabilities are supported by the use of ontologies, and which is their application domain.},
  file = {C:\Users\leemar\Zotero\storage\Z4VDWNEK\a-review-and-comparison-of-ontology-based-approaches-to-robot-autonomy.pdf}
}

@article{oliveiraAutomaticInformationSafety2014,
  title = {Automatic Information and Safety Systems for Driving Assistance},
  author = {Oliveira, M.},
  date = {2014},
  journaltitle = {Electronic Letters on Computer Vision and Image Analysis},
  volume = {13},
  number = {2},
  pages = {49--50},
  doi = {10.5565/rev/elcvia.629},
  abstract = {The main object of this thesis is the study of algorithms for automatic information processing and representation, in particular information provided by onboard sensors (2D and 3D), to be used in the context of driving assistance. The work focuses on some of the problems facing todays Autonomous Driving (AD) systems and Advanced Drivers Assistance Systems (ADAS). The document is composed of two parts. The first part describes the design, construction and development of three robotic prototypes, including remarks about onboard sensors, algorithms and software architectures. These robots were used as test beds for testing and validating the developed techniques; additionally, they have participated in several autonomous driving competitions with very good results. The second part presents several algorithms for generating intermediate representations of the raw sensor data. They can be used to enhance existing pattern recognition, detection or navigation techniques, and may thus benefit future AD or ADAS applications. Since vehicles often contain a large amount of sensors of different natures, intermediate representations are particularly advantageous; they can be used for tackling problems related with the diverse nature of the data (2D, 3D, photometric, etc.), with the asynchrony of the data (multiple sensors streaming data at different frequencies), or with the alignment of the data (calibration issues, different sensors providing different measurements of the same object). Within this scope, novel techniques are proposed for computing a multi-camera multi-modal inverse perspective mapping representation, executing color correction between images for obtaining quality mosaics, or to produce a scene representation based on polygonal primitives that can cope with very large amounts of 3D and 2D data, including the ability of refining the representation as new information is continuously received.}
}

@article{oliveiraAutomaticInformationSafety2014a,
  title = {Automatic Information and Safety Systems for Driving Assistance},
  author = {Oliveira, M.},
  date = {2014},
  journaltitle = {Electronic Letters on Computer Vision and Image Analysis},
  volume = {13},
  number = {2},
  pages = {49--50},
  doi = {10.5565/rev/elcvia.629},
  abstract = {The main object of this thesis is the study of algorithms for automatic information processing and representation, in particular information provided by onboard sensors (2D and 3D), to be used in the context of driving assistance. The work focuses on some of the problems facing todays Autonomous Driving (AD) systems and Advanced Drivers Assistance Systems (ADAS). The document is composed of two parts. The first part describes the design, construction and development of three robotic prototypes, including remarks about onboard sensors, algorithms and software architectures. These robots were used as test beds for testing and validating the developed techniques; additionally, they have participated in several autonomous driving competitions with very good results. The second part presents several algorithms for generating intermediate representations of the raw sensor data. They can be used to enhance existing pattern recognition, detection or navigation techniques, and may thus benefit future AD or ADAS applications. Since vehicles often contain a large amount of sensors of different natures, intermediate representations are particularly advantageous; they can be used for tackling problems related with the diverse nature of the data (2D, 3D, photometric, etc.), with the asynchrony of the data (multiple sensors streaming data at different frequencies), or with the alignment of the data (calibration issues, different sensors providing different measurements of the same object). Within this scope, novel techniques are proposed for computing a multi-camera multi-modal inverse perspective mapping representation, executing color correction between images for obtaining quality mosaics, or to produce a scene representation based on polygonal primitives that can cope with very large amounts of 3D and 2D data, including the ability of refining the representation as new information is continuously received.}
}

@article{oliveiraSoftwareForestSpecies2019,
  title = {Software for Forest Species Recognition Based on Digital Images of Wood},
  author = {family=Oliveira, given=W., prefix=de, useprefix=false and Filho, P. L. P. and Martins, J. G.},
  date = {2019},
  journaltitle = {Floresta},
  volume = {49},
  number = {3},
  pages = {543--552},
  doi = {10.5380/rf.v49i3.60075},
  abstract = {Classifying forest species is an essential process for the correct management of wood and forest control. After cutting off the trunk of the tree, many of the characteristics of the species are lost and identifying them becomes a much more difficult task. In this context, an anatomical analysis of the wood becomes necessary, needing to be done by specialists who know very well the cellular structures of each species. However, such methodology approaches few automated techniques, making it a delayed and error-prone activity. These factors undermine environmental control and decision-making. The use of computer vision is an alternative to automatic recognition, since it allows the development of intelligent systems, in which, from images, are able to detect features and perform a final classification. One of the techniques of Computer Vision is the use of Convolutional Neural Networks, technique that represents the state of the art in this area, it is the construction of models capable of interpreting patterns in images. This research addresses experiments using convolutional neural networks for recognizing forest species from digital images. Two original datasets were used, one including macroscopic images and the other including microscopic images, for which three models were created: scale recognition, species recognition from macroscopic images and species recognition from microscopic. The best models provide 100\% recognition rates for the scale dataset, 98.73\% for the macroscopic and 99.11\% for the microscopic which made possible to develop a software as a final product, using these three models.}
}

@article{Ong2008167,
  title = {An Implementation of Seamless Human-Robot Interaction for Telerobotics},
  author = {Ong, K.W. and Seet, G. and Sim, S.K.},
  date = {2008},
  journaltitle = {International Journal of Advanced Robotic Systems},
  volume = {5},
  number = {2},
  pages = {167--176},
  doi = {10.5772/5647}
}

@article{oscarDetectionComplexObjects2013,
  title = {Detection of Complex Objects by Using Neural Networks and Ocular Microtremor | {{Deteccion}} de Objetos Complejos Usando Redes Neurales y Micro Temblor Ocular},
  author = {Oscar, G. and Chang, T.},
  date = {2013},
  journaltitle = {Revista de la Facultad de Ingenieria},
  volume = {28},
  number = {4},
  pages = {49--56},
  abstract = {We present a tracking-recognition system in which two cascaded, independently trained neural networks, cooperate in order to process images and produce the real time reliable recognition of an object that moves in the real world and is visualized through a web cam. The first net specializes in tracking one specific object and once trained it participates in a closed loop control system in which received images directly control eye movements. This arrangement artificially reproduces a phenomenon similar to the ocular micro tremor (OMT) characteristic in mammals' eyes. The micro tremor signals are stored in short term memory elements and become the input to a second net which converges into a single "concept cell", whose activity determines the presence of the selected object. The method has been tested using real time real world images under rough visual conditions which include complex background, complex objects and variations in scaling, tilt and perspective. Thanks to its acute artificial vision, our proposed system could be used in relevant social activities such as: Medicine (automatic recognition of tumors and fractures, help to vision impaired people), Agriculture (crop health), Ecology (fire detection and unusual environment behavior), construction (building progress measurement), security (intruder detection), military (moving target tracking and detection), among others.}
}

@article{oscarDetectionComplexObjects2013a,
  title = {Detection of Complex Objects by Using Neural Networks and Ocular Microtremor | {{Deteccion}} de Objetos Complejos Usando Redes Neurales y Micro Temblor Ocular},
  author = {Oscar, G. and Chang, T.},
  date = {2013},
  journaltitle = {Revista de la Facultad de Ingenieria},
  volume = {28},
  number = {4},
  pages = {49--56},
  abstract = {We present a tracking-recognition system in which two cascaded, independently trained neural networks, cooperate in order to process images and produce the real time reliable recognition of an object that moves in the real world and is visualized through a web cam. The first net specializes in tracking one specific object and once trained it participates in a closed loop control system in which received images directly control eye movements. This arrangement artificially reproduces a phenomenon similar to the ocular micro tremor (OMT) characteristic in mammals' eyes. The micro tremor signals are stored in short term memory elements and become the input to a second net which converges into a single "concept cell", whose activity determines the presence of the selected object. The method has been tested using real time real world images under rough visual conditions which include complex background, complex objects and variations in scaling, tilt and perspective. Thanks to its acute artificial vision, our proposed system could be used in relevant social activities such as: Medicine (automatic recognition of tumors and fractures, help to vision impaired people), Agriculture (crop health), Ecology (fire detection and unusual environment behavior), construction (building progress measurement), security (intruder detection), military (moving target tracking and detection), among others.}
}

@article{ostrowska-wawryniukPrefabricationBIMaidedDesign2021,
  title = {Prefabrication 4.0: {{BIM-aided}} Design of Sustainable {{DIY-oriented}} Houses},
  author = {Ostrowska-Wawryniuk, K.},
  date = {2021},
  journaltitle = {International Journal of Architectural Computing},
  volume = {19},
  number = {2},
  pages = {142--156},
  doi = {10.1177/1478077120966496},
  abstract = {In the context of continuous housing shortage, increasing construction standards and rising labour costs, one of the possibilities to address this array of problems is prefabrication directed towards do-it-yourself (DIY) construction methods. This paper presents a prototype tool for aiding the design of DIY-oriented single-family houses with the use of small-element timber prefabrication. The introduced solution uses the potential of BIM technology for adapting a traditionally designed house to the prefabrication requirements and reduction of waste generated in the assembly process. The experimental tool was developed in the Autodesk Revit software. It incorporates custom Dynamo-for-Revit scripts. The experimental tool implemented the user- and technology-specified boundary conditions and converted an input BIM model into a prefabricated alternative. The tool was tested on the design of a two-story single-family house. The results compare the automated optimized panelization with manual approach. The simulation revealed the possibility of the construction waste reduction by at least 50\% when comparing to the non-optimized panelization.}
}

@article{ostrowska-wawryniukPrefabricationBIMaidedDesign2021a,
  title = {Prefabrication 4.0: {{BIM-aided}} Design of Sustainable {{DIY-oriented}} Houses},
  author = {Ostrowska-Wawryniuk, K.},
  date = {2021},
  journaltitle = {International Journal of Architectural Computing},
  volume = {19},
  number = {2},
  pages = {142--156},
  doi = {10.1177/1478077120966496},
  abstract = {In the context of continuous housing shortage, increasing construction standards and rising labour costs, one of the possibilities to address this array of problems is prefabrication directed towards do-it-yourself (DIY) construction methods. This paper presents a prototype tool for aiding the design of DIY-oriented single-family houses with the use of small-element timber prefabrication. The introduced solution uses the potential of BIM technology for adapting a traditionally designed house to the prefabrication requirements and reduction of waste generated in the assembly process. The experimental tool was developed in the Autodesk Revit software. It incorporates custom Dynamo-for-Revit scripts. The experimental tool implemented the user- and technology-specified boundary conditions and converted an input BIM model into a prefabricated alternative. The tool was tested on the design of a two-story single-family house. The results compare the automated optimized panelization with manual approach. The simulation revealed the possibility of the construction waste reduction by at least 50\% when comparing to the non-optimized panelization.}
}

@article{otgonboldSHEL5KExtendedDataset2022,
  title = {{{SHEL5K}}: {{An Extended Dataset}} and {{Benchmarking}} for {{Safety Helmet Detection}}},
  author = {Otgonbold, M.-E. and Gochoo, M. and Alnajjar, F. and Ali, L. and Tan, T.-H. and Hsieh, J.-W. and Chen, P.-Y.},
  date = {2022},
  journaltitle = {Sensors},
  volume = {22},
  number = {6},
  doi = {10.3390/s22062315},
  abstract = {Wearing a safety helmet is important in construction and manufacturing industrial activities to avoid unpleasant situations. This safety compliance can be ensured by developing an automatic helmet detection system using various computer vision and deep learning approaches. Developing a deep-learning-based helmet detection model usually requires an enormous amount of training data. However, there are very few public safety helmet datasets available in the literature, in which most of them are not entirely labeled, and the labeled one contains fewer classes. This paper presents the Safety HELmet dataset with 5K images (SHEL5K) dataset, an enhanced version of the SHD dataset. The proposed dataset consists of six completely labeled classes (helmet, head, head with helmet, person with helmet, person without helmet, and face). The proposed dataset was tested on multiple state-of-the-art object detection models, i.e., YOLOv3 (YOLOv3, YOLOv3-tiny, and YOLOv3-SPP), YOLOv4 (YOLOv4 and YOLOv4pacsp-x-mish), YOLOv5-P5 (YOLOv5s, YOLOv5m, and YOLOv5x), the Faster Region-based Convolutional Neural Network (Faster-RCNN) with the Inception V2 architecture, and YOLOR. The experimental results from the various models on the proposed dataset were compared and showed improvement in the mean Average Precision (mAP). The SHEL5K dataset had an advantage over other safety helmet datasets as it contains fewer images with better labels and more classes, making helmet detection more accurate.}
}

@article{otgonboldSHEL5KExtendedDataset2022a,
  title = {{{SHEL5K}}: {{An Extended Dataset}} and {{Benchmarking}} for {{Safety Helmet Detection}}},
  author = {Otgonbold, M.-E. and Gochoo, M. and Alnajjar, F. and Ali, L. and Tan, T.-H. and Hsieh, J.-W. and Chen, P.-Y.},
  date = {2022},
  journaltitle = {Sensors},
  volume = {22},
  number = {6},
  doi = {10.3390/s22062315},
  abstract = {Wearing a safety helmet is important in construction and manufacturing industrial activities to avoid unpleasant situations. This safety compliance can be ensured by developing an automatic helmet detection system using various computer vision and deep learning approaches. Developing a deep-learning-based helmet detection model usually requires an enormous amount of training data. However, there are very few public safety helmet datasets available in the literature, in which most of them are not entirely labeled, and the labeled one contains fewer classes. This paper presents the Safety HELmet dataset with 5K images (SHEL5K) dataset, an enhanced version of the SHD dataset. The proposed dataset consists of six completely labeled classes (helmet, head, head with helmet, person with helmet, person without helmet, and face). The proposed dataset was tested on multiple state-of-the-art object detection models, i.e., YOLOv3 (YOLOv3, YOLOv3-tiny, and YOLOv3-SPP), YOLOv4 (YOLOv4 and YOLOv4pacsp-x-mish), YOLOv5-P5 (YOLOv5s, YOLOv5m, and YOLOv5x), the Faster Region-based Convolutional Neural Network (Faster-RCNN) with the Inception V2 architecture, and YOLOR. The experimental results from the various models on the proposed dataset were compared and showed improvement in the mean Average Precision (mAP). The SHEL5K dataset had an advantage over other safety helmet datasets as it contains fewer images with better labels and more classes, making helmet detection more accurate.}
}

@article{othmanTalentManagementBased2022,
  title = {A Talent Management Based Framework for Developing Sustainable Quality of Work Life in Architectural Design Firms in {{Egypt}}},
  author = {Othman, Ayman Ahmed Ezzat and Elwazer, Marwa Naguib},
  date = {2022-06},
  journaltitle = {Archnet-IJAR: International Journal of Architectural Research},
  issn = {2631-6862},
  doi = {10.1108/ARCH-12-2021-0365},
  url = {https://www.emerald.com/insight/content/doi/10.1108/ARCH-12-2021-0365/full/html},
  abstract = {Purpose: This research aims to develop a talent management (TM) based framework to achieve a sustainable quality of work life (QWL) in architectural design firms (ADFs) in Egypt. Design/methodology/approach: A research methodology consisted of literature review, case studies and a survey questionnaire, was designed to achieve the abovementioned aim. Firstly, the literature review was used to investigate the work environment's demotivating factors in ADFs, TM strategies and process to depict the relationship between developing sustainable QWL and TM and finally explore how TM can assist in achieving Egypt's vision 2030. Secondly, three case studies of ADFs from Denmark, Norway and Singapore were analysed to investigate the role of TM in developing sustainable QWL. Thirdly, a survey questionnaire was carried out with a representative sample of ADFs in Egypt to examine their perception and application of TM towards developing sustainable QWL. Based on the results of the above, the research developed and validated a framework to facilitate the implementation of TM as an approach for developing sustainable QWL in ADFs in Egypt. Findings: Through literature review, the research identified the highest 28 demotivating factors that affect the QWL in ADFs and grouped them into seven categories. In addition, TM strategies for sustainable business are identified and quantified. Results of the case studies confirmed the most common demotivating factors and highlighted the TM strategies adopted to develop sustainable QWL. Findings of data analysis showed that the highest-ranked demotivating factors that encounter ADFs were “poor organizational culture”, “negative leadership behaviour” and “project induced stress”. Furthermore, the TM strategies that have the highest rank were “performance recognition”, “helping employees objectively assess their skills, strengths and weaknesses”, “creating a family-friendly work environment” and “proper reward system”. These findings informed the research findings and helped in the development of the proposed framework. Practical implications: This research presents a practical framework to facilitate the development of sustainable QWL in ADFs in Egypt. It was based on the findings of literature review, case studies and survey questionnaire. The framework explained in a workable way the objectives of the framework functions; required activities; tools and techniques; involved personnel and needed resources and output. The framework was validated by representative sample of ADFs in Egypt to ensure its practicability and viability for implementation. Moreover, strategies to facilitate the framework implementation were suggested. Originality/value: The research identified, categorised and analysed the architects' demotivating factors and defined the TM strategies and characteristics of sustainable QWL in ADFs. In addition, real life case studies validated the identified factors and investigated the most effective TM strategies in ADFs. The research tackled a topic that received scant attention in construction literature especially in Egypt. In addition, this paper developed and validated a TM based framework to achieve a sustainable QWL in ADFs in Egypt. It represents a synthesis that is novel and creative in thought and adds value to the knowledge in a manner that has not previously occurred.}
}

@article{othmanTalentManagementBased2022a,
  title = {A Talent Management Based Framework for Developing Sustainable Quality of Work Life in Architectural Design Firms in {{Egypt}}},
  author = {Othman, Ayman Ahmed Ezzat and Elwazer, Marwa Naguib},
  date = {2022-06-27},
  journaltitle = {Archnet-IJAR: International Journal of Architectural Research},
  issn = {2631-6862},
  doi = {10.1108/ARCH-12-2021-0365},
  url = {https://www.emerald.com/insight/content/doi/10.1108/ARCH-12-2021-0365/full/html},
  abstract = {Purpose: This research aims to develop a talent management (TM) based framework to achieve a sustainable quality of work life (QWL) in architectural design firms (ADFs) in Egypt. Design/methodology/approach: A research methodology consisted of literature review, case studies and a survey questionnaire, was designed to achieve the abovementioned aim. Firstly, the literature review was used to investigate the work environment's demotivating factors in ADFs, TM strategies and process to depict the relationship between developing sustainable QWL and TM and finally explore how TM can assist in achieving Egypt's vision 2030. Secondly, three case studies of ADFs from Denmark, Norway and Singapore were analysed to investigate the role of TM in developing sustainable QWL. Thirdly, a survey questionnaire was carried out with a representative sample of ADFs in Egypt to examine their perception and application of TM towards developing sustainable QWL. Based on the results of the above, the research developed and validated a framework to facilitate the implementation of TM as an approach for developing sustainable QWL in ADFs in Egypt. Findings: Through literature review, the research identified the highest 28 demotivating factors that affect the QWL in ADFs and grouped them into seven categories. In addition, TM strategies for sustainable business are identified and quantified. Results of the case studies confirmed the most common demotivating factors and highlighted the TM strategies adopted to develop sustainable QWL. Findings of data analysis showed that the highest-ranked demotivating factors that encounter ADFs were “poor organizational culture”, “negative leadership behaviour” and “project induced stress”. Furthermore, the TM strategies that have the highest rank were “performance recognition”, “helping employees objectively assess their skills, strengths and weaknesses”, “creating a family-friendly work environment” and “proper reward system”. These findings informed the research findings and helped in the development of the proposed framework. Practical implications: This research presents a practical framework to facilitate the development of sustainable QWL in ADFs in Egypt. It was based on the findings of literature review, case studies and survey questionnaire. The framework explained in a workable way the objectives of the framework functions; required activities; tools and techniques; involved personnel and needed resources and output. The framework was validated by representative sample of ADFs in Egypt to ensure its practicability and viability for implementation. Moreover, strategies to facilitate the framework implementation were suggested. Originality/value: The research identified, categorised and analysed the architects' demotivating factors and defined the TM strategies and characteristics of sustainable QWL in ADFs. In addition, real life case studies validated the identified factors and investigated the most effective TM strategies in ADFs. The research tackled a topic that received scant attention in construction literature especially in Egypt. In addition, this paper developed and validated a TM based framework to achieve a sustainable QWL in ADFs in Egypt. It represents a synthesis that is novel and creative in thought and adds value to the knowledge in a manner that has not previously occurred.}
}

@article{owenCloselyObservedBodies2009,
  title = {Closely Observed Bodies: {{Corporeality}}, Totalitarianism and Subversion in Jiří Menzel’s 1960s Adaptations of {{Bohumil Hrabal}}},
  author = {Owen, J. L.},
  date = {2009},
  journaltitle = {Canadian Slavonic Papers},
  volume = {51},
  number = {4},
  pages = {495--511},
  doi = {10.1080/00085006.2009.11092625},
  abstract = {This article concerns the exploration of sexuality, the body and materiality in Czech New Wave filmmaker Jiří Menzel’s 1960s adaptations of the writings of Bohumil Hrabal. Particular attention is paid to two of Menzel’s most celebrated films, Ostře sledované vlaky [Closely Observed Trains, 1966] and Skřivánci na niti [Skylarks on a String, 1969]. I consider the subversive, political implications of these themes, especially in relation to Czechoslovak communist society. Sexuality and bodily need comprise for Menzel a means of evoking a resilient human ‘nature’, and represent a point of convergence between the expression of individual uniqueness and the recognition of human commonality. In this way the erotic or corporeal dimension offers resistance to the homogenizing and transformative ambitions of totalitarian power. This dimension is crucial both to Menzel’s construction of a kind of quotidian utopia, and to his repudiation of the tyrannical utopianism of Stalinism or Nazism. Menzel’s representation of sexuality is also considered in relation to his affirmation of wasteful or purposeless activity. Here I draw on Georges Bataille’s notion of the “unproductive expenditure” that defies the “rational” realm of instrumental actions. Ultimately I claim that while Menzel’s work is subversive in its opposition to Stalinism and other totalitarian regimes, it is conservative in its approach to sexual politics and falls short of Hrabal’s more challenging and complex vision.}
}

@article{owenCloselyObservedBodies2009a,
  title = {Closely Observed Bodies: {{Corporeality}}, Totalitarianism and Subversion in Jiří Menzel’s 1960s Adaptations of {{Bohumil Hrabal}}},
  author = {Owen, J.L.},
  date = {2009},
  journaltitle = {Canadian Slavonic Papers},
  volume = {51},
  number = {4},
  pages = {495--511},
  doi = {10.1080/00085006.2009.11092625},
  abstract = {This article concerns the exploration of sexuality, the body and materiality in Czech New Wave filmmaker Jiří Menzel’s 1960s adaptations of the writings of Bohumil Hrabal. Particular attention is paid to two of Menzel’s most celebrated films, Ostře sledované vlaky [Closely Observed Trains, 1966] and Skřivánci na niti [Skylarks on a String, 1969]. I consider the subversive, political implications of these themes, especially in relation to Czechoslovak communist society. Sexuality and bodily need comprise for Menzel a means of evoking a resilient human ‘nature’, and represent a point of convergence between the expression of individual uniqueness and the recognition of human commonality. In this way the erotic or corporeal dimension offers resistance to the homogenizing and transformative ambitions of totalitarian power. This dimension is crucial both to Menzel’s construction of a kind of quotidian utopia, and to his repudiation of the tyrannical utopianism of Stalinism or Nazism. Menzel’s representation of sexuality is also considered in relation to his affirmation of wasteful or purposeless activity. Here I draw on Georges Bataille’s notion of the “unproductive expenditure” that defies the “rational” realm of instrumental actions. Ultimately I claim that while Menzel’s work is subversive in its opposition to Stalinism and other totalitarian regimes, it is conservative in its approach to sexual politics and falls short of Hrabal’s more challenging and complex vision.}
}

@article{oyetokePracticalApplicationARM2017,
  title = {A Practical Application of {{ARM}} Cortex-{{M3}} Processor Core in Embedded System Engineering},
  author = {Oyetoke, O.O.},
  date = {2017},
  journaltitle = {International Journal of Intelligent Systems and Applications},
  volume = {9},
  number = {7},
  pages = {70--88},
  doi = {10.5815/ijisa.2017.07.08},
  abstract = {Embedded Systems Engineering has grown in recent years to become an integral part of our daily living as it finds striking applications in various spheres of our lives. These range from Manufacturing, Electronic Health, Telecommunications, Construction and Robotics to numerous other fields. Primarily, Embedded Systems are usually a combination of selected electrical and electronic components functioning together under the direct control of a programmed controller. They serve fundamentally as additional units incorporated within already existing infrastructures with the sole aim of providing dedicated services to the larger infrastructure. Many of the controllers used operate on uniquely designed processor cores, instruction sets, and architecture profiles. This paper seeks to elucidate the application of the ARM Cortext-M3 processor based NXP LPC 1768 Microcontroller unit in the design and development of a Temperature Monitoring and Logging System. The write-up starts off with an overview of the principal ARM processor core families, architecture profiles, instruction sets and subsequently, demonstrates its utilization in the design of a Temperature Monitoring and Logging System. The paper shows how the NXP LPC 1768 Microcontroller Unit successfully serves as the brain of the temperature logger device through its standardized interfacing with a TMP102 temperature sensor using the Inter- Integrated Circuit(I2C) protocol.The Microcontroller is programmed using Embedded C while other unique functionalities of the ARM Cortex-M3 core such as Interrupt Handling and System Tick Timer efficiency are also explored.}
}

@article{oyetokePracticalApplicationARM2017a,
  title = {A Practical Application of {{ARM}} Cortex-{{M3}} Processor Core in Embedded System Engineering},
  author = {Oyetoke, O.O.},
  date = {2017},
  journaltitle = {International Journal of Intelligent Systems and Applications},
  volume = {9},
  number = {7},
  pages = {70--88},
  doi = {10.5815/ijisa.2017.07.08},
  abstract = {Embedded Systems Engineering has grown in recent years to become an integral part of our daily living as it finds striking applications in various spheres of our lives. These range from Manufacturing, Electronic Health, Telecommunications, Construction and Robotics to numerous other fields. Primarily, Embedded Systems are usually a combination of selected electrical and electronic components functioning together under the direct control of a programmed controller. They serve fundamentally as additional units incorporated within already existing infrastructures with the sole aim of providing dedicated services to the larger infrastructure. Many of the controllers used operate on uniquely designed processor cores, instruction sets, and architecture profiles. This paper seeks to elucidate the application of the ARM Cortext-M3 processor based NXP LPC 1768 Microcontroller unit in the design and development of a Temperature Monitoring and Logging System. The write-up starts off with an overview of the principal ARM processor core families, architecture profiles, instruction sets and subsequently, demonstrates its utilization in the design of a Temperature Monitoring and Logging System. The paper shows how the NXP LPC 1768 Microcontroller Unit successfully serves as the brain of the temperature logger device through its standardized interfacing with a TMP102 temperature sensor using the Inter- Integrated Circuit(I2C) protocol.The Microcontroller is programmed using Embedded C while other unique functionalities of the ARM Cortex-M3 core such as Interrupt Handling and System Tick Timer efficiency are also explored.}
}

@article{palAutonomousPlanetaryVehicle2019,
  title = {Autonomous Planetary Vehicle Development Platform},
  author = {Pal, B. and Khaiyum, S.},
  date = {2019},
  journaltitle = {International Journal of Engineering and Advanced Technology},
  volume = {9},
  number = {1},
  pages = {6793--6803},
  doi = {10.35940/ijeat.A2979.109119},
  abstract = {This paper presents the design, architecture, and constructions of a planetary autonomous exploration vehicle platform, which can be used to develop and test Artificial Intelligence, based software and generate a large dataset for the training of neural networks. Rovers will be at the frontier of planetary exploration, capable of executing tasks without human supervision in a harsh and unpredictable environment, and to do so it requires real-time command execution to keep it away from a risky situation. Due to the limitations imposed by communication latency and small window to communicate through deep space satellites, existing mars rovers are semi-autonomous. To develop AI-based software for the rover, a low-cost alternative of a planetary rover is required to generate data from different types of sensors and actuators for a long duration of time and perform all possible scenarios and actions. Presently this task is done using simulation or replicas of the actual rovers used in planetary missions which are very costly. The proposed rover design is a low-cost alternative, capable of powering, driving varieties of sensors, scale up to new hardware and record data as specified by the user. It can also be used to test the newly developed algorithm before being tested on an actual rover. This platform can be used as a simulation platform for software as the proposed platform is directly in contact with the environmental factors.}
}

@article{palAutonomousPlanetaryVehicle2019a,
  title = {Autonomous Planetary Vehicle Development Platform},
  author = {Pal, B. and Khaiyum, S.},
  date = {2019},
  journaltitle = {International Journal of Engineering and Advanced Technology},
  volume = {9},
  number = {1},
  pages = {6793--6803},
  doi = {10.35940/ijeat.A2979.109119},
  abstract = {This paper presents the design, architecture, and constructions of a planetary autonomous exploration vehicle platform, which can be used to develop and test Artificial Intelligence, based software and generate a large dataset for the training of neural networks. Rovers will be at the frontier of planetary exploration, capable of executing tasks without human supervision in a harsh and unpredictable environment, and to do so it requires real-time command execution to keep it away from a risky situation. Due to the limitations imposed by communication latency and small window to communicate through deep space satellites, existing mars rovers are semi-autonomous. To develop AI-based software for the rover, a low-cost alternative of a planetary rover is required to generate data from different types of sensors and actuators for a long duration of time and perform all possible scenarios and actions. Presently this task is done using simulation or replicas of the actual rovers used in planetary missions which are very costly. The proposed rover design is a low-cost alternative, capable of powering, driving varieties of sensors, scale up to new hardware and record data as specified by the user. It can also be used to test the newly developed algorithm before being tested on an actual rover. This platform can be used as a simulation platform for software as the proposed platform is directly in contact with the environmental factors.}
}

@inproceedings{panahiIdentifyingModularConstruction2021,
  title = {Identifying {{Modular Construction Worker Tasks Using Computer Vision}}},
  booktitle = {Computing in {{Civil Engineering}} 2021 - {{Selected Papers}} from the {{ASCE International Conference}} on {{Computing}} in {{Civil Engineering}} 2021},
  author = {Panahi, R. and Louis, J. and Aziere, N. and Podder, A. and Swanson, C.},
  date = {2021},
  pages = {959--966},
  doi = {10.1061/9780784483893.118},
  abstract = {Modular construction is increasingly being seen as an attractive method for delivering building projects due to advantages in safety, quality, and lead-time. Despite these benefits, this method still relies heavily on human labor, which causes variability in factory assembly-line performance that can erode performance benefits of modular construction. Continuous improvement methods can alleviate some of these issues, but they also require continuous monitoring of human workers' performance. Due to limitations of manual time study and automated sensor-based monitoring methods, recently computer vision-based methods have gained momentum in identifying the activities of construction workers from the videos of onsite construction. Therefore, this paper explores the use of computer vision-based human activity recognition techniques to identify and classify worker activities in modular construction videos. Computer vision-based tracking method has been used to track the human workers in each frame, and Resnet-50 network has been used to classify the activity of tracked workers. Evaluation of this framework has achieved higher than 90\% accuracy and recall in testing.},
  isbn = {978-0-7844-8389-3}
}

@inproceedings{panahiIdentifyingModularConstruction2021a,
  title = {Identifying {{Modular Construction Worker Tasks Using Computer Vision}}},
  booktitle = {Computing in {{Civil Engineering}} 2021 - {{Selected Papers}} from the {{ASCE International Conference}} on {{Computing}} in {{Civil Engineering}} 2021},
  author = {Panahi, R. and Louis, J. and Aziere, N. and Podder, A. and Swanson, C.},
  date = {2021},
  pages = {959--966},
  doi = {10.1061/9780784483893.118},
  abstract = {Modular construction is increasingly being seen as an attractive method for delivering building projects due to advantages in safety, quality, and lead-time. Despite these benefits, this method still relies heavily on human labor, which causes variability in factory assembly-line performance that can erode performance benefits of modular construction. Continuous improvement methods can alleviate some of these issues, but they also require continuous monitoring of human workers' performance. Due to limitations of manual time study and automated sensor-based monitoring methods, recently computer vision-based methods have gained momentum in identifying the activities of construction workers from the videos of onsite construction. Therefore, this paper explores the use of computer vision-based human activity recognition techniques to identify and classify worker activities in modular construction videos. Computer vision-based tracking method has been used to track the human workers in each frame, and Resnet-50 network has been used to classify the activity of tracked workers. Evaluation of this framework has achieved higher than 90\% accuracy and recall in testing.},
  isbn = {978-0-7844-8389-3}
}

@article{panCellularRoboticArchitecture2012,
  title = {Cellular Robotic Architecture},
  author = {Pan, C.-A. and Jeng, T.},
  date = {2012},
  journaltitle = {International Journal of Architectural Computing},
  volume = {10},
  number = {3},
  pages = {319--340},
  doi = {10.1260/1478-0771.10.3.319},
  abstract = {An emerging need for interactive architecture is currently making buildings mutable, flexible in use, and adaptable to changes in climate by introducing robotic systems. However, the feasibility of the seamless integration of building construction details and kinetic robotics has become a critical issue for developing robotic architecture. The objective of this work is to develop a robotic architecture with an emphasis on the integration of cellular robotics with a distributed kinetic building surface. The kinetic building surface integrates an actuating system, a localization and remote control system, which become part of the kinetic building system. This paper presents a systematic framework by reviewing theories and related work of robotic architecture and automated control. An architectural design scheme is proposed to simulate a scenario of application in a physical space. The functionality of the electrical and control system and the integration of the effects of actual construction were examined by a prototype of a kinetic surface. Our prototype presents a feasible construction method, and a prominent energy-saving effect. The potential strength and restrictions of the cellular robotic approach to architectural applications are discussed. The applicability of the prototype system and issues about controlling the behavior of spatial robots are demonstrated in this paper.}
}

@article{panCellularRoboticArchitecture2012a,
  title = {Cellular Robotic Architecture},
  author = {Pan, C.-A. and Jeng, T.},
  date = {2012},
  journaltitle = {International Journal of Architectural Computing},
  volume = {10},
  number = {3},
  pages = {319--340},
  doi = {10.1260/1478-0771.10.3.319},
  abstract = {An emerging need for interactive architecture is currently making buildings mutable, flexible in use, and adaptable to changes in climate by introducing robotic systems. However, the feasibility of the seamless integration of building construction details and kinetic robotics has become a critical issue for developing robotic architecture. The objective of this work is to develop a robotic architecture with an emphasis on the integration of cellular robotics with a distributed kinetic building surface. The kinetic building surface integrates an actuating system, a localization and remote control system, which become part of the kinetic building system. This paper presents a systematic framework by reviewing theories and related work of robotic architecture and automated control. An architectural design scheme is proposed to simulate a scenario of application in a physical space. The functionality of the electrical and control system and the integration of the effects of actual construction were examined by a prototype of a kinetic surface. Our prototype presents a feasible construction method, and a prominent energy-saving effect. The potential strength and restrictions of the cellular robotic approach to architectural applications are discussed. The applicability of the prototype system and issues about controlling the behavior of spatial robots are demonstrated in this paper.}
}

@article{pandaLearningRecognizeActions2018,
  title = {Learning to Recognize Actions from Limited Training Examples Using a Recurrent Spiking Neural Model},
  author = {Panda, P. and Srinivasa, N.},
  date = {2018},
  journaltitle = {Frontiers in Neuroscience},
  volume = {12},
  doi = {10.3389/fnins.2018.00126},
  abstract = {A fundamental challenge in machine learning today is to build a model that can learn from few examples. Here, we describe a reservoir based spiking neural model for learning to recognize actions with a limited number of labeled videos. First, we propose a novel encoding, inspired by how microsaccades influence visual perception, to extract spike information from raw video data while preserving the temporal correlation across different frames. Using this encoding, we show that the reservoir generalizes its rich dynamical activity toward signature action/movements enabling it to learn from few training examples. We evaluate our approach on the UCF-101 dataset. Our experiments demonstrate that our proposed reservoir achieves 81.3/87\% Top-1/Top-5 accuracy, respectively, on the 101-class data while requiring just 8 video examples per class for training. Our results establish a new benchmark for action recognition from limited video examples for spiking neural models while yielding competitive accuracy with respect to state-of-the-art non-spiking neural models.},
  issue = {MAR}
}

@article{pandaLearningRecognizeActions2018a,
  title = {Learning to Recognize Actions from Limited Training Examples Using a Recurrent Spiking Neural Model},
  author = {Panda, P. and Srinivasa, N.},
  date = {2018},
  journaltitle = {Frontiers in Neuroscience},
  volume = {12},
  doi = {10.3389/fnins.2018.00126},
  abstract = {A fundamental challenge in machine learning today is to build a model that can learn from few examples. Here, we describe a reservoir based spiking neural model for learning to recognize actions with a limited number of labeled videos. First, we propose a novel encoding, inspired by how microsaccades influence visual perception, to extract spike information from raw video data while preserving the temporal correlation across different frames. Using this encoding, we show that the reservoir generalizes its rich dynamical activity toward signature action/movements enabling it to learn from few training examples. We evaluate our approach on the UCF-101 dataset. Our experiments demonstrate that our proposed reservoir achieves 81.3/87\% Top-1/Top-5 accuracy, respectively, on the 101-class data while requiring just 8 video examples per class for training. Our results establish a new benchmark for action recognition from limited video examples for spiking neural models while yielding competitive accuracy with respect to state-of-the-art non-spiking neural models.},
  issue = {MAR}
}

@misc{PanMaiXiangSheZhaiZhiLu1JuZhuZhengYiJieFangSheHuiZhuZhaiPiJingZhanJiZhaoChuLu,
  title = {邁向社宅之路1 / 居住正義解方 社會住宅披荊斬棘找出路},
  author = {潘, 姿羽},
  url = {https://www.cna.com.tw/news/afe/202307230030.aspx}
}

@article{pantazisGeometricComplexityCritical2019,
  title = {Beyond Geometric Complexity: A Critical Review of Complexity Theory and How It Relates to Architecture Engineering and Construction},
  author = {Pantazis, E. and Gerber, D.J.},
  date = {2019},
  journaltitle = {Architectural Science Review},
  volume = {62},
  number = {5},
  pages = {371--388},
  doi = {10.1080/00038628.2019.1659750},
  abstract = {The wide application of digital design, the advances of digital fabrication and robotic processes have facilitated the materialization of bespoke geometries. In turn it has raised the issue of how architects can reduce design complexity using computational techniques. This paper presents a survey on complexity theory inclusive of work from the disciplines which range from cybernetics to systems and information theory. We synthesize a taxonomy of different definitions of complexity and ways of managing design complexity by decomposing its different levels as they relate to the fields of architecture, engineering and construction. Our hypothesis is that by reviewing the literature on complexity theory which appears to be highly fragmented, we can aid designers build a better understanding of the underlying principles. Thus designers can develop a more system approach towards the use of digital design tools and make use of concepts coming from the field of complexity theory such as abstraction, adaptation and self-organization in order to come up with novel computational design methods. Such methods can enable designers to deal with design problems holistically and manage design complexity in the contemporary digital design context.}
}

@article{pantazisGeometricComplexityCritical2019a,
  title = {Beyond Geometric Complexity: A Critical Review of Complexity Theory and How It Relates to Architecture Engineering and Construction},
  author = {Pantazis, E. and Gerber, D.J.},
  date = {2019},
  journaltitle = {Architectural Science Review},
  volume = {62},
  number = {5},
  pages = {371--388},
  doi = {10.1080/00038628.2019.1659750},
  abstract = {The wide application of digital design, the advances of digital fabrication and robotic processes have facilitated the materialization of bespoke geometries. In turn it has raised the issue of how architects can reduce design complexity using computational techniques. This paper presents a survey on complexity theory inclusive of work from the disciplines which range from cybernetics to systems and information theory. We synthesize a taxonomy of different definitions of complexity and ways of managing design complexity by decomposing its different levels as they relate to the fields of architecture, engineering and construction. Our hypothesis is that by reviewing the literature on complexity theory which appears to be highly fragmented, we can aid designers build a better understanding of the underlying principles. Thus designers can develop a more system approach towards the use of digital design tools and make use of concepts coming from the field of complexity theory such as abstraction, adaptation and self-organization in order to come up with novel computational design methods. Such methods can enable designers to deal with design problems holistically and manage design complexity in the contemporary digital design context.}
}

@article{paoliniBIMbasedStructuralDynamic2018,
  entrysubtype = {magazine},
  title = {{{BIM-based}} Structural Dynamic Analysis Using Higher-Order Volumetric Finite Elements | {{BIM}} Gestützte Strukturdynamische {{Analyse}} Mit {{Volumenelementen}} Höherer {{Ordnung}}},
  author = {Paolini, A. and Frischmann, F. and Kollmannsberger, S. and Rabold, A. and Horger, T. and Wohlmuth, B. and Rank, E.},
  date = {2018},
  journaltitle = {Bauingenieur},
  volume = {93},
  number = {4},
  pages = {160--166},
  abstract = {Building Information Modeling allows to automate the generation of simulation models and thus forms an important basis for saving time and costs as well as for increasing the quality in the planning of buildings. The type of the simulation model is largely dependent on the specific problem to resolve. For vibration analyses of solid timber constructions, a mechanically correct representation of the junctions between the components is essential. For this purpose, models consisting of hexahedral finite elements are much better suited than shell elements. With available mesh generators, however, matching hexahedral meshes can only be created automatically in case of specific building geometries and show a large number of elements at joints, which can lead to a high computational effort. Therefore, an alternative procedure to derive a hexahedral Finite Element Model from a Buiding Information Model (BIM) is presented. Therein, the building components defined in the BIM are meshed individually and their connections to each other are modelled by means of the mortar method. A great computational efficiency is gained by using higher order shape functions in combination with a relatively coarse mesh. After the description of the procedure, its applicability is demonstrated in case of a multi-storey timber building.}
}

@article{paoliniBIMbasedStructuralDynamic2018a,
  entrysubtype = {magazine},
  title = {{{BIM-based}} Structural Dynamic Analysis Using Higher-Order Volumetric Finite Elements | {{BIM}} Gestützte Strukturdynamische {{Analyse}} Mit {{Volumenelementen}} Höherer {{Ordnung}}},
  author = {Paolini, A. and Frischmann, F. and Kollmannsberger, S. and Rabold, A. and Horger, T. and Wohlmuth, B. and Rank, E.},
  date = {2018},
  journaltitle = {Bauingenieur},
  volume = {93},
  number = {4},
  pages = {160--166},
  abstract = {Building Information Modeling allows to automate the generation of simulation models and thus forms an important basis for saving time and costs as well as for increasing the quality in the planning of buildings. The type of the simulation model is largely dependent on the specific problem to resolve. For vibration analyses of solid timber constructions, a mechanically correct representation of the junctions between the components is essential. For this purpose, models consisting of hexahedral finite elements are much better suited than shell elements. With available mesh generators, however, matching hexahedral meshes can only be created automatically in case of specific building geometries and show a large number of elements at joints, which can lead to a high computational effort. Therefore, an alternative procedure to derive a hexahedral Finite Element Model from a Buiding Information Model (BIM) is presented. Therein, the building components defined in the BIM are meshed individually and their connections to each other are modelled by means of the mortar method. A great computational efficiency is gained by using higher order shape functions in combination with a relatively coarse mesh. After the description of the procedure, its applicability is demonstrated in case of a multi-storey timber building.}
}

@article{paraschosAutonomousUnderwaterVehicle2021,
  title = {Autonomous Underwater Vehicle Challenge: Design and Construction of a Medium-Sized, {{AI-enabled}} Low-Cost Prototype},
  author = {Paraschos, D. and Papadakis, N.K.},
  date = {2021},
  journaltitle = {Journal of Defense Modeling and Simulation},
  doi = {10.1177/15485129211027236},
  abstract = {The design of an autonomous underwater vehicle (AUV) with physical dimensions of 1100 mm × 700 mm × 330 mm, and weight of 55 kg, is introduced herein. This paper describes the design, materials, hydrodynamics, and system architecture of an AUV prototype named Synoris, developed as a low-cost and medium-scale testbed platform. Synoris moves via six brushless motors, can reach up to 200 m depth, has an autonomy estimated around 6 hours and a modular design for multiple payload options. Stability control, autonomous movement, obstacle avoidance temperature/pressure sensing, and video/image capturing are simultaneously performed by exploiting a set of onboard computers that are described briefly in Section 4. The whole platform is built on top of the open source software called ROS (robotic operating system) that provides a flexible framework for writing robot software by providing services such as low-level device control, message parsing, data fusion, and system integration. Synoris is ideal for underwater applications and missions, involving machine learning and computer vision features. AUV development in general meets high-cost solutions due to the complexity and harshness of the operational environment. Even the most cost-effective solutions demand plentiful resources. This paper describes the entire process of development and how a relatively low-cost approach can provide a reliable AUV for many underwater applications, involving AI and machine-learning capabilities.}
}

@article{paraschosAutonomousUnderwaterVehicle2021a,
  title = {Autonomous Underwater Vehicle Challenge: Design and Construction of a Medium-Sized, {{AI-enabled}} Low-Cost Prototype},
  author = {Paraschos, D. and Papadakis, N.K.},
  date = {2021},
  journaltitle = {Journal of Defense Modeling and Simulation},
  doi = {10.1177/15485129211027236},
  abstract = {The design of an autonomous underwater vehicle (AUV) with physical dimensions of 1100 mm × 700 mm × 330 mm, and weight of 55 kg, is introduced herein. This paper describes the design, materials, hydrodynamics, and system architecture of an AUV prototype named Synoris, developed as a low-cost and medium-scale testbed platform. Synoris moves via six brushless motors, can reach up to 200 m depth, has an autonomy estimated around 6 hours and a modular design for multiple payload options. Stability control, autonomous movement, obstacle avoidance temperature/pressure sensing, and video/image capturing are simultaneously performed by exploiting a set of onboard computers that are described briefly in Section 4. The whole platform is built on top of the open source software called ROS (robotic operating system) that provides a flexible framework for writing robot software by providing services such as low-level device control, message parsing, data fusion, and system integration. Synoris is ideal for underwater applications and missions, involving machine learning and computer vision features. AUV development in general meets high-cost solutions due to the complexity and harshness of the operational environment. Even the most cost-effective solutions demand plentiful resources. This paper describes the entire process of development and how a relatively low-cost approach can provide a reliable AUV for many underwater applications, involving AI and machine-learning capabilities.}
}

@article{pariSurprisingEffectivenessRepresentation2021,
  title = {The {{Surprising Effectiveness}} of {{Representation Learning}} for {{Visual Imitation}}},
  author = {Pari, Jyothish and Shafiullah, Nur Muhammad and Arunachalam, Sridhar Pandian and Pinto, Lerrel},
  date = {2021},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2112.01511},
  url = {https://arxiv.org/abs/2112.01511},
  urldate = {2023-03-23},
  abstract = {While visual imitation learning offers one of the most effective ways of learning from visual demonstrations, generalizing from them requires either hundreds of diverse demonstrations, task specific priors, or large, hard-to-train parametric models. One reason such complexities arise is because standard visual imitation frameworks try to solve two coupled problems at once: learning a succinct but good representation from the diverse visual data, while simultaneously learning to associate the demonstrated actions with such representations. Such joint learning causes an interdependence between these two problems, which often results in needing large amounts of demonstrations for learning. To address this challenge, we instead propose to decouple representation learning from behavior learning for visual imitation. First, we learn a visual representation encoder from offline data using standard supervised and self-supervised learning methods. Once the representations are trained, we use non-parametric Locally Weighted Regression to predict the actions. We experimentally show that this simple decoupling improves the performance of visual imitation models on both offline demonstration datasets and real-robot door opening compared to prior work in visual imitation. All of our generated data, code, and robot videos are publicly available at https://jyopari.github.io/VINN/.},
  version = {2},
  keywords = {Artificial Intelligence (cs.AI),Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Machine Learning (cs.LG),Robotics (cs.RO)}
}

@article{parkFrameworkProactiveConstruction2013,
  title = {A Framework for Proactive Construction Defect Management Using {{BIM}}, Augmented Reality and Ontology-Based Data Collection Template},
  author = {Park, Chan Sik and Lee, Do Yeop and Kwon, Oh Seong and Wang, Xiangyu},
  date = {2013},
  journaltitle = {Automation in Construction},
  volume = {33},
  pages = {61--71},
  publisher = {{Elsevier B.V.}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2012.09.010},
  url = {http://dx.doi.org/10.1016/j.autcon.2012.09.010},
  abstract = {In construction process, defects occur inevitably and repeatedly. It is one of the primary causes of project schedule and cost overruns. Many studies on defect causation analysis and management system have been conducted to facilitate defect measures and rectifications as well as to reduce the reoccurrence of the defect. However, those studies did not sufficiently consider the relationship of defect information flow in the construction process, which resulted in reactive rather than proactive defect management plan. This paper investigates the issues and needs of current defect management practices in the construction industry. It also presents a conceptual system framework for construction defect management that integrates ontology and augmented reality (AR) with building information modeling (BIM). The following three main technical solutions are proposed in the system framework: 1) defect data collection template to assure data quality and accuracy; 2) defect domain ontology to search and retrieve project or work-specific defect information; and 3) AR-based Defect Inspection System to support field defect management. It is envisaged that the system framework and solutions could enable proactive reduction of the defect occurrence during the construction process and that could greatly improve current defect management practices in the construction industry. © 2012 Elsevier B.V.},
  keywords = {Augmented reality,BIM,Construction defect management,Data collection template,Ontology}
}

@article{parkFrameworkProactiveConstruction2013a,
  title = {A Framework for Proactive Construction Defect Management Using {{BIM}}, Augmented Reality and Ontology-Based Data Collection Template},
  author = {Park, Chan Sik and Lee, Do Yeop and Kwon, Oh Seong and Wang, Xiangyu},
  date = {2013},
  journaltitle = {Automation in Construction},
  volume = {33},
  pages = {61--71},
  publisher = {{Elsevier B.V.}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2012.09.010},
  url = {http://dx.doi.org/10.1016/j.autcon.2012.09.010},
  abstract = {In construction process, defects occur inevitably and repeatedly. It is one of the primary causes of project schedule and cost overruns. Many studies on defect causation analysis and management system have been conducted to facilitate defect measures and rectifications as well as to reduce the reoccurrence of the defect. However, those studies did not sufficiently consider the relationship of defect information flow in the construction process, which resulted in reactive rather than proactive defect management plan. This paper investigates the issues and needs of current defect management practices in the construction industry. It also presents a conceptual system framework for construction defect management that integrates ontology and augmented reality (AR) with building information modeling (BIM). The following three main technical solutions are proposed in the system framework: 1) defect data collection template to assure data quality and accuracy; 2) defect domain ontology to search and retrieve project or work-specific defect information; and 3) AR-based Defect Inspection System to support field defect management. It is envisaged that the system framework and solutions could enable proactive reduction of the defect occurrence during the construction process and that could greatly improve current defect management practices in the construction industry. © 2012 Elsevier B.V.},
  keywords = {Augmented reality,BIM,Construction defect management,Data collection template,Ontology},
  file = {C:\Users\leemar\Zotero\storage\FRF23I35\1-s2.0-S0926580512001598-main.pdf}
}

@article{patlakasAutomaticCodeCompliance2018,
  title = {Automatic Code Compliance with Multi-Dimensional Data Fitting in a {{BIM}} Context},
  author = {Patlakas, P. and Livingstone, A. and Hairstans, R. and Neighbour, G.},
  date = {2018},
  journaltitle = {Advanced Engineering Informatics},
  volume = {38},
  pages = {216--231},
  doi = {10.1016/j.aei.2018.07.002},
  abstract = {BIM-based tools can contribute to addressing some of the challenges faced by structural engineering practitioners. A BIM-based framework for the development of components that deliver Automatic Code Compliance (ACC) is presented. The structural design problems that such components solve are categorised as simple, where ACC can be implemented directly, or complex, where more advanced approaches are needed. The mathematical process of Multi-Dimensional Data Fitting (MDDF) is introduced in order for the latter, enabling the compression of complex engineering calculations to a single equation that can be easily implemented into a BIM software engineering package. Proof-of-concept examples are given for both cases: offsite-manufactured structural joists are utilised as a non-recursive example, implementing the results obtained in the manufacturer's literature; the axial capacity of metal fasteners in axially loaded timber-to-timber connections are utilised as an example of recursive problems. The MDDF analysis and its implementation in a BIM package of those problems are presented. Finally, the concept is generalised for non-structural aspects at a framework level, and the challenges, implications, and prospects of ACC in a BIM context are discussed.}
}

@article{patlakasAutomaticCodeCompliance2018a,
  title = {Automatic Code Compliance with Multi-Dimensional Data Fitting in a {{BIM}} Context},
  author = {Patlakas, P. and Livingstone, A. and Hairstans, R. and Neighbour, G.},
  date = {2018},
  journaltitle = {Advanced Engineering Informatics},
  volume = {38},
  pages = {216--231},
  doi = {10.1016/j.aei.2018.07.002},
  abstract = {BIM-based tools can contribute to addressing some of the challenges faced by structural engineering practitioners. A BIM-based framework for the development of components that deliver Automatic Code Compliance (ACC) is presented. The structural design problems that such components solve are categorised as simple, where ACC can be implemented directly, or complex, where more advanced approaches are needed. The mathematical process of Multi-Dimensional Data Fitting (MDDF) is introduced in order for the latter, enabling the compression of complex engineering calculations to a single equation that can be easily implemented into a BIM software engineering package. Proof-of-concept examples are given for both cases: offsite-manufactured structural joists are utilised as a non-recursive example, implementing the results obtained in the manufacturer's literature; the axial capacity of metal fasteners in axially loaded timber-to-timber connections are utilised as an example of recursive problems. The MDDF analysis and its implementation in a BIM package of those problems are presented. Finally, the concept is generalised for non-structural aspects at a framework level, and the challenges, implications, and prospects of ACC in a BIM context are discussed.}
}

@inproceedings{pauliusFunctionalObjectorientedNetwork2016,
  title = {Functional Object-Oriented Network for Manipulation Learning},
  booktitle = {2016 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Paulius, David and Huang, Yongqiang and Milton, Roger and Buchanan, William D. and Sam, Jeanine and Sun, Yu},
  date = {2016-10},
  pages = {2655--2662},
  publisher = {{IEEE}},
  location = {{Daejeon, South Korea}},
  doi = {10.1109/IROS.2016.7759413},
  url = {http://ieeexplore.ieee.org/document/7759413/},
  urldate = {2023-03-23},
  eventtitle = {2016 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  isbn = {978-1-5090-3762-9},
  file = {C:\Users\leemar\Zotero\storage\K4T4L39J\Paulius et al. - 2016 - Functional object-oriented network for manipulatio.pdf}
}

@article{pauliusSurveyKnowledgeRepresentation2018,
  title = {A {{Survey}} of {{Knowledge Representation}} in {{Service Robotics}}},
  author = {Paulius, David and Sun, Yu},
  date = {2018-07},
  doi = {10.1016/j.robot.2019.03.005},
  url = {http://arxiv.org/abs/1807.02192 http://dx.doi.org/10.1016/j.robot.2019.03.005},
  abstract = {Within the realm of service robotics, researchers have placed a great amount of effort into learning, understanding, and representing motions as manipulations for task execution by robots. The task of robot learning and problem-solving is very broad, as it integrates a variety of tasks such as object detection, activity recognition, task/motion planning, localization, knowledge representation and retrieval, and the intertwining of perception/vision and machine learning techniques. In this paper, we solely focus on knowledge representations and notably how knowledge is typically gathered, represented, and reproduced to solve problems as done by researchers in the past decades. In accordance with the definition of knowledge representations, we discuss the key distinction between such representations and useful learning models that have extensively been introduced and studied in recent years, such as machine learning, deep learning, probabilistic modelling, and semantic graphical structures. Along with an overview of such tools, we discuss the problems which have existed in robot learning and how they have been built and used as solutions, technologies or developments (if any) which have contributed to solving them. Finally, we discuss key principles that should be considered when designing an effective knowledge representation.}
}

@unpublished{pauliusSurveyKnowledgeRepresentation2018a,
  title = {A {{Survey}} of {{Knowledge Representation}} in {{Service Robotics}}},
  author = {Paulius, David and Sun, Yu},
  date = {2018-07-05},
  eprint = {1807.02192},
  eprinttype = {arxiv},
  doi = {10.1016/j.robot.2019.03.005},
  url = {http://arxiv.org/abs/1807.02192},
  abstract = {Within the realm of service robotics, researchers have placed a great amount of effort into learning, understanding, and representing motions as manipulations for task execution by robots. The task of robot learning and problem-solving is very broad, as it integrates a variety of tasks such as object detection, activity recognition, task/motion planning, localization, knowledge representation and retrieval, and the intertwining of perception/vision and machine learning techniques. In this paper, we solely focus on knowledge representations and notably how knowledge is typically gathered, represented, and reproduced to solve problems as done by researchers in the past decades. In accordance with the definition of knowledge representations, we discuss the key distinction between such representations and useful learning models that have extensively been introduced and studied in recent years, such as machine learning, deep learning, probabilistic modelling, and semantic graphical structures. Along with an overview of such tools, we discuss the problems which have existed in robot learning and how they have been built and used as solutions, technologies or developments (if any) which have contributed to solving them. Finally, we discuss key principles that should be considered when designing an effective knowledge representation.},
  file = {C:\Users\leemar\Zotero\storage\FYF6BLHW\1807.02192.pdf}
}

@article{peigneuxRoleLateralOccipitotemporal2000,
  title = {The Role of Lateral Occipitotemporal Junction and Area {{MT}}/{{V5}} in the Visual Analysis of Upper-Limb Postures},
  author = {Peigneux, P. and Salmon, E. and Linden, M. Van Der and Garraux, G. and Aerts, J. and Delfiore, G. and Degueldre, C. and Luxen, A. and Orban, G. and Franck, G.},
  date = {2000},
  journaltitle = {NeuroImage},
  volume = {11},
  pages = {644--655},
  doi = {10.1006/nimg.2000.0578},
  abstract = {Humans, like numerous other species, strongly rely on the observation of gestures of other individuals in their everyday life. It is hypothesized that the visual processing of human gestures is sustained by a specific functional architecture, even at an early prelexical cognitive stage, different from that required for the processing of other visual entities. In the present PET study, the neural basis of visual gesture analysis was investigated with functional neuroimaging of brain activity during naming and orientation tasks performed on pictures of either static gestures (upperlimb postures) or tridimensional objects. To prevent automatic object-related cerebral activation during the visual processing of postures, only intransitive postures were selected, i.e., symbolic or meaningless postures which do not imply the handling of objects. Conversely, only intransitive objects which cannot be handled were selected to prevent gesture-related activation during their visual processing. Results clearly demonstrate a significant functional segregation between the processing of static intransitive postures and the processing of intransitive tridimensional objects. Visual processing of objects elicited mainly occipital and fusiform gyrus activity, while visual processing of postures strongly activated the lateral occipitotemporal junction, encroaching upon area MT/V5, involved in motion analysis. These findings suggest that the lateral occipitotemporal junction, working in association with area MT/V5, plays a prominent role in the high-level perceptual analysis of gesture, namely the construction of its visual representation, available for subsequent recognition or imitation. (C) 2000 Academic Press.},
  issue = {6 I}
}

@article{peigneuxRoleLateralOccipitotemporal2000a,
  title = {The Role of Lateral Occipitotemporal Junction and Area {{MT}}/{{V5}} in the Visual Analysis of Upper-Limb Postures},
  author = {Peigneux, P. and Salmon, E. and Van Der Linden, M. and Garraux, G. and Aerts, J. and Delfiore, G. and Degueldre, C. and Luxen, A. and Orban, G. and Franck, G.},
  date = {2000},
  journaltitle = {NeuroImage},
  volume = {11},
  pages = {644--655},
  doi = {10.1006/nimg.2000.0578},
  abstract = {Humans, like numerous other species, strongly rely on the observation of gestures of other individuals in their everyday life. It is hypothesized that the visual processing of human gestures is sustained by a specific functional architecture, even at an early prelexical cognitive stage, different from that required for the processing of other visual entities. In the present PET study, the neural basis of visual gesture analysis was investigated with functional neuroimaging of brain activity during naming and orientation tasks performed on pictures of either static gestures (upperlimb postures) or tridimensional objects. To prevent automatic object-related cerebral activation during the visual processing of postures, only intransitive postures were selected, i.e., symbolic or meaningless postures which do not imply the handling of objects. Conversely, only intransitive objects which cannot be handled were selected to prevent gesture-related activation during their visual processing. Results clearly demonstrate a significant functional segregation between the processing of static intransitive postures and the processing of intransitive tridimensional objects. Visual processing of objects elicited mainly occipital and fusiform gyrus activity, while visual processing of postures strongly activated the lateral occipitotemporal junction, encroaching upon area MT/V5, involved in motion analysis. These findings suggest that the lateral occipitotemporal junction, working in association with area MT/V5, plays a prominent role in the high-level perceptual analysis of gesture, namely the construction of its visual representation, available for subsequent recognition or imitation. (C) 2000 Academic Press.},
  issue = {6 I}
}

@inproceedings{Perez-D'Arpino20156175,
  title = {Fast Target Prediction of Human Reaching Motion for Cooperative Human-Robot Manipulation Tasks Using Time Series Classification},
  author = {Perez-D'Arpino, C. and Shah, J.A.},
  date = {2015},
  series = {Proceedings - {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  volume = {2015-June},
  number = {June},
  pages = {6175--6182},
  doi = {10.1109/ICRA.2015.7140066},
  art_number = {7140066}
}

@book{petkovicHumanIntentionRecognition2018,
  title = {Human {{Intention Recognition}} in {{Flexible Robotized Warehouses Based}} on {{Markov Decision Processes}}},
  author = {Petković, T. and Marković, I. and Petrović, I.},
  date = {2018},
  journaltitle = {Advances in Intelligent Systems and Computing},
  volume = {694},
  doi = {10.1007/978-3-319-70836-2_52},
  abstract = {The rapid growth of e-commerce increases the need for larger warehouses and their automation, thus using robots as assistants to human workers becomes a priority. In order to operate efficiently and safely, robot assistants or the supervising system should recognize human intentions. Theory of mind (ToM) is an intuitive conception of other agents’ mental state, i.e., beliefs and desires, and how they cause behavior. In this paper we present a ToM-based algorithm for human intention recognition in flexible robotized warehouses. We have placed the warehouse worker in a simulated 2D environment with three potential goals. We observe agent’s actions and validate them with respect to the goal locations using a Markov decision process framework. Those observations are then processed by the proposed hidden Markov model framework which estimated agent’s desires. We demonstrate that the proposed framework predicts human warehouse worker’s desires in an intuitive manner and in the end we discuss the simulation results.},
  isbn = {978-3-319-70835-5},
  pagetotal = {629-640}
}

@book{petkovicHumanIntentionRecognition2018a,
  title = {Human {{Intention Recognition}} in {{Flexible Robotized Warehouses Based}} on {{Markov Decision Processes}}},
  author = {Petković, T. and Marković, I. and Petrović, I.},
  date = {2018},
  journaltitle = {Advances in Intelligent Systems and Computing},
  volume = {694},
  doi = {10.1007/978-3-319-70836-2_52},
  abstract = {The rapid growth of e-commerce increases the need for larger warehouses and their automation, thus using robots as assistants to human workers becomes a priority. In order to operate efficiently and safely, robot assistants or the supervising system should recognize human intentions. Theory of mind (ToM) is an intuitive conception of other agents’ mental state, i.e., beliefs and desires, and how they cause behavior. In this paper we present a ToM-based algorithm for human intention recognition in flexible robotized warehouses. We have placed the warehouse worker in a simulated 2D environment with three potential goals. We observe agent’s actions and validate them with respect to the goal locations using a Markov decision process framework. Those observations are then processed by the proposed hidden Markov model framework which estimated agent’s desires. We demonstrate that the proposed framework predicts human warehouse worker’s desires in an intuitive manner and in the end we discuss the simulation results.},
  isbn = {978-3-319-70835-5},
  pagetotal = {629-640}
}

@inproceedings{petkovicHumanIntentionRecognition2020,
  title = {Human {{Intention Recognition}} for {{Human Aware Planning}} in {{Integrated Warehouse Systems}}},
  booktitle = {2020 28th {{Mediterranean Conference}} on {{Control}} and {{Automation}}, {{MED}} 2020},
  author = {Petkovic, T. and Hvezda, J. and Rybecky, T. and Markovic, I. and Kulich, M. and Preucil, L. and Petrovic, I.},
  date = {2020},
  pages = {586--591},
  doi = {10.1109/MED48518.2020.9183266},
  abstract = {With the substantial growth of logistics businesses the need for larger and more automated warehouses increases, thus giving rise to fully robotized shop-floors with mobile robots in charge of transporting and distributing goods. However, even in fully automatized warehouse systems the need for human intervention frequently arises, whether because of maintenance or because of fulfilling specific orders, thus bringing mobile robots and humans ever closer in an integrated warehouse environment. In order to ensure smooth and efficient operation of such a warehouse, paths of both robots and humans need to be carefully planned; however, due to the possibility of humans deviating from the assigned path, this becomes an even more challenging task. Given that, the supervising system should be able to recognize human intentions and its alternative paths in real-time. In this paper, we propose a framework for human deviation detection and intention recognition which outputs the most probable paths of the humans workers and the planner that acts accordingly by replanning for robots to move out of the human's path. Experimental results demonstrate that the proposed framework increases total number of deliveries, especially human deliveries, and reduces human-robot encounters.},
  isbn = {978-1-72815-742-9}
}

@inproceedings{petkovicHumanIntentionRecognition2020a,
  title = {Human {{Intention Recognition}} for {{Human Aware Planning}} in {{Integrated Warehouse Systems}}},
  booktitle = {2020 28th {{Mediterranean Conference}} on {{Control}} and {{Automation}}, {{MED}} 2020},
  author = {Petkovic, T. and Hvezda, J. and Rybecky, T. and Markovic, I. and Kulich, M. and Preucil, L. and Petrovic, I.},
  date = {2020},
  pages = {586--591},
  doi = {10.1109/MED48518.2020.9183266},
  abstract = {With the substantial growth of logistics businesses the need for larger and more automated warehouses increases, thus giving rise to fully robotized shop-floors with mobile robots in charge of transporting and distributing goods. However, even in fully automatized warehouse systems the need for human intervention frequently arises, whether because of maintenance or because of fulfilling specific orders, thus bringing mobile robots and humans ever closer in an integrated warehouse environment. In order to ensure smooth and efficient operation of such a warehouse, paths of both robots and humans need to be carefully planned; however, due to the possibility of humans deviating from the assigned path, this becomes an even more challenging task. Given that, the supervising system should be able to recognize human intentions and its alternative paths in real-time. In this paper, we propose a framework for human deviation detection and intention recognition which outputs the most probable paths of the humans workers and the planner that acts accordingly by replanning for robots to move out of the human's path. Experimental results demonstrate that the proposed framework increases total number of deliveries, especially human deliveries, and reduces human-robot encounters.},
  isbn = {978-1-72815-742-9}
}

@article{piroozfarConfigurationPlatformCustomisation2019,
  title = {Configuration Platform for Customisation of Design, Manufacturing and Assembly Processes of Building Façade Systems: {{A}} Building Information Modelling Perspective},
  author = {Piroozfar, Poorang and Farr, Eric R. P. and Hvam, Lars and Robinson, Dexter and Shafiee, Sara},
  date = {2019},
  journaltitle = {Automation in Construction},
  volume = {106},
  issn = {09265805},
  doi = {10.1016/j.autcon.2019.102914},
  abstract = {Literature on BIM reports case studies and challenges observed when applying BIM in the construction industry. Literature on mass customisation elaborates on methods and experiences of applying modularisation and product configuration including examples from the Architecture, Engineering and Construction (AEC) industry. However, only limited literature is available on how modularisation and configuration can be applied in a BIM context. This paper aims to investigate how the principles of configuration contribute to overcome some of the reported challenges while applying BIM in the AEC industry. This study sets out to explore the principles of platform design, the relations between industrialisation and mass customisation through serialisation facilitated by BIM for a given case of design, manufacturing and assembly processes of building envelopes in the AEC industry. A customisable façade system has been developed to accommodate: 1) The panel components which can lodge different materials; 2) The mullions which can oblige different geometries, 3) The support structure which can accommodate a variation of different geometries and lodge components with different shapes, sizes and dimensions. The identified possible improvements of using BIM, supported by modularisation and configuration, have been tested and evaluated through the case study.},
  issue = {July},
  keywords = {AEC industry,BIM application,Configuration,Configurators,Mass customisation,Modularisation,Modularity,Personalisation,Platform design,Product families}
}

@article{piroozfarConfigurationPlatformCustomisation2019a,
  title = {Configuration Platform for Customisation of Design, Manufacturing and Assembly Processes of Building Façade Systems: {{A}} Building Information Modelling Perspective},
  author = {Piroozfar, Poorang and Farr, Eric R.P. and Hvam, Lars and Robinson, Dexter and Shafiee, Sara},
  date = {2019},
  journaltitle = {Automation in Construction},
  volume = {106},
  issn = {09265805},
  doi = {10.1016/j.autcon.2019.102914},
  abstract = {Literature on BIM reports case studies and challenges observed when applying BIM in the construction industry. Literature on mass customisation elaborates on methods and experiences of applying modularisation and product configuration including examples from the Architecture, Engineering and Construction (AEC) industry. However, only limited literature is available on how modularisation and configuration can be applied in a BIM context. This paper aims to investigate how the principles of configuration contribute to overcome some of the reported challenges while applying BIM in the AEC industry. This study sets out to explore the principles of platform design, the relations between industrialisation and mass customisation through serialisation facilitated by BIM for a given case of design, manufacturing and assembly processes of building envelopes in the AEC industry. A customisable façade system has been developed to accommodate: 1) The panel components which can lodge different materials; 2) The mullions which can oblige different geometries, 3) The support structure which can accommodate a variation of different geometries and lodge components with different shapes, sizes and dimensions. The identified possible improvements of using BIM, supported by modularisation and configuration, have been tested and evaluated through the case study.},
  issue = {July},
  keywords = {★,AEC industry,BIM application,Configuration,Configurators,Mass customisation,Modularisation,Modularity,Personalisation,Platform design,Product families},
  file = {C:\Users\leemar\Zotero\storage\6YE47VG3\1-s2.0-S0926580518307957-main.pdf}
}

@article{Poppe2010976,
  title = {A Survey on Vision-Based Human Action Recognition},
  author = {Poppe, R.},
  date = {2010},
  journaltitle = {Image and Vision Computing},
  volume = {28},
  number = {6},
  pages = {976--990},
  doi = {10.1016/j.imavis.2009.11.014}
}

@article{priyaParallelAlgorithmArchitecture2006,
  title = {A Parallel Algorithm, Architecture and {{FPGA}} Realization for High Speed Determination of the Complete Visibility Graph for Convex Objects},
  author = {Priya, T.K. and Sridharan, K.},
  date = {2006},
  journaltitle = {Microprocessors and Microsystems},
  volume = {30},
  number = {1},
  pages = {1--14},
  doi = {10.1016/j.micpro.2005.02.002},
  abstract = {The complete visibility graph is a valuable geometric structure in robot path planning. The literature on constructing the graph has focussed on sequential algorithms and implementations on general-purpose processors. With an increasing need to handle cluttered and/or dynamic environments, a very high speed solution for constructing the graph via custom hardware becomes important. This paper presents a new parallel algorithm for construction of the complete visibility graph of an environment with multiple convex polygonal objects. The algorithm runs in O(n(p+log(n/p))) time for an environment with p objects having a total of n vertices. Results of implementation of the hardware design in Xilinx Virtex FPGA show that the design operates at high speed with low area requirement. In particular, the solution operates at 50 MHz for n close to 100. Further, the design fits on one FPGA device for fairly large input sizes. © 2005 Elsevier B.V. All rights reserved.}
}

@article{priyaParallelAlgorithmArchitecture2006a,
  title = {A Parallel Algorithm, Architecture and {{FPGA}} Realization for High Speed Determination of the Complete Visibility Graph for Convex Objects},
  author = {Priya, T.K. and Sridharan, K.},
  date = {2006},
  journaltitle = {Microprocessors and Microsystems},
  volume = {30},
  number = {1},
  pages = {1--14},
  doi = {10.1016/j.micpro.2005.02.002},
  abstract = {The complete visibility graph is a valuable geometric structure in robot path planning. The literature on constructing the graph has focussed on sequential algorithms and implementations on general-purpose processors. With an increasing need to handle cluttered and/or dynamic environments, a very high speed solution for constructing the graph via custom hardware becomes important. This paper presents a new parallel algorithm for construction of the complete visibility graph of an environment with multiple convex polygonal objects. The algorithm runs in O(n(p+log(n/p))) time for an environment with p objects having a total of n vertices. Results of implementation of the hardware design in Xilinx Virtex FPGA show that the design operates at high speed with low area requirement. In particular, the solution operates at 50 MHz for n close to 100. Further, the design fits on one FPGA device for fairly large input sizes. © 2005 Elsevier B.V. All rights reserved.}
}

@article{probstServiceInnovationSmart2015,
  title = {Service Innovation for Smart Industry: Human–Robot Collaboration},
  author = {Probst, L and Frideres, L and Pedersen, B and Caputi, C},
  date = {2015},
  journaltitle = {European Commission, Luxembourg}
}

@inproceedings{professnerNewOpportunitiesWood2016,
  title = {New Opportunities for Wood in Digitization and in the Internet of Things},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Professner, H. and Rhomberg, H.},
  date = {2016},
  abstract = {Whether national or international, the current construction process - both in economic, environmental and social terms - reached its limits. Worldwide there are no other industries which hold on to old traditions for so many years, as the construction industry still does. The development - both sides of planning, as well as execution - of new processes, new tools, new materials and new methods almost stands still. Wood as a renewable material will play an important part in the future building industry. It allows to pre-fab big size modules in high quality and low weight, which can especially be produced locally. This means less waste, less transports, local workmanship and high quality. Each building based on wood is a carbon storage building and therefore good for our environment and health.},
  isbn = {978-3-903039-00-1}
}

@inproceedings{professnerNewOpportunitiesWood2016a,
  title = {New Opportunities for Wood in Digitization and in the Internet of Things},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Professner, H. and Rhomberg, H.},
  date = {2016},
  abstract = {Whether national or international, the current construction process - both in economic, environmental and social terms - reached its limits. Worldwide there are no other industries which hold on to old traditions for so many years, as the construction industry still does. The development - both sides of planning, as well as execution - of new processes, new tools, new materials and new methods almost stands still. Wood as a renewable material will play an important part in the future building industry. It allows to pre-fab big size modules in high quality and low weight, which can especially be produced locally. This means less waste, less transports, local workmanship and high quality. Each building based on wood is a carbon storage building and therefore good for our environment and health.},
  isbn = {978-3-903039-00-1}
}

@article{psarakisFosteringShorttermHuman2022,
  title = {Fostering Short-Term Human Anticipatory Behavior in Human-Robot Collaboration},
  author = {Psarakis, Loizos and Nathanael, Dimitris and Marmaras, Nicolas},
  date = {2022-01},
  journaltitle = {International Journal of Industrial Ergonomics},
  shortjournal = {International Journal of Industrial Ergonomics},
  volume = {87},
  pages = {103241},
  issn = {01698141},
  doi = {10.1016/j.ergon.2021.103241},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0169814121001591},
  urldate = {2023-11-13},
  langid = {english}
}

@article{quintasImprovingVisualPerception2022,
  title = {Improving {{Visual Perception}} of {{Artificial Social Companions Using}} a {{Standardized Knowledge Representation}} in a {{Human-Machine Interaction Framework}}},
  author = {Quintas, J.},
  date = {2022},
  journaltitle = {International Journal of Social Robotics},
  doi = {10.1007/s12369-021-00859-6},
  abstract = {In Human-Machine Interaction for Artificial Social Companions, we must incorporate features that allow an agent to be capable of delivering a sociable experience to the user. The associated technological challenges include active perception features, mobility in unstructured environments, understanding human actions, detect human behaviours and predict human intentions, access to large repositories of personal and social related data, adapt to changing context. These features are paramount for applications in the field of Active and Assisted Living (AAL), where the primary goal is to provide solutions that help people through ageing, by promoting active and healthy living. The research questions being addressed can be stated as: What strategy could be developed to mitigate low specificity? How can we adopt standards in ASCs - Social Robots implementation? We believe that part of the answer to these questions is to improve the way user’s needs and expectations are described and represented in knowledge models used in ASC, and these knowledge models should adhere to flexible, extensible and standardized knowledge representations. In these knowledge models we shall incorporate the representation for decision processes to cope with redundancy and fall-back mechanisms in terms of interaction functionalities that result in the agent’s self-adaptation to its context (e.g. user model and environment conditions). To test our hypothesis, we formulated our concept for designing a framework that captures the expected behaviour of the agent into descriptive scenarios, then translates these into the agent’s information model and use the resulting representation in probabilistic planning and decision-making to control interaction. Our expectation was that adopting this framework could reduce errors and faults on agent’s operation, resulting in an improved performance while interacting with the user. The results, from our experiment, confirmed that our framework is effective to a certain level and can improve agent’s performance by improving specificity. Although, we consider that designing and implementing interaction workflows in artificial social companions are still challenging. Taking into consideration the landscape of Artificial Social Companions (i.e. Social Robots) for Active and Assisted Living, and associated barriers for the adoption of such solutions. We believe this study will contribute to this field of application, in particular, contributing to the demonstration of concrete experiments adhering to active standards.}
}

@article{quintasImprovingVisualPerception2022a,
  title = {Improving {{Visual Perception}} of {{Artificial Social Companions Using}} a {{Standardized Knowledge Representation}} in a {{Human-Machine Interaction Framework}}},
  author = {Quintas, J.},
  date = {2022},
  journaltitle = {International Journal of Social Robotics},
  doi = {10.1007/s12369-021-00859-6},
  abstract = {In Human-Machine Interaction for Artificial Social Companions, we must incorporate features that allow an agent to be capable of delivering a sociable experience to the user. The associated technological challenges include active perception features, mobility in unstructured environments, understanding human actions, detect human behaviours and predict human intentions, access to large repositories of personal and social related data, adapt to changing context. These features are paramount for applications in the field of Active and Assisted Living (AAL), where the primary goal is to provide solutions that help people through ageing, by promoting active and healthy living. The research questions being addressed can be stated as: What strategy could be developed to mitigate low specificity? How can we adopt standards in ASCs - Social Robots implementation? We believe that part of the answer to these questions is to improve the way user’s needs and expectations are described and represented in knowledge models used in ASC, and these knowledge models should adhere to flexible, extensible and standardized knowledge representations. In these knowledge models we shall incorporate the representation for decision processes to cope with redundancy and fall-back mechanisms in terms of interaction functionalities that result in the agent’s self-adaptation to its context (e.g. user model and environment conditions). To test our hypothesis, we formulated our concept for designing a framework that captures the expected behaviour of the agent into descriptive scenarios, then translates these into the agent’s information model and use the resulting representation in probabilistic planning and decision-making to control interaction. Our expectation was that adopting this framework could reduce errors and faults on agent’s operation, resulting in an improved performance while interacting with the user. The results, from our experiment, confirmed that our framework is effective to a certain level and can improve agent’s performance by improving specificity. Although, we consider that designing and implementing interaction workflows in artificial social companions are still challenging. Taking into consideration the landscape of Artificial Social Companions (i.e. Social Robots) for Active and Assisted Living, and associated barriers for the adoption of such solutions. We believe this study will contribute to this field of application, in particular, contributing to the demonstration of concrete experiments adhering to active standards.}
}

@inproceedings{raboldSEABasedPrediction2020,
  title = {{{SEA}} Based Prediction for Integrated Vibroacoustical Design Optimization of Multi-Storey Buildings},
  booktitle = {Euronoise 2015},
  author = {Rabold, A. and Schramm, M. and Châteauvieux-Hellwig, C.},
  date = {2020},
  pages = {1399--1404},
  abstract = {In order to enable the design of a multi-storey timber building with respect to the requirements or recommendations for an enhanced acoustic comfort, a collaboration of various experts is required during the design process creating their own individual building models. A simplification of the design process and the procedure of verification could be achieved if all of the experts involved work on one single CAD based Building Information Model (BIM). The required design tools (FEM and SEA for the acoustic computation) can be directly coupled to the BIM. For this purpose, it is necessary to allocate much more validated input data for timber building elements.}
}

@inproceedings{raboldSEABasedPrediction2020a,
  title = {{{SEA}} Based Prediction for Integrated Vibroacoustical Design Optimization of Multi-Storey Buildings},
  booktitle = {Euronoise 2015},
  author = {Rabold, A. and Schramm, M. and Châteauvieux-Hellwig, C.},
  date = {2020},
  pages = {1399--1404},
  abstract = {In order to enable the design of a multi-storey timber building with respect to the requirements or recommendations for an enhanced acoustic comfort, a collaboration of various experts is required during the design process creating their own individual building models. A simplification of the design process and the procedure of verification could be achieved if all of the experts involved work on one single CAD based Building Information Model (BIM). The required design tools (FEM and SEA for the acoustic computation) can be directly coupled to the BIM. For this purpose, it is necessary to allocate much more validated input data for timber building elements.}
}

@inproceedings{Rack2015153,
  title = {Enabling Synchronous Joint Action in Human-Robot Teams},
  author = {Rack, S. and Iqbal, T. and Riek, L.D.},
  date = {2015},
  series = {{{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  volume = {02-05-March-2015},
  pages = {153--154},
  doi = {10.1145/2701973.2702064}
}

@article{radziszewskiRoboticsArchitecturalEducation2019,
  title = {Robotics in Architectural Education},
  author = {Radziszewski, K. and Cudzik, J.},
  date = {2019},
  journaltitle = {World Transactions on Engineering and Technology Education},
  volume = {17},
  number = {4},
  pages = {459--464},
  abstract = {Robotics rapidly is becoming an important part of architectural design at all stages, from early conceptual work to construction. In this article is presented the present state of the art in the field related to architectural education, from computer numerical control (CNC) milling tools, through drones to multi-axis robotic arms. Professionals involved in modern design techniques often use them to create precise, complex forms that previously were not possible. This raises the question of whether and how architecture schools can provide adequate knowledge and basic skills. In this article, the authors discuss, through the example of a design course at Gdansk University of Technology, Gdansk, Poland, the introduction of robotics to Master's students at the Faculty of Architecture. It gives an overview of exercises, requirements, results and evaluation.}
}

@article{radziszewskiRoboticsArchitecturalEducation2019a,
  title = {Robotics in Architectural Education},
  author = {Radziszewski, K. and Cudzik, J.},
  date = {2019},
  journaltitle = {World Transactions on Engineering and Technology Education},
  volume = {17},
  number = {4},
  pages = {459--464},
  abstract = {Robotics rapidly is becoming an important part of architectural design at all stages, from early conceptual work to construction. In this article is presented the present state of the art in the field related to architectural education, from computer numerical control (CNC) milling tools, through drones to multi-axis robotic arms. Professionals involved in modern design techniques often use them to create precise, complex forms that previously were not possible. This raises the question of whether and how architecture schools can provide adequate knowledge and basic skills. In this article, the authors discuss, through the example of a design course at Gdansk University of Technology, Gdansk, Poland, the introduction of robotics to Master's students at the Faculty of Architecture. It gives an overview of exercises, requirements, results and evaluation.}
}

@article{raghuResourceCadastreCircular2023,
  title = {Towards a ‘Resource Cadastre’ for a Circular Economy – {{Urban-scale}} Building Material Detection Using Street View Imagery and Computer Vision},
  author = {Raghu, Deepika and Bucher, Martin Juan José and De Wolf, Catherine},
  date = {2023-11},
  journaltitle = {Resources, Conservation and Recycling},
  shortjournal = {Resources, Conservation and Recycling},
  volume = {198},
  pages = {107140},
  issn = {09213449},
  doi = {10.1016/j.resconrec.2023.107140},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0921344923002768},
  urldate = {2023-09-03},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\UH67RCMD\Raghu 等。 - 2023 - Towards a ‘resource cadastre’ for a circular econo.pdf}
}

@article{ramanActivityRecognitionUsing2016,
  title = {Activity Recognition Using a Supervised Non-Parametric Hierarchical {{HMM}}},
  author = {Raman, N. and Maybank, S. J.},
  date = {2016},
  journaltitle = {Neurocomputing},
  volume = {199},
  pages = {163--177},
  doi = {10.1016/j.neucom.2016.03.024},
  abstract = {The problem of classifying human activities occurring in depth image sequences is addressed. The 3D joint positions of a human skeleton and the local depth image pattern around these joint positions define the features. A two level hierarchical Hidden Markov Model (H-HMM), with independent Markov chains for the joint positions and depth image pattern, is used to model the features. The states corresponding to the H-HMM bottom level characterize the granular poses while the top level characterizes the coarser actions associated with the activities. Further, the H-HMM is based on a Hierarchical Dirichlet Process (HDP), and is fully non-parametric with the number of pose and action states inferred automatically from data. This is a significant advantage over classical HMM and its extensions. In order to perform classification, the relationships between the actions and the activity labels are captured using multinomial logistic regression. The proposed inference procedure ensures alignment of actions from activities with similar labels. Our construction enables information sharing, allows incorporation of unlabelled examples and provides a flexible factorized representation to include multiple data channels. Experiments with multiple real world datasets show the efficacy of our classification approach.}
}

@article{ramanActivityRecognitionUsing2016a,
  title = {Activity Recognition Using a Supervised Non-Parametric Hierarchical {{HMM}}},
  author = {Raman, N. and Maybank, S.J.},
  date = {2016},
  journaltitle = {Neurocomputing},
  volume = {199},
  pages = {163--177},
  doi = {10.1016/j.neucom.2016.03.024},
  abstract = {The problem of classifying human activities occurring in depth image sequences is addressed. The 3D joint positions of a human skeleton and the local depth image pattern around these joint positions define the features. A two level hierarchical Hidden Markov Model (H-HMM), with independent Markov chains for the joint positions and depth image pattern, is used to model the features. The states corresponding to the H-HMM bottom level characterize the granular poses while the top level characterizes the coarser actions associated with the activities. Further, the H-HMM is based on a Hierarchical Dirichlet Process (HDP), and is fully non-parametric with the number of pose and action states inferred automatically from data. This is a significant advantage over classical HMM and its extensions. In order to perform classification, the relationships between the actions and the activity labels are captured using multinomial logistic regression. The proposed inference procedure ensures alignment of actions from activities with similar labels. Our construction enables information sharing, allows incorporation of unlabelled examples and provides a flexible factorized representation to include multiple data channels. Experiments with multiple real world datasets show the efficacy of our classification approach.}
}

@article{Ramanathan2014650,
  title = {Human Action Recognition with Video Data: {{Research}} and Evaluation Challenges},
  author = {Ramanathan, M. and Yau, W.-Y. and Teoh, E.K.},
  date = {2014},
  journaltitle = {IEEE Transactions on Human-Machine Systems},
  volume = {44},
  number = {5},
  pages = {650--663},
  doi = {10.1109/THMS.2014.2325871},
  art_number = {6832553}
}

@article{ramirez-amaroSurveySemanticbasedMethods2019,
  title = {A Survey on Semantic-Based Methods for the Understanding of Human Movements},
  author = {Ramirez-Amaro, Karinne and Yang, Yezhou and Cheng, Gordon},
  date = {2019-09},
  journaltitle = {Robotics and Autonomous Systems},
  shortjournal = {Robotics and Autonomous Systems},
  volume = {119},
  pages = {31--50},
  issn = {09218890},
  doi = {10.1016/j.robot.2019.05.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0921889018303932},
  urldate = {2023-03-23},
  langid = {english}
}

@article{ramirez-amaroSurveySemanticbasedMethods2019a,
  title = {A Survey on Semantic-Based Methods for the Understanding of Human Movements},
  author = {Ramirez-Amaro, Karinne and Yang, Yezhou and Cheng, Gordon},
  date = {2019-09},
  journaltitle = {Robotics and Autonomous Systems},
  shortjournal = {Robotics and Autonomous Systems},
  volume = {119},
  pages = {31--50},
  issn = {09218890},
  doi = {10.1016/j.robot.2019.05.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0921889018303932},
  urldate = {2023-03-22},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\SNNRQV5W\Ramirez-Amaro et al. - 2019 - A survey on semantic-based methods for the underst.pdf}
}

@article{ramirez-amaroTransferringSkillsHumanoid2017,
  title = {Transferring Skills to Humanoid Robots by Extracting Semantic Representations from Observations of Human Activities},
  author = {Ramirez-Amaro, Karinne and Beetz, Michael and Cheng, Gordon},
  date = {2017-06},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {247},
  pages = {95--118},
  issn = {00043702},
  doi = {10.1016/j.artint.2015.08.009},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370215001320},
  urldate = {2023-03-23},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\2IMPS3SY\Ramirez-Amaro et al. - 2017 - Transferring skills to humanoid robots by extracti.pdf}
}

@article{ranaweeraAutomatedRealtimeMonitoring2013,
  title = {Automated Real-Time Monitoring System to Measure Shift Production of Tunnel Construction Projects},
  author = {Ranaweera, K. and Ruwanpura, J. and Fernando, S.},
  date = {2013},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {27},
  number = {1},
  pages = {68--77},
  doi = {10.1061/(ASCE)CP.1943-5487.0000199},
  abstract = {The productivity of a tunnel construction project can deviate from the predicted plan due to many factors, such as equipment failure, weather conditions and unexpected soil characteristics. Early detection of such deviations can help management teams to reallocate resources and take necessary actions to maximize the productivity. The real-time monitoring of actual productivity would yield tremendous information toward this end, but such monitoring is difficult, especially with remote construction sites. Therefore, the common practice has been to periodically obtain manually generated aggregated productivity reports from sites. These aggregated reports are not available to both site and office management in real time and may lack detailed information. To avoid these drawbacks, the research presented in this paper proposes an automated tunnel construction monitoring system to measure the productivity of the tunnel construction in terms of shift production (meters/shift). This system computes the shift production in real time using time-lapsed images of a tunnel construction site and provides instant access to these reports through a secure web portal. The web portal also shows video clips of remote site activities. The reports generated by the system can be verified without obtaining any additional input from the sites. This paper describes the design of the proposed system in detail, including its principles, image processing algorithms, system architecture, and user interface details. System operation is illustrated using real examples. Validation results are presented and analyzed at the algorithmic level as well as at the system level. © 2013 American Society of Civil Engineers.}
}

@article{ranaweeraAutomatedRealtimeMonitoring2013a,
  title = {Automated Real-Time Monitoring System to Measure Shift Production of Tunnel Construction Projects},
  author = {Ranaweera, K. and Ruwanpura, J. and Fernando, S.},
  date = {2013},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {27},
  number = {1},
  pages = {68--77},
  doi = {10.1061/(ASCE)CP.1943-5487.0000199},
  abstract = {The productivity of a tunnel construction project can deviate from the predicted plan due to many factors, such as equipment failure, weather conditions and unexpected soil characteristics. Early detection of such deviations can help management teams to reallocate resources and take necessary actions to maximize the productivity. The real-time monitoring of actual productivity would yield tremendous information toward this end, but such monitoring is difficult, especially with remote construction sites. Therefore, the common practice has been to periodically obtain manually generated aggregated productivity reports from sites. These aggregated reports are not available to both site and office management in real time and may lack detailed information. To avoid these drawbacks, the research presented in this paper proposes an automated tunnel construction monitoring system to measure the productivity of the tunnel construction in terms of shift production (meters/shift). This system computes the shift production in real time using time-lapsed images of a tunnel construction site and provides instant access to these reports through a secure web portal. The web portal also shows video clips of remote site activities. The reports generated by the system can be verified without obtaining any additional input from the sites. This paper describes the design of the proposed system in detail, including its principles, image processing algorithms, system architecture, and user interface details. System operation is illustrated using real examples. Validation results are presented and analyzed at the algorithmic level as well as at the system level. © 2013 American Society of Civil Engineers.}
}

@article{randhawaHumanActivityDetection2020,
  title = {Human Activity Detection Using Machine Learning Methods from Wearable Sensors},
  author = {Randhawa, P. and Shanthagiri, V. and Kumar, A. and Yadav, V.},
  date = {2020},
  journaltitle = {Sensor Review},
  volume = {40},
  number = {5},
  pages = {591--603},
  doi = {10.1108/SR-02-2020-0027},
  abstract = {Purpose: The paper aims to develop a novel method for the classification of different physical activities of a human being, using fabric sensors. This method focuses mainly on classifying the physical activity between normal action and violent attack on a victim and verifies its validity. Design/methodology/approach: The system is realized as a protective jacket that can be worn by the subject. Stretch sensors, pressure sensors and a 9 degree of freedom accelerometer are strategically woven on the jacket. The jacket has an internal bus system made of conductive fabric that connects the sensors to the Flora chip, which acts as the data acquisition unit for the data generated. Different activities such as still, standing up, walking, twist-jump-turn, dancing and violent action are performed. The jacket in this study is worn by a healthy subject. The main phases which describe the activity recognition method undertaken in this study are the placement of sensors, pre-processing of data and deploying machine learning models for classification. Findings: The effectiveness of the method was validated in a controlled environment. Certain challenges are also faced in building the experimental setup for the collection of data from the hardware. The most tedious challenge is to collect the data without noise and error, created by voltage fluctuations when stretched. The results show that the support vector machine classifier can classify different activities and is able to differentiate normal action and violent attacks with an accuracy of 98.8\%, which is superior to other methods and algorithms. Practical implications: This study leads to an understanding of human physical movement under violent activity. The results show that data compared with normal physical motion, which includes even a form of dance is quite different from the data collected during violent physical motion. This jacket construction with woven sensors can capture every dimension of the physical motion adding features to the data on which the machine learning model will be built. Originality/value: Unlike other studies, where sensors are placed on isolated parts of the body, in this study, the fabric sensors are woven into the fabric itself to collect the data and to achieve maximum accuracy instead of using isolated wearable sensors. This method, together with a fabric pressure and stretch sensors, can provide key data and accurate feedback information when the victim is being attacked or is in a normal state of action.}
}

@article{randhawaHumanActivityDetection2020a,
  title = {Human Activity Detection Using Machine Learning Methods from Wearable Sensors},
  author = {Randhawa, P. and Shanthagiri, V. and Kumar, A. and Yadav, V.},
  date = {2020},
  journaltitle = {Sensor Review},
  volume = {40},
  number = {5},
  pages = {591--603},
  doi = {10.1108/SR-02-2020-0027},
  abstract = {Purpose: The paper aims to develop a novel method for the classification of different physical activities of a human being, using fabric sensors. This method focuses mainly on classifying the physical activity between normal action and violent attack on a victim and verifies its validity. Design/methodology/approach: The system is realized as a protective jacket that can be worn by the subject. Stretch sensors, pressure sensors and a 9 degree of freedom accelerometer are strategically woven on the jacket. The jacket has an internal bus system made of conductive fabric that connects the sensors to the Flora chip, which acts as the data acquisition unit for the data generated. Different activities such as still, standing up, walking, twist-jump-turn, dancing and violent action are performed. The jacket in this study is worn by a healthy subject. The main phases which describe the activity recognition method undertaken in this study are the placement of sensors, pre-processing of data and deploying machine learning models for classification. Findings: The effectiveness of the method was validated in a controlled environment. Certain challenges are also faced in building the experimental setup for the collection of data from the hardware. The most tedious challenge is to collect the data without noise and error, created by voltage fluctuations when stretched. The results show that the support vector machine classifier can classify different activities and is able to differentiate normal action and violent attacks with an accuracy of 98.8\%, which is superior to other methods and algorithms. Practical implications: This study leads to an understanding of human physical movement under violent activity. The results show that data compared with normal physical motion, which includes even a form of dance is quite different from the data collected during violent physical motion. This jacket construction with woven sensors can capture every dimension of the physical motion adding features to the data on which the machine learning model will be built. Originality/value: Unlike other studies, where sensors are placed on isolated parts of the body, in this study, the fabric sensors are woven into the fabric itself to collect the data and to achieve maximum accuracy instead of using isolated wearable sensors. This method, together with a fabric pressure and stretch sensors, can provide key data and accurate feedback information when the victim is being attacked or is in a normal state of action.}
}

@inproceedings{randoFinansparkenBjergstedInnovative2019,
  title = {Finansparken {{Bjergsted}}: {{An}} Innovative Timber-Framed Office Building},
  booktitle = {{{IABSE Symposium}}, {{Guimaraes}} 2019: {{Towards}} a {{Resilient Built Environment Risk}} and {{Asset Management}} - {{Report}}},
  author = {Rando, M. and Mo, G. and Overton, K. and Ibáñez, F. and Sánchez-Solís, M.},
  date = {2019},
  pages = {729--736},
  abstract = {Finansparken Bjergsted is an office building currently under construction in Stavanger, Norway, for SR-Bank. The structural system above ground level uses timber as the principal load bearing elements (a natural, renewable and readily available local material). Floors are cross-laminated timber (CLT) panels supported by glued laminated timber (GL) beams and columns. For strength and complex geometrical requirements, laminated veneer lumber (LVL) made of beech is also used. The three basement levels and the four communications and services cores are of reinforced concrete. Mass timber structural elements are engineered for strength and are prefabricated with strict tolerances for a rapid construction process using mainly direct contact timber connections, without metal fasteners. The beams are shaped and fabricated with openings to suit both the architectural aesthetics and services requirements by means of a fully integrated BIM system.},
  isbn = {978-3-85748-163-5}
}

@inproceedings{randoFinansparkenBjergstedInnovative2019a,
  title = {Finansparken {{Bjergsted}}: {{An}} Innovative Timber-Framed Office Building},
  booktitle = {{{IABSE Symposium}}, {{Guimaraes}} 2019: {{Towards}} a {{Resilient Built Environment Risk}} and {{Asset Management}} - {{Report}}},
  author = {Rando, M. and Mo, G. and Overton, K. and Ibáñez, F. and Sánchez-Solís, M.},
  date = {2019},
  pages = {729--736},
  abstract = {Finansparken Bjergsted is an office building currently under construction in Stavanger, Norway, for SR-Bank. The structural system above ground level uses timber as the principal load bearing elements (a natural, renewable and readily available local material). Floors are cross-laminated timber (CLT) panels supported by glued laminated timber (GL) beams and columns. For strength and complex geometrical requirements, laminated veneer lumber (LVL) made of beech is also used. The three basement levels and the four communications and services cores are of reinforced concrete. Mass timber structural elements are engineered for strength and are prefabricated with strict tolerances for a rapid construction process using mainly direct contact timber connections, without metal fasteners. The beams are shaped and fabricated with openings to suit both the architectural aesthetics and services requirements by means of a fully integrated BIM system.},
  isbn = {978-3-85748-163-5}
}

@inproceedings{raoofiMaskRcnnDeep2020,
  title = {Mask R-Cnn Deep Learning-Based Approach to Detect Construction Machinery on Jobsites},
  booktitle = {Proceedings of the 37th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2020: {{From Demonstration}} to {{Practical Use}} - {{To New Stage}} of {{Construction Robot}}},
  author = {Raoofi, H. and Motamedi, A.},
  date = {2020},
  pages = {1122--1127},
  abstract = {In the construction industry, there is often a need to identify and localize assets and activities on the jobsite to assess and improve the performance of their associated processes. Traditional methods for monitoring construction activities are costly and time-consuming. Excavators and dump trucks are among the most common assets used in the construction industry. Consequently, accurately monitoring their activities can reduce time and increase the efficiency of progress monitoring. With the presence of cameras on jobsites and the advancement of methods based on artificial intelligence and computer vision, progress monitoring activities can be automated. Furthermore, by using techniques such as deep learning, a wider range of data resources can be processed, and oftentimes more accurate results can be produced for the purpose of object detection. This research proposes a computer-vision approach that utilizes a Mask Region Based Convolutional Neural Network (Mask-RCNN) to detect excavators and dump trucks in a construction site. This research investigates an innovative technique to achieve high accuracy object detection using relatively small datasets. To overcome the problem of overfitting and improve generalization, a pre-trained model based on a Microsoft COCO dataset is used as a network that presumably has already been trained to distinguish basic features. Finally, the model is further fine-tuned to minimize validation loss.},
  isbn = {978-952-94-3634-7}
}

@inproceedings{raoofiMaskRcnnDeep2020a,
  title = {Mask R-Cnn Deep Learning-Based Approach to Detect Construction Machinery on Jobsites},
  booktitle = {Proceedings of the 37th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2020: {{From Demonstration}} to {{Practical Use}} - {{To New Stage}} of {{Construction Robot}}},
  author = {Raoofi, H. and Motamedi, A.},
  date = {2020},
  pages = {1122--1127},
  abstract = {In the construction industry, there is often a need to identify and localize assets and activities on the jobsite to assess and improve the performance of their associated processes. Traditional methods for monitoring construction activities are costly and time-consuming. Excavators and dump trucks are among the most common assets used in the construction industry. Consequently, accurately monitoring their activities can reduce time and increase the efficiency of progress monitoring. With the presence of cameras on jobsites and the advancement of methods based on artificial intelligence and computer vision, progress monitoring activities can be automated. Furthermore, by using techniques such as deep learning, a wider range of data resources can be processed, and oftentimes more accurate results can be produced for the purpose of object detection. This research proposes a computer-vision approach that utilizes a Mask Region Based Convolutional Neural Network (Mask-RCNN) to detect excavators and dump trucks in a construction site. This research investigates an innovative technique to achieve high accuracy object detection using relatively small datasets. To overcome the problem of overfitting and improve generalization, a pre-trained model based on a Microsoft COCO dataset is used as a network that presumably has already been trained to distinguish basic features. Finally, the model is further fine-tuned to minimize validation loss.},
  isbn = {978-952-94-3634-7}
}

@article{rashidActivityIdentificationModular2020,
  title = {Activity Identification in Modular Construction Using Audio Signals and Machine Learning},
  author = {Rashid, K. M. and Louis, J.},
  date = {2020},
  journaltitle = {Automation in Construction},
  volume = {119},
  doi = {10.1016/j.autcon.2020.103361},
  abstract = {Modular construction is an attractive building method due to its advantages over traditional stick-built methods in terms of reduced waste and construction time, more control over resources and environment, and easier implementation of novel techniques and technologies in a controlled factory setting. However, efficient and timely decision-making in modular factories requires spatiotemporal information about the resources regarding their locations and activities which motivates the necessity for an automated activity identification framework. Thus, this paper utilizes sound, a ubiquitous data source present in every modular construction factory, for the automatic identification of commonly performed manual activities such as hammering, nailing, sawing, etc. To develop a robust activity identification model, it is imperative to engineer the appropriate features of the data source (i.e., traits of the signal) that provides a compact yet descriptive representation of the parameterized audio signal based on the nature of the sound, which is very dependent on the application domain. In-depth analysis regarding appropriate features selection and engineering for audio-based activity identification in construction is missing from current research. Thus, this research extensively investigates the effects of various features extracted from four different domains related to audio signals (time-, time-frequency-, cepstral-, and wavelet-domains), in the overall performance of the activity identification model. The effect of these features on activity identification performance was tested by collecting and analyzing audio data generated from manual activities at a modular construction factory. The collected audio signals were first balanced using time-series data augmentation techniques and then used to extract a 318-dimensional feature vector containing 18 different feature sets from the abovementioned four domains. Several sensitivity analyses were performed to optimize the feature space using a feature ranking technique (i.e., Relief algorithm), and the contribution of features in the top feature sets using a support vector machine (SVM). Eventually, a final feature space was designed containing a 130-dimensional feature vector and 0.5-second window size yielding about 97\% F-1 score for identifying different activities. The contributions of this study are two-fold: 1. A novel means of automated manual construction activity identification using audio signal is presented; and 2. Foundational knowledge on the selection and optimization of the feature space from four domains is provided for future work in this research field. The result of this study demonstrates the potential of the proposed system to be applied for automated monitoring and data collection in modular construction factory in conjunction with other activity recognition frameworks based on computer vision (CV) and/or inertial measurement units (IMU).}
}

@article{rashidActivityIdentificationModular2020a,
  title = {Activity Identification in Modular Construction Using Audio Signals and Machine Learning},
  author = {Rashid, K.M. and Louis, J.},
  date = {2020},
  journaltitle = {Automation in Construction},
  volume = {119},
  doi = {10.1016/j.autcon.2020.103361},
  abstract = {Modular construction is an attractive building method due to its advantages over traditional stick-built methods in terms of reduced waste and construction time, more control over resources and environment, and easier implementation of novel techniques and technologies in a controlled factory setting. However, efficient and timely decision-making in modular factories requires spatiotemporal information about the resources regarding their locations and activities which motivates the necessity for an automated activity identification framework. Thus, this paper utilizes sound, a ubiquitous data source present in every modular construction factory, for the automatic identification of commonly performed manual activities such as hammering, nailing, sawing, etc. To develop a robust activity identification model, it is imperative to engineer the appropriate features of the data source (i.e., traits of the signal) that provides a compact yet descriptive representation of the parameterized audio signal based on the nature of the sound, which is very dependent on the application domain. In-depth analysis regarding appropriate features selection and engineering for audio-based activity identification in construction is missing from current research. Thus, this research extensively investigates the effects of various features extracted from four different domains related to audio signals (time-, time-frequency-, cepstral-, and wavelet-domains), in the overall performance of the activity identification model. The effect of these features on activity identification performance was tested by collecting and analyzing audio data generated from manual activities at a modular construction factory. The collected audio signals were first balanced using time-series data augmentation techniques and then used to extract a 318-dimensional feature vector containing 18 different feature sets from the abovementioned four domains. Several sensitivity analyses were performed to optimize the feature space using a feature ranking technique (i.e., Relief algorithm), and the contribution of features in the top feature sets using a support vector machine (SVM). Eventually, a final feature space was designed containing a 130-dimensional feature vector and 0.5-second window size yielding about 97\% F-1 score for identifying different activities. The contributions of this study are two-fold: 1. A novel means of automated manual construction activity identification using audio signal is presented; and 2. Foundational knowledge on the selection and optimization of the feature space from four domains is provided for future work in this research field. The result of this study demonstrates the potential of the proposed system to be applied for automated monitoring and data collection in modular construction factory in conjunction with other activity recognition frameworks based on computer vision (CV) and/or inertial measurement units (IMU).}
}

@article{ratsameeSocialInteractiveRobot2015,
  title = {Social Interactive Robot Navigation Based on Human Intention Analysis from Face Orientation and Human Path Prediction},
  author = {Ratsamee, P. and Mae, Y. and Kamiyama, K. and Horade, M. and Kojima, M. and Arai, T.},
  date = {2015},
  journaltitle = {ROBOMECH Journal},
  volume = {2},
  number = {1},
  doi = {10.1186/s40648-015-0033-z},
  abstract = {Robot navigation in a human environment is challenging because human moves according to many factors such as social rules and the way other moves. By introducing a robot to a human environment, many situations are expected such as human want to interact with robot or humans expect robot to avoid collision. Robot navigation modeling have to take these factors into consideration. This paper presents a Social Navigation Model (SNM) as a unified navigation and interaction model that allows a robot to navigate in a human environment and response to human according to human intentions, in particular during a situation where the human encounters a robot and human wants to avoid, unavoid (maintain his/her course), or approach (interact) the robot. The proposed model is developed based on human motion and behavior (especially face orientation and overlapping personal space) analysis in preliminary experiments of human-human interaction. Avoiding, unavoiding, and approaching trajectories of humans are classified based on the face orientation and predicted path on a modified social force model. Our experimental evidence demonstrates that the robot is able to adapt its motion by preserving personal distance from passers-by, and interact with persons who want to interact with the robot with a success rate of 90 \%. The simulation results show that robot navigated by proposed method can operate in populated environment and significantly reduced the average of overlapping area of personal space by 33.2 \% and reduced average time human needs to arrive the goal by 15.7 \% compared to original social force model. This work contributes to the future development of a human-robot socialization environment.}
}

@article{ratsameeSocialInteractiveRobot2015a,
  title = {Social Interactive Robot Navigation Based on Human Intention Analysis from Face Orientation and Human Path Prediction},
  author = {Ratsamee, P. and Mae, Y. and Kamiyama, K. and Horade, M. and Kojima, M. and Arai, T.},
  date = {2015},
  journaltitle = {ROBOMECH Journal},
  volume = {2},
  number = {1},
  doi = {10.1186/s40648-015-0033-z},
  abstract = {Robot navigation in a human environment is challenging because human moves according to many factors such as social rules and the way other moves. By introducing a robot to a human environment, many situations are expected such as human want to interact with robot or humans expect robot to avoid collision. Robot navigation modeling have to take these factors into consideration. This paper presents a Social Navigation Model (SNM) as a unified navigation and interaction model that allows a robot to navigate in a human environment and response to human according to human intentions, in particular during a situation where the human encounters a robot and human wants to avoid, unavoid (maintain his/her course), or approach (interact) the robot. The proposed model is developed based on human motion and behavior (especially face orientation and overlapping personal space) analysis in preliminary experiments of human-human interaction. Avoiding, unavoiding, and approaching trajectories of humans are classified based on the face orientation and predicted path on a modified social force model. Our experimental evidence demonstrates that the robot is able to adapt its motion by preserving personal distance from passers-by, and interact with persons who want to interact with the robot with a success rate of 90 \%. The simulation results show that robot navigated by proposed method can operate in populated environment and significantly reduced the average of overlapping area of personal space by 33.2 \% and reduced average time human needs to arrive the goal by 15.7 \% compared to original social force model. This work contributes to the future development of a human-robot socialization environment.}
}

@article{realExperimentalEvaluationTeam2021,
  title = {Experimental {{Evaluation}} of a {{Team}} of {{Multiple Unmanned Aerial Vehicles}} for {{Cooperative Construction}}},
  author = {Real, F. and Castano, A.R. and Torres-Gonzalez, A. and Capitan, J. and Sanchez-Cuevas, P.J. and Fernandez, M.J. and Villar, M. and Ollero, A.},
  date = {2021},
  journaltitle = {IEEE Access},
  volume = {9},
  pages = {6817--6835},
  doi = {10.1109/ACCESS.2021.3049433},
  abstract = {This article presents a team of multiple Unmanned Aerial Vehicles (UAVs) to perform cooperative missions for autonomous construction. In particular, the UAVs have to build a wall made of bricks that need to be picked and transported from different locations. First, we propose a novel architecture for multi-robot systems operating in outdoor and unstructured environments, where robustness and reliability play a key role. Then, we describe the design of our aerial platforms and grasping mechanisms to pick, transport and place bricks. The system was particularly developed for the Mohamed Bin Zayed International Robotics Challenge (MBZIRC), where Challenge 2 consisted of building a wall cooperatively with multiple UAVs. However, our approach is more general and extensible to other multi-UAV applications involving physical interaction, like package delivery. We present not only our results in the final stage of MBZIRC, but also our simulations and field experiments throughout the previous months to the competition, where we tuned our system and assessed its performance.}
}

@article{realExperimentalEvaluationTeam2021a,
  title = {Experimental {{Evaluation}} of a {{Team}} of {{Multiple Unmanned Aerial Vehicles}} for {{Cooperative Construction}}},
  author = {Real, F. and Castano, A.R. and Torres-Gonzalez, A. and Capitan, J. and Sanchez-Cuevas, P.J. and Fernandez, M.J. and Villar, M. and Ollero, A.},
  date = {2021},
  journaltitle = {IEEE Access},
  volume = {9},
  pages = {6817--6835},
  doi = {10.1109/ACCESS.2021.3049433},
  abstract = {This article presents a team of multiple Unmanned Aerial Vehicles (UAVs) to perform cooperative missions for autonomous construction. In particular, the UAVs have to build a wall made of bricks that need to be picked and transported from different locations. First, we propose a novel architecture for multi-robot systems operating in outdoor and unstructured environments, where robustness and reliability play a key role. Then, we describe the design of our aerial platforms and grasping mechanisms to pick, transport and place bricks. The system was particularly developed for the Mohamed Bin Zayed International Robotics Challenge (MBZIRC), where Challenge 2 consisted of building a wall cooperatively with multiple UAVs. However, our approach is more general and extensible to other multi-UAV applications involving physical interaction, like package delivery. We present not only our results in the final stage of MBZIRC, but also our simulations and field experiments throughout the previous months to the competition, where we tuned our system and assessed its performance.}
}

@article{reichertFibrousStructuresIntegrative2014,
  title = {Fibrous Structures: {{An}} Integrative Approach to Design Computation, Simulation and Fabrication for Lightweight, Glass and Carbon Fibre Composite Structures in Architecture Based on Biomimetic Design Principles},
  author = {Reichert, S. and Schwinn, T. and La Magna, R. and Waimer, F. and Knippers, J. and Menges, A.},
  date = {2014},
  journaltitle = {CAD Computer Aided Design},
  volume = {52},
  pages = {27--39},
  doi = {10.1016/j.cad.2014.02.005},
  abstract = {In this paper the authors present research into an integrative computational design methodology for the design and robotic implementation of fibre-composite systems. The proposed approach is based on the concurrent and reciprocal integration of biological analysis, material design, structural analysis, and the constraints of robotic filament winding within a coherent computational design process. A particular focus is set on the development of specific tools and solvers for the generation, simulation and optimization of the fibre layout and their feedback into the global morphology of the system. The methodology demonstrates how fibre reinforced composites can be arranged and processed in order to meet the specific requirements of architectural design and building construction. This was further tested through the design and fabrication of a full-scale architectural prototype. © 2014 Elsevier Ltd. All rights reserved.}
}

@article{reichertFibrousStructuresIntegrative2014a,
  title = {Fibrous Structures: {{An}} Integrative Approach to Design Computation, Simulation and Fabrication for Lightweight, Glass and Carbon Fibre Composite Structures in Architecture Based on Biomimetic Design Principles},
  author = {Reichert, S. and Schwinn, T. and La Magna, R. and Waimer, F. and Knippers, J. and Menges, A.},
  date = {2014},
  journaltitle = {CAD Computer Aided Design},
  volume = {52},
  pages = {27--39},
  doi = {10.1016/j.cad.2014.02.005},
  abstract = {In this paper the authors present research into an integrative computational design methodology for the design and robotic implementation of fibre-composite systems. The proposed approach is based on the concurrent and reciprocal integration of biological analysis, material design, structural analysis, and the constraints of robotic filament winding within a coherent computational design process. A particular focus is set on the development of specific tools and solvers for the generation, simulation and optimization of the fibre layout and their feedback into the global morphology of the system. The methodology demonstrates how fibre reinforced composites can be arranged and processed in order to meet the specific requirements of architectural design and building construction. This was further tested through the design and fabrication of a full-scale architectural prototype. © 2014 Elsevier Ltd. All rights reserved.}
}

@inproceedings{resendeErgowearAmbulatoryNonintrusive2021,
  title = {Ergowear: {{An}} Ambulatory, Non-Intrusive, and Interoperable System towards a {{Human-Aware Human-robot Collaborative}} Framework},
  booktitle = {2021 {{IEEE International Conference}} on {{Autonomous Robot Systems}} and {{Competitions}}, {{ICARSC}} 2021},
  author = {Resende, A. and Cerqueira, S. and Barbosa, J. and Damasio, E. and Pombeiro, A. and Silva, A. and Santos, C.},
  date = {2021},
  pages = {56--61},
  doi = {10.1109/ICARSC52212.2021.9429796},
  abstract = {Motivated by industry 5.0 paradigm and Human-robot collaboration (HRC) technology, this paper presents the first steps of the design and development of Ergowear, a wearable, non-intrusive, interoperable upper body inertial Motion Capture system. This system was developed aiming to be used as a sensing technology to make the robot aware of the human's intentions and states and, therefore, achieving human-Awareness. Consequently, it was developed to run on ROS2, to ease its integration in a HRC framework. This work depicts the design process and development of the prototype. Firstly, the system requirements are presented along with the system components and architecture. To verify interoperability, a protocol was designed to test the Ergowear's hardware, namely its autonomy, storing capacity, wireless communication's performance, and overall mechanical robustness. Overall, the achieved results are within the specified technical requirements, presenting the Ergowear as a promising sensing technology to be integrated within a Human-Aware HRC framework.},
  isbn = {978-1-66543-198-9}
}

@inproceedings{resendeErgowearAmbulatoryNonintrusive2021a,
  title = {Ergowear: {{An}} Ambulatory, Non-Intrusive, and Interoperable System towards a {{Human-Aware Human-robot Collaborative}} Framework},
  booktitle = {2021 {{IEEE International Conference}} on {{Autonomous Robot Systems}} and {{Competitions}}, {{ICARSC}} 2021},
  author = {Resende, A. and Cerqueira, S. and Barbosa, J. and Damasio, E. and Pombeiro, A. and Silva, A. and Santos, C.},
  date = {2021},
  pages = {56--61},
  doi = {10.1109/ICARSC52212.2021.9429796},
  abstract = {Motivated by industry 5.0 paradigm and Human-robot collaboration (HRC) technology, this paper presents the first steps of the design and development of Ergowear, a wearable, non-intrusive, interoperable upper body inertial Motion Capture system. This system was developed aiming to be used as a sensing technology to make the robot aware of the human's intentions and states and, therefore, achieving human-Awareness. Consequently, it was developed to run on ROS2, to ease its integration in a HRC framework. This work depicts the design process and development of the prototype. Firstly, the system requirements are presented along with the system components and architecture. To verify interoperability, a protocol was designed to test the Ergowear's hardware, namely its autonomy, storing capacity, wireless communication's performance, and overall mechanical robustness. Overall, the achieved results are within the specified technical requirements, presenting the Ergowear as a promising sensing technology to be integrated within a Human-Aware HRC framework.},
  isbn = {978-1-66543-198-9}
}

@inproceedings{rezazadehazarVisionbasedRecognitionDirt2012,
  title = {Vision-Based Recognition of Dirt Loading Cycles in Construction Sites},
  booktitle = {Construction {{Research Congress}} 2012: {{Construction Challenges}} in a {{Flat World}}, {{Proceedings}} of the 2012 {{Construction Research Congress}}},
  author = {Rezazadeh Azar, E. and McCabe, B.},
  date = {2012},
  pages = {1042--1051},
  doi = {10.1061/9780784412329.105},
  abstract = {Automated control of production lines in different segments of manufacturing has been advanced due to emergence of sensing devices and the repetitive character of the processes. The construction industry, however, still suffers from inefficiencies in real-time control of activities due to the manual practice of monitoring, and the fragmented and temporary nature of construction projects. Several sensing technologies including computer vision-based systems have been introduced to address this issue on construction sites. Earthmoving projects are one of the most suitable areas to employ vision-based techniques to extract productivity data because it is possible to select clear sightlines and earthmoving equipment are relatively easy to recognize. In addition to challenges of developing efficient object detection and tracking algorithms, activity recognition based on collected data from detection and tracking engines is yet to be tackled. In this paper, a logical framework is introduced that combines object recognition, tracking, and rational events to recognize dirt loading to a dump truck by a hydraulic excavators, and measure the working cycles and idle times of the earthmoving plants. This logical algorithm showed promising performance in which the variations were caused by deficiencies of recognition and tracking engines rather than the activity recognition algorithm. © 2012 ASCE.},
  isbn = {978-0-7844-1232-9}
}

@article{Richardson2012,
  title = {Measuring Group Synchrony: {{A}} Cluster-Phase Method for Analyzing Multivariate Movement Time-Series},
  author = {Richardson, M.J. and Garcia, R.L. and Frank, T.D. and Gergor, M. and Marsh, K.L.},
  date = {2012},
  journaltitle = {Frontiers in Physiology},
  volume = {3 OCT},
  doi = {10.3389/fphys.2012.00405},
  art_number = {Article 405}
}

@article{Riek2008,
  title = {Real-Time Empathy: {{Facial}} Mimicry on a Robot},
  author = {Riek, L.D. and Robinson, P.},
  date = {2008},
  journaltitle = {International Conference on Multimodal Interfaces, Affective Interaction in Natural Environments (AFFINE).}
}

@inproceedings{Riek201061,
  title = {Cooperative Gestures: {{Effective}} Signaling for Humanoid Robots},
  author = {Riek, L.D. and Rabinowitch, T.-C. and Bremner, P. and Pipe, A.G. and Fraser, M. and Robinson, P.},
  date = {2010},
  series = {5th {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}, {{HRI}} 2010},
  pages = {61--68},
  doi = {10.1145/1734454.1734474}
}

@inproceedings{Riek201061,
  title = {Cooperative Gestures: {{Effective}} Signaling for Humanoid Robots},
  author = {Riek, L.D. and Rabinowitch, T.-C. and Bremner, P. and Pipe, A.G. and Fraser, M. and Robinson, P.},
  date = {2010},
  series = {5th {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}, {{HRI}} 2010},
  pages = {61--68},
  doi = {10.1145/1734454.1734474}
}

@article{Riek201099,
  title = {When My Robot Smiles at Me: {{Enabling}} Human-Robot Rapport via Real-Time Head Gesture Mimicry},
  author = {Riek, L.D. and Paul, P.C. and Robinson, P.},
  date = {2010},
  journaltitle = {Journal on Multimodal User Interfaces},
  volume = {3},
  number = {1},
  pages = {99--108},
  doi = {10.1007/s12193-009-0028-2}
}

@article{Riek2013,
  title = {The Social Co-Robotics Problem Space: {{Six}} Key Challenges},
  author = {Riek, L.D.},
  date = {2013},
  journaltitle = {Robotics: Science, and Systems (RSS), Robotics Challenges and Visions}
}

@article{robertsonSoftPneumaticActuatordriven2021,
  title = {Soft Pneumatic Actuator-Driven Origami-Inspired Modular Robotic “Pneumagami”},
  author = {Robertson, Matthew A and Kara, Ozdemir Can and Paik, Jamie},
  date = {2021-01-18},
  journaltitle = {International Journal of Robotics Research},
  volume = {40},
  number = {1},
  pages = {72--85},
  issn = {17413176},
  doi = {10.1177/0278364920909905},
  url = {http://journals.sagepub.com/doi/10.1177/0278364920909905},
  abstract = {This article presents a new modular robotic platform for enabling reconfigurable, actively controlled, high-degree-of-freedom (high-DoF) systems with compact form factor. The robotic modules exploit the advantages of origami-inspired construction methods and materials, and soft pneumatic actuators (SPAs) to achieve an actuator embedded, parallel kinematic mechanism with three independently controlled “waterbomb” base legs. The multi-material, layer-fabricated body of the modules features selectively compliant flexure hinge elements between rigid panels that define the module as a kinematic 6R spherical joint. The precision layer-fabrication technique is also used to form embedded distribution channels within the module base to connect actuators to onboard control hardware. A decentralized control architecture is applied by integrating each module with small-scale solenoid valves, communication electronics, and sensors. This design approach enables a single pneumatic supply line to be shared between modules, while still allowing independent control of each leg joint, driven by soft, inflatable pouch actuators. A passive pneumatic relay is also designed and incorporated in each module to leverage the coupled, inverted inflation, and exhaust states between antagonistic actuator pairs allowing both to be controlled by a single solenoid valve. A prototype module is presented as the first demonstration of integrated modular origami and SPA design, or pneumagami, which allows predefined kinematic structural mechanisms to locally prescribe specific motions by active effect, not just through passive compliance, to dictate task space and motion. The design strategy facilitates the composition of lightweight, high-strength robotic structures with many DoFs that will benefit various fields such as wearable robotics.},
  keywords = {continuum robots,diaphragm actuators,layer fabrication,Modular robots,not the focus,origami robots,parallel kinematics,reconfigurable robots,soft pneumatic actuators,soft robots}
}

@article{robertsonSoftPneumaticActuatordriven2021a,
  title = {Soft Pneumatic Actuator-Driven Origami-Inspired Modular Robotic “Pneumagami”},
  author = {Robertson, M.A. and Kara, O.C. and Paik, J.},
  date = {2021},
  journaltitle = {International Journal of Robotics Research},
  volume = {40},
  number = {1},
  pages = {72--85},
  doi = {10.1177/0278364920909905},
  abstract = {This article presents a new modular robotic platform for enabling reconfigurable, actively controlled, high-degree-of-freedom (high-DoF) systems with compact form factor. The robotic modules exploit the advantages of origami-inspired construction methods and materials, and soft pneumatic actuators (SPAs) to achieve an actuator embedded, parallel kinematic mechanism with three independently controlled “waterbomb” base legs. The multi-material, layer-fabricated body of the modules features selectively compliant flexure hinge elements between rigid panels that define the module as a kinematic 6R spherical joint. The precision layer-fabrication technique is also used to form embedded distribution channels within the module base to connect actuators to onboard control hardware. A decentralized control architecture is applied by integrating each module with small-scale solenoid valves, communication electronics, and sensors. This design approach enables a single pneumatic supply line to be shared between modules, while still allowing independent control of each leg joint, driven by soft, inflatable pouch actuators. A passive pneumatic relay is also designed and incorporated in each module to leverage the coupled, inverted inflation, and exhaust states between antagonistic actuator pairs allowing both to be controlled by a single solenoid valve. A prototype module is presented as the first demonstration of integrated modular origami and SPA design, or pneumagami, which allows predefined kinematic structural mechanisms to locally prescribe specific motions by active effect, not just through passive compliance, to dictate task space and motion. The design strategy facilitates the composition of lightweight, high-strength robotic structures with many DoFs that will benefit various fields such as wearable robotics.}
}

@inproceedings{robertsVisionbasedConstructionActivity2018,
  title = {Vision-Based Construction Activity Analysis in Long Video Sequences via Hidden Markov Models: {{Experiments}} on Earthmoving Operations},
  booktitle = {Construction {{Research Congress}} 2018: {{Safety}} and {{Disaster Management}} - {{Selected Papers}} from the {{Construction Research Congress}} 2018},
  author = {Roberts, D. and Golparvar-Fard, M. and Niebles, J. C. and Gwak, J. and Bao, R.},
  date = {2018},
  volume = {2018-April},
  pages = {164--173},
  doi = {10.1061/9780784481288.017},
  abstract = {This paper presents a new method for detailed activity analysis of dynamic construction resources in highly varying videos obtained from construction site cameras. Toward this goal, we propose a Hidden Markov Model (HMM) that is able to automatically discover and assign sequences of activities that are most discriminative for an observed construction operation. To do so, the algorithm leverages dense trajectory features from a detected dynamic resource (e.g., excavator) in a video. Using these dense trajectory features, we train a Gaussian mixture model (GMM) to estimate the probability density function of each activity with multiple one-versus-all support vector machine classifiers. The proposed HMM also models duration of each activity, and the transition between activities (e.g., "swing bucket loaded" after "load bucket" for earth-moving activities of an excavator). As a proof-of-concept, we train and test our HMM+GMM model on an unprecedented dataset of 10 real-world long video sequences of interacting pairs of excavators and dumptrucks. Our preliminary experimental results on long-sequence activity recognition in presence of noise, occlusions, and scene clutter demonstrate the effectiveness of our method.},
  isbn = {978-0-7844-8128-8}
}

@inproceedings{robertsVisionbasedConstructionActivity2018a,
  title = {Vision-Based Construction Activity Analysis in Long Video Sequences via Hidden Markov Models: {{Experiments}} on Earthmoving Operations},
  booktitle = {Construction {{Research Congress}} 2018: {{Safety}} and {{Disaster Management}} - {{Selected Papers}} from the {{Construction Research Congress}} 2018},
  author = {Roberts, D. and Golparvar-Fard, M. and Niebles, J.C. and Gwak, J. and Bao, R.},
  date = {2018},
  volume = {2018-April},
  pages = {164--173},
  doi = {10.1061/9780784481288.017},
  abstract = {This paper presents a new method for detailed activity analysis of dynamic construction resources in highly varying videos obtained from construction site cameras. Toward this goal, we propose a Hidden Markov Model (HMM) that is able to automatically discover and assign sequences of activities that are most discriminative for an observed construction operation. To do so, the algorithm leverages dense trajectory features from a detected dynamic resource (e.g., excavator) in a video. Using these dense trajectory features, we train a Gaussian mixture model (GMM) to estimate the probability density function of each activity with multiple one-versus-all support vector machine classifiers. The proposed HMM also models duration of each activity, and the transition between activities (e.g., "swing bucket loaded" after "load bucket" for earth-moving activities of an excavator). As a proof-of-concept, we train and test our HMM+GMM model on an unprecedented dataset of 10 real-world long video sequences of interacting pairs of excavators and dumptrucks. Our preliminary experimental results on long-sequence activity recognition in presence of noise, occlusions, and scene clutter demonstrate the effectiveness of our method.},
  isbn = {978-0-7844-8128-8}
}

@article{rogeauIntegratedDesignTool2021,
  title = {An Integrated Design Tool for Timber Plate Structures to Generate Joints Geometry, Fabrication Toolpath, and Robot Trajectories},
  author = {Rogeau, N. and Latteur, P. and Weinand, Y.},
  date = {2021},
  journaltitle = {Automation in Construction},
  volume = {130},
  doi = {10.1016/j.autcon.2021.103875},
  abstract = {This paper presents an integrated design tool for structures composed of engineered timber panels that are connected by traditional wood joints. Recent advances in computational architecture have permitted to automate the fabrication and assembly of such structures using Computer Numerical Control (CNC) machines and industrial robotic arms. While several large-scale demonstrators have been realized, most developed algorithms are closed-source or project-oriented. The lack of a general framework makes it difficult for architects, engineers and designers to effectively manipulate this innovative construction system. Therefore, this research aims at developing a holistic design tool targeting a wide range of architectural applications. Main achievements include: (1) a new data structure to deal with modular assemblies, (2) an analytical parametrization of the geometry of five timber joints, (3) a method to generate CNC toolpath while integrating fabrication constraints, and (4) a method to automatically compute robot trajectories for a given stack of timber plates.}
}

@article{rogeauIntegratedDesignTool2021a,
  title = {An Integrated Design Tool for Timber Plate Structures to Generate Joints Geometry, Fabrication Toolpath, and Robot Trajectories},
  author = {Rogeau, N. and Latteur, P. and Weinand, Y.},
  date = {2021},
  journaltitle = {Automation in Construction},
  volume = {130},
  doi = {10.1016/j.autcon.2021.103875},
  abstract = {This paper presents an integrated design tool for structures composed of engineered timber panels that are connected by traditional wood joints. Recent advances in computational architecture have permitted to automate the fabrication and assembly of such structures using Computer Numerical Control (CNC) machines and industrial robotic arms. While several large-scale demonstrators have been realized, most developed algorithms are closed-source or project-oriented. The lack of a general framework makes it difficult for architects, engineers and designers to effectively manipulate this innovative construction system. Therefore, this research aims at developing a holistic design tool targeting a wide range of architectural applications. Main achievements include: (1) a new data structure to deal with modular assemblies, (2) an analytical parametrization of the geometry of five timber joints, (3) a method to generate CNC toolpath while integrating fabrication constraints, and (4) a method to automatically compute robot trajectories for a given stack of timber plates.}
}

@inproceedings{ronconeTransparentRoleAssignment2017,
  title = {Transparent Role Assignment and Task Allocation in Human Robot Collaboration},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Roncone, Alessandro and Mangin, Olivier and Scassellati, Brian},
  date = {2017-05},
  pages = {1014--1021},
  publisher = {{IEEE}},
  location = {{Singapore, Singapore}},
  doi = {10.1109/ICRA.2017.7989122},
  url = {http://ieeexplore.ieee.org/document/7989122/},
  urldate = {2023-04-24},
  abstract = {Collaborative robots represent a clear added value to manufacturing, as they promise to increase productivity and improve working conditions of such environments. Although modern robotic systems have become safe and reliable enough to operate close to human workers on a day-to-day basis, the workload is still skewed in favor of a limited contribution from the robot’s side, and a significant cognitive load is allotted to the human. We believe the transition from robots as recipients of human instruction to robots as capable collaborators hinges around the implementation of transparent systems, where mental models about the task are shared between peers, and the human partner is freed from the responsibility of taking care of both actors. In this work, we implement a transparent task planner able to be deployed in realistic, nearfuture applications. The proposed framework is capable of basic reasoning capabilities for what concerns role assignment and task allocation, and it interfaces with the human partner at the level of abstraction he is most comfortable with. The system is readily available to non-expert users, and programmable with high-level commands in an intuitive interface. Our results demonstrate an overall improvement in terms of completion time, as well as a reduced cognitive load for the human partner.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-5090-4633-1},
  langid = {english},
  file = {/Volumes/WIP/library/Transparent_role_assignment_and_task_allocation_in_human_robot_collaboration.pdf}
}

@article{rosenbaumAcquisitionIntellectualPerceptualMotor2001,
  title = {Acquisition of {{Intellectual}} and {{Perceptual-Motor Skills}}},
  author = {Rosenbaum, David A. and Carlson, Richard A. and Gilmore, Rick O.},
  date = {2001-02},
  journaltitle = {Annual Review of Psychology},
  shortjournal = {Annu. Rev. Psychol.},
  volume = {52},
  number = {1},
  pages = {453--470},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev.psych.52.1.453},
  url = {https://www.annualreviews.org/doi/10.1146/annurev.psych.52.1.453},
  urldate = {2023-03-22},
  abstract = {▪ Abstract\hspace{0.6em} Recent evidence indicates that intellectual and perceptual-motor skills are acquired in fundamentally similar ways. Transfer specificity, generativity, and the use of abstract rules and reflexlike productions are similar in the two skill domains; brain sites subserving thought processes and perceptual-motor processes are not as distinct as once thought; explicit and implicit knowledge characterize both kinds of skill; learning rates, training effects, and learning stages are remarkably similar for the two skill classes; and imagery, long thought to play a distinctive role in high-level thought, also plays a role in perceptual-motor learning and control. The conclusion that intellectual skills and perceptual-motor skills are psychologically more alike than different accords with the view that all knowledge is performatory.},
  langid = {english}
}

@inproceedings{roshtkhariMultiscaleHierarchicalCodebook2012,
  title = {A Multi-Scale Hierarchical Codebook Method for Human Action Recognition in Videos Using a Single Example},
  booktitle = {Proceedings of the 2012 9th {{Conference}} on {{Computer}} and {{Robot Vision}}, {{CRV}} 2012},
  author = {Roshtkhari, M. J. and Levine, M. D.},
  date = {2012},
  pages = {182--189},
  doi = {10.1109/CRV.2012.32},
  abstract = {This paper presents a novel action matching method based on a hierarchical codebook of local spatio-temporal video volumes (STVs). Given a single example of an activity as a query video, the proposed method finds similar videos to the query in a video dataset. It is based on the bag of video words (BOV) representation and does not require prior knowledge about actions, background subtraction, motion estimation or tracking. It is also robust to spatial and temporal scale changes, as well as some deformations. The hierarchical algorithm yields a compact subset of salient code words of STVs for the query video, and then the likelihood of similarity between the query video and all STVs in the target video is measured using a probabilistic inference mechanism. This hierarchy is achieved by initially constructing a codebook of STVs, while considering the uncertainty in the codebook construction, which is always ignored in current versions of the BOV approach. At the second level of the hierarchy, a large contextual region containing many STVs (Ensemble of STVs) is considered in order to construct a probabilistic model of STVs and their spatio-temporal compositions. At the third level of the hierarchy a codebook is formed for the ensembles of STVs based on their contextual similarities. The latter are the proposed labels (code words) for the actions being exhibited in the video. Finally, at the highest level of the hierarchy, the salient labels for the actions are selected by analyzing the high level code words assigned to each image pixel as a function of time. The algorithm was applied to three available video datasets for action recognition with different complexities (KTH, Weizmann, and MSR II) and the results were superior to other approaches, especially in the cases of a single training example and cross-dataset action recognition. © 2012 IEEE.},
  isbn = {978-0-7695-4683-4}
}

@inproceedings{roshtkhariMultiscaleHierarchicalCodebook2012a,
  title = {A Multi-Scale Hierarchical Codebook Method for Human Action Recognition in Videos Using a Single Example},
  booktitle = {Proceedings of the 2012 9th {{Conference}} on {{Computer}} and {{Robot Vision}}, {{CRV}} 2012},
  author = {Roshtkhari, M.J. and Levine, M.D.},
  date = {2012},
  pages = {182--189},
  doi = {10.1109/CRV.2012.32},
  abstract = {This paper presents a novel action matching method based on a hierarchical codebook of local spatio-temporal video volumes (STVs). Given a single example of an activity as a query video, the proposed method finds similar videos to the query in a video dataset. It is based on the bag of video words (BOV) representation and does not require prior knowledge about actions, background subtraction, motion estimation or tracking. It is also robust to spatial and temporal scale changes, as well as some deformations. The hierarchical algorithm yields a compact subset of salient code words of STVs for the query video, and then the likelihood of similarity between the query video and all STVs in the target video is measured using a probabilistic inference mechanism. This hierarchy is achieved by initially constructing a codebook of STVs, while considering the uncertainty in the codebook construction, which is always ignored in current versions of the BOV approach. At the second level of the hierarchy, a large contextual region containing many STVs (Ensemble of STVs) is considered in order to construct a probabilistic model of STVs and their spatio-temporal compositions. At the third level of the hierarchy a codebook is formed for the ensembles of STVs based on their contextual similarities. The latter are the proposed labels (code words) for the actions being exhibited in the video. Finally, at the highest level of the hierarchy, the salient labels for the actions are selected by analyzing the high level code words assigned to each image pixel as a function of time. The algorithm was applied to three available video datasets for action recognition with different complexities (KTH, Weizmann, and MSR II) and the results were superior to other approaches, especially in the cases of a single training example and cross-dataset action recognition. © 2012 IEEE.},
  isbn = {978-0-7695-4683-4}
}

@book{rothrock2011human,
  title = {Human-in-the-Loop Simulations},
  author = {Rothrock, Ling and Narayanan, S},
  date = {2011},
  publisher = {{Springer}}
}

@article{rozoLearningControllersReactive2016,
  title = {Learning Controllers for Reactive and Proactive Behaviors in Human-Robot Collaboration},
  author = {Rozo, Leonel and Silvério, João and Calinon, Sylvain and Caldwell, Darwin G.},
  date = {2016-06},
  journaltitle = {Frontiers Robotics AI},
  volume = {3},
  publisher = {{Frontiers Media S.A.}},
  issn = {22969144},
  doi = {10.3389/frobt.2016.00030},
  abstract = {Designed to safely share the same workspace as humans and assist them in various tasks, the new collaborative robots are targeting manufacturing and service applications that once were considered unattainable. The large diversity of tasks to carry out, the unstructured environments, and the close interaction with humans call for collaborative robots to seamlessly adapt their behaviors, so as to cooperate with the users successfully under different and possibly new situations (characterized, for example, by positions of objects/landmarks in the environment or by the user pose). This paper investigates how controllers capable of reactive and proactive behaviors in collaborative tasks can be learned from demonstrations. The proposed approach exploits the temporal coherence and dynamic characteristics of the task observed during the training phase to build a probabilistic model that enables the robot to both react to the user actions and lead the task when needed. The method is an extension of the hidden semi-Markov model where the duration probability distribution is adapted according to the interaction with the user. This adaptive duration hidden semi-Markov model (ADHSMM) is used to retrieve a sequence of states governing a trajectory optimization that provides the reference and gain matrices to the robot controller. A proof-of-concept evaluation is first carried out in a pouring task. The proposed framework is then tested in a collaborative task using a 7-DOF backdrivable manipulator.},
  issue = {JUN},
  keywords = {Collaborative robots,Human-robot collaboration,Learning from demonstration,Minimal intervention control,Robot learning and control}
}

@article{rozoLearningControllersReactive2016a,
  title = {Learning Controllers for Reactive and Proactive Behaviors in Human-Robot Collaboration},
  author = {Rozo, Leonel and Silvério, João and Calinon, Sylvain and Caldwell, Darwin G.},
  date = {2016-06-01},
  journaltitle = {Frontiers Robotics AI},
  volume = {3},
  publisher = {{Frontiers Media S.A.}},
  issn = {22969144},
  doi = {10.3389/frobt.2016.00030},
  abstract = {Designed to safely share the same workspace as humans and assist them in various tasks, the new collaborative robots are targeting manufacturing and service applications that once were considered unattainable. The large diversity of tasks to carry out, the unstructured environments, and the close interaction with humans call for collaborative robots to seamlessly adapt their behaviors, so as to cooperate with the users successfully under different and possibly new situations (characterized, for example, by positions of objects/landmarks in the environment or by the user pose). This paper investigates how controllers capable of reactive and proactive behaviors in collaborative tasks can be learned from demonstrations. The proposed approach exploits the temporal coherence and dynamic characteristics of the task observed during the training phase to build a probabilistic model that enables the robot to both react to the user actions and lead the task when needed. The method is an extension of the hidden semi-Markov model where the duration probability distribution is adapted according to the interaction with the user. This adaptive duration hidden semi-Markov model (ADHSMM) is used to retrieve a sequence of states governing a trajectory optimization that provides the reference and gain matrices to the robot controller. A proof-of-concept evaluation is first carried out in a pouring task. The proposed framework is then tested in a collaborative task using a 7-DOF backdrivable manipulator.},
  issue = {JUN},
  keywords = {Collaborative robots,Human-robot collaboration,Learning from demonstration,Minimal intervention control,Robot learning and control},
  file = {C:\Users\leemar\Zotero\storage\ESJ64X5M\frobt-03-00030.pdf}
}

@article{rudolphQuestEthnicReclassification2016,
  title = {The Quest for Ethnic Reclassification in Multiculturalist {{Taiwan}}: {{The}} Case of the {{Sakizaya}}},
  author = {Rudolph, M.},
  date = {2016},
  journaltitle = {Archiv Orientalni},
  volume = {84},
  number = {2},
  pages = {413--443},
  abstract = {This paper argues that the large-scale ethnic resurgence, as observed in the quest for ethnic reclassification in Taiwan today, is not simply the result of deep-seated feelings of primordial attachment of people in a post-colonial society. As it has been described in the case of Brazil, the phenomenon seems also to be supported by a national and international context that valorises indigenous identities as a means of reasserting political and territorial claims. As we have seen from various undertakings of the aboriginal and Pingpu movements, members often try to use the UN for political leverage. Another related reason is the strong elitist influence in the movements seeking ethnic reclassification. Focussing on the example of the Sakizaya, who were recognized as Taiwan's 13th aboriginal group in 2007, I describe how the process of campaigning was dominated by elites who had a thorough understanding of national and international requirements and frameworks. Their visions and ensuing cultural constructions, however, did not always reflect the perspectives of the common people and therefore served as another affirmation of the "elites without people" phenomenon observed in earlier activities of Taiwan's aboriginal revitalization movement. Although the petition with which the Sakizaya successfully gained recognition as a unique ethnic group in 2007 claimed a total of 15,000 members, fewer than 900 Sakizaya had registered by the end of 2015.}
}

@article{rudolphQuestEthnicReclassification2016a,
  title = {The Quest for Ethnic Reclassification in Multiculturalist {{Taiwan}}: {{The}} Case of the {{Sakizaya}}},
  author = {Rudolph, M.},
  date = {2016},
  journaltitle = {Archiv Orientalni},
  volume = {84},
  number = {2},
  pages = {413--443},
  abstract = {This paper argues that the large-scale ethnic resurgence, as observed in the quest for ethnic reclassification in Taiwan today, is not simply the result of deep-seated feelings of primordial attachment of people in a post-colonial society. As it has been described in the case of Brazil, the phenomenon seems also to be supported by a national and international context that valorises indigenous identities as a means of reasserting political and territorial claims. As we have seen from various undertakings of the aboriginal and Pingpu movements, members often try to use the UN for political leverage. Another related reason is the strong elitist influence in the movements seeking ethnic reclassification. Focussing on the example of the Sakizaya, who were recognized as Taiwan's 13th aboriginal group in 2007, I describe how the process of campaigning was dominated by elites who had a thorough understanding of national and international requirements and frameworks. Their visions and ensuing cultural constructions, however, did not always reflect the perspectives of the common people and therefore served as another affirmation of the "elites without people" phenomenon observed in earlier activities of Taiwan's aboriginal revitalization movement. Although the petition with which the Sakizaya successfully gained recognition as a unique ethnic group in 2007 claimed a total of 15,000 members, fewer than 900 Sakizaya had registered by the end of 2015.}
}

@article{russoKnowledgeAcquisitionDesign2021,
  title = {Knowledge {{Acquisition}} and {{Design Using Semantics}} and {{Perception}}: {{A Case Study}} for {{Autonomous Robots}}},
  author = {Russo, Cristiano and Madani, Kurosh and Rinaldi, Antonio M.},
  date = {2021},
  journaltitle = {Neural Processing Letters},
  volume = {53},
  number = {5},
  pages = {3153--3168},
  publisher = {{Springer US}},
  issn = {1573773X},
  doi = {10.1007/s11063-020-10311-x},
  url = {https://doi.org/10.1007/s11063-020-10311-x},
  abstract = {The pervasive use of artificial intelligence and neural networks in several different research fields has noticeably improved multiple aspects of human life. The application of these techniques to machines has made them progressively more “intelligent” and able to solve tasks considered extremely complex for a human being. This technological evolution has deeply influenced the way we interact with machines. Purely symbolic artificial intelligence and techniques like ontologies, have also been successfully used in the past applied to robotics, but have also shown some limitations and failings in the knowledge construction task. In fact, the exhibited “intelligence” is rarely the result of a real autonomous decision, but it is rather hard-encoded in the machine. While a number of approaches have already been proposed in literature concerning knowledge acquisition from the surrounding environment, they are either exclusively based on low-level features or they involve solely high-level semantics-based attributes. Moreover, they often don’t use a general high-level knowledge base for grounding the acquired knowledge. In this contexts, the use of semantics technologies, such as ontologies, is mostly employed for action-oriented tasks. In this article we propose an extension of a novel approach for knowledge acquisition based on a general semantic knowledge-base and the fusion of semantics and visual information by means of neural networks and ontologies. The proposed approach has been implemented on a humanoid robotic platform and the experimental results are shown and discussed.},
  keywords = {Knowledge construction,Neural networks,Ontologies,Robots}
}

@article{russoKnowledgeAcquisitionDesign2021a,
  title = {Knowledge {{Acquisition}} and {{Design Using Semantics}} and {{Perception}}: {{A Case Study}} for {{Autonomous Robots}}},
  author = {Russo, Cristiano and Madani, Kurosh and Rinaldi, Antonio M.},
  date = {2021},
  journaltitle = {Neural Processing Letters},
  volume = {53},
  number = {5},
  pages = {3153--3168},
  publisher = {{Springer US}},
  issn = {1573773X},
  doi = {10.1007/s11063-020-10311-x},
  url = {https://doi.org/10.1007/s11063-020-10311-x},
  abstract = {The pervasive use of artificial intelligence and neural networks in several different research fields has noticeably improved multiple aspects of human life. The application of these techniques to machines has made them progressively more “intelligent” and able to solve tasks considered extremely complex for a human being. This technological evolution has deeply influenced the way we interact with machines. Purely symbolic artificial intelligence and techniques like ontologies, have also been successfully used in the past applied to robotics, but have also shown some limitations and failings in the knowledge construction task. In fact, the exhibited “intelligence” is rarely the result of a real autonomous decision, but it is rather hard-encoded in the machine. While a number of approaches have already been proposed in literature concerning knowledge acquisition from the surrounding environment, they are either exclusively based on low-level features or they involve solely high-level semantics-based attributes. Moreover, they often don’t use a general high-level knowledge base for grounding the acquired knowledge. In this contexts, the use of semantics technologies, such as ontologies, is mostly employed for action-oriented tasks. In this article we propose an extension of a novel approach for knowledge acquisition based on a general semantic knowledge-base and the fusion of semantics and visual information by means of neural networks and ontologies. The proposed approach has been implemented on a humanoid robotic platform and the experimental results are shown and discussed.},
  keywords = {Knowledge construction,Neural networks,Ontologies,Robots},
  file = {C:\Users\leemar\Zotero\storage\RBKCV7D5\Russo2021_Article_KnowledgeAcquisitionAndDesignU-2.pdf}
}

@inproceedings{ruuskaEfficiencyDeliveryMultistory2016,
  title = {Efficiency in the {{Delivery}} of {{Multi-story Timber Buildings}}},
  booktitle = {Energy {{Procedia}}},
  author = {Ruuska, A. and Häkkinen, T.},
  date = {2016},
  volume = {96},
  pages = {190--201},
  doi = {10.1016/j.egypro.2016.09.120},
  abstract = {The construction of wooden multi-story buildings was boosted by changes in building regulations in 2011, which allowed the use of wood in up to 8-story buildings. Thus far more than 50 wooden multi-story buildings have been built in Finland. The public sector has an important role in promoting wood-based multi-story building. Despite of intensive development, the experiences in wood-based multi-story building in Finland are still limited. Building processes may still suffer from some lacks in efficiency in terms of process management and use of resources. It may be possible to address different kinds of issues which would be able to make the process more effective and lean. The objectives of the research were 1) to find inefficiencies in multi-story timber building projects, 2) to address reason and causes for the lacks of efficiency, and 3) to make suggestions that might help to improve the lean nature of the process. The premise of this research was that some of the following reasons may cause ineffectiveness in the delivery of wood based multi-story building projects: lacks in development and standardization of structural systems, lacks in the availability of BIM software for wood buildings, specific additional building requirements set for timber buildings, inexperience of different actors with regard to multi-story timber building and current project delivery and procurement methods. The approach was to study recent literature, select two significant on-going cases which represent different structural systems, interview the representatives over the whole value chain and study the results against our hypothesis and make conclusions.},
  file = {C:\Users\leemar\Zotero\storage\GBFA2NRU\Efficiency-in-the-Delivery-of-Multistory-Timber-BuildingsEnergy-Procedia.pdf}
}

@inproceedings{ruuskaEfficiencyDeliveryMultistory2016a,
  title = {Efficiency in the {{Delivery}} of {{Multi-story Timber Buildings}}},
  booktitle = {Energy {{Procedia}}},
  author = {Ruuska, A. and Häkkinen, T.},
  date = {2016},
  volume = {96},
  pages = {190--201},
  doi = {10.1016/j.egypro.2016.09.120},
  abstract = {The construction of wooden multi-story buildings was boosted by changes in building regulations in 2011, which allowed the use of wood in up to 8-story buildings. Thus far more than 50 wooden multi-story buildings have been built in Finland. The public sector has an important role in promoting wood-based multi-story building. Despite of intensive development, the experiences in wood-based multi-story building in Finland are still limited. Building processes may still suffer from some lacks in efficiency in terms of process management and use of resources. It may be possible to address different kinds of issues which would be able to make the process more effective and lean. The objectives of the research were 1) to find inefficiencies in multi-story timber building projects, 2) to address reason and causes for the lacks of efficiency, and 3) to make suggestions that might help to improve the lean nature of the process. The premise of this research was that some of the following reasons may cause ineffectiveness in the delivery of wood based multi-story building projects: lacks in development and standardization of structural systems, lacks in the availability of BIM software for wood buildings, specific additional building requirements set for timber buildings, inexperience of different actors with regard to multi-story timber building and current project delivery and procurement methods. The approach was to study recent literature, select two significant on-going cases which represent different structural systems, interview the representatives over the whole value chain and study the results against our hypothesis and make conclusions.},
  file = {C:\Users\leemar\Zotero\storage\KVYF3YSR\Efficiency-in-the-Delivery-of-Multistory-Timber-BuildingsEnergy-Procedia.pdf}
}

@inproceedings{Ryoo20132730,
  title = {First-Person Activity Recognition: {{What}} Are They Doing to Me?},
  author = {Ryoo, M.S. and Matthies, L.},
  date = {2013},
  series = {Proceedings of the {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  pages = {2730--2737},
  doi = {10.1109/CVPR.2013.352},
  art_number = {6619196}
}

@inproceedings{Ryoo2015295,
  title = {Robot-Centric Activity Prediction from First-Person Videos: {{What}} Will They Do to Me?},
  author = {Ryoo, M.S. and Fuchs, T.J. and Xia, L. and Aggarwal, J.K. and Matthies, L.},
  date = {2015},
  series = {{{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  volume = {2015-March},
  pages = {295--302},
  doi = {10.1145/2696454.2696462}
}

@incollection{sadrfaridpourModelingControlTrust2016,
  title = {Modeling and {{Control}} of {{Trust}} in {{Human-Robot Collaborative Manufacturing}}},
  booktitle = {Robust {{Intelligence}} and {{Trust}} in {{Autonomous Systems}}},
  author = {Sadrfaridpour, Behzad and Saeidi, Hamed and Burke, Jenny and Madathil, Kapil and Wang, Yue},
  editor = {Mittu, Ranjeev and Sofge, Donald and Wagner, Alan and Lawless, W.F.},
  date = {2016},
  pages = {115--141},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7668-0_7},
  url = {http://link.springer.com/10.1007/978-1-4899-7668-0_7},
  urldate = {2023-06-07},
  isbn = {978-1-4899-7666-6 978-1-4899-7668-0},
  langid = {english},
  file = {/Volumes/WIP/library/978-1-4899-7668-0.pdf}
}

@book{sajjadianFourAnglesUsing2021,
  title = {Four {{Angles}} of {{Using Timber}} in {{Tall Buildings}}},
  author = {Sajjadian, S.M. and Tupenaite, L. and Barlow, C.},
  date = {2021},
  journaltitle = {Smart Innovation, Systems and Technologies},
  volume = {203},
  doi = {10.1007/978-981-15-8783-2_15},
  abstract = {Increasing attention to utilise more sustainable materials in the construction industry has made timber-based building elements more desirable. The advantages of timber in prefabrication and sustainable development are widely known, and recent investigations are looking at using timber for high-rise buildings. Until this point, many tall buildings are already built by timber, and new proposals to use it in design and as a prefabricated component are being made from academics and industry every year. This paper looks at four angles of using timber in high-rise buildings on structural capacity, construction practice, environmental and acoustic performance. A case study is also used to quantify the operational performance of a high-rise building in London, UK, and through a BIM tool, a costing is also accomplished to compare the cost of a high-rise building in CLT with steel and concrete. The study reveals the potential, challenges and advantages of using timber from four perspectives that have rarely been investigated.},
  isbn = {9789811587825},
  pagetotal = {183-193}
}

@book{sajjadianFourAnglesUsing2021a,
  title = {Four {{Angles}} of {{Using Timber}} in {{Tall Buildings}}},
  author = {Sajjadian, S.M. and Tupenaite, L. and Barlow, C.},
  date = {2021},
  journaltitle = {Smart Innovation, Systems and Technologies},
  volume = {203},
  doi = {10.1007/978-981-15-8783-2_15},
  abstract = {Increasing attention to utilise more sustainable materials in the construction industry has made timber-based building elements more desirable. The advantages of timber in prefabrication and sustainable development are widely known, and recent investigations are looking at using timber for high-rise buildings. Until this point, many tall buildings are already built by timber, and new proposals to use it in design and as a prefabricated component are being made from academics and industry every year. This paper looks at four angles of using timber in high-rise buildings on structural capacity, construction practice, environmental and acoustic performance. A case study is also used to quantify the operational performance of a high-rise building in London, UK, and through a BIM tool, a costing is also accomplished to compare the cost of a high-rise building in CLT with steel and concrete. The study reveals the potential, challenges and advantages of using timber from four perspectives that have rarely been investigated.},
  isbn = {9789811587825},
  pagetotal = {183-193}
}

@article{santana-sosaHolisticApproachIndustrializing2019,
  title = {A Holistic Approach for Industrializing Timber Construction},
  author = {Santana-Sosa, A. and Fadai, A.},
  date = {2019-09-06},
  journaltitle = {IOP Conference Series: Earth and Environmental Science},
  volume = {323},
  number = {1},
  pages = {012015},
  issn = {1755-1315},
  doi = {10.1088/1755-1315/323/1/012015},
  url = {https://iopscience.iop.org/article/10.1088/1755-1315/323/1/012015},
  abstract = {Many strategies have been investigated seeking for efficiency in construction sector, since it has been pointed out as the largest consumer of raw materials worldwide and responsible of about 1/3 of the global CO2 emissions. While operational carbon has been strongly reduced due to building regulations, embodied carbon is becoming dominating. Resources and processes involved from material extraction to building erection should be carefully optimized aiming to reduce the emissions from the cradle to service. New advancements in timber engineering have shown the capabilities of this renewable and CO2 neutral material in multi-storey buildings. Since their erection is based on prefabrication, an accurate construction management is eased where variations and waste are sensible to be minimized. Through this paper, the factors constraining the use of wood as main material for multi-storey buildings will be explored and the potential benefits of using Lean Construction principles in the timber industry are highlighted aiming to achieve a standardized workflow from design to execution. Hence, a holistic approach towards industrialization is proposed from an integrated BIM model, through an optimized supply chain of off-site production, and to a precise aligned scheduled on-site assembly.},
  file = {C:\Users\leemar\Zotero\storage\SRPZPBNI\Santana-Sosa_2019_IOP_Conf._Ser.%3A_Earth_Environ._Sci._323_012015.pdf}
}

@inproceedings{santana-sosaHolisticApproachIndustrializing2019a,
  title = {A Holistic Approach for Industrializing Timber Construction},
  booktitle = {{{IOP Conference Series}}: {{Earth}} and {{Environmental Science}}},
  author = {Santana-Sosa, A. and Fadai, A.},
  date = {2019},
  volume = {323},
  number = {1},
  doi = {10.1088/1755-1315/323/1/012015},
  abstract = {Many strategies have been investigated seeking for efficiency in construction sector, since it has been pointed out as the largest consumer of raw materials worldwide and responsible of about 1/3 of the global CO2 emissions. While operational carbon has been strongly reduced due to building regulations, embodied carbon is becoming dominating. Resources and processes involved from material extraction to building erection should be carefully optimized aiming to reduce the emissions from the cradle to service. New advancements in timber engineering have shown the capabilities of this renewable and CO2 neutral material in multi-storey buildings. Since their erection is based on prefabrication, an accurate construction management is eased where variations and waste are sensible to be minimized. Through this paper, the factors constraining the use of wood as main material for multi-storey buildings will be explored and the potential benefits of using Lean Construction principles in the timber industry are highlighted aiming to achieve a standardized workflow from design to execution. Hence, a holistic approach towards industrialization is proposed from an integrated BIM model, through an optimized supply chain of off-site production, and to a precise aligned scheduled on-site assembly.}
}

@inproceedings{santana-sosaTheoreticalApproachRessource2018,
  title = {A Theoretical Approach towards Ressource Efficiency in Multi-Story Timber Buildings through {{BIM}} and Lean},
  booktitle = {{{WCTE}} 2018 - {{World Conference}} on {{Timber Engineering}}},
  author = {Santana-Sosa, A. and Riola-Parada, F.},
  date = {2018},
  abstract = {The timber industry has experienced in the last decades a relevant increase in terms of high performance buildings. Despite these advancements and the favorable properties of building with wood, the traditional position of "choosing by costs" still finds wooden building as more expensive than concrete or steel ones. In order to be competitive in the market against these two main building materials and meet the expectations of modern and large-volume wood based constructions, new improvements based on standardization and prefabricated systems have to be implemented. At the same time a full collaborative work between all the participants on a project is needed to redefine and optimize the construction and design processes through sharing specific and detailed information and extended know-how at a very early project stage. Through this approach, the high potential of combining off-site construction, Building Information Modeling (BIM) as a work methodology and lean management practices will be investigated, involving architects, engineers, BIM users in the timber industry, timber manufactures, contractors and all the stakeholders with the aim of reaching the most effective and productive design and construction process in multi-story timber buildings.}
}

@inproceedings{santana-sosaTheoreticalApproachRessource2018a,
  title = {A Theoretical Approach towards Ressource Efficiency in Multi-Story Timber Buildings through {{BIM}} and Lean},
  booktitle = {{{WCTE}} 2018 - {{World Conference}} on {{Timber Engineering}}},
  author = {Santana-Sosa, A. and Riola-Parada, F.},
  date = {2018},
  abstract = {The timber industry has experienced in the last decades a relevant increase in terms of high performance buildings. Despite these advancements and the favorable properties of building with wood, the traditional position of "choosing by costs" still finds wooden building as more expensive than concrete or steel ones. In order to be competitive in the market against these two main building materials and meet the expectations of modern and large-volume wood based constructions, new improvements based on standardization and prefabricated systems have to be implemented. At the same time a full collaborative work between all the participants on a project is needed to redefine and optimize the construction and design processes through sharing specific and detailed information and extended know-how at a very early project stage. Through this approach, the high potential of combining off-site construction, Building Information Modeling (BIM) as a work methodology and lean management practices will be investigated, involving architects, engineers, BIM users in the timber industry, timber manufactures, contractors and all the stakeholders with the aim of reaching the most effective and productive design and construction process in multi-story timber buildings.}
}

@article{saranliModularRealtimeFieldbus2011,
  title = {A Modular Real-Time Fieldbus Architecture for Mobile Robotic Platforms},
  author = {Saranli, U. and Avci, A. and Öztürk, M.C.},
  date = {2011},
  journaltitle = {IEEE Transactions on Instrumentation and Measurement},
  volume = {60},
  number = {3},
  pages = {916--927},
  doi = {10.1109/TIM.2010.2078351},
  abstract = {The design and construction of complex and reconfigurable embedded systems such as small autonomous mobile robots is a challenging task that involves the selection, interfacing, and programming of a large number of sensors and actuators. Facilitating this tedious process requires modularity and extensibility both in hardware and software components. In this paper, we introduce the universal robot bus (URB), a real-time fieldbus architecture that facilitates rapid integration of heterogeneous sensor and actuator nodes to a central processing unit (CPU) while providing a software abstraction that eliminates complications arising from the lack of hardware homogeneity. Motivated by our primary application area of mobile robotics, URB is designed to be very lightweight and efficient, with real-time support for Recommended Standard (RS) 232 or universal serial bus connections to a central computer and inter-integrated circuit (I2C), controller area network, or RS485 bus connections to embedded nodes. It supports automatic synchronization of data acquisition across multiple nodes, provides high data bandwidth at low deterministic latencies, and includes flexible libraries for modular software development both for local nodes and the CPU. This paper describes the design of the URB architecture, provides a careful experimental characterization of its performance, and demonstrates its utility in the context of its deployment in a legged robot platform. © 2006 IEEE.}
}

@article{saranliModularRealtimeFieldbus2011a,
  title = {A Modular Real-Time Fieldbus Architecture for Mobile Robotic Platforms},
  author = {Saranli, U. and Avci, A. and Öztürk, M.C.},
  date = {2011},
  journaltitle = {IEEE Transactions on Instrumentation and Measurement},
  volume = {60},
  number = {3},
  pages = {916--927},
  doi = {10.1109/TIM.2010.2078351},
  abstract = {The design and construction of complex and reconfigurable embedded systems such as small autonomous mobile robots is a challenging task that involves the selection, interfacing, and programming of a large number of sensors and actuators. Facilitating this tedious process requires modularity and extensibility both in hardware and software components. In this paper, we introduce the universal robot bus (URB), a real-time fieldbus architecture that facilitates rapid integration of heterogeneous sensor and actuator nodes to a central processing unit (CPU) while providing a software abstraction that eliminates complications arising from the lack of hardware homogeneity. Motivated by our primary application area of mobile robotics, URB is designed to be very lightweight and efficient, with real-time support for Recommended Standard (RS) 232 or universal serial bus connections to a central computer and inter-integrated circuit (I2C), controller area network, or RS485 bus connections to embedded nodes. It supports automatic synchronization of data acquisition across multiple nodes, provides high data bandwidth at low deterministic latencies, and includes flexible libraries for modular software development both for local nodes and the CPU. This paper describes the design of the URB architecture, provides a careful experimental characterization of its performance, and demonstrates its utility in the context of its deployment in a legged robot platform. © 2006 IEEE.}
}

@article{sasikumarFirstPassProcessingValue2018,
  title = {First-{{Pass Processing}} of {{Value Cues}} in the {{Ventral Visual Pathway}}},
  author = {Sasikumar, D. and Emeric, E. and Stuphorn, V. and Connor, C. E.},
  date = {2018},
  journaltitle = {Current Biology},
  volume = {28},
  number = {4},
  pages = {538-548.e3},
  doi = {10.1016/j.cub.2018.01.051},
  abstract = {Real-world value often depends on subtle, continuously variable visual cues specific to particular object categories, like the tailoring of a suit, the condition of an automobile, or the construction of a house. Here, we used microelectrode recording in behaving monkeys to test two possible mechanisms for category-specific value-cue processing: (1) previous findings suggest that prefrontal cortex (PFC) identifies object categories, and based on category identity, PFC could use top-down attentional modulation to enhance visual processing of category-specific value cues, providing signals to PFC for calculating value, and (2) a faster mechanism would be first-pass visual processing of category-specific value cues, immediately providing the necessary visual information to PFC. This, however, would require learned mechanisms for processing the appropriate cues in a given object category. To test these hypotheses, we trained monkeys to discriminate value in four letter-like stimulus categories. Each category had a different, continuously variable shape cue that signified value (liquid reward amount) as well as other cues that were irrelevant. Monkeys chose between stimuli of different reward values. Consistent with the first-pass hypothesis, we found early signals for category-specific value cues in area TE (the final stage in monkey ventral visual pathway) beginning 81 ms after stimulus onset—essentially at the start of TE responses. Task-related activity emerged in lateral PFC approximately 40 ms later and consisted mainly of category-invariant value tuning. Our results show that, for familiar, behaviorally relevant object categories, high-level ventral pathway cortex can implement rapid, first-pass processing of category-specific value cues. Real-world value judgments often depend on subtle variations in object appearance. Sasikumar et al. show that neurons in high-level cortex can become sensitive to these variations following extensive training with specific object categories. This provides a fast mechanism for value judgments in familiar object categories.}
}

@article{sasikumarFirstPassProcessingValue2018a,
  title = {First-{{Pass Processing}} of {{Value Cues}} in the {{Ventral Visual Pathway}}},
  author = {Sasikumar, D. and Emeric, E. and Stuphorn, V. and Connor, C.E.},
  date = {2018},
  journaltitle = {Current Biology},
  volume = {28},
  number = {4},
  pages = {538-548.e3},
  doi = {10.1016/j.cub.2018.01.051},
  abstract = {Real-world value often depends on subtle, continuously variable visual cues specific to particular object categories, like the tailoring of a suit, the condition of an automobile, or the construction of a house. Here, we used microelectrode recording in behaving monkeys to test two possible mechanisms for category-specific value-cue processing: (1) previous findings suggest that prefrontal cortex (PFC) identifies object categories, and based on category identity, PFC could use top-down attentional modulation to enhance visual processing of category-specific value cues, providing signals to PFC for calculating value, and (2) a faster mechanism would be first-pass visual processing of category-specific value cues, immediately providing the necessary visual information to PFC. This, however, would require learned mechanisms for processing the appropriate cues in a given object category. To test these hypotheses, we trained monkeys to discriminate value in four letter-like stimulus categories. Each category had a different, continuously variable shape cue that signified value (liquid reward amount) as well as other cues that were irrelevant. Monkeys chose between stimuli of different reward values. Consistent with the first-pass hypothesis, we found early signals for category-specific value cues in area TE (the final stage in monkey ventral visual pathway) beginning 81 ms after stimulus onset—essentially at the start of TE responses. Task-related activity emerged in lateral PFC approximately 40 ms later and consisted mainly of category-invariant value tuning. Our results show that, for familiar, behaviorally relevant object categories, high-level ventral pathway cortex can implement rapid, first-pass processing of category-specific value cues. Real-world value judgments often depend on subtle variations in object appearance. Sasikumar et al. show that neurons in high-level cortex can become sensitive to these variations following extensive training with specific object categories. This provides a fast mechanism for value judgments in familiar object categories.}
}

@inproceedings{sauppeSocialImpactRobot2015,
  title = {The {{Social Impact}} of a {{Robot Co-Worker}} in {{Industrial Settings}}},
  booktitle = {Proceedings of the 33rd {{Annual ACM Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Sauppé, Allison and Mutlu, Bilge},
  date = {2015-04-18},
  pages = {3613--3622},
  publisher = {{ACM}},
  location = {{Seoul Republic of Korea}},
  doi = {10.1145/2702123.2702181},
  url = {https://dl.acm.org/doi/10.1145/2702123.2702181},
  urldate = {2023-08-20},
  eventtitle = {{{CHI}} '15: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-3145-6},
  langid = {english}
}

@article{scheibleFreeChoiceProject2019,
  entrysubtype = {magazine},
  title = {Free Choice - {{The}} Project Determines the Planning Method | {{Freie Wahl}} – Das {{Projekt}} Bestimmt Die {{Planungsmethode}}},
  author = {Scheible, F. and Peter, B.},
  date = {2019},
  journaltitle = {Bautechnik},
  volume = {96},
  number = {12},
  pages = {939--944},
  doi = {10.1002/bate.201900096},
  abstract = {Free choice – the project determines the planning method. In the wake of digitalisation, a trend towards precise regulation and standardisation of individual steps has developed, far removed from an understanding of working in which the success of the work is paramount, and where the planners themselves decide upon the actual planning method. According to a survey carried out by DIN in 2017, around 85 \% of those questioned rated the development of new standards as either “very urgent” or űrgent”. In future, these standards will dictate to planning teams how they must undertake their planning work. Freelance planners in particular need to play a more active role in the shaping of these standards, along with the related question: “How would we like to plan in future?”. For Shenzhen airport, the ‘Nachhallgalerie' at the Berlin State Opera, the multistorey timber construction ‘The Cradle' in Düsseldorf and the new ‘Elephant World' in Stuttgart, the Knippers Helbig practice, together with its planning partners, has developed project-specific process chains that cannot be recorded normatively. This shows how important it is that, in future too, planners retain the freedom to help shape the processes.}
}

@article{scheibleFreeChoiceProject2019a,
  entrysubtype = {magazine},
  title = {Free Choice - {{The}} Project Determines the Planning Method | {{Freie Wahl}} – Das {{Projekt}} Bestimmt Die {{Planungsmethode}}},
  author = {Scheible, F. and Peter, B.},
  date = {2019},
  journaltitle = {Bautechnik},
  volume = {96},
  number = {12},
  pages = {939--944},
  doi = {10.1002/bate.201900096},
  abstract = {Free choice – the project determines the planning method. In the wake of digitalisation, a trend towards precise regulation and standardisation of individual steps has developed, far removed from an understanding of working in which the success of the work is paramount, and where the planners themselves decide upon the actual planning method. According to a survey carried out by DIN in 2017, around 85 \% of those questioned rated the development of new standards as either “very urgent” or űrgent”. In future, these standards will dictate to planning teams how they must undertake their planning work. Freelance planners in particular need to play a more active role in the shaping of these standards, along with the related question: “How would we like to plan in future?”. For Shenzhen airport, the ‘Nachhallgalerie' at the Berlin State Opera, the multistorey timber construction ‘The Cradle' in Düsseldorf and the new ‘Elephant World' in Stuttgart, the Knippers Helbig practice, together with its planning partners, has developed project-specific process chains that cannot be recorded normatively. This shows how important it is that, in future too, planners retain the freedom to help shape the processes.}
}

@article{schmidProactiveRobotTask2007,
  title = {Proactive Robot Task Selection given a Human Intention Estimate},
  author = {Schmid, Andreas J. and Weede, Oliver and Wörn, Heinz},
  date = {2007},
  journaltitle = {Proceedings - IEEE International Workshop on Robot and Human Interactive Communication},
  number = {I},
  pages = {726--731},
  doi = {10.1109/ROMAN.2007.4415181},
  abstract = {Intuitive human-robot cooperation presents a challenge to robots since it demands of them a high level of understanding of the human user. Our approach is to estimate the human intention and select and proactively execute an appropriate robot task without requiring an explicit user command. This paper describes the concept and details of our proactive execution module and how it forms an integral part of our intuitive human-robot cooperation system. We present implementation details and the results of an evaluation scenario. ©2007 IEEE.},
  isbn = {1424416345}
}

@article{schmidProactiveRobotTask2007a,
  title = {Proactive Robot Task Selection given a Human Intention Estimate},
  author = {Schmid, Andreas J. and Weede, Oliver and Wörn, Heinz},
  date = {2007},
  journaltitle = {Proceedings - IEEE International Workshop on Robot and Human Interactive Communication},
  number = {I},
  pages = {726--731},
  doi = {10.1109/ROMAN.2007.4415181},
  abstract = {Intuitive human-robot cooperation presents a challenge to robots since it demands of them a high level of understanding of the human user. Our approach is to estimate the human intention and select and proactively execute an appropriate robot task without requiring an explicit user command. This paper describes the concept and details of our proactive execution module and how it forms an integral part of our intuitive human-robot cooperation system. We present implementation details and the results of an evaluation scenario. ©2007 IEEE.},
  isbn = {1424416345},
  file = {C:\Users\leemar\Zotero\storage\H2DPLJ5H\Proactive_Robot_Task_Selection_Given_a_Human_Intention_Estimate.pdf}
}

@article{schnake-mahlGentrificationNeighborhoodChange2020,
  title = {Gentrification, {{Neighborhood Change}}, and {{Population Health}}: A {{Systematic Review}}},
  shorttitle = {Gentrification, {{Neighborhood Change}}, and {{Population Health}}},
  author = {Schnake-Mahl, Alina S. and Jahn, Jaquelyn L. and Subramanian, S.V. and Waters, Mary C. and Arcaya, Mariana},
  date = {2020-02},
  journaltitle = {Journal of Urban Health},
  shortjournal = {J Urban Health},
  volume = {97},
  number = {1},
  pages = {1--25},
  issn = {1099-3460, 1468-2869},
  doi = {10.1007/s11524-019-00400-1},
  url = {https://link.springer.com/10.1007/s11524-019-00400-1},
  urldate = {2023-09-16},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\GMPFNC5T\Schnake-Mahl 等。 - 2020 - Gentrification, Neighborhood Change, and Populatio.pdf}
}

@article{Sebanz200670,
  title = {Joint Action: {{Bodies}} and Minds Moving Together},
  author = {Sebanz, N. and Bekkering, H. and Knoblich, G.},
  date = {2006},
  journaltitle = {Trends in Cognitive Sciences},
  volume = {10},
  number = {2},
  pages = {70--76},
  doi = {10.1016/j.tics.2005.12.009}
}

@article{Sebanz2009353,
  title = {Prediction in Joint Action: {{What}}, When, and Where},
  author = {Sebanz, N. and Knoblich, G.},
  date = {2009},
  journaltitle = {Topics in Cognitive Science},
  volume = {1},
  number = {2},
  pages = {353--367},
  doi = {10.1111/j.1756-8765.2009.01024.x}
}

@article{sepulchreCyberphysicalHumanSystems2020,
  title = {Cyberphysical {{Human Systems}} [{{About This Issue}}]},
  author = {Sepulchre, R.},
  date = {2020},
  journaltitle = {IEEE Control Systems},
  volume = {40},
  number = {6},
  pages = {5--8},
  doi = {10.1109/MCS.2020.3019144},
  abstract = {The theme of the special issue of IEEE Control Systems is entitled ‘Cyberphysical Human Systems: An Introduction to the Special Issue’. An article entitled ‘Human-in-the-Loop Robot Control for Human–Robot Collaboration’, by Ashwin P. Dani, Iman Salehi, Ghananeel Rotithor, Daniel Trombetta, and Harish Ravichandar, presents an estimation and control framework to estimate human intentions and synthesize a safe robot controller in a human–robot collaboration setting. Another article entitled Behavioral Economics for Human in-the-Loop Control Systems Design’, by Marius Protte, Rene Á Fahr, and Daniel E. Quevedo, investigates human behavior in control engineering settings, focusing on behavioral phenomena that are well established in behavioral economics literature.}
}

@article{sepulchreCyberphysicalHumanSystems2020a,
  title = {Cyberphysical {{Human Systems}} [{{About This Issue}}]},
  author = {Sepulchre, R.},
  date = {2020},
  journaltitle = {IEEE Control Systems},
  volume = {40},
  number = {6},
  pages = {5--8},
  doi = {10.1109/MCS.2020.3019144},
  abstract = {The theme of the special issue of IEEE Control Systems is entitled ‘Cyberphysical Human Systems: An Introduction to the Special Issue’. An article entitled ‘Human-in-the-Loop Robot Control for Human–Robot Collaboration’, by Ashwin P. Dani, Iman Salehi, Ghananeel Rotithor, Daniel Trombetta, and Harish Ravichandar, presents an estimation and control framework to estimate human intentions and synthesize a safe robot controller in a human–robot collaboration setting. Another article entitled Behavioral Economics for Human in-the-Loop Control Systems Design’, by Marius Protte, Rene Á Fahr, and Daniel E. Quevedo, investigates human behavior in control engineering settings, focusing on behavioral phenomena that are well established in behavioral economics literature.}
}

@inproceedings{sewtzRobustMUSICBasedSound2020,
  title = {Robust {{MUSIC-Based}} Sound Source Localization in Reverberant and Echoic Environments},
  booktitle = {{{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Sewtz, M. and Bodenmuller, T. and Triebel, R.},
  date = {2020},
  pages = {2474--2480},
  doi = {10.1109/IROS45743.2020.9340826},
  abstract = {Intuitive human robot interfaces like speech or gesture recognition are essential for gaining acceptance for robots in daily life. However, such interaction requires that the robot detects the human's intention to interact, tracks his position and keeps its sensor systems in an optimal configuration. Audio is a suitable modality for such task as it allows for detecting a speaker in arbitrary positions around the robot. In this paper, we present a novel approach for localization of sound sources by analyzing the frequency spectrum of the received signal and applying a motion model to the estimation process. We use an improved version of the Generalized Singular Value Decomposition (GSVD) based MUltiple SIgnal Classification (MUSIC) algorithm as a direction of arrival (DoA) estimator. Further, we introduce a motion model to enable robust localization in reverberant and echoic environments.We evaluate the system under real conditions in an experimental setup. Our experiments show that our approach outperforms current state-of-the-art algorithm and demonstrate the robustness against the previously mentioned disruptive factors.},
  isbn = {978-1-72816-212-6}
}

@inproceedings{sewtzRobustMUSICBasedSound2020a,
  title = {Robust {{MUSIC-Based}} Sound Source Localization in Reverberant and Echoic Environments},
  booktitle = {{{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Sewtz, M. and Bodenmuller, T. and Triebel, R.},
  date = {2020},
  pages = {2474--2480},
  doi = {10.1109/IROS45743.2020.9340826},
  abstract = {Intuitive human robot interfaces like speech or gesture recognition are essential for gaining acceptance for robots in daily life. However, such interaction requires that the robot detects the human's intention to interact, tracks his position and keeps its sensor systems in an optimal configuration. Audio is a suitable modality for such task as it allows for detecting a speaker in arbitrary positions around the robot. In this paper, we present a novel approach for localization of sound sources by analyzing the frequency spectrum of the received signal and applying a motion model to the estimation process. We use an improved version of the Generalized Singular Value Decomposition (GSVD) based MUltiple SIgnal Classification (MUSIC) algorithm as a direction of arrival (DoA) estimator. Further, we introduce a motion model to enable robust localization in reverberant and echoic environments.We evaluate the system under real conditions in an experimental setup. Our experiments show that our approach outperforms current state-of-the-art algorithm and demonstrate the robustness against the previously mentioned disruptive factors.},
  isbn = {978-1-72816-212-6}
}

@article{Shah2010234,
  title = {An Empirical Analysis of Team Coordination Behaviors and Action Planning with Application to Human-Robot Teaming},
  author = {Shah, J. and Breazeal, C.},
  date = {2010},
  journaltitle = {Human Factors},
  volume = {52},
  number = {2},
  pages = {234--245},
  doi = {10.1177/0018720809350882}
}

@inproceedings{Shah201129,
  title = {Improved Human-Robot Team Performance Using {{Chaski}}, a Human-Inspired Plan Execution System},
  author = {Shah, J. and Wiken, J. and Breazeal, C. and Williams, B.},
  date = {2011},
  series = {{{HRI}} 2011 - {{Proceedings}} of the 6th {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  pages = {29--36},
  doi = {10.1145/1957656.1957668}
}

@article{shahEmpiricalAnalysisTeam2010,
  title = {An {{Empirical Analysis}} of {{Team Coordination Behaviors}} and {{Action Planning With Application}} to {{Human}}–{{Robot Teaming}}},
  author = {Shah, Julie and Breazeal, Cynthia},
  date = {2010-04},
  journaltitle = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
  shortjournal = {Hum Factors},
  volume = {52},
  number = {2},
  pages = {234--245},
  issn = {0018-7208, 1547-8181},
  doi = {10.1177/0018720809350882},
  url = {http://journals.sagepub.com/doi/10.1177/0018720809350882},
  urldate = {2023-04-24},
  abstract = {Objective: We conducted an empirical analysis of human teamwork to investigate the ways teammates incorporate coordination behaviors, including verbal and nonverbal cues, into their action planning. Background: In space, military, aviation, and medical industries, teams of people effectively coordinate to perform complex tasks under stress induced by uncertainty, ambiguity, and time pressure. As robots increasingly are introduced into these domains, we seek to understand effective human-team coordination to inform natural and effective human-robot coordination. Method: We conducted teamwork experiments in which teams of two people performed a complex task, involving ordering, timing, and resource constraints. Half the teams performed under time pressure, and half performed without time pressure. We cataloged the coordination behaviors used by each team and analyzed the speed of response and specificity of each coordination behavior. Results: Analysis shows that teammates respond to explicit cues, including commands meant to control actions, more quickly than implicit cues, which include short verbal and gestural attention getters and status updates. Analysis also shows that nearly all explicit cues and implicit gestural cues were used to refer to one specific action, whereas approximately half of implicit cues did not often refer to one specific action. Conclusion: These results provide insight into how human teams use coordination behaviors in their action planning. For example, implicit cues seem to offer the teammate flexibility on when to perform the indicated action, whereas explicit cues seem to demand immediate response. Application: We discuss how these findings inform the design of more natural and fluid human-robot teaming.},
  langid = {english},
  file = {/Volumes/WIP/library/0018720809350882.pdf}
}

@inproceedings{shamAWWAG300Standard2011,
  title = {{{AWWA G300}} Standard: {{Steps}} to Protect Source Water},
  booktitle = {American {{Water Works Association Annual Conference}} and {{Exposition}} 2011, {{ACE}} 2011},
  author = {Sham, C. H. and Long, S. C. and Gullick, R. W.},
  date = {2011},
  pages = {1185--1207},
  abstract = {One of the main goals of the American Water Works Association (AWWA) is to support water utilities in evaluating and improving their water quality, operations, maintenance, and infrastructure. Several different programs and types of publications are used to support this mission. One key program is the AWWA standards process, which has existed more than 100 years to produce peer-reviewed standards for materials and processes used by the water and wastewater utility industries. These standards, which are American National Standards Institute (ANSI) approved, are recognized worldwide and have been adopted by many utilities and organizations. The AWWA standards program is designed to assist water and wastewater utilities and their service providers to meet expectations of their customers, investors, and government regulators. The standards developed under the program are generally intended to improve a utility's overall operations and service. AWWA has developed a new series of utility management standards for water and wastewater utilities in the past decade. The Utility Management Standards program provides a means to assess service quality and management efficiency based on recognized standards for best available practices. Through establishment of standards and formal recognition by professional organizations, the program will serve water and wastewater utilities by promoting improvements in the quality of services and efficient management. The utility management standards address the widespread need of utility managers to have some consistency and reliability in knowing what is generally expected in the management and operation of utilities. These standards are also valuable resources in light of the many issues facing utilities, including increased scrutiny on accountability, increased regulation, and difficult economic realities such as aging infrastructure, changing demand for water, and a shrinking workforce. The utility management standards (also known as the G Series) are designed to cover the principal activities of a typical water and/or wastewater utility. Some examples include standards for distribution systems operations and management (G200), source water protection (G300), utility management systems (G400), security practices (G430). Other standards under development include business practices, emergency planning, and communication and customer relations. Additional topics will be added over time, including ones specifically relevant to wastewater utilities. The utility management standards are developed using the same formal, ANSI-recognized, AWWA-managed process. Volunteer standards committees establish standard practices in a uniform and appropriate format. Formal standards committees are formed to address the individual standards practices for the diverse areas of water and wastewater utility operations. ANSI/AWWA Standard G300, Source Water Protection, provides the definitive standard for a drinking water utility to protect its drinking water supply source(s). AWWA G300 became effective on July 1, 2007, and outlines the six primary components of successful SWP programs and the requirements for meeting the standard (AWWA 2007). The primary objectives of Source Water Protection (SWP) programs are to maintain, safeguard, and/or improve the quality of a given source water. Numerous benefits may be achieved because of these aims, and each may be considered as incentives or drivers for a utility to develop and implement SWP activities. The potential incentives include greater public health protection by ensuring higher quality raw water, especially for sensitive subpopulations. In addition to reduced illnesses and mortalities, public health protection can provide economic benefits in terms of reduced health care costs and reduced loss of productivity and work time; providing a way to respond to uncertainties presented by the growing number of unknown or unregulated microbiological and chemical contaminants (i.e., preventing contamination that treatment may not remove); avoiding costs of treating, monitoring, and remediating contamination; and greater likelihood of complying with existing and future drinking water regulations. A clear and important aspect of this premise is that pollution prevention is greatly preferable to remediating or treating contaminated source water. SWP programs should provide a means to assess and prevent future contamination, and should not just emphasize reducing current contamination. To minimize impacts from chemical, microbiological, and radiological contaminants, some pollutant sources that SWP programs should address include stormwater runoff from natural events containing contaminants such as microorganisms, nutrients, heavy metals, organic chemicals, and sediment; treated and untreated municipal and industrial wastewater discharges; combined and sanitary sewer overflows; septic systems; abandoned, injection, and production wells; animal waste from livestock, pets, and wildlife; agricultural, commercial, and residential use of fertilizers and pesticides; mining and oil and gas extraction; and solid waste and hazardous waste disposal sites (including Superfund sites). A wide variety of technical and managerial SWP practices are available for use, including management practices for point and nonpoint pollution sources; stormwater management; wastewater treatment plant upgrades and maintenance; rules and assistance for maintaining septic systems; agricultural management practices, incentives, and land stewardship programs; erosion and sediment control for construction projects; land-use controls; source water monitoring (including early warning monitoring and chemical and microbial pollutant source tracking); and watershed protection, management, and stewardship programs. SWP is a highly site-specific and place-based process. Different water sources may require widely different approaches. For example, vastly different SWP programs would be appropriate for pristine mountain streams, the lower reaches of highly developed rivers, and groundwater supplies. Even similar types of water supplies may require different program components as a result of the differing natures of their watersheds, accompanying land uses, and potential contaminant sources. Therefore, a general framework for the development and implementation of SWP programs, as opposed to contaminant-specific guidance and ratings, is the most appropriate approach for utilities to address their unique SWP issues. Within this generic bottom-up framework, specific SWP programs must account for local conditions, incorporate diverse stakeholder interests, require commitment to the SWP process by all involved parties, and be sustainable over the long term. Six main elements (or steps) comprise the process of developing and implementing a successful SWP program at the water utility level and the SWP standard is based on these steps. Although each of the six primary steps may differ greatly in terms of complexity or effort, they are each vital to the success of every SWP program. Accordingly, basic success in each area must be demonstrated in order for a utility to meet the criteria of ANSI/AWWA Standard G300, Source Water Protection. The primary objectives and components of each of the six elements of successful SWP programs are discussed briefly below. SWP Vision - A formalized vision guides the development and implementation of a SWP program. The vision may be articulated in a mission statement or policy of the governing body of the utility and is a statement of the utility's commitment to SWP. This written vision helps to align priorities and resources for the SWP program. Source Water Characterization - This is the information collection and analysis phase of SWP programs. Characterization and assessment of the source water and the land or subsurface area from which the source water is derived is essential for obtaining the understanding and knowledge needed to develop the goals and plans and implement the actions that will realize the SWP vision. (Note: For many water systems, states and USEPA have already conducted an initial source water assessment that can be used as a starting point for further characterization.) Using that information, a risk assessment or usceptibility analysis is conducted to identify and prioritize the key water quality and SWP issues and contamination sources. Program Goals - Goals and objectives need to be formulated to guide the SWP program and its specific elements. The goals should be targets developed in response to specific problem areas identified through the source water and SWP area characterization and risk assessment processes, and they should address each of the drivers motivating the SWP program, including the SWP vision. Goals may address both current and potential future issues. The goals should be prioritized to reflect the concerns of greatest importance and ideally should specify temporal and qualitative and/or quantitative dimensions (e.g., specific timelines and measurable goals). Both internal and external stakeholders should be involved in the development of the goals. Action Plan - The action plan lays out a road map of activities to be conducted to achieve the desired watershed protection goals based on the vision, source water area characterization, and susceptibility analysis. The plan identifies required actions (regulations, agreements, practices, etc.) to mitigate existing and future threats to source water quality, develops priorities for implementation, and includes a timetable for implementation, identification of necessary resources and means for obtaining those resources (e.g., funding), and metrics for measuring success of each component of the plan. 2011 © American Water Works Association.},
  isbn = {978-1-61839-160-5}
}

@inproceedings{shamAWWAG300Standard2011a,
  title = {{{AWWA G300}} Standard: {{Steps}} to Protect Source Water},
  booktitle = {American {{Water Works Association Annual Conference}} and {{Exposition}} 2011, {{ACE}} 2011},
  author = {Sham, C.H. and Long, S.C. and Gullick, R.W.},
  date = {2011},
  pages = {1185--1207},
  abstract = {One of the main goals of the American Water Works Association (AWWA) is to support water utilities in evaluating and improving their water quality, operations, maintenance, and infrastructure. Several different programs and types of publications are used to support this mission. One key program is the AWWA standards process, which has existed more than 100 years to produce peer-reviewed standards for materials and processes used by the water and wastewater utility industries. These standards, which are American National Standards Institute (ANSI) approved, are recognized worldwide and have been adopted by many utilities and organizations. The AWWA standards program is designed to assist water and wastewater utilities and their service providers to meet expectations of their customers, investors, and government regulators. The standards developed under the program are generally intended to improve a utility's overall operations and service. AWWA has developed a new series of utility management standards for water and wastewater utilities in the past decade. The Utility Management Standards program provides a means to assess service quality and management efficiency based on recognized standards for best available practices. Through establishment of standards and formal recognition by professional organizations, the program will serve water and wastewater utilities by promoting improvements in the quality of services and efficient management. The utility management standards address the widespread need of utility managers to have some consistency and reliability in knowing what is generally expected in the management and operation of utilities. These standards are also valuable resources in light of the many issues facing utilities, including increased scrutiny on accountability, increased regulation, and difficult economic realities such as aging infrastructure, changing demand for water, and a shrinking workforce. The utility management standards (also known as the G Series) are designed to cover the principal activities of a typical water and/or wastewater utility. Some examples include standards for distribution systems operations and management (G200), source water protection (G300), utility management systems (G400), security practices (G430). Other standards under development include business practices, emergency planning, and communication and customer relations. Additional topics will be added over time, including ones specifically relevant to wastewater utilities. The utility management standards are developed using the same formal, ANSI-recognized, AWWA-managed process. Volunteer standards committees establish standard practices in a uniform and appropriate format. Formal standards committees are formed to address the individual standards practices for the diverse areas of water and wastewater utility operations. ANSI/AWWA Standard G300, Source Water Protection, provides the definitive standard for a drinking water utility to protect its drinking water supply source(s). AWWA G300 became effective on July 1, 2007, and outlines the six primary components of successful SWP programs and the requirements for meeting the standard (AWWA 2007). The primary objectives of Source Water Protection (SWP) programs are to maintain, safeguard, and/or improve the quality of a given source water. Numerous benefits may be achieved because of these aims, and each may be considered as incentives or drivers for a utility to develop and implement SWP activities. The potential incentives include greater public health protection by ensuring higher quality raw water, especially for sensitive subpopulations. In addition to reduced illnesses and mortalities, public health protection can provide economic benefits in terms of reduced health care costs and reduced loss of productivity and work time; providing a way to respond to uncertainties presented by the growing number of unknown or unregulated microbiological and chemical contaminants (i.e., preventing contamination that treatment may not remove); avoiding costs of treating, monitoring, and remediating contamination; and greater likelihood of complying with existing and future drinking water regulations. A clear and important aspect of this premise is that pollution prevention is greatly preferable to remediating or treating contaminated source water. SWP programs should provide a means to assess and prevent future contamination, and should not just emphasize reducing current contamination. To minimize impacts from chemical, microbiological, and radiological contaminants, some pollutant sources that SWP programs should address include stormwater runoff from natural events containing contaminants such as microorganisms, nutrients, heavy metals, organic chemicals, and sediment; treated and untreated municipal and industrial wastewater discharges; combined and sanitary sewer overflows; septic systems; abandoned, injection, and production wells; animal waste from livestock, pets, and wildlife; agricultural, commercial, and residential use of fertilizers and pesticides; mining and oil and gas extraction; and solid waste and hazardous waste disposal sites (including Superfund sites). A wide variety of technical and managerial SWP practices are available for use, including management practices for point and nonpoint pollution sources; stormwater management; wastewater treatment plant upgrades and maintenance; rules and assistance for maintaining septic systems; agricultural management practices, incentives, and land stewardship programs; erosion and sediment control for construction projects; land-use controls; source water monitoring (including early warning monitoring and chemical and microbial pollutant source tracking); and watershed protection, management, and stewardship programs. SWP is a highly site-specific and place-based process. Different water sources may require widely different approaches. For example, vastly different SWP programs would be appropriate for pristine mountain streams, the lower reaches of highly developed rivers, and groundwater supplies. Even similar types of water supplies may require different program components as a result of the differing natures of their watersheds, accompanying land uses, and potential contaminant sources. Therefore, a general framework for the development and implementation of SWP programs, as opposed to contaminant-specific guidance and ratings, is the most appropriate approach for utilities to address their unique SWP issues. Within this generic bottom-up framework, specific SWP programs must account for local conditions, incorporate diverse stakeholder interests, require commitment to the SWP process by all involved parties, and be sustainable over the long term. Six main elements (or steps) comprise the process of developing and implementing a successful SWP program at the water utility level and the SWP standard is based on these steps. Although each of the six primary steps may differ greatly in terms of complexity or effort, they are each vital to the success of every SWP program. Accordingly, basic success in each area must be demonstrated in order for a utility to meet the criteria of ANSI/AWWA Standard G300, Source Water Protection. The primary objectives and components of each of the six elements of successful SWP programs are discussed briefly below. SWP Vision - A formalized vision guides the development and implementation of a SWP program. The vision may be articulated in a mission statement or policy of the governing body of the utility and is a statement of the utility's commitment to SWP. This written vision helps to align priorities and resources for the SWP program. Source Water Characterization - This is the information collection and analysis phase of SWP programs. Characterization and assessment of the source water and the land or subsurface area from which the source water is derived is essential for obtaining the understanding and knowledge needed to develop the goals and plans and implement the actions that will realize the SWP vision. (Note: For many water systems, states and USEPA have already conducted an initial source water assessment that can be used as a starting point for further characterization.) Using that information, a risk assessment or usceptibility analysis is conducted to identify and prioritize the key water quality and SWP issues and contamination sources. Program Goals - Goals and objectives need to be formulated to guide the SWP program and its specific elements. The goals should be targets developed in response to specific problem areas identified through the source water and SWP area characterization and risk assessment processes, and they should address each of the drivers motivating the SWP program, including the SWP vision. Goals may address both current and potential future issues. The goals should be prioritized to reflect the concerns of greatest importance and ideally should specify temporal and qualitative and/or quantitative dimensions (e.g., specific timelines and measurable goals). Both internal and external stakeholders should be involved in the development of the goals. Action Plan - The action plan lays out a road map of activities to be conducted to achieve the desired watershed protection goals based on the vision, source water area characterization, and susceptibility analysis. The plan identifies required actions (regulations, agreements, practices, etc.) to mitigate existing and future threats to source water quality, develops priorities for implementation, and includes a timetable for implementation, identification of necessary resources and means for obtaining those resources (e.g., funding), and metrics for measuring success of each component of the plan. 2011 © American Water Works Association.},
  isbn = {978-1-61839-160-5}
}

@article{sherafatAutomatedMethodsActivity2020,
  title = {Automated {{Methods}} for {{Activity Recognition}} of {{Construction Workers}} and {{Equipment}}: {{State-of-the-Art Review}}},
  author = {Sherafat, B. and Ahn, C. R. and Akhavian, R. and Behzadan, A. H. and Golparvar-Fard, M. and Kim, H. and Lee, Y.-C. and Rashidi, A. and Azar, E. R.},
  date = {2020},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {146},
  number = {6},
  doi = {10.1061/(ASCE)CO.1943-7862.0001843},
  abstract = {Equipment and workers are two important resources in the construction industry. Performance monitoring of these resources would help project managers improve the productivity rates of construction jobsites and discover potential performance issues. A typical construction workface monitoring system consists of four major levels: location tracking, activity recognition, activity tracking, and performance monitoring. These levels are employed to evaluate work sequences over time and also assess the workers' and equipment's well-being and abnormal edge cases. Results of an automated performance monitoring system could be used to employ preventive measures to minimize operating/repair costs and downtimes. The authors of this paper have studied the feasibility of implementing a wide range of technologies and computational techniques for automated activity recognition and tracking of construction equipment and workers. This paper provides a comprehensive review of these methods and techniques as well as describes their advantages, practical value, and limitations. Additionally, a multifaceted comparison between these methods is presented, and potential knowledge gaps and future research directions are discussed.}
}

@article{sherafatAutomatedMethodsActivity2020a,
  title = {Automated {{Methods}} for {{Activity Recognition}} of {{Construction Workers}} and {{Equipment}}: {{State-of-the-Art Review}}},
  author = {Sherafat, B. and Ahn, C.R. and Akhavian, R. and Behzadan, A.H. and Golparvar-Fard, M. and Kim, H. and Lee, Y.-C. and Rashidi, A. and Azar, E.R.},
  date = {2020},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {146},
  number = {6},
  doi = {10.1061/(ASCE)CO.1943-7862.0001843},
  abstract = {Equipment and workers are two important resources in the construction industry. Performance monitoring of these resources would help project managers improve the productivity rates of construction jobsites and discover potential performance issues. A typical construction workface monitoring system consists of four major levels: location tracking, activity recognition, activity tracking, and performance monitoring. These levels are employed to evaluate work sequences over time and also assess the workers' and equipment's well-being and abnormal edge cases. Results of an automated performance monitoring system could be used to employ preventive measures to minimize operating/repair costs and downtimes. The authors of this paper have studied the feasibility of implementing a wide range of technologies and computational techniques for automated activity recognition and tracking of construction equipment and workers. This paper provides a comprehensive review of these methods and techniques as well as describes their advantages, practical value, and limitations. Additionally, a multifaceted comparison between these methods is presented, and potential knowledge gaps and future research directions are discussed.}
}

@article{Shi201324,
  title = {A Model of Distributional Handing Interaction for a Mobile Robot},
  author = {Shi, C. and Shiomi, M. and Smith, C. and Kanda, T. and Ishiguro, H.},
  date = {2013},
  journaltitle = {Robotics: Science and Systems},
  pages = {24--28}
}

@article{shiDidacticPedagogicalApproach2020,
  title = {A Didactic Pedagogical Approach toward Sustainable Architectural Education through Robotic Tectonics},
  author = {Shi, X. and Fang, X. and Chen, Z. and Phillips, T.K. and Fukuda, H.},
  date = {2020},
  journaltitle = {Sustainability (Switzerland)},
  volume = {12},
  number = {5},
  doi = {10.3390/su12051757},
  abstract = {Robotic tectonics have been integrated into the architectural profession through automated construction for more than a decade, advancing sustainability initiatives in the industry and increasing the quality of building construction. Over the years, avant-garde architects have explored the feasibility of this new design paradigm through the integration of newly-developed digital design software into automated construction. This robotic digital workflow continues to push designers to re-think the complete architecture process (from design conception to physical construction) and guides the building industry towards more precise, efficient, and sustainable development. However, in the current environment of architectural education, professional courses can be fragmented, thematic, and overly academic. Such content is not inherently compatible with the latest technological developments. The lack of understanding and application of digital technological can subsequently lead to the lack of sustainable development in architectural education. In this paper, we aim to introduce a new didactic pedagogical approach that is reliant on the principles of robotic tectonics and is defined through linear development in four distinct, developmental stages (based on information gleaned from four "Robotic Tectonics" workshops and various other rich teaching practices). This pedagogical framework provides interdisciplinary knowledge to architecture students and enables them to use advanced digital tools such as robots for automated construction, laying the groundwork for the discovery of new and complex building processes that will redefine architecture in the near future.}
}

@article{shiDidacticPedagogicalApproach2020a,
  title = {A Didactic Pedagogical Approach toward Sustainable Architectural Education through Robotic Tectonics},
  author = {Shi, X. and Fang, X. and Chen, Z. and Phillips, T.K. and Fukuda, H.},
  date = {2020},
  journaltitle = {Sustainability (Switzerland)},
  volume = {12},
  number = {5},
  doi = {10.3390/su12051757},
  abstract = {Robotic tectonics have been integrated into the architectural profession through automated construction for more than a decade, advancing sustainability initiatives in the industry and increasing the quality of building construction. Over the years, avant-garde architects have explored the feasibility of this new design paradigm through the integration of newly-developed digital design software into automated construction. This robotic digital workflow continues to push designers to re-think the complete architecture process (from design conception to physical construction) and guides the building industry towards more precise, efficient, and sustainable development. However, in the current environment of architectural education, professional courses can be fragmented, thematic, and overly academic. Such content is not inherently compatible with the latest technological developments. The lack of understanding and application of digital technological can subsequently lead to the lack of sustainable development in architectural education. In this paper, we aim to introduce a new didactic pedagogical approach that is reliant on the principles of robotic tectonics and is defined through linear development in four distinct, developmental stages (based on information gleaned from four "Robotic Tectonics" workshops and various other rich teaching practices). This pedagogical framework provides interdisciplinary knowledge to architecture students and enables them to use advanced digital tools such as robots for automated construction, laying the groundwork for the discovery of new and complex building processes that will redefine architecture in the near future.}
}

@inproceedings{shinSeismicDesignMethod2016,
  title = {Seismic Design Method for {{HanOk}} Considering Joint Lateral Rigidity Using {{BIM}}},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Shin, S. and Lee, B. and Yoon, J.},
  date = {2016},
  abstract = {The purpose of this study is to develop a seismic capacity evaluation technique for traditional wooden structures in Korea (HanOk). The shape information is derived from a BIM design procedure. The joint stiffness DB for the lateral direction of a HanOk is determined from the test results of 1/5 scale model building. A modified DDD method to build a HanOk, based on a seismic design procedure of the NEESWood report, is proposed.},
  isbn = {978-3-903039-00-1}
}

@inproceedings{shinSeismicDesignMethod2016a,
  title = {Seismic Design Method for {{HanOk}} Considering Joint Lateral Rigidity Using {{BIM}}},
  booktitle = {{{WCTE}} 2016 - {{World Conference}} on {{Timber Engineering}}},
  author = {Shin, S. and Lee, B. and Yoon, J.},
  date = {2016},
  abstract = {The purpose of this study is to develop a seismic capacity evaluation technique for traditional wooden structures in Korea (HanOk). The shape information is derived from a BIM design procedure. The joint stiffness DB for the lateral direction of a HanOk is determined from the test results of 1/5 scale model building. A modified DDD method to build a HanOk, based on a seismic design procedure of the NEESWood report, is proposed.},
  isbn = {978-3-903039-00-1}
}

@article{shochiAnalyticalStudyVisualmotor1971,
  title = {An Analytical Study of Visual-Motor Function in Cerebral Palsied Children},
  author = {Shochi, K.},
  date = {1971},
  journaltitle = {The Japanese journal of psychology},
  volume = {42},
  number = {2},
  pages = {55--66},
  doi = {10.4992/jjpsy.42.55},
  abstract = {The purpose of the present study was to examine the characteristic relationship between recognition and reconstruction in the visualmotor function of cerebral palsied children. Three experiments were conducted, in which their performance in a block design test was observed. The block design test consisted of seven designs which where devised according to the stability of the frame (square, diamond, and cross) and the symmetricity of the figure. Exp. I Subjects were a group of cerebral palsied children and a control group of normal children. Performance of Ss in the tasks which required recongnition of block designs and these which required the ability to reconstruct block designs was compared between two groups. Exp. II Performance in the block design test of cerebral palsied children and of normal children was examined to find how the back-ground condition affected their construction. Exp. III Individual performance and its relation to the conditions of the tests which were administered after Ss completed the block design tests, were evaluated. The results obtained in the experiments were as follows: (1) There was no difference in the ability to compare and recognize similar block designs between the cerebral palsied children and the normal children, but the ability to reconstruct block designs by the cerebral palsied children was significantly inferior to that of the normal children. (p{$<$}.01) (2) There was no inter-relationship between the function of recognition and the degree of motor handicap. The ability to reconstruct block design patterns was influenced by the degree of the severity of their handicap. (3) The designs of the square in which the designs (colored parts and white parts) were symmetrical were difficult for cerebral palsied children to reconstruct. But, the design of the cross was comparatively easy for cerebral palsied children to reconstruct. (4) The designs which were unstable and asymmetrical were not easy for cerebral palsied children to recognize. (5) The cerebral palsied children, in their reconstruction of global patterns, responded only to the colored parts of the designs. In the translative pattern they tried to transfer the model to the conductive one. (6) Cerebral palsied children were disturbed by the background condition and could not make constructive use of it when they reconstructed the designs. (7) The background condition which consisted of color and lines or of only color made the reconstruction easy for cerebral palsied children. (8) The tests which were divided vertically into two parts, the tests which had 2/4 clue of the design, and the tests which had 1/4 clue having many blockings were difficult to reconstruct for cerebral palsied children. To summerize, in discussing the visualmotor function of cerebral palsied children, a distinction should be drawn between their performance on the tests which reveal their difficuly of recognition, and their performance on the tests which reveal their difficulty of reconstruction. © 1971, The Japanese Psychological Association. All rights reserved.}
}

@article{shochiAnalyticalStudyVisualmotor1971a,
  title = {An Analytical Study of Visual-Motor Function in Cerebral Palsied Children},
  author = {Shochi, K.},
  date = {1971},
  journaltitle = {The Japanese journal of psychology},
  volume = {42},
  number = {2},
  pages = {55--66},
  doi = {10.4992/jjpsy.42.55},
  abstract = {The purpose of the present study was to examine the characteristic relationship between recognition and reconstruction in the visualmotor function of cerebral palsied children. Three experiments were conducted, in which their performance in a block design test was observed. The block design test consisted of seven designs which where devised according to the stability of the frame (square, diamond, and cross) and the symmetricity of the figure. Exp. I Subjects were a group of cerebral palsied children and a control group of normal children. Performance of Ss in the tasks which required recongnition of block designs and these which required the ability to reconstruct block designs was compared between two groups. Exp. II Performance in the block design test of cerebral palsied children and of normal children was examined to find how the back-ground condition affected their construction. Exp. III Individual performance and its relation to the conditions of the tests which were administered after Ss completed the block design tests, were evaluated. The results obtained in the experiments were as follows: (1) There was no difference in the ability to compare and recognize similar block designs between the cerebral palsied children and the normal children, but the ability to reconstruct block designs by the cerebral palsied children was significantly inferior to that of the normal children. (p{$<$}.01) (2) There was no inter-relationship between the function of recognition and the degree of motor handicap. The ability to reconstruct block design patterns was influenced by the degree of the severity of their handicap. (3) The designs of the square in which the designs (colored parts and white parts) were symmetrical were difficult for cerebral palsied children to reconstruct. But, the design of the cross was comparatively easy for cerebral palsied children to reconstruct. (4) The designs which were unstable and asymmetrical were not easy for cerebral palsied children to recognize. (5) The cerebral palsied children, in their reconstruction of global patterns, responded only to the colored parts of the designs. In the translative pattern they tried to transfer the model to the conductive one. (6) Cerebral palsied children were disturbed by the background condition and could not make constructive use of it when they reconstructed the designs. (7) The background condition which consisted of color and lines or of only color made the reconstruction easy for cerebral palsied children. (8) The tests which were divided vertically into two parts, the tests which had 2/4 clue of the design, and the tests which had 1/4 clue having many blockings were difficult to reconstruct for cerebral palsied children. To summerize, in discussing the visualmotor function of cerebral palsied children, a distinction should be drawn between their performance on the tests which reveal their difficuly of recognition, and their performance on the tests which reveal their difficulty of reconstruction. © 1971, The Japanese Psychological Association. All rights reserved.}
}

@article{simoesDesigningHumanrobotCollaboration2022,
  title = {Designing Human-Robot Collaboration ({{HRC}}) Workspaces in Industrial Settings: {{A}} Systemic Literature Review},
  author = {Simões, Ana Correia and Pinto, Ana and Santos, Joana and Pinheiro, Sofia and Romero, David},
  date = {2022},
  journaltitle = {Journal of Manufacturing Systems},
  volume = {62},
  pages = {28--43},
  issn = {02786125},
  doi = {10.1016/j.jmsy.2021.11.007},
  abstract = {In the pursuit of increasing efficiency, productivity and flexibility at production lines and their corresponding workstations, manufacturing companies have started to heavily invest in “collaborative workspaces” where close interaction between humans and robots promises to lead to these goals that neither can achieve on their own. Therefore, it is necessary to know the contributions, recommendations and guidelines that literature presents in terms of designing a manufacturing workplace where humans and cobots interact with each other to accomplish the defined objectives. These aspects need to be explored in an integrated and multidisciplinary way to maximize human involvement in the decision chain and to promote wellbeing and quality of work. This paper presents a systematic literature review on designing human-robot collaboration (HRC) workspaces for humans and robots in industrial settings. The study involved 252 articles in international journals and conferences proceedings published till 2019. A detailed selection process led to including 65 articles to further analysis. A framework that represents the complexity levels of the influencing factors presented in human-robot interaction (HRI) contexts was developed for the content analysis. Based on this framework the guidelines and recommendations of the analysed articles are presented in three categories: Category 1 – the first level of complexity, which considers only one specific influencing factor in the HRI. This category was split into two: human operator, and technology; Category 2 – the second level of complexity, includes recommendations and guidelines related to human-robot team's performance, and thus several influencing factors are present in the HRI; and, finally, Category 3 – the third level of complexity, where recommendations and guidelines for more complex and holistic approaches in the HRI are presented. The literature offers contributions from several knowledge areas capable to design safe, ergonomic, sustainable, and healthy human-centred workplaces where not only technical but also social and psychophysical aspects of collaboration are considered.},
  issue = {November 2021},
  keywords = {Collaborative robots (cobots),Ergonomics,Human factors,Human-centred automation,Human-robot interaction (HRI)}
}

@article{simoesDesigningHumanrobotCollaboration2022a,
  title = {Designing Human-Robot Collaboration ({{HRC}}) Workspaces in Industrial Settings: {{A}} Systemic Literature Review},
  author = {Simões, Ana Correia and Pinto, Ana and Santos, Joana and Pinheiro, Sofia and Romero, David},
  date = {2022},
  journaltitle = {Journal of Manufacturing Systems},
  volume = {62},
  pages = {28--43},
  issn = {02786125},
  doi = {10.1016/j.jmsy.2021.11.007},
  abstract = {In the pursuit of increasing efficiency, productivity and flexibility at production lines and their corresponding workstations, manufacturing companies have started to heavily invest in “collaborative workspaces” where close interaction between humans and robots promises to lead to these goals that neither can achieve on their own. Therefore, it is necessary to know the contributions, recommendations and guidelines that literature presents in terms of designing a manufacturing workplace where humans and cobots interact with each other to accomplish the defined objectives. These aspects need to be explored in an integrated and multidisciplinary way to maximize human involvement in the decision chain and to promote wellbeing and quality of work. This paper presents a systematic literature review on designing human-robot collaboration (HRC) workspaces for humans and robots in industrial settings. The study involved 252 articles in international journals and conferences proceedings published till 2019. A detailed selection process led to including 65 articles to further analysis. A framework that represents the complexity levels of the influencing factors presented in human-robot interaction (HRI) contexts was developed for the content analysis. Based on this framework the guidelines and recommendations of the analysed articles are presented in three categories: Category 1 – the first level of complexity, which considers only one specific influencing factor in the HRI. This category was split into two: human operator, and technology; Category 2 – the second level of complexity, includes recommendations and guidelines related to human-robot team's performance, and thus several influencing factors are present in the HRI; and, finally, Category 3 – the third level of complexity, where recommendations and guidelines for more complex and holistic approaches in the HRI are presented. The literature offers contributions from several knowledge areas capable to design safe, ergonomic, sustainable, and healthy human-centred workplaces where not only technical but also social and psychophysical aspects of collaboration are considered.},
  issue = {November 2021},
  keywords = {Collaborative robots (cobots),Ergonomics,Human factors,Human-centred automation,Human-robot interaction (HRI)},
  file = {C:\Users\leemar\Zotero\storage\AK72YAM4\ManuscriptRG.pdf}
}

@article{singhOptimized3DLaser2020,
  title = {Optimized {{3D}} Laser Point Cloud Reconstruction by Gradient Descent Technique},
  author = {Singh, R. and Khurana, A. and Kumar, S.},
  date = {2020},
  journaltitle = {Industrial Robot},
  volume = {47},
  number = {3},
  pages = {409--421},
  doi = {10.1108/IR-12-2019-0244},
  abstract = {Purpose: This study aims to develop an optimized 3D laser point reconstruction using Descent Gradient algorithm. Precise and accurate reconstruction of 3D laser point cloud of the complex environment/object is a key solution for many industries such as construction, gaming, automobiles, aerial navigation, architecture and automation. A 2D laser scanner along with a servo motor/pan tilt/inertial measurement unit is used for generating 3D point cloud (either environment/object or both) by acquiring the real-time data from sensors. However, while generating the 3D laser point cloud, various problems related to time synchronization problem between laser and servomotor and torque variation in servomotors arise, which causes misalignment in stacking the 2D laser scan for generating the 3D point cloud of the environment. Because of the misalignment in stacking, the 2D laser scan corresponding to the erroneous angular and position information by the servomotor and the 3D laser point cloud become distorted in terms of inconsistency for measuring the dimension of the objects. Design/methodology/approach: This paper addresses a modified 3D laser system assembled from a 2D laser scanner coupled with a servomotor (dynamixel motor) for developing an efficient 3D laser point cloud with the implementation of an optimization technique: descent gradient filter (DGT). The proposed approach reduces the cost function (error) in the angular and position coordinates of the servo motor caused because of torque variation and time synchronization, which resulted in enhancing the accuracy in 3D point cloud mapping for the accurate measurement of the object’s dimensions. Findings: Various real-world experiments are performed with the proposed DGT filter linked with laser scanner and servomotor and an improvement of 6.5 per cent in measuring the accurate dimension of object is obtained while comparing with conventional approaches for generating a 3D laser point cloud. Originality/value: This proposed technique may be applicable for various industrial applications that are based on robotics arms (such as painting, welding and cutting) in the automobile industry, the optimized measurement of object, efficient mobile robot navigation, precise 3D reconstruction of environment/object in construction, architecture applications, airborne applications and aerial navigation.}
}

@article{singhOptimized3DLaser2020a,
  title = {Optimized {{3D}} Laser Point Cloud Reconstruction by Gradient Descent Technique},
  author = {Singh, R. and Khurana, A. and Kumar, S.},
  date = {2020},
  journaltitle = {Industrial Robot},
  volume = {47},
  number = {3},
  pages = {409--421},
  doi = {10.1108/IR-12-2019-0244},
  abstract = {Purpose: This study aims to develop an optimized 3D laser point reconstruction using Descent Gradient algorithm. Precise and accurate reconstruction of 3D laser point cloud of the complex environment/object is a key solution for many industries such as construction, gaming, automobiles, aerial navigation, architecture and automation. A 2D laser scanner along with a servo motor/pan tilt/inertial measurement unit is used for generating 3D point cloud (either environment/object or both) by acquiring the real-time data from sensors. However, while generating the 3D laser point cloud, various problems related to time synchronization problem between laser and servomotor and torque variation in servomotors arise, which causes misalignment in stacking the 2D laser scan for generating the 3D point cloud of the environment. Because of the misalignment in stacking, the 2D laser scan corresponding to the erroneous angular and position information by the servomotor and the 3D laser point cloud become distorted in terms of inconsistency for measuring the dimension of the objects. Design/methodology/approach: This paper addresses a modified 3D laser system assembled from a 2D laser scanner coupled with a servomotor (dynamixel motor) for developing an efficient 3D laser point cloud with the implementation of an optimization technique: descent gradient filter (DGT). The proposed approach reduces the cost function (error) in the angular and position coordinates of the servo motor caused because of torque variation and time synchronization, which resulted in enhancing the accuracy in 3D point cloud mapping for the accurate measurement of the object’s dimensions. Findings: Various real-world experiments are performed with the proposed DGT filter linked with laser scanner and servomotor and an improvement of 6.5 per cent in measuring the accurate dimension of object is obtained while comparing with conventional approaches for generating a 3D laser point cloud. Originality/value: This proposed technique may be applicable for various industrial applications that are based on robotics arms (such as painting, welding and cutting) in the automobile industry, the optimized measurement of object, efficient mobile robot navigation, precise 3D reconstruction of environment/object in construction, architecture applications, airborne applications and aerial navigation.}
}

@inproceedings{singhRepairRetrofittingBridges2018,
  title = {Repair and Retrofitting of Bridges – Present and Future},
  booktitle = {Maintenance, {{Safety}}, {{Risk}}, {{Management}} and {{Life-Cycle Performance}} of {{Bridges}} - {{Proceedings}} of the 9th {{International Conference}} on {{Bridge Maintenance}}, {{Safety}} and {{Management}}, {{IABMAS}} 2018},
  author = {Singh, H.},
  date = {2018},
  pages = {1209--1215},
  abstract = {Bridges are being constructed around the world and are increasing the number of assets to be maintained in the future. Since the Roman Empire to Victorian Era, the bridges are being constructed of timber, stone, masonry to the modern era of constructing the bridge with Glass-Fiber Reinforced Plastic materials. From stone masonry to concrete and steel, the bridge of each material type has different durability level, maintenance issues, repair and retrofitting requirements. The modern bridges being constructed are more durable and lower life cycle cost. Now the focus is more on the environmental aggressivity in which the structure is being constructed and take adequate preventive measures at the design stage. The old structures before the 1980s have a lot of repair and retrofitting requirements. With the increasing load of traffic and the requirement to accommodate more number of lanes per bridge, it is a challenge for bridge engineers to check the structure to the lowest factor of safety, thus avoiding the widening of bridges in some cases and contributing to the long-term sustainability. To overcome the challenges for the optimum use of bridges, the paper suggests the way forward for inspection, monitoring and asset management. With the BIM becoming more popular, it has also discussed about the requirement of single database of bridge assets where all the inspections, current and new assets information can be centrally located. The requirements for the assessment and repair of structures is discussed and the way forward for 3D printing for repair of concrete bridges. The paper also discusses about the various standards available for bridge maintenance in different countries. In the end, the critical discussion is presented about the future of bridges and repair requirements and the latest materials available to explore for use in structures to avoid major repair and maintenance in the future.},
  isbn = {978-1-138-73045-8}
}

@inproceedings{singhRepairRetrofittingBridges2018a,
  title = {Repair and Retrofitting of Bridges – Present and Future},
  booktitle = {Maintenance, {{Safety}}, {{Risk}}, {{Management}} and {{Life-Cycle Performance}} of {{Bridges}} - {{Proceedings}} of the 9th {{International Conference}} on {{Bridge Maintenance}}, {{Safety}} and {{Management}}, {{IABMAS}} 2018},
  author = {Singh, H.},
  date = {2018},
  pages = {1209--1215},
  abstract = {Bridges are being constructed around the world and are increasing the number of assets to be maintained in the future. Since the Roman Empire to Victorian Era, the bridges are being constructed of timber, stone, masonry to the modern era of constructing the bridge with Glass-Fiber Reinforced Plastic materials. From stone masonry to concrete and steel, the bridge of each material type has different durability level, maintenance issues, repair and retrofitting requirements. The modern bridges being constructed are more durable and lower life cycle cost. Now the focus is more on the environmental aggressivity in which the structure is being constructed and take adequate preventive measures at the design stage. The old structures before the 1980s have a lot of repair and retrofitting requirements. With the increasing load of traffic and the requirement to accommodate more number of lanes per bridge, it is a challenge for bridge engineers to check the structure to the lowest factor of safety, thus avoiding the widening of bridges in some cases and contributing to the long-term sustainability. To overcome the challenges for the optimum use of bridges, the paper suggests the way forward for inspection, monitoring and asset management. With the BIM becoming more popular, it has also discussed about the requirement of single database of bridge assets where all the inspections, current and new assets information can be centrally located. The requirements for the assessment and repair of structures is discussed and the way forward for 3D printing for repair of concrete bridges. The paper also discusses about the various standards available for bridge maintenance in different countries. In the end, the critical discussion is presented about the future of bridges and repair requirements and the latest materials available to explore for use in structures to avoid major repair and maintenance in the future.},
  isbn = {978-1-138-73045-8}
}

@inproceedings{sirintunaDetectingHumanMotion2020,
  title = {Detecting {{Human Motion Intention}} during {{pHRI Using Artificial Neural Networks Trained}} by {{EMG Signals}}},
  booktitle = {29th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}}, {{RO-MAN}} 2020},
  author = {Sirintuna, D. and Ozdamar, I. and Aydin, Y. and Basdogan, C.},
  date = {2020},
  pages = {1280--1287},
  doi = {10.1109/RO-MAN47096.2020.9223438},
  abstract = {With the recent advances in cobot (collaborative robot) technology, we can now work with a robot side by side in manufacturing environments. The collaboration between human and cobot can be enhanced by detecting the intentions of human to make the production more flexible and effective in future factories. In this regard, interpreting human intention and then adjusting the controller of cobot accordingly to assist human is a core challenge in physical human-robot interaction (pHRI). In this study, we propose a classifier based on Artificial Neural Networks (ANN) that predicts intended direction of human movement by utilizing electromyography (EMG) signals acquired from human arm muscles. We employ this classifier in an admittance control architecture to constrain human arm motion to the intended direction and prevent undesired movements along other directions. The proposed classifier and the control architecture have been validated through a path following task by utilizing a KUKA LBR iiwa 7 R800 cobot. The results of our experimental study with 6 participants show that the proposed architecture provides an effective assistance to human during the execution of task and reduces undesired motion errors, while not sacrificing from the task completion time.},
  isbn = {978-1-72816-075-7}
}

@inproceedings{sirintunaDetectingHumanMotion2020a,
  title = {Detecting {{Human Motion Intention}} during {{pHRI Using Artificial Neural Networks Trained}} by {{EMG Signals}}},
  booktitle = {29th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}}, {{RO-MAN}} 2020},
  author = {Sirintuna, D. and Ozdamar, I. and Aydin, Y. and Basdogan, C.},
  date = {2020},
  pages = {1280--1287},
  doi = {10.1109/RO-MAN47096.2020.9223438},
  abstract = {With the recent advances in cobot (collaborative robot) technology, we can now work with a robot side by side in manufacturing environments. The collaboration between human and cobot can be enhanced by detecting the intentions of human to make the production more flexible and effective in future factories. In this regard, interpreting human intention and then adjusting the controller of cobot accordingly to assist human is a core challenge in physical human-robot interaction (pHRI). In this study, we propose a classifier based on Artificial Neural Networks (ANN) that predicts intended direction of human movement by utilizing electromyography (EMG) signals acquired from human arm muscles. We employ this classifier in an admittance control architecture to constrain human arm motion to the intended direction and prevent undesired movements along other directions. The proposed classifier and the control architecture have been validated through a path following task by utilizing a KUKA LBR iiwa 7 R800 cobot. The results of our experimental study with 6 participants show that the proposed architecture provides an effective assistance to human during the execution of task and reduces undesired motion errors, while not sacrificing from the task completion time.},
  isbn = {978-1-72816-075-7}
}

@article{slatonConstructionActivityRecognition2020,
  title = {Construction Activity Recognition with Convolutional Recurrent Networks},
  author = {Slaton, Trevor and Hernandez, Carlos and Akhavian, Reza},
  date = {2020-05},
  journaltitle = {Automation in Construction},
  volume = {113},
  publisher = {{Elsevier B.V.}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2020.103138},
  abstract = {Although heavy equipment is an indispensable resource in many construction projects, it is often underutilized. Inefficient usage patterns and frequent idling contribute to increased emissions and project costs. Efforts to improve usage patterns often begin with activity tracking. Recent research into automated activity tracking has leveraged sensing devices and Internet-of-Things (IoT) frameworks to power machine learning models that can predict the behaviors of monitored equipment. However, shallow machine learning models require complex manual feature engineering that could be further automated with more recent deep learning approaches. Deep learning approaches not only increase automation but also promise improved accuracies by avoiding biases introduced by manual feature design. This paper proposes a construction equipment activity recognition framework that uses deep learning architectures to predict the activities of heavy construction equipment monitored via accelerometers and applies this framework to a roller compactor and an excavator performing real work. The performance of a simple baseline convolutional neural network (CNN) is compared to a hybrid network that contains both convolutional and recurrent long short-term memory (LSTM) layers. The hybrid model outperforms the baseline model in all instances studied. In the task of classifying the activities of the roller compactor, the hybrid model achieves a validation accuracy of 77.1\% when presented with six activities and a validation accuracy of 96.2\% when distinguishing only direction. In the task of classifying seven activities of the excavator, the hybrid model achieves a validation accuracy of 77.6\%, with some confusion between isolated activities and a Various category that includes elements of the isolated activities. With the Various category removed, the hybrid model achieves a validation accuracy of 90.7\%. This study demonstrates that deep learning frameworks can model the activities of construction equipment with high accuracy. In particular, this work shows that convolutional and LSTM layers can each form effective parts of deep learning models that characterize equipment activities based on accelerometer data, and furthermore that these components can produce more effective models when combined. The findings of this study can be leveraged by researchers and industry professionals to develop reliable automated activity recognition systems for tracking and monitoring equipment performance and for measuring the productivity and the efficiency of the work performed.}
}

@article{slatonConstructionActivityRecognition2020a,
  title = {Construction Activity Recognition with Convolutional Recurrent Networks},
  author = {Slaton, Trevor and Hernandez, Carlos and Akhavian, Reza},
  date = {2020-05-01},
  journaltitle = {Automation in Construction},
  volume = {113},
  publisher = {{Elsevier B.V.}},
  issn = {09265805},
  doi = {10.1016/j.autcon.2020.103138},
  abstract = {Although heavy equipment is an indispensable resource in many construction projects, it is often underutilized. Inefficient usage patterns and frequent idling contribute to increased emissions and project costs. Efforts to improve usage patterns often begin with activity tracking. Recent research into automated activity tracking has leveraged sensing devices and Internet-of-Things (IoT) frameworks to power machine learning models that can predict the behaviors of monitored equipment. However, shallow machine learning models require complex manual feature engineering that could be further automated with more recent deep learning approaches. Deep learning approaches not only increase automation but also promise improved accuracies by avoiding biases introduced by manual feature design. This paper proposes a construction equipment activity recognition framework that uses deep learning architectures to predict the activities of heavy construction equipment monitored via accelerometers and applies this framework to a roller compactor and an excavator performing real work. The performance of a simple baseline convolutional neural network (CNN) is compared to a hybrid network that contains both convolutional and recurrent long short-term memory (LSTM) layers. The hybrid model outperforms the baseline model in all instances studied. In the task of classifying the activities of the roller compactor, the hybrid model achieves a validation accuracy of 77.1\% when presented with six activities and a validation accuracy of 96.2\% when distinguishing only direction. In the task of classifying seven activities of the excavator, the hybrid model achieves a validation accuracy of 77.6\%, with some confusion between isolated activities and a Various category that includes elements of the isolated activities. With the Various category removed, the hybrid model achieves a validation accuracy of 90.7\%. This study demonstrates that deep learning frameworks can model the activities of construction equipment with high accuracy. In particular, this work shows that convolutional and LSTM layers can each form effective parts of deep learning models that characterize equipment activities based on accelerometer data, and furthermore that these components can produce more effective models when combined. The findings of this study can be leveraged by researchers and industry professionals to develop reliable automated activity recognition systems for tracking and monitoring equipment performance and for measuring the productivity and the efficiency of the work performed.},
  keywords = {★},
  file = {C:\Users\leemar\Zotero\storage\R2WM68ZJ\1-s2.0-S0926580519310234-main.pdf}
}

@article{Słowiński2016,
  title = {Dynamic Similarity Promotes Interpersonal Coordination in Joint Action},
  author = {Słowiński, P. and Zhai, C. and Alderisio, F. and Salesse, R. and Gueugnon, M. and Marin, L. and Bardy, B.G. and Di Bernardo, M. and Tsaneva-Atanasova, K.},
  date = {2016},
  journaltitle = {Journal of the Royal Society Interface},
  volume = {13},
  number = {116},
  doi = {10.1098/rsif.2015.1093},
  art_number = {20151093}
}

@article{slowinskiDynamicSimilarityPromotes2016,
  title = {Dynamic Similarity Promotes Interpersonal Coordination in Joint Action},
  author = {Słowiński, Piotr and Zhai, Chao and Alderisio, Francesco and Salesse, Robin and Gueugnon, Mathieu and Marin, Ludovic and Bardy, Benoit G. and family=Bernardo, given=Mario, prefix=di, useprefix=true and Tsaneva-Atanasova, Krasimira},
  date = {2016-03},
  journaltitle = {Journal of The Royal Society Interface},
  volume = {13},
  number = {116},
  pages = {20151093},
  issn = {1742-5689},
  doi = {10.1098/rsif.2015.1093},
  abstract = {{$<$}p{$>$}Human movement has been studied for decades, and dynamic laws of motion that are common to all humans have been derived. Yet, every individual moves differently from everyone else (faster/slower, harder/smoother, etc.). We propose here an index of such variability, namely an individual motor signature (IMS) able to capture the subtle differences in the way each of us moves. We show that the IMS of a person is time-invariant and that it significantly differs from those of other individuals. This allows us to quantify the dynamic similarity, a measure of rapport between dynamics of different individuals' movements, and demonstrate that it facilitates coordination during interaction. We use our measure to confirm a key prediction of the theory of similarity that coordination between two individuals performing a joint-action task is higher if their motions share similar dynamic features. Furthermore, we use a virtual avatar driven by an interactive cognitive architecture based on feedback control theory to explore the effects of different kinematic features of the avatar motion on coordination with human players.{$<$}/p{$>$}}
}

@article{smithSociallyAwareRobot2021,
  title = {Socially {{Aware Robot Obstacle Avoidance Considering Human Intention}} and {{Preferences}}},
  author = {Smith, T. and Chen, Y. and Hewitt, N. and Hu, B. and Gu, Y.},
  date = {2021},
  journaltitle = {International Journal of Social Robotics},
  doi = {10.1007/s12369-021-00795-5},
  abstract = {In order to navigate safely and effectively with humans in close proximity, robots must be capable of predicting the future motions of humans. This study first consolidates human studies in motion, intention, and preference into a discretized human model that can readily be used in robotics decision making algorithms. Cooperative Markov Decision Process (Co-MDP), a novel framework that improves upon Multiagent MDPs, is then proposed for enabling socially aware robot obstacle avoidance. Utilizing the consolidated and discretized human model, Co-MDP allows the system to (1) approximate rational human behavior and intention, (2) generate socially-aware robotic obstacle avoidance behavior, and (3) remain robust to the uncertainty of human intention and motion variance. Simulations of a human-robot co-populated environment verify Co-MDP as a feasible obstacle avoidance algorithm. In addition, the anthropomorphic behavior of Co-MDP was assessed and confirmed with a human-in-the-loop experiment. Results reveal that participants can not directly differentiate agents that were controlled by human operators from Co-MDP, and the reported confidences of their choices indicates that the predictions from participants were backed by behavioral evidence rather than random guesses. Thus the main contributions for this paper are: consolidating past human studies of rational human behavior and intention into a simple, discretized model; the development of Co-MDP: a robotic decision framework that can utilize this human model and maximize the joint utility between the human and robot; and an experimental design for evaluation of the human acceptance of obstacle avoidance algorithms.}
}

@article{smithSociallyAwareRobot2021a,
  title = {Socially {{Aware Robot Obstacle Avoidance Considering Human Intention}} and {{Preferences}}},
  author = {Smith, T. and Chen, Y. and Hewitt, N. and Hu, B. and Gu, Y.},
  date = {2021},
  journaltitle = {International Journal of Social Robotics},
  doi = {10.1007/s12369-021-00795-5},
  abstract = {In order to navigate safely and effectively with humans in close proximity, robots must be capable of predicting the future motions of humans. This study first consolidates human studies in motion, intention, and preference into a discretized human model that can readily be used in robotics decision making algorithms. Cooperative Markov Decision Process (Co-MDP), a novel framework that improves upon Multiagent MDPs, is then proposed for enabling socially aware robot obstacle avoidance. Utilizing the consolidated and discretized human model, Co-MDP allows the system to (1) approximate rational human behavior and intention, (2) generate socially-aware robotic obstacle avoidance behavior, and (3) remain robust to the uncertainty of human intention and motion variance. Simulations of a human-robot co-populated environment verify Co-MDP as a feasible obstacle avoidance algorithm. In addition, the anthropomorphic behavior of Co-MDP was assessed and confirmed with a human-in-the-loop experiment. Results reveal that participants can not directly differentiate agents that were controlled by human operators from Co-MDP, and the reported confidences of their choices indicates that the predictions from participants were backed by behavioral evidence rather than random guesses. Thus the main contributions for this paper are: consolidating past human studies of rational human behavior and intention into a simple, discretized model; the development of Co-MDP: a robotic decision framework that can utilize this human model and maximize the joint utility between the human and robot; and an experimental design for evaluation of the human acceptance of obstacle avoidance algorithms.}
}

@inproceedings{soltaniEvaluatingPerformanceConvolutional2017,
  title = {Evaluating the Performance of {{Convolutional Neural Network}} for Classifying Equipment on Construction Sites},
  booktitle = {{{ISARC}} 2017 - {{Proceedings}} of the 34th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  author = {Soltani, M. M. and Karandish, S.-F. and Ahmed, W. and Zhu, Z. and Hammad, A.},
  date = {2017},
  pages = {509--516},
  abstract = {Estimating the productivity of construction operations is one of the most challenging tasks for project managers. Therefore, the construction industry always looks toward new advancements for automating this process. New automated methods for productivity estimation aim to detect the types, locations, and activities of construction equipment based on sensory data. Computer Vision (CV) is one of the most promising automated methods and it provides an affordable opportunity for estimating the productivity since it only requires regular surveillance cameras for data collection, which are available on many construction sites. One of the widely used CV methods for classifying equipment is Histogram of Oriented Gradient (HOG). Additionally, Bag of Words (BoWs) and Local Binary Pattern (LBP) are other types of descriptors widely used for the object classification. However, these methods reduce the dimensions of the image features to train the classifiers for object detection, which may reduce the reliability of the results. Convolutional Neural Networks (CNN), which are a special type of Artificial Neural Networks (ANN) with deeper layer structure, provide a better approach for object detection compared to the conventional methods due to their deeper understanding of the object features. Furthermore, the advancements in Graphical Processing Units (GPU) made this computationally heavy method more applicable in practice. This paper aims to evaluate the performance of CNN for detecting equipment on construction sites. Several configurations of CNN are trained for detecting multiple equipment (i.e. dump trucks, excavators and loaders). The results of these configurations are compared with those of conventional detectors.}
}

@inproceedings{soltaniEvaluatingPerformanceConvolutional2017a,
  title = {Evaluating the Performance of {{Convolutional Neural Network}} for Classifying Equipment on Construction Sites},
  booktitle = {{{ISARC}} 2017 - {{Proceedings}} of the 34th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  author = {Soltani, M.M. and Karandish, S.-F. and Ahmed, W. and Zhu, Z. and Hammad, A.},
  date = {2017},
  pages = {509--516},
  abstract = {Estimating the productivity of construction operations is one of the most challenging tasks for project managers. Therefore, the construction industry always looks toward new advancements for automating this process. New automated methods for productivity estimation aim to detect the types, locations, and activities of construction equipment based on sensory data. Computer Vision (CV) is one of the most promising automated methods and it provides an affordable opportunity for estimating the productivity since it only requires regular surveillance cameras for data collection, which are available on many construction sites. One of the widely used CV methods for classifying equipment is Histogram of Oriented Gradient (HOG). Additionally, Bag of Words (BoWs) and Local Binary Pattern (LBP) are other types of descriptors widely used for the object classification. However, these methods reduce the dimensions of the image features to train the classifiers for object detection, which may reduce the reliability of the results. Convolutional Neural Networks (CNN), which are a special type of Artificial Neural Networks (ANN) with deeper layer structure, provide a better approach for object detection compared to the conventional methods due to their deeper understanding of the object features. Furthermore, the advancements in Graphical Processing Units (GPU) made this computationally heavy method more applicable in practice. This paper aims to evaluate the performance of CNN for detecting equipment on construction sites. Several configurations of CNN are trained for detecting multiple equipment (i.e. dump trucks, excavators and loaders). The results of these configurations are compared with those of conventional detectors.}
}

@article{songSystemsControlModels2008,
  title = {Systems, Control Models, and Codec for Collaborative Observation of Remote Environments with an Autonomous Networked Robotic Camera},
  author = {Song, D. and Qin, N. and Goldberg, K.},
  date = {2008},
  journaltitle = {Autonomous Robots},
  volume = {24},
  number = {4},
  pages = {435--449},
  doi = {10.1007/s10514-008-9089-4},
  abstract = {Networked robotic cameras are becoming popular in remote observation applications such as natural observation, surveillance, and distance learning. Equipped with a high optical zoom lens and agile pan-tilt mechanisms, a networked robotic camera can cover a large region with various resolutions. The optimal selection of camera control parameters for competing observation requests and the on-demand delivery of video content for various spatiotemporal queries are two challenges in the design of such autonomous systems. For camera control, we introduce memoryless and temporal frame selection models that effectively enable collaborative control of the camera based on the competing inputs from in-situ sensors and users. For content delivery, we design a patch-based motion panorama representation and coding/decoding algorithms (codec) to allow efficient storage and computation. We present system architecture, frame selection models, user interface, and codec algorithms. We have implemented the system and extensively tested our design in real world applications including natural observation, public surveillance, distance learning, and building construction monitoring. Experiment results show that our frame selection models are robust and effective and our on-demand content delivery codec can satisfy a variety of spatiotemporal queries efficiently in terms of computation time communications bandwidth. © 2008 Springer Science+Business Media, LLC.}
}

@article{songSystemsControlModels2008a,
  title = {Systems, Control Models, and Codec for Collaborative Observation of Remote Environments with an Autonomous Networked Robotic Camera},
  author = {Song, D. and Qin, N. and Goldberg, K.},
  date = {2008},
  journaltitle = {Autonomous Robots},
  volume = {24},
  number = {4},
  pages = {435--449},
  doi = {10.1007/s10514-008-9089-4},
  abstract = {Networked robotic cameras are becoming popular in remote observation applications such as natural observation, surveillance, and distance learning. Equipped with a high optical zoom lens and agile pan-tilt mechanisms, a networked robotic camera can cover a large region with various resolutions. The optimal selection of camera control parameters for competing observation requests and the on-demand delivery of video content for various spatiotemporal queries are two challenges in the design of such autonomous systems. For camera control, we introduce memoryless and temporal frame selection models that effectively enable collaborative control of the camera based on the competing inputs from in-situ sensors and users. For content delivery, we design a patch-based motion panorama representation and coding/decoding algorithms (codec) to allow efficient storage and computation. We present system architecture, frame selection models, user interface, and codec algorithms. We have implemented the system and extensively tested our design in real world applications including natural observation, public surveillance, distance learning, and building construction monitoring. Experiment results show that our frame selection models are robust and effective and our on-demand content delivery codec can satisfy a variety of spatiotemporal queries efficiently in terms of computation time communications bandwidth. © 2008 Springer Science+Business Media, LLC.}
}

@article{sousaRoboticTechnologiesNonStandard2017,
  title = {Robotic {{Technologies}} for {{Non-Standard Design}} and {{Construction}} in {{Architecture}}},
  author = {Sousa, J.P.},
  date = {2017},
  journaltitle = {Nexus Network Journal},
  volume = {19},
  number = {1},
  pages = {73--83},
  doi = {10.1007/s00004-016-0312-x},
  abstract = {In November 2015, the Faculty of Architecture at the University of Porto and the Institute for Systems and Computer Engineering, Technology and Science concluded a 2-year research project on the use of robotic fabrication technologies in architecture and building construction. Funded by the national Foundation of Science and Technology, this was a unique and vibrant experience on a new research field for the two institutions. This paper provides a brief description of the research project and its results.}
}

@article{sousaRoboticTechnologiesNonStandard2017a,
  title = {Robotic {{Technologies}} for {{Non-Standard Design}} and {{Construction}} in {{Architecture}}},
  author = {Sousa, J.P.},
  date = {2017},
  journaltitle = {Nexus Network Journal},
  volume = {19},
  number = {1},
  pages = {73--83},
  doi = {10.1007/s00004-016-0312-x},
  abstract = {In November 2015, the Faculty of Architecture at the University of Porto and the Institute for Systems and Computer Engineering, Technology and Science concluded a 2-year research project on the use of robotic fabrication technologies in architecture and building construction. Funded by the national Foundation of Science and Technology, this was a unique and vibrant experience on a new research field for the two institutions. This paper provides a brief description of the research project and its results.}
}

@article{soust-verdaguerComparativeBIMbasedLife2020,
  title = {Comparative {{BIM-based Life Cycle Assessment}} of {{Uruguayan}} Timber and Concrete-Masonry Single-Family Houses in Design Stage},
  author = {Soust-Verdaguer, B. and Llatas, C. and Moya, L.},
  date = {2020},
  journaltitle = {Journal of Cleaner Production},
  volume = {277},
  doi = {10.1016/j.jclepro.2020.121958},
  abstract = {The use of wood and engineered wood products is today considered an opportunity for the mitigation of negative building environmental impacts, such as greenhouse gas emissions. However, the literature provides evidence that the quantification and generalization of the environmental benefits of wood during the whole building life cycle can be difficult. This paper presents a quantitative method based on Life Cycle Assessment (LCA) to compare, during their design stages, the environmental impacts produced by a timber-frame single-family house versus those of a concrete-masonry-based house built in Uruguay. The method, conceived as a decision-oriented tool, integrates Building Information Modelling (BIM) and LCA to quantify and compare the environmental impacts of one of the most common dwelling typologies in Uruguay. The results of the cradle-to-grave assessment show that the timber-frame building produced the lowest impacts in Global Warming Potential, Human Toxicity, Acidification Potential, Ozone Depletion Potential, and Freshwater Ecotoxicity, but yielded the highest impacts in Eutrophication Potential. The findings also show that the method developed herein facilitated the comparison and contrast between the pros and cons of both design options during their design stages.},
  file = {C:\Users\leemar\Zotero\storage\PDSBA4QW\Comparative-BIMbased-Life-Cycle-Assessment-of-Uruguayan-timber-and-concretemasonry-singlefamily-houses-in-design-stageJournal-of-Cleaner-Production.pdf}
}

@article{soust-verdaguerComparativeBIMbasedLife2020a,
  title = {Comparative {{BIM-based Life Cycle Assessment}} of {{Uruguayan}} Timber and Concrete-Masonry Single-Family Houses in Design Stage},
  author = {Soust-Verdaguer, B. and Llatas, C. and Moya, L.},
  date = {2020},
  journaltitle = {Journal of Cleaner Production},
  volume = {277},
  doi = {10.1016/j.jclepro.2020.121958},
  abstract = {The use of wood and engineered wood products is today considered an opportunity for the mitigation of negative building environmental impacts, such as greenhouse gas emissions. However, the literature provides evidence that the quantification and generalization of the environmental benefits of wood during the whole building life cycle can be difficult. This paper presents a quantitative method based on Life Cycle Assessment (LCA) to compare, during their design stages, the environmental impacts produced by a timber-frame single-family house versus those of a concrete-masonry-based house built in Uruguay. The method, conceived as a decision-oriented tool, integrates Building Information Modelling (BIM) and LCA to quantify and compare the environmental impacts of one of the most common dwelling typologies in Uruguay. The results of the cradle-to-grave assessment show that the timber-frame building produced the lowest impacts in Global Warming Potential, Human Toxicity, Acidification Potential, Ozone Depletion Potential, and Freshwater Ecotoxicity, but yielded the highest impacts in Eutrophication Potential. The findings also show that the method developed herein facilitated the comparison and contrast between the pros and cons of both design options during their design stages.},
  file = {C:\Users\leemar\Zotero\storage\XK9JVEGH\Comparative-BIMbased-Life-Cycle-Assessment-of-Uruguayan-timber-and-concretemasonry-singlefamily-houses-in-design-stageJournal-of-Cleaner-Production.pdf}
}

@inproceedings{sowmyaConstructionWorkersActivity2017,
  title = {Construction {{Workers Activity Detection Using BOF}}},
  booktitle = {Proceedings - 2017 {{International Conference}} on {{Recent Advances}} in {{Electronics}} and {{Communication Technology}}, {{ICRAECT}} 2017},
  author = {Sowmya, K. S.},
  date = {2017},
  pages = {159--163},
  doi = {10.1109/ICRAECT.2017.54},
  abstract = {Human Activity detection is an imperative area of research in computer vision. This paper focuses on activity recognition by construction personnel at the construction sites. The method uses bag of features (BOF) approach to detect an activity. Here we have considered five types of activities done at construction sites namely ladder climbing, brick laying, carpentry work, painting and plastering work. Still images of activities at construction sites are obtained from Internet and few were added from personal digital collection to form a new construction workers database, comprising a total of 389 images. 30\% of the images from the dataset are used for training, 40\% for validation and 30\% for testing. Bag of features classifier is applied to the training set to form 500 visual words. The test images are classified as one of the five categories with an accuracy of 95\%. The proposed method is also tested on KTH and willows action dataset. The accuracy for KTH dataset is 96\% and for Willows action dataset is 95\%. All algorithms are tested using MATLAB 2012b software.},
  isbn = {978-1-5090-6701-5}
}

@inproceedings{sowmyaConstructionWorkersActivity2017a,
  title = {Construction {{Workers Activity Detection Using BOF}}},
  booktitle = {Proceedings - 2017 {{International Conference}} on {{Recent Advances}} in {{Electronics}} and {{Communication Technology}}, {{ICRAECT}} 2017},
  author = {Sowmya, K.S.},
  date = {2017},
  pages = {159--163},
  doi = {10.1109/ICRAECT.2017.54},
  abstract = {Human Activity detection is an imperative area of research in computer vision. This paper focuses on activity recognition by construction personnel at the construction sites. The method uses bag of features (BOF) approach to detect an activity. Here we have considered five types of activities done at construction sites namely ladder climbing, brick laying, carpentry work, painting and plastering work. Still images of activities at construction sites are obtained from Internet and few were added from personal digital collection to form a new construction workers database, comprising a total of 389 images. 30\% of the images from the dataset are used for training, 40\% for validation and 30\% for testing. Bag of features classifier is applied to the training set to form 500 visual words. The test images are classified as one of the five categories with an accuracy of 95\%. The proposed method is also tested on KTH and willows action dataset. The accuracy for KTH dataset is 96\% and for Willows action dataset is 95\%. All algorithms are tested using MATLAB 2012b software.},
  isbn = {978-1-5090-6701-5}
}

@inproceedings{spagnoloPostureEstimationVisual2003,
  title = {Posture Estimation in Visual Surveillance of Archaeological Sites},
  booktitle = {Proceedings - {{IEEE Conference}} on {{Advanced Video}} and {{Signal Based Surveillance}}, {{AVSS}} 2003},
  author = {Spagnolo, P. and Leo, M. and Leone, A. and Attolico, G. and Distante, A.},
  date = {2003},
  pages = {277--283},
  doi = {10.1109/AVSS.2003.1217932},
  abstract = {The paper presents a fast and reliable approach to estimate body postures in outdoor visual surveillance. It works on patches corresponding to people, recognized by two subsystems (motion detection and object recognition) on image sequences coming from a still camera. The proposed algorithm is based on an unsupervised clustering approach and is substantially independent from a-priori assumption about the possible output postures. Horizontal and vertical histograms of the binary shapes associated to humans are selected as features. The Manhattan distance is used for building clusters and for run-time classification. After experimental tests the BCLS (Basic Competitive Learning Scheme) algorithm has been selected for the construction of clusters. The whole approach has been verified on real sequences acquired while typical illegal activities involved in stealing were simulated in an archeological site.},
  isbn = {978-0-7695-1971-5}
}

@inproceedings{spagnoloPostureEstimationVisual2003a,
  title = {Posture Estimation in Visual Surveillance of Archaeological Sites},
  booktitle = {Proceedings - {{IEEE Conference}} on {{Advanced Video}} and {{Signal Based Surveillance}}, {{AVSS}} 2003},
  author = {Spagnolo, P. and Leo, M. and Leone, A. and Attolico, G. and Distante, A.},
  date = {2003},
  pages = {277--283},
  doi = {10.1109/AVSS.2003.1217932},
  abstract = {The paper presents a fast and reliable approach to estimate body postures in outdoor visual surveillance. It works on patches corresponding to people, recognized by two subsystems (motion detection and object recognition) on image sequences coming from a still camera. The proposed algorithm is based on an unsupervised clustering approach and is substantially independent from a-priori assumption about the possible output postures. Horizontal and vertical histograms of the binary shapes associated to humans are selected as features. The Manhattan distance is used for building clusters and for run-time classification. After experimental tests the BCLS (Basic Competitive Learning Scheme) algorithm has been selected for the construction of clusters. The whole approach has been verified on real sequences acquired while typical illegal activities involved in stealing were simulated in an archeological site.},
  isbn = {978-0-7695-1971-5}
}

@article{srinivasanramanagopalMotionPlanningStrategy2018,
  title = {A {{Motion Planning Strategy}} for the {{Active Vision-Based Mapping}} of {{Ground-Level Structures}}},
  author = {Srinivasan Ramanagopal, M. and Nguyen, A.P.-V. and Le Ny, J.},
  date = {2018},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {15},
  number = {1},
  pages = {356--368},
  doi = {10.1109/TASE.2017.2762088},
  abstract = {This paper presents a strategy to guide a mobile ground robot equipped with a camera or depth sensor, in order to autonomously map the visible part of a bounded 3-D structure. We describe motion planning algorithms that determine appropriate successive viewpoints and attempt to fill holes automatically in a point cloud produced by the sensing and perception layer. The emphasis is on accurately reconstructing a 3-D model of a structure of moderate size rather than mapping large open environments, with applications for example in architecture, construction, and inspection. The proposed algorithms do not require any initialization in the form of a mesh model or a bounding box, and the paths generated are well adapted to situations where the vision sensor is used simultaneously for mapping and for localizing the robot, in the absence of additional absolute positioning system. We analyze the coverage properties of our policy, and compare its performance with the classic frontier-based exploration algorithm. We illustrate its efficacy for different structure sizes, levels of localization accuracy, and range of the depth sensor, and validate our design on a real-world experiment. Note to Practitioners - The objective of this paper is to automate the process of building a 3-D model of a structure of interest that is as complete as possible, using a mobile camera or depth sensor, in the absence of any prior information about this structure. Given that increasingly robust solutions for the visual simultaneous localization and mapping problem are now readily available, the key challenge that we address here is to develop motion planning policies to control the trajectory of the sensor in a way that improves the mapping performance. We target in particular scenarios where no external absolute positioning system is available, such as mapping certain indoor environments where GPS signals are blocked. In this case, it is often important to revisit previously seen locations relatively quickly, in order to avoid excessive drift in the dead-reckoning localization system. Our system works by first determining the boundaries of the structure, before attempting to fill the holes in the constructed model. Its performance is illustrated through simulations, and a real-world experiment performed with a depth sensor carried by a mobile manipulator.}
}

@article{srinivasanramanagopalMotionPlanningStrategy2018a,
  title = {A {{Motion Planning Strategy}} for the {{Active Vision-Based Mapping}} of {{Ground-Level Structures}}},
  author = {Srinivasan Ramanagopal, M. and Nguyen, A.P.-V. and Le Ny, J.},
  date = {2018},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {15},
  number = {1},
  pages = {356--368},
  doi = {10.1109/TASE.2017.2762088},
  abstract = {This paper presents a strategy to guide a mobile ground robot equipped with a camera or depth sensor, in order to autonomously map the visible part of a bounded 3-D structure. We describe motion planning algorithms that determine appropriate successive viewpoints and attempt to fill holes automatically in a point cloud produced by the sensing and perception layer. The emphasis is on accurately reconstructing a 3-D model of a structure of moderate size rather than mapping large open environments, with applications for example in architecture, construction, and inspection. The proposed algorithms do not require any initialization in the form of a mesh model or a bounding box, and the paths generated are well adapted to situations where the vision sensor is used simultaneously for mapping and for localizing the robot, in the absence of additional absolute positioning system. We analyze the coverage properties of our policy, and compare its performance with the classic frontier-based exploration algorithm. We illustrate its efficacy for different structure sizes, levels of localization accuracy, and range of the depth sensor, and validate our design on a real-world experiment. Note to Practitioners - The objective of this paper is to automate the process of building a 3-D model of a structure of interest that is as complete as possible, using a mobile camera or depth sensor, in the absence of any prior information about this structure. Given that increasingly robust solutions for the visual simultaneous localization and mapping problem are now readily available, the key challenge that we address here is to develop motion planning policies to control the trajectory of the sensor in a way that improves the mapping performance. We target in particular scenarios where no external absolute positioning system is available, such as mapping certain indoor environments where GPS signals are blocked. In this case, it is often important to revisit previously seen locations relatively quickly, in order to avoid excessive drift in the dead-reckoning localization system. Our system works by first determining the boundaries of the structure, before attempting to fill the holes in the constructed model. Its performance is illustrated through simulations, and a real-world experiment performed with a depth sensor carried by a mobile manipulator.}
}

@article{srivastavaFirstExperimentsPowerPlay2013,
  title = {First Experiments with {{PowerPlay}}},
  author = {Srivastava, R.K. and Steunebrink, B.R. and Schmidhuber, J.},
  date = {2013},
  journaltitle = {Neural Networks},
  volume = {41},
  pages = {130--136},
  doi = {10.1016/j.neunet.2013.01.022},
  abstract = {Like a scientist or a playing child, PowerPlay (Schmidhuber, 2011) not only learns new skills to solve given problems, but also invents new interesting problems by itself. By design, it continually comes up with the fastest to find, initially novel, but eventually solvable tasks. It also continually simplifies or compresses or speeds up solutions to previous tasks. Here we describe first experiments with PowerPlay. A self-delimiting recurrent neural network SLIM RNN (Schmidhuber, 2012) is used as a general computational problem solving architecture. Its connection weights can encode arbitrary, self-delimiting, halting or non-halting programs affecting both environment (through effectors) and internal states encoding abstractions of event sequences. Our PowerPlay-driven SLIM RNN learns to become an increasingly general solver of self-invented problems, continually adding new problem solving procedures to its growing skill repertoire. Extending a recent conference paper (Srivastava, Steunebrink, Stollenga, \& Schmidhuber, 2012), we identify interesting, emerging, developmental stages of our open-ended system. We also show how it automatically self-modularizes, frequently re-using code for previously invented skills, always trying to invent novel tasks that can be quickly validated because they do not require too many weight changes affecting too many previous tasks. © 2013 Elsevier Ltd.}
}

@article{srivastavaFirstExperimentsPowerPlay2013a,
  title = {First Experiments with {{PowerPlay}}},
  author = {Srivastava, R.K. and Steunebrink, B.R. and Schmidhuber, J.},
  date = {2013},
  journaltitle = {Neural Networks},
  volume = {41},
  pages = {130--136},
  doi = {10.1016/j.neunet.2013.01.022},
  abstract = {Like a scientist or a playing child, PowerPlay (Schmidhuber, 2011) not only learns new skills to solve given problems, but also invents new interesting problems by itself. By design, it continually comes up with the fastest to find, initially novel, but eventually solvable tasks. It also continually simplifies or compresses or speeds up solutions to previous tasks. Here we describe first experiments with PowerPlay. A self-delimiting recurrent neural network SLIM RNN (Schmidhuber, 2012) is used as a general computational problem solving architecture. Its connection weights can encode arbitrary, self-delimiting, halting or non-halting programs affecting both environment (through effectors) and internal states encoding abstractions of event sequences. Our PowerPlay-driven SLIM RNN learns to become an increasingly general solver of self-invented problems, continually adding new problem solving procedures to its growing skill repertoire. Extending a recent conference paper (Srivastava, Steunebrink, Stollenga, \& Schmidhuber, 2012), we identify interesting, emerging, developmental stages of our open-ended system. We also show how it automatically self-modularizes, frequently re-using code for previously invented skills, always trying to invent novel tasks that can be quickly validated because they do not require too many weight changes affecting too many previous tasks. © 2013 Elsevier Ltd.}
}

@article{staub-frenchConstructionProcessInnovation2021,
  title = {Construction Process Innovation on {{Brock Commons Tallwood House}}},
  author = {Staub-French, S. and Pilon, A. and Poirier, E. and Fallahi, A. and Kasbar, M. and Calderon, F. and Teshnizi, Z. and Froese, T.},
  date = {2021},
  journaltitle = {Construction Innovation},
  doi = {10.1108/CI-11-2019-0117},
  abstract = {Purpose: The purpose of this paper is to present the construction process innovations that enabled the successful delivery of the hybrid mass timber high-rise building in Canada, the Brock Commons Tallwood House at the University of British Columbia. It is one of a set of papers examining the project, including companion papers that describe innovations in the mass timber design process and the impact of these innovations on construction performance. The focus of this paper is on innovation in the construction phase and its relationship to innovations implemented in previous project phases. Design/methodology/approach: A mixed-method, longitudinal case study approach was used in this research project to investigate and document the Tallwood House project over a three-year period. Both quantitative and qualitative data collection and analysis techniques were used. Members of the research team observed prefabrication and construction, conducted periodic interviews and reviewed project artefacts. Findings: The research identified three innovation “clusters,” including the use of innovative tools, techniques and strategies in the design and construction processes and the role they played in delivering the project. The “clusters” were further characterized according to the type of “connectivity” they afforded, either facilitation, operationalization or materialization. These two perspectives support a compounding view on innovation and help to understand how it can flow throughout a project’s life cycle and across its supply chain. Three process-based innovations were initiated during the design phase, integrated design process, building information modeling and virtual design and construction and flowed through to the construction phase. These were seen to enable the creation of connections that were crucial to the overall success of the project. These innovations were operationalized and enacted through the construction phase as design for manufacturing and assembly and prefabrication, staged construction and just-in-time delivery, integration of safety and risk management and a rigorous quality control and quality assurance process. Finally, a full-scale mock-up was produced for practice and constructability assessment, materializing the radical product innovation that was the mass timber structure. These strategies are used together for a synergistic and integrated approach to increase productivity, expedite the construction schedule and develop an innovative building product. Originality/value: This paper details an in-depth investigation into the diffusion dynamics of multiple systemic innovations for the construction process of a unique building project, the tools and techniques used by the construction manager and team, and the challenges, solutions and lessons learned.}
}

@article{staub-frenchConstructionProcessInnovation2021a,
  title = {Construction Process Innovation on {{Brock Commons Tallwood House}}},
  author = {Staub-French, S. and Pilon, A. and Poirier, E. and Fallahi, A. and Kasbar, M. and Calderon, F. and Teshnizi, Z. and Froese, T.},
  date = {2021},
  journaltitle = {Construction Innovation},
  doi = {10.1108/CI-11-2019-0117},
  abstract = {Purpose: The purpose of this paper is to present the construction process innovations that enabled the successful delivery of the hybrid mass timber high-rise building in Canada, the Brock Commons Tallwood House at the University of British Columbia. It is one of a set of papers examining the project, including companion papers that describe innovations in the mass timber design process and the impact of these innovations on construction performance. The focus of this paper is on innovation in the construction phase and its relationship to innovations implemented in previous project phases. Design/methodology/approach: A mixed-method, longitudinal case study approach was used in this research project to investigate and document the Tallwood House project over a three-year period. Both quantitative and qualitative data collection and analysis techniques were used. Members of the research team observed prefabrication and construction, conducted periodic interviews and reviewed project artefacts. Findings: The research identified three innovation “clusters,” including the use of innovative tools, techniques and strategies in the design and construction processes and the role they played in delivering the project. The “clusters” were further characterized according to the type of “connectivity” they afforded, either facilitation, operationalization or materialization. These two perspectives support a compounding view on innovation and help to understand how it can flow throughout a project’s life cycle and across its supply chain. Three process-based innovations were initiated during the design phase, integrated design process, building information modeling and virtual design and construction and flowed through to the construction phase. These were seen to enable the creation of connections that were crucial to the overall success of the project. These innovations were operationalized and enacted through the construction phase as design for manufacturing and assembly and prefabrication, staged construction and just-in-time delivery, integration of safety and risk management and a rigorous quality control and quality assurance process. Finally, a full-scale mock-up was produced for practice and constructability assessment, materializing the radical product innovation that was the mass timber structure. These strategies are used together for a synergistic and integrated approach to increase productivity, expedite the construction schedule and develop an innovative building product. Originality/value: This paper details an in-depth investigation into the diffusion dynamics of multiple systemic innovations for the construction process of a unique building project, the tools and techniques used by the construction manager and team, and the challenges, solutions and lessons learned.}
}

@article{Strabala2013112,
  title = {Towards Seamless Human-Robot Handovers},
  author = {Strabala, K.W. and Lee, M.K. and Dragan, A.D. and Forlizzi, J.L. and Srinivasa, S. and Cakmak, M. and Micelli, V.},
  date = {2013},
  journaltitle = {Journal of Human-Robot Interaction},
  volume = {2},
  number = {1},
  pages = {112--132}
}

@article{stuart-smithBehaviouralProductionAutonomous2016,
  title = {Behavioural Production: {{Autonomous}} Swarm-Constructed Architecture},
  author = {Stuart-Smith, R.},
  date = {2016},
  journaltitle = {Architectural Design},
  volume = {86},
  number = {2},
  pages = {54--59},
  doi = {10.1002/ad.2024},
  abstract = {Until now, parametric processes have largely been confined to the architectural and engineering phases of a building's design. What possibilities, however, do robotics and artificial intelligence programming open up for extending Parametricism's influence into the construction phase? Robert Stuart-Smith, a course master at the Architectural Association Design Research Laboratory (AADRL), explores how architecture might adopt autonomous swarm-construction techniques. He describes the research that he has carried out with colleagues and students employing flying multicopters or unmanned aerial vehicles (UAVs) to design and additively manufacture 3D-printed buildings onsite.}
}

@article{stuart-smithBehaviouralProductionAutonomous2016a,
  title = {Behavioural Production: {{Autonomous}} Swarm-Constructed Architecture},
  author = {Stuart-Smith, R.},
  date = {2016},
  journaltitle = {Architectural Design},
  volume = {86},
  number = {2},
  pages = {54--59},
  doi = {10.1002/ad.2024},
  abstract = {Until now, parametric processes have largely been confined to the architectural and engineering phases of a building's design. What possibilities, however, do robotics and artificial intelligence programming open up for extending Parametricism's influence into the construction phase? Robert Stuart-Smith, a course master at the Architectural Association Design Research Laboratory (AADRL), explores how architecture might adopt autonomous swarm-construction techniques. He describes the research that he has carried out with colleagues and students employing flying multicopters or unmanned aerial vehicles (UAVs) to design and additively manufacture 3D-printed buildings onsite.}
}

@book{SustainableCommunitiesPeople,
  title = {Sustainable Communities: People, Places and Prosperity}
}

@article{sweetResurrectingMasterBuilder2016,
  title = {Resurrecting the Master Builder: {{A}} Pedagogical Strategy for Robotic Construction},
  author = {Sweet, K.},
  date = {2016},
  journaltitle = {Automation in Construction},
  volume = {72},
  pages = {33--38},
  doi = {10.1016/j.autcon.2016.07.001},
  abstract = {As software interfaces become more intuitive and require less technical expertise, the robotic arm is not only becoming a tool for automating bespoke construction, it is becoming a tool to help bring the concept of the “Master Builder” back to the architectural profession. Being analogous to a human arm, it is easy to imagine limitless possibilities the robotic arm. However, understanding and utilizing it for the purpose of construction requires more knowledge than just imagining it as prosthetic. Besides a fundamental understanding of the digital workflow from the initial design based data (3D modelling) to machine understandable data (proprietary output code), it requires the design and conception of the robot's physical environment from the tool at the end of its arm (end effector) to its physical surroundings(work cell). Contemporary software tools provide the capabilities for manufacturing purposes and allow for virtual simulations of the production process, ensuring higher rates of success for construction. It is the crossover between the virtual environment and the physical world that will empower architects of the future to reclaim the title of master builders as they will be required to not only comprehend but design and participate in the entire building process inclusive of the manufacturing of components. This paper outlines a pedagogical framework to introduce the multi-layered levels of knowledge to students of architecture that will allow them to use a 6-axis robotic arm for the purpose of automated construction, making them aware of a new and complex building process that will be integral to redefining architecture in the near future.}
}

@article{sweetResurrectingMasterBuilder2016a,
  title = {Resurrecting the Master Builder: {{A}} Pedagogical Strategy for Robotic Construction},
  author = {Sweet, K.},
  date = {2016},
  journaltitle = {Automation in Construction},
  volume = {72},
  pages = {33--38},
  doi = {10.1016/j.autcon.2016.07.001},
  abstract = {As software interfaces become more intuitive and require less technical expertise, the robotic arm is not only becoming a tool for automating bespoke construction, it is becoming a tool to help bring the concept of the “Master Builder” back to the architectural profession. Being analogous to a human arm, it is easy to imagine limitless possibilities the robotic arm. However, understanding and utilizing it for the purpose of construction requires more knowledge than just imagining it as prosthetic. Besides a fundamental understanding of the digital workflow from the initial design based data (3D modelling) to machine understandable data (proprietary output code), it requires the design and conception of the robot's physical environment from the tool at the end of its arm (end effector) to its physical surroundings(work cell). Contemporary software tools provide the capabilities for manufacturing purposes and allow for virtual simulations of the production process, ensuring higher rates of success for construction. It is the crossover between the virtual environment and the physical world that will empower architects of the future to reclaim the title of master builders as they will be required to not only comprehend but design and participate in the entire building process inclusive of the manufacturing of components. This paper outlines a pedagogical framework to introduce the multi-layered levels of knowledge to students of architecture that will allow them to use a 6-axis robotic arm for the purpose of automated construction, making them aware of a new and complex building process that will be integral to redefining architecture in the near future.}
}

@article{syrseloudisDesignSimpleModular2011,
  title = {Design of a Simple and Modular 2-{{DOF}} Ankle Physiotherapy Device Relying on a Hybrid Serial-Parallel Robotic Architecture},
  author = {Syrseloudis, C.E. and Emiris, I.Z. and Lilas, T. and Maglara, A.},
  date = {2011},
  journaltitle = {Applied Bionics and Biomechanics},
  volume = {8},
  number = {1},
  pages = {101--114},
  doi = {10.3233/ABB-2011-010},
  abstract = {The aim of this work is to propose a new 2-DOF robotic platform with hybrid parallel-serial structure and to undertake its parametric design so that it can follow the whole range of ankle related foot movements. This robot can serve as a human ankle rehabilitation device. The existing ankle rehabilitation devices present typically one or more of the following shortcomings: redundancy, large size, or high cost, hence the need for a device that could offer simplicity, modularity, and low cost of construction and maintenance. In addition, our targeted device must be safe during operation, disallow undesirable movements of the foot, while adaptable to any human foot. Our detailed study of foot kinematics has led us to a new hybrid architecture, which strikes a balance among all aforementioned goals. It consists of a passive serial kinematics chain with two adjustable screws so that the axes of the chain match the two main ankle-axes of typical feet. An active parallel chain, which consists of two prismatic actuators, provides the movement of the platform. Thus, the platform can follow the foot movements, thanks to the passive chain, and also possesses the advantages of parallel robots, including rigidity, high stiffness and force capabilities. The lack of redundancy yields a simpler device with lower size and cost. The paper describes the kinematics modelling of the platform and analyses the force and velocity transmission. The parametric design of the platform is carried out; our simulations confirm the platform's suitability for ankle rehabilitation. © 2011 - IOS Press and the authors. All rights reserved.}
}

@article{syrseloudisDesignSimpleModular2011a,
  title = {Design of a Simple and Modular 2-{{DOF}} Ankle Physiotherapy Device Relying on a Hybrid Serial-Parallel Robotic Architecture},
  author = {Syrseloudis, C.E. and Emiris, I.Z. and Lilas, T. and Maglara, A.},
  date = {2011},
  journaltitle = {Applied Bionics and Biomechanics},
  volume = {8},
  number = {1},
  pages = {101--114},
  doi = {10.3233/ABB-2011-010},
  abstract = {The aim of this work is to propose a new 2-DOF robotic platform with hybrid parallel-serial structure and to undertake its parametric design so that it can follow the whole range of ankle related foot movements. This robot can serve as a human ankle rehabilitation device. The existing ankle rehabilitation devices present typically one or more of the following shortcomings: redundancy, large size, or high cost, hence the need for a device that could offer simplicity, modularity, and low cost of construction and maintenance. In addition, our targeted device must be safe during operation, disallow undesirable movements of the foot, while adaptable to any human foot. Our detailed study of foot kinematics has led us to a new hybrid architecture, which strikes a balance among all aforementioned goals. It consists of a passive serial kinematics chain with two adjustable screws so that the axes of the chain match the two main ankle-axes of typical feet. An active parallel chain, which consists of two prismatic actuators, provides the movement of the platform. Thus, the platform can follow the foot movements, thanks to the passive chain, and also possesses the advantages of parallel robots, including rigidity, high stiffness and force capabilities. The lack of redundancy yields a simpler device with lower size and cost. The paper describes the kinematics modelling of the platform and analyses the force and velocity transmission. The parametric design of the platform is carried out; our simulations confirm the platform's suitability for ankle rehabilitation. © 2011 - IOS Press and the authors. All rights reserved.}
}

@article{szumanskiModelingBehaviorIntegrated1981,
  title = {Modeling of the Behavior of an Integrated Industrial System during a Catastrophe},
  author = {Szumański, Zbigniew},
  date = {1981-03},
  journaltitle = {Computers in Industry},
  volume = {2},
  number = {1},
  pages = {13--21},
  issn = {01663615},
  doi = {10.1016/0166-3615(81)90042-7},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0166361581900427},
  abstract = {Lines and groups of equipment including robots are recognized as the basic level of the Integrated Industrial System, IIS. The management system is considered as a high level of the IIS which is controlled with a Hierarchical Numerical Control, system HNC. Metallurgical objects, in particular sand foundries are taken into consideration. The evaluation criterion of a catastrophe course is the speed of the decrease in the IIS reliability (R) in the crash time period (τcr): VR = dR/dτcr. If failures appear, then VR≈0 and the system structures tolerates the failures. If the failures increase, the threshold tolerance is crossed, and VR will increase as well. VR assumes low values for the soft degradation of the IIS system, while VR → ∞for the crash degradation. The course of catastrophe can be simulated by testing the IIS system model. Simulating testing of the IIS takes into consideration the transformation of reliability structure under the influence of load changes. This process determines the behavior of the system during a catastrophe. The basis for determining the transformation is the construction of a formula for a generalized reliability connection. The generalized reliability connection is characteristic for reactions of the soft degradation type. During a catastrophe caused by system load growth and decreasing reserves, there occurs an IIS structure transformation in the following sequence: \&\#x02022; -parallel multibranch reserving with multiple reserve, \&\#x02022; -parallel singlebranch reserving with full reserve, \&\#x02022; -parallel with partial reserve, \&\#x02022; -series. If one element is damaged after the final stage transformation (for the series structure), the IIS system will be crashed. Evaluation of the course of a catastrophe of the IIS system allows: (1) the correct decisions for the prevention of the catastrophe, (2) the design of the fault tolerance system architecture when VR ≈0. © 1981.},
  keywords = {catastrophe phase,Hierarchy Numerical Control,HNC,IIS,integrated industrial system,reliability structure,robotics,soft degradation,structure transformation}
}

@article{szumanskiModelingBehaviorIntegrated1981a,
  title = {Modeling of the Behavior of an Integrated Industrial System during a Catastrophe},
  author = {Szumański, Z.},
  date = {1981},
  journaltitle = {Computers in Industry},
  volume = {2},
  number = {1},
  pages = {13--21},
  doi = {10.1016/0166-3615(81)90042-7},
  abstract = {Lines and groups of equipment including robots are recognized as the basic level of the Integrated Industrial System, IIS. The management system is considered as a high level of the IIS which is controlled with a Hierarchical Numerical Control, system HNC. Metallurgical objects, in particular sand foundries are taken into consideration. The evaluation criterion of a catastrophe course is the speed of the decrease in the IIS reliability (R) in the crash time period (τcr): VR = dR/dτcr. If failures appear, then VR≈0 and the system structures tolerates the failures. If the failures increase, the threshold tolerance is crossed, and VR will increase as well. VR assumes low values for the soft degradation of the IIS system, while VR → ∞for the crash degradation. The course of catastrophe can be simulated by testing the IIS system model. Simulating testing of the IIS takes into consideration the transformation of reliability structure under the influence of load changes. This process determines the behavior of the system during a catastrophe. The basis for determining the transformation is the construction of a formula for a generalized reliability connection. The generalized reliability connection is characteristic for reactions of the soft degradation type. During a catastrophe caused by system load growth and decreasing reserves, there occurs an IIS structure transformation in the following sequence: \&\#x02022; -parallel multibranch reserving with multiple reserve, \&\#x02022; -parallel singlebranch reserving with full reserve, \&\#x02022; -parallel with partial reserve, \&\#x02022; -series. If one element is damaged after the final stage transformation (for the series structure), the IIS system will be crashed. Evaluation of the course of a catastrophe of the IIS system allows: (1) the correct decisions for the prevention of the catastrophe, (2) the design of the fault tolerance system architecture when VR ≈0. © 1981.}
}

@inproceedings{tahboubNovelHumanmachineInteraction2005,
  title = {A Novel Human-Machine Interaction Architecture - {{Intention}} Recognition Approach},
  booktitle = {{{IFAC Proceedings Volumes}} ({{IFAC-PapersOnline}})},
  author = {Tahboub, K. A.},
  date = {2005},
  volume = {16},
  pages = {82--87},
  doi = {10.3182/20050703-6-cz-1902.01416},
  abstract = {A novel human-machine interaction architecture is presented. It is based on the machine intention recognition of the human. This work is motivated by the desire to minimize the need for classical direct human-machine interface and communication. Here, the intention-action-state scenario is modified and modelled by dynamic Bayesian networks to facilitate for probabilistic intention inference. The recognized intention, then, drives the interactive behaviour of the machine such that it complies with the human intention in light of the real state of the world. an illustrative example of a human commanding a mobile robot remotely is given and discussed in details. Copyright © 2005 IFAC.},
  isbn = {978-0-08-045108-4}
}

@inproceedings{tahboubNovelHumanmachineInteraction2005a,
  title = {A Novel Human-Machine Interaction Architecture - {{Intention}} Recognition Approach},
  booktitle = {{{IFAC Proceedings Volumes}} ({{IFAC-PapersOnline}})},
  author = {Tahboub, K.A.},
  date = {2005},
  volume = {16},
  pages = {82--87},
  doi = {10.3182/20050703-6-cz-1902.01416},
  abstract = {A novel human-machine interaction architecture is presented. It is based on the machine intention recognition of the human. This work is motivated by the desire to minimize the need for classical direct human-machine interface and communication. Here, the intention-action-state scenario is modified and modelled by dynamic Bayesian networks to facilitate for probabilistic intention inference. The recognized intention, then, drives the interactive behaviour of the machine such that it complies with the human intention in light of the real state of the world. an illustrative example of a human commanding a mobile robot remotely is given and discussed in details. Copyright © 2005 IFAC.},
  isbn = {978-0-08-045108-4}
}

@online{tanCanChatGPTReplace2023,
  title = {Can {{ChatGPT Replace Traditional KBQA Models}}? {{An In-depth Analysis}} of the {{Question Answering Performance}} of the {{GPT LLM Family}}},
  shorttitle = {Can {{ChatGPT Replace Traditional KBQA Models}}?},
  author = {Tan, Yiming and Min, Dehai and Li, Yu and Li, Wenbo and Hu, Nan and Chen, Yongrui and Qi, Guilin},
  date = {2023-09-20},
  eprint = {2303.07992},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2303.07992},
  urldate = {2023-11-19},
  abstract = {ChatGPT is a powerful large language model (LLM) that covers knowledge resources such as Wikipedia and supports natural language question answering using its own knowledge. Therefore, there is growing interest in exploring whether ChatGPT can replace traditional knowledge-based question answering (KBQA) models. Although there have been some works analyzing the question answering performance of ChatGPT, there is still a lack of large-scale, comprehensive testing of various types of complex questions to analyze the limitations of the model. In this paper, we present a framework that follows the black-box testing specifications of CheckList proposed by Ribeiro et. al. We evaluate ChatGPT and its family of LLMs on eight real-world KB-based complex question answering datasets, which include six English datasets and two multilingual datasets. The total number of test cases is approximately 190,000. In addition to the GPT family of LLMs, we also evaluate the well-known FLAN-T5 to identify commonalities between the GPT family and other LLMs. The dataset and code are available at https://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-GPT-family.git},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\leemar\Zotero\storage\JPU737V7\Tan 等。 - 2023 - Can ChatGPT Replace Traditional KBQA Models An In.pdf}
}

@article{tangMachineLearningBasedRisk2021,
  title = {Machine {{Learning-Based Risk Analysis}} for {{Construction Worker Safety}} from {{Ubiquitous Site Photos}} and {{Videos}}},
  author = {Tang, S. and Golparvar-Fard, M.},
  date = {2021},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {35},
  number = {6},
  doi = {10.1061/(ASCE)CP.1943-5487.0000979},
  abstract = {This paper proposes a new method for single-worker severity level prediction from already collected site images and video clips. Onsite safety observers often assess workers' severity levels during construction activities. While risk analysis is key to improving long-term construction site safety, omnipresent monitoring is still time-consuming and costly to implement. The recent growth of visual data captured actively on construction sites has opened a new opportunity to increase the frequency of worker safety monitoring. This paper shows that a comprehensive vision-based assessment is the most informative to automatically infer worker severity level from images. Efficient computer vision models are presented to conduct this risk analysis. The method is validated on a challenging image dataset first of its kind. Specifically, the proposed method detects and evaluates the worker state from visual data, defined by (1) worker body posture, (2) the usage of personal protective equipment, (3) worker interactions with tools and materials, (4) the construction activity being performed, and (5) the presence of surrounding workplace hazards. To estimate the worker state, a multitasked recognition model is introduced that recognizes objects, activity, and keypoints from visual data simultaneously, taking 36.6\% less time and 40.1\% less memory while keeping comparably performances compared to a system running individual models for each subtask. Worker activity recognition is further improved with a spatio-temporal graph neural network model using recognized per-frame worker activity, detected bounding boxes of tools and materials, and estimated worker poses. Finally, severity levels are predicted by a trained classifier on a dataset of images of construction workers accompanied with ground truth severity level annotations. In the test dataset assembled from real-world projects, the severity level prediction model achieves 85.7\% cross-validation accuracy in a bricklaying task and 86.6\% cross-validation accuracy for a plastering task, demonstrating the potential for near real-time worker safety detection and severity assessment.}
}

@article{tangMachineLearningBasedRisk2021a,
  title = {Machine {{Learning-Based Risk Analysis}} for {{Construction Worker Safety}} from {{Ubiquitous Site Photos}} and {{Videos}}},
  author = {Tang, S. and Golparvar-Fard, M.},
  date = {2021},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {35},
  number = {6},
  doi = {10.1061/(ASCE)CP.1943-5487.0000979},
  abstract = {This paper proposes a new method for single-worker severity level prediction from already collected site images and video clips. Onsite safety observers often assess workers' severity levels during construction activities. While risk analysis is key to improving long-term construction site safety, omnipresent monitoring is still time-consuming and costly to implement. The recent growth of visual data captured actively on construction sites has opened a new opportunity to increase the frequency of worker safety monitoring. This paper shows that a comprehensive vision-based assessment is the most informative to automatically infer worker severity level from images. Efficient computer vision models are presented to conduct this risk analysis. The method is validated on a challenging image dataset first of its kind. Specifically, the proposed method detects and evaluates the worker state from visual data, defined by (1) worker body posture, (2) the usage of personal protective equipment, (3) worker interactions with tools and materials, (4) the construction activity being performed, and (5) the presence of surrounding workplace hazards. To estimate the worker state, a multitasked recognition model is introduced that recognizes objects, activity, and keypoints from visual data simultaneously, taking 36.6\% less time and 40.1\% less memory while keeping comparably performances compared to a system running individual models for each subtask. Worker activity recognition is further improved with a spatio-temporal graph neural network model using recognized per-frame worker activity, detected bounding boxes of tools and materials, and estimated worker poses. Finally, severity levels are predicted by a trained classifier on a dataset of images of construction workers accompanied with ground truth severity level annotations. In the test dataset assembled from real-world projects, the severity level prediction model achieves 85.7\% cross-validation accuracy in a bricklaying task and 86.6\% cross-validation accuracy for a plastering task, demonstrating the potential for near real-time worker safety detection and severity assessment.}
}

@article{tangProbabilisticModelBasedLearning2022,
  title = {Probabilistic {{Model-Based Learning Control}} of a {{Soft Pneumatic Glove}} for {{Hand Rehabilitation}}},
  author = {Tang, Z. Q. and Heung, H. L. and Shi, X. Q. and Tong, R. K. Y. and Li, Z.},
  date = {2022},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  volume = {69},
  number = {2},
  pages = {1016--1028},
  doi = {10.1109/TBME.2021.3111891},
  abstract = {Objective: Stroke survivors are usually unable to perform activities of daily living (ADL) independently due to loss of hand functions. Soft pneumatic gloves provide a promising assistance approach for stroke survivors to conduct ADL tasks. However, few studies have explored effective control strategies for the 'human-soft robot' integrated system due to challenges in the nonlinearities of soft robots and uncertainties of human intentions. Therefore, this work aims to develop control approaches for the system to improve stroke survivors' hand functions. Methods: Firstly, a soft pneumatic glove was utilized to aid with stroke-impaired hands. Secondly, a probabilistic model-based learning control approach was proposed to overcome the challenges. Then a task-oriented intention-driven training modality was designed. Finally, the control performance was evaluated on three able-bodied subjects and three stroke survivors who attended 20-session rehabilitation training. Results: The proposed approach could enable the soft pneumatic glove to provide adaptive assistance for all participants to accomplish different tasks. The tracking error and muscle co-contraction index showed decreasing trends while the hand gesture index showed an increasing tendency over training sessions. All stroke survivors showed improved hand functions and better muscle coordinations after training. Conclusion: This work developed a learning-based soft robotic glove training system and demonstrated its potential in post-stroke hand rehabilitation. Significance: This work promotes the application of soft robotic training systems in stroke rehabilitation.}
}

@article{tangProbabilisticModelBasedLearning2022a,
  title = {Probabilistic {{Model-Based Learning Control}} of a {{Soft Pneumatic Glove}} for {{Hand Rehabilitation}}},
  author = {Tang, Z.Q. and Heung, H.L. and Shi, X.Q. and Tong, R.K.Y. and Li, Z.},
  date = {2022},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  volume = {69},
  number = {2},
  pages = {1016--1028},
  doi = {10.1109/TBME.2021.3111891},
  abstract = {Objective: Stroke survivors are usually unable to perform activities of daily living (ADL) independently due to loss of hand functions. Soft pneumatic gloves provide a promising assistance approach for stroke survivors to conduct ADL tasks. However, few studies have explored effective control strategies for the 'human-soft robot' integrated system due to challenges in the nonlinearities of soft robots and uncertainties of human intentions. Therefore, this work aims to develop control approaches for the system to improve stroke survivors' hand functions. Methods: Firstly, a soft pneumatic glove was utilized to aid with stroke-impaired hands. Secondly, a probabilistic model-based learning control approach was proposed to overcome the challenges. Then a task-oriented intention-driven training modality was designed. Finally, the control performance was evaluated on three able-bodied subjects and three stroke survivors who attended 20-session rehabilitation training. Results: The proposed approach could enable the soft pneumatic glove to provide adaptive assistance for all participants to accomplish different tasks. The tracking error and muscle co-contraction index showed decreasing trends while the hand gesture index showed an increasing tendency over training sessions. All stroke survivors showed improved hand functions and better muscle coordinations after training. Conclusion: This work developed a learning-based soft robotic glove training system and demonstrated its potential in post-stroke hand rehabilitation. Significance: This work promotes the application of soft robotic training systems in stroke rehabilitation.}
}

@article{tanimotoConnectingMiddleSchool1998,
  title = {Connecting Middle School Mathematics to Computer Vision and Pattern Recognition},
  author = {Tanimoto, S. L.},
  date = {1998},
  journaltitle = {International Journal of Pattern Recognition and Artificial Intelligence},
  volume = {12},
  number = {8},
  pages = {1053--1070},
  doi = {10.1142/S0218001498000592},
  abstract = {The subject matter of computer vision and pattern recognition can play a useful role in the education of mathematics for students in middle school. New standards in education call for new content relevant to students' lives, and new pedagogical methods involving construction, group work, discovery, and the use of new technology. The project Mathematics Experiences Through Image Processing at the University of Washington has developed software and learning activities that enable middle school and high school students to use mathematical tools and concepts to explore some exciting ideas of image processing. This paper describes these materials and discusses how the ideas of computer vision and pattern recognition can be integrated into the curriculum. Not only do we use 2D topics such as digital geometry and edge detection, but also 3D topics such as surface construction and stereogram generation.}
}

@article{tanimotoConnectingMiddleSchool1998a,
  title = {Connecting Middle School Mathematics to Computer Vision and Pattern Recognition},
  author = {Tanimoto, S.L.},
  date = {1998},
  journaltitle = {International Journal of Pattern Recognition and Artificial Intelligence},
  volume = {12},
  number = {8},
  pages = {1053--1070},
  doi = {10.1142/S0218001498000592},
  abstract = {The subject matter of computer vision and pattern recognition can play a useful role in the education of mathematics for students in middle school. New standards in education call for new content relevant to students' lives, and new pedagogical methods involving construction, group work, discovery, and the use of new technology. The project Mathematics Experiences Through Image Processing at the University of Washington has developed software and learning activities that enable middle school and high school students to use mathematical tools and concepts to explore some exciting ideas of image processing. This paper describes these materials and discusses how the ideas of computer vision and pattern recognition can be integrated into the curriculum. Not only do we use 2D topics such as digital geometry and edge detection, but also 3D topics such as surface construction and stereogram generation.}
}

@inproceedings{tarinFinansparkenBjergstedInnovative2019,
  title = {Finansparken {{Bjergsted}}: {{An}} Innovative Timber-Framed Office Building},
  booktitle = {{{IASS Symposium}} 2019 - 60th {{Anniversary Symposium}} of the {{International Association}} for {{Shell}} and {{Spatial Structures}}; {{Structural Membranes}} 2019 - 9th {{International Conference}} on {{Textile Composites}} and {{Inflatable Structures}}, {{FORM}} and {{FORCE}}},
  author = {Tarin, P. and Overton, K. and Sánchez-Solís, M. and Rando, M. and Ibáñez, F.},
  date = {2019},
  pages = {2903--2910},
  abstract = {Finansparken Bjergsted is an office building currently under construction in Stavanger, Norway, for SR-Bank. The structural system above ground level uses timber as the principal load bearing elements (a natural, renewable and readily available local material). Floors are cross-laminated timber (CLT) panels supported by glued laminated timber (GL) beams and columns. For strength and complex geometrical requirements, laminated veneer lumber (LVL) made of beech is also used. The three basement levels and the four communications and services cores are of reinforced concrete. Mass timber structural elements are engineered for strength and are prefabricated with strict tolerances for a rapid construction process using mainly direct contact timber connections, without metal fasteners. The beams are shaped and fabricated with openings to suit both the architectural aesthetics and services requirements by means of a fully integrated BIM system.},
  isbn = {978-84-12-11010-4}
}

@inproceedings{tarinFinansparkenBjergstedInnovative2019a,
  title = {Finansparken {{Bjergsted}}: {{An}} Innovative Timber-Framed Office Building},
  booktitle = {{{IASS Symposium}} 2019 - 60th {{Anniversary Symposium}} of the {{International Association}} for {{Shell}} and {{Spatial Structures}}; {{Structural Membranes}} 2019 - 9th {{International Conference}} on {{Textile Composites}} and {{Inflatable Structures}}, {{FORM}} and {{FORCE}}},
  author = {Tarin, P. and Overton, K. and Sánchez-Solís, M. and Rando, M. and Ibáñez, F.},
  date = {2019},
  pages = {2903--2910},
  abstract = {Finansparken Bjergsted is an office building currently under construction in Stavanger, Norway, for SR-Bank. The structural system above ground level uses timber as the principal load bearing elements (a natural, renewable and readily available local material). Floors are cross-laminated timber (CLT) panels supported by glued laminated timber (GL) beams and columns. For strength and complex geometrical requirements, laminated veneer lumber (LVL) made of beech is also used. The three basement levels and the four communications and services cores are of reinforced concrete. Mass timber structural elements are engineered for strength and are prefabricated with strict tolerances for a rapid construction process using mainly direct contact timber connections, without metal fasteners. The beams are shaped and fabricated with openings to suit both the architectural aesthetics and services requirements by means of a fully integrated BIM system.},
  isbn = {978-84-12-11010-4}
}

@article{tenorthRepresentationsRobotKnowledge2017,
  title = {Representations for Robot Knowledge in the {{KnowRob}} Framework},
  author = {Tenorth, Moritz and Beetz, Michael},
  date = {2017-06},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {247},
  pages = {151--169},
  issn = {00043702},
  doi = {10.1016/j.artint.2015.05.010},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370215000843},
  urldate = {2023-03-23},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\PQ78KV8V\Tenorth and Beetz - 2017 - Representations for robot knowledge in the KnowRob.pdf}
}

@inproceedings{teradaNoticeRemovalWearable2015,
  title = {Notice of {{Removal}}: {{Wearable EEG-based}} Human Intention Detection and Its Application in Human Care-Robot Systems},
  booktitle = {2015 54th {{Annual Conference}} of the {{Society}} of {{Instrument}} and {{Control Engineers}} of {{Japan}}, {{SICE}} 2015},
  author = {Terada, S. and Luo, Z.},
  date = {2015},
  pages = {91--94},
  doi = {10.1109/SICE.2015.7285441},
  abstract = {This research developed a wearable EEG-based brain robot interface (WE-BRI) which detects the human subject's intention using steady-state visual evoked potential (SSVEP) and is applied in the food care tasks of robots. In detail, five types of visual stimuli with different frequencies are displayed on the different locations of a PC monitor. The human subject can select his/her intended food by focusing on a related specific visual stimulus for several seconds. A wearable EEG sensor then measures the subject's EEG and followed by on line frequency analysis. From the frequency analysis, the robot can detect the human subject's intention within limited time and can perform the task to move the related food to the subject. In this research, 5 health subjects are tested using this WE-BRI. It is found that in order to increase the success rate of intention detection, the subject should focus on a specific visual stimulus for more than 4 seconds. The highest success rate of the detection can reach to 92\%. The developed WE-BRI is also expected to be applied in wider range of robotic human care tasks.},
  isbn = {978-4-907764-48-7}
}

@inproceedings{teradaNoticeRemovalWearable2015a,
  title = {Notice of {{Removal}}: {{Wearable EEG-based}} Human Intention Detection and Its Application in Human Care-Robot Systems},
  booktitle = {2015 54th {{Annual Conference}} of the {{Society}} of {{Instrument}} and {{Control Engineers}} of {{Japan}}, {{SICE}} 2015},
  author = {Terada, S. and Luo, Z.},
  date = {2015},
  pages = {91--94},
  doi = {10.1109/SICE.2015.7285441},
  abstract = {This research developed a wearable EEG-based brain robot interface (WE-BRI) which detects the human subject's intention using steady-state visual evoked potential (SSVEP) and is applied in the food care tasks of robots. In detail, five types of visual stimuli with different frequencies are displayed on the different locations of a PC monitor. The human subject can select his/her intended food by focusing on a related specific visual stimulus for several seconds. A wearable EEG sensor then measures the subject's EEG and followed by on line frequency analysis. From the frequency analysis, the robot can detect the human subject's intention within limited time and can perform the task to move the related food to the subject. In this research, 5 health subjects are tested using this WE-BRI. It is found that in order to increase the success rate of intention detection, the subject should focus on a specific visual stimulus for more than 4 seconds. The highest success rate of the detection can reach to 92\%. The developed WE-BRI is also expected to be applied in wider range of robotic human care tasks.},
  isbn = {978-4-907764-48-7}
}

@article{Thomaz2016105,
  title = {Computational Human-Robot Interaction},
  author = {Thomaz, A. and Hoffman, G. and Cakmak, M.},
  date = {2016},
  journaltitle = {Foundations and Trends in Robotics},
  volume = {4},
  number = {2-3},
  pages = {105--223}
}

@article{tianConstructionMotionData2022,
  title = {Construction Motion Data Library: An Integrated Motion Dataset for on-Site Activity Recognition},
  author = {Tian, Yuanyuan and Li, Heng and Cui, Hongzhi and Chen, Jiayu},
  date = {2022-12},
  journaltitle = {Scientific Data},
  volume = {9},
  number = {1},
  eprint = {36435886},
  eprinttype = {pmid},
  publisher = {{Nature Research}},
  issn = {20524463},
  doi = {10.1038/s41597-022-01841-1},
  abstract = {Identifying workers’ activities is crucial for ensuring the safety and productivity of the human workforce on construction sites. Many studies implement vision-based or inertial-based sensors to construct 3D human skeletons for automated postures and activity recognition. Researchers have developed enormous and heterogeneous datasets for generic motion and artificially intelligent models based on these datasets. However, the construction-related motion dataset and labels should be specifically designed, as construction workers are often exposed to awkward postures and intensive physical tasks. This study developed a small construction-related activity dataset with an in-lab experiment and implemented the datasets to manually label a large-scale construction motion data library (CML) for activity recognition. The developed CML dataset contains 225 types of activities and 146,480 samples; among them, 60 types of activities and 61,275 samples are highly related to construction activities. To verify the dataset, five widely applied deep learning algorithms were adopted to examine the dataset, and the usability, quality, and sufficiency were reported. The average accuracy of models without tunning can reach 74.62\% to 83.92\%.}
}

@article{tianConstructionMotionData2022a,
  title = {Construction Motion Data Library: An Integrated Motion Dataset for on-Site Activity Recognition},
  author = {Tian, Yuanyuan and Li, Heng and Cui, Hongzhi and Chen, Jiayu},
  date = {2022-12-01},
  journaltitle = {Scientific Data},
  volume = {9},
  number = {1},
  eprint = {36435886},
  eprinttype = {pmid},
  publisher = {{Nature Research}},
  issn = {20524463},
  doi = {10.1038/s41597-022-01841-1},
  abstract = {Identifying workers’ activities is crucial for ensuring the safety and productivity of the human workforce on construction sites. Many studies implement vision-based or inertial-based sensors to construct 3D human skeletons for automated postures and activity recognition. Researchers have developed enormous and heterogeneous datasets for generic motion and artificially intelligent models based on these datasets. However, the construction-related motion dataset and labels should be specifically designed, as construction workers are often exposed to awkward postures and intensive physical tasks. This study developed a small construction-related activity dataset with an in-lab experiment and implemented the datasets to manually label a large-scale construction motion data library (CML) for activity recognition. The developed CML dataset contains 225 types of activities and 146,480 samples; among them, 60 types of activities and 61,275 samples are highly related to construction activities. To verify the dataset, five widely applied deep learning algorithms were adopted to examine the dataset, and the usability, quality, and sufficiency were reported. The average accuracy of models without tunning can reach 74.62\% to 83.92\%.},
  file = {C:\Users\leemar\Zotero\storage\TF48I7E2\s41597-022-01841-1.pdf}
}

@article{tibuzziRevisitingStereotomicPrinciples2018,
  title = {Revisiting {{Stereotomic Principles}} in {{Contemporary AEC Practice}}},
  author = {Tibuzzi, E.},
  date = {2018},
  journaltitle = {Nexus Network Journal},
  volume = {20},
  number = {3},
  pages = {693--705},
  doi = {10.1007/s00004-018-0406-8},
  abstract = {The past 15 years have been characterised by constant technological and digital innovations, and, as a consequence, computer science has evolved past its academic and elitist status to become the common language adopted by professionals in many fields, revolutionising the methods and tools, and even creating new industries and markets. This shift permeated the architectural and construction industry, dramatically influencing the form and function of modern buildings. Stereotomy, one of the most fascinating and complex techniques in the history of pre-modern architecture, captures best the potential of being able to use digital design to integrate architectural form, structural integrity and environmental performance in a single multi-performative “skin”. The intention of the following text is to highlight some application of new digital technologies in real life projects that fundamentally have a close link to the traditional stereotomic principles of “solid cutting” (Fallacara and Barberio in Handbook of research on form and morphogenesis in modern architectural contexts. IGI Global, Hershey, 2017).}
}

@article{tibuzziRevisitingStereotomicPrinciples2018a,
  title = {Revisiting {{Stereotomic Principles}} in {{Contemporary AEC Practice}}},
  author = {Tibuzzi, E.},
  date = {2018},
  journaltitle = {Nexus Network Journal},
  volume = {20},
  number = {3},
  pages = {693--705},
  doi = {10.1007/s00004-018-0406-8},
  abstract = {The past 15 years have been characterised by constant technological and digital innovations, and, as a consequence, computer science has evolved past its academic and elitist status to become the common language adopted by professionals in many fields, revolutionising the methods and tools, and even creating new industries and markets. This shift permeated the architectural and construction industry, dramatically influencing the form and function of modern buildings. Stereotomy, one of the most fascinating and complex techniques in the history of pre-modern architecture, captures best the potential of being able to use digital design to integrate architectural form, structural integrity and environmental performance in a single multi-performative “skin”. The intention of the following text is to highlight some application of new digital technologies in real life projects that fundamentally have a close link to the traditional stereotomic principles of “solid cutting” (Fallacara and Barberio in Handbook of research on form and morphogenesis in modern architectural contexts. IGI Global, Hershey, 2017).}
}

@inproceedings{tomczykContributionActiveContour2007,
  title = {Contribution of Active Contour Approach to Image Understanding},
  booktitle = {Proceedings of the 2007 {{IEEE International Workshop}} on {{Imaging Systems}} and {{Techniques}}, {{IST}}'07},
  author = {Tomczyk, A. and Szczepaniak, P. S.},
  date = {2007},
  doi = {10.1109/ist.2007.379598},
  abstract = {The paper proposes a formal, though a simple, model of the activity of human vision system. That model serves as a reference point for description of relational and contextual recognition and allows to formulate a definition of image understanding problem. As a potential solution of that problem active contour methods are proposed, which do not possess some limitations of classic recognition algorithms. Moreover, they can be used not only as methods of construction of contextual pixel classifiers, but also as methods of identification of relations between any arbitrary more complicated structures (concepts). ©2007 IEEE.},
  isbn = {978-1-4244-0965-5}
}

@inproceedings{tomczykContributionActiveContour2007a,
  title = {Contribution of Active Contour Approach to Image Understanding},
  booktitle = {Proceedings of the 2007 {{IEEE International Workshop}} on {{Imaging Systems}} and {{Techniques}}, {{IST}}'07},
  author = {Tomczyk, A. and Szczepaniak, P.S.},
  date = {2007},
  doi = {10.1109/ist.2007.379598},
  abstract = {The paper proposes a formal, though a simple, model of the activity of human vision system. That model serves as a reference point for description of relational and contextual recognition and allows to formulate a definition of image understanding problem. As a potential solution of that problem active contour methods are proposed, which do not possess some limitations of classic recognition algorithms. Moreover, they can be used not only as methods of construction of contextual pixel classifiers, but also as methods of identification of relations between any arbitrary more complicated structures (concepts). ©2007 IEEE.},
  isbn = {978-1-4244-0965-5}
}

@article{torabiTwoDimensionalThreeDimensionalCNNBased2022,
  title = {Two-{{Dimensional}} and {{Three-Dimensional CNN-Based Simultaneous Detection}} and {{Activity Classification}} of {{Construction Workers}}},
  author = {Torabi, Ghazaleh and Hammad, Amin and Bouguila, Nizar},
  date = {2022-07},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {36},
  number = {4},
  issn = {0887-3801},
  doi = {10.1061/(ASCE)CP.1943-5487.0001024},
  url = {https://ascelibrary.org/doi/10.1061/%28ASCE%29CP.1943-5487.0001024},
  abstract = {The type and duration of construction workers' activities are useful information for project management purposes. Therefore, several studies have used surveillance cameras and computer vision to automate the time-consuming process of manually gathering this information. However, the three-stage method they have adopted consisting of separate detection, tracking, and activity classification modules is not fully optimized. Additionally, the activity classification module is trained per-clip/segment on trimmed video clips and fails when applied to long untrimmed construction videos. This paper aims to (1) investigate the benefits of a fully optimized method such as you only watch once (YOWO) and a per-frame and per-worker annotated untrimmed data set over the previous approach for activity recognition of construction workers; (2) propose an improved version of YOWO, called YOWO53, to improve detection performance; (3) propose a semiautomatic data set annotation; (4) conduct a sensitivity analysis to compare the performance of YOWO, YOWO53, and the three-stage method; and (5) conduct a case study to compute the percentage of different workers' activities. YOWO53 improves the detection recall of YOWO by up to 3\%, and the classification accuracy of the three-stage method by 16.3\%. Although YOWO53 has a lower inference speed, it is still sufficiently fast for productivity analysis.}
}

@article{torabiTwoDimensionalThreeDimensionalCNNBased2022a,
  title = {Two-{{Dimensional}} and {{Three-Dimensional CNN-Based Simultaneous Detection}} and {{Activity Classification}} of {{Construction Workers}}},
  author = {Torabi, Ghazaleh and Hammad, Amin and Bouguila, Nizar},
  date = {2022-07},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {36},
  number = {4},
  issn = {0887-3801},
  doi = {10.1061/(ASCE)CP.1943-5487.0001024},
  url = {https://ascelibrary.org/doi/10.1061/%28ASCE%29CP.1943-5487.0001024},
  abstract = {The type and duration of construction workers' activities are useful information for project management purposes. Therefore, several studies have used surveillance cameras and computer vision to automate the time-consuming process of manually gathering this information. However, the three-stage method they have adopted consisting of separate detection, tracking, and activity classification modules is not fully optimized. Additionally, the activity classification module is trained per-clip/segment on trimmed video clips and fails when applied to long untrimmed construction videos. This paper aims to (1) investigate the benefits of a fully optimized method such as you only watch once (YOWO) and a per-frame and per-worker annotated untrimmed data set over the previous approach for activity recognition of construction workers; (2) propose an improved version of YOWO, called YOWO53, to improve detection performance; (3) propose a semiautomatic data set annotation; (4) conduct a sensitivity analysis to compare the performance of YOWO, YOWO53, and the three-stage method; and (5) conduct a case study to compute the percentage of different workers' activities. YOWO53 improves the detection recall of YOWO by up to 3\%, and the classification accuracy of the three-stage method by 16.3\%. Although YOWO53 has a lower inference speed, it is still sufficiently fast for productivity analysis.},
  file = {C:\Users\leemar\Zotero\storage\3RIXPQ7T\%28ASCE%29CP.1943-5487.0001024.pdf}
}

@inproceedings{trombettaHumanIntentionEstimation2020,
  title = {Human Intention Estimation Using Fusion of Pupil and Hand Motion},
  booktitle = {{{IFAC-PapersOnLine}}},
  author = {Trombetta, D. and Rotithor, G. S. and Salehi, I. and Dani, A. P.},
  date = {2020},
  volume = {53},
  pages = {9535--9540},
  doi = {10.1016/j.ifacol.2020.12.2431},
  abstract = {This paper addresses the problem of human intention inference in the context of human-robot collaboration by fusing information from both hand motion obtained using skeletal tracking and eye gaze obtained using pupil tracking to predict a human's current intention. Intention is modeled as a motion profile that converges to a goal location. A Kalman filter is used on eye gaze data to obtain gaze point estimates. The gaze estimates are transformed into a reference frame common to the hand data. An IMM filter that tracks hand motion is designed which takes advantage of the gaze filter's model probabilities by fusing them with its own. The fusion is performed with user chosen parameters that determine the degree to which each filter's predictions are weighed over time. An experiment is designed to show the utility of the proposed algorithm in a setting in which multiple reaching tasks are completed in an unknown order. The results show that the proposed algorithm can accurately predict the human's intention before the tasks are completed.}
}

@inproceedings{trombettaHumanIntentionEstimation2020a,
  title = {Human Intention Estimation Using Fusion of Pupil and Hand Motion},
  booktitle = {{{IFAC-PapersOnLine}}},
  author = {Trombetta, D. and Rotithor, G.S. and Salehi, I. and Dani, A.P.},
  date = {2020},
  volume = {53},
  pages = {9535--9540},
  doi = {10.1016/j.ifacol.2020.12.2431},
  abstract = {This paper addresses the problem of human intention inference in the context of human-robot collaboration by fusing information from both hand motion obtained using skeletal tracking and eye gaze obtained using pupil tracking to predict a human's current intention. Intention is modeled as a motion profile that converges to a goal location. A Kalman filter is used on eye gaze data to obtain gaze point estimates. The gaze estimates are transformed into a reference frame common to the hand data. An IMM filter that tracks hand motion is designed which takes advantage of the gaze filter's model probabilities by fusing them with its own. The fusion is performed with user chosen parameters that determine the degree to which each filter's predictions are weighed over time. An experiment is designed to show the utility of the proposed algorithm in a setting in which multiple reaching tasks are completed in an unknown order. The results show that the proposed algorithm can accurately predict the human's intention before the tasks are completed.}
}

@article{tsarouchiHumanrobotCollaborationAssembly2017,
  title = {On a Human-Robot Collaboration in an Assembly Cell},
  author = {Tsarouchi, Panagiota and Matthaiakis, Alexandros-Stereos and Makris, Sotiris and Chryssolouris, George},
  date = {2017-06-03},
  journaltitle = {International Journal of Computer Integrated Manufacturing},
  shortjournal = {International Journal of Computer Integrated Manufacturing},
  volume = {30},
  number = {6},
  pages = {580--589},
  issn = {0951-192X, 1362-3052},
  doi = {10.1080/0951192X.2016.1187297},
  url = {https://www.tandfonline.com/doi/full/10.1080/0951192X.2016.1187297},
  urldate = {2023-06-07},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\MWCHWBXR\Tsarouchi et al. - 2017 - On a human-robot collaboration in an assembly cell.pdf}
}

@article{tuliKnowledgeBasedDigitalTwin2021,
  title = {Knowledge-{{Based Digital Twin}} for {{Predicting Interactions}} in {{Human-Robot Collaboration}}},
  author = {Tuli, Tadele Belay and Kohl, Linus and Chala, Sisay Adugna and Manns, Martin and Ansari, Fazel},
  date = {2021},
  journaltitle = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
  volume = {2021-Septe},
  publisher = {{IEEE}},
  issn = {19460759},
  doi = {10.1109/ETFA45728.2021.9613342},
  abstract = {Semantic representation of motions in a human-robot collaborative environment is essential for agile design and development of digital twins (DT) towards ensuring efficient collaboration between humans and robots in hybrid work systems, e.g., in assembly operations. Dividing activities into actions helps to further conceptualize motion models for predicting what a human intends to do in a hybrid work system. However, it is not straightforward to identify human intentions in collaborative operations for robots to understand and collaborate. This paper presents a concept for semantic representation of human actions and intention prediction using a flexible task ontology interface in the semantic data hub stored in a domain knowledge base. This semantic data hub enables the construction of a DT with corresponding reasoning and simulation algorithms. Furthermore, a knowledge-based DT concept is used to analyze and verify the presented use-case of Human-Robot Collaboration in assembly operations. The preliminary evaluation showed a promising reduction of time for assembly tasks, which identifies the potential to i) improve efficiency reflected by reducing costs and errors and ultimately ii) assist human workers in improving decision making. Thus the contribution of the current work involves a marriage of machine learning, robotics, and ontology engineering into DT to improve human-robot interaction and productivity in a collaborative production environment.},
  isbn = {9781728129891},
  keywords = {Digital twin,Human action models,Human-robot interaction,Machine learning,Ontology}
}

@article{tuliKnowledgeBasedDigitalTwin2021a,
  title = {Knowledge-{{Based Digital Twin}} for {{Predicting Interactions}} in {{Human-Robot Collaboration}}},
  author = {Tuli, Tadele Belay and Kohl, Linus and Chala, Sisay Adugna and Manns, Martin and Ansari, Fazel},
  date = {2021},
  journaltitle = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
  volume = {2021-Septe},
  publisher = {{IEEE}},
  issn = {19460759},
  doi = {10.1109/ETFA45728.2021.9613342},
  abstract = {Semantic representation of motions in a human-robot collaborative environment is essential for agile design and development of digital twins (DT) towards ensuring efficient collaboration between humans and robots in hybrid work systems, e.g., in assembly operations. Dividing activities into actions helps to further conceptualize motion models for predicting what a human intends to do in a hybrid work system. However, it is not straightforward to identify human intentions in collaborative operations for robots to understand and collaborate. This paper presents a concept for semantic representation of human actions and intention prediction using a flexible task ontology interface in the semantic data hub stored in a domain knowledge base. This semantic data hub enables the construction of a DT with corresponding reasoning and simulation algorithms. Furthermore, a knowledge-based DT concept is used to analyze and verify the presented use-case of Human-Robot Collaboration in assembly operations. The preliminary evaluation showed a promising reduction of time for assembly tasks, which identifies the potential to i) improve efficiency reflected by reducing costs and errors and ultimately ii) assist human workers in improving decision making. Thus the contribution of the current work involves a marriage of machine learning, robotics, and ontology engineering into DT to improve human-robot interaction and productivity in a collaborative production environment.},
  isbn = {9781728129891},
  keywords = {Digital twin,Human action models,Human-robot interaction,Machine learning,Ontology},
  file = {C:\Users\leemar\Zotero\storage\2RZV3LT8\Knowledge-Based_Digital_Twin_for_Predicting_Interactions_in_Human-Robot_Collaboration.pdf}
}

@article{tuoAdvancesProspectsWood2021,
  title = {Advances and Prospects of Wood Identification Technology Coupled with Computer Vision},
  author = {Tuo, H. and Shoujia, L. and Yang, L. and Lichao, J. and Yafang, Y.},
  date = {2021},
  journaltitle = {Journal of Forestry Engineering},
  volume = {6},
  number = {3},
  pages = {18--27},
  doi = {10.13360/j.issn.2096-1359.202007014},
  abstract = {Forests house over half of the world's wild plant and animal species, and produce valuable forest products for human. The over-exploitation of forest products poses huge threats to global biodiversity and ecosystem. China is one of the world's largest countries in the production, trade and consumption of forest products, and consequently, causes a broad concern all over the world. However, in the trade of wood and wood products, there are often mixtures of fakes and adulterants, which brings severe challenges to implementation and enforcement of international convention, and the supervision of the forest products industry. The critical step for implementation of international convention and national supervision of wood and wood products is definition identification of wood species. Traditional wood identifi cation methods are based on wood anatomy, which generally can only identify wood to the "genus" or "class" level. Although other emerging wood identification technologies, i.e. DNA barcoding, near infrared spectroscopy can exam ine the "species" level of wood, it remains challenging to realize the automatic and accurate identification of a large number of samples at ports or on sites for filed screening of wood species, where the illegal activities of wood and wood products often happens. With the rapid development of computer technology in past decades, computer vision recognition technology could be deployed to extract key features from images of different classes for classification tasks, which brings an alternative approach for wood species identification. This study reviews the developments and applications of computer vision recognition technology for wood species identification. The research progress of tradi tional computer vision recognition technology for wood species identifications, including image acquisition, feature extraction and tree species classification, are reviewed. Additionally, the research advances and applications of com puter vision recognition technology based on deep learning for wood species identification are further reviewed with multiple aspects, i.e. image data set establishment, model construction, training, and testing, as well as system de velopment and applications. Conclusively, prospects and suggestions are proposed for the future application of comput-er vision recognition technology based on deep learning in the field of wood species identification, so as to provide scientific and technical supports for automated and accurate wood species identification.}
}

@article{tuoAdvancesProspectsWood2021a,
  title = {Advances and Prospects of Wood Identification Technology Coupled with Computer Vision},
  author = {Tuo, H. and Shoujia, L. and Yang, L. and Lichao, J. and Yafang, Y.},
  date = {2021},
  journaltitle = {Journal of Forestry Engineering},
  volume = {6},
  number = {3},
  pages = {18--27},
  doi = {10.13360/j.issn.2096-1359.202007014},
  abstract = {Forests house over half of the world's wild plant and animal species, and produce valuable forest products for human. The over-exploitation of forest products poses huge threats to global biodiversity and ecosystem. China is one of the world's largest countries in the production, trade and consumption of forest products, and consequently, causes a broad concern all over the world. However, in the trade of wood and wood products, there are often mixtures of fakes and adulterants, which brings severe challenges to implementation and enforcement of international convention, and the supervision of the forest products industry. The critical step for implementation of international convention and national supervision of wood and wood products is definition identification of wood species. Traditional wood identifi cation methods are based on wood anatomy, which generally can only identify wood to the "genus" or "class" level. Although other emerging wood identification technologies, i.e. DNA barcoding, near infrared spectroscopy can exam ine the "species" level of wood, it remains challenging to realize the automatic and accurate identification of a large number of samples at ports or on sites for filed screening of wood species, where the illegal activities of wood and wood products often happens. With the rapid development of computer technology in past decades, computer vision recognition technology could be deployed to extract key features from images of different classes for classification tasks, which brings an alternative approach for wood species identification. This study reviews the developments and applications of computer vision recognition technology for wood species identification. The research progress of tradi tional computer vision recognition technology for wood species identifications, including image acquisition, feature extraction and tree species classification, are reviewed. Additionally, the research advances and applications of com puter vision recognition technology based on deep learning for wood species identification are further reviewed with multiple aspects, i.e. image data set establishment, model construction, training, and testing, as well as system de velopment and applications. Conclusively, prospects and suggestions are proposed for the future application of comput-er vision recognition technology based on deep learning in the field of wood species identification, so as to provide scientific and technical supports for automated and accurate wood species identification.}
}

@article{tuoConstructionApplicationHumanComputer2022,
  title = {Construction and {{Application}} of a {{Human-Computer Collaborative Multimodal Practice Teaching Model}} for {{Preschool Education}}},
  author = {Tuo, M. and Long, B.},
  date = {2022},
  journaltitle = {Computational intelligence and neuroscience},
  volume = {2022},
  pages = {2973954},
  doi = {10.1155/2022/2973954},
  abstract = {This paper adopts the multimodal approach of human-computer collaboration to conduct an in-depth study and analysis of the practical teaching model of preschool education, and applies the designed model to the actual teaching process. The application of multimodal theory to preschool teaching is chosen to theoretically help expand the research scope of multimodal theory and enrich the research of preschool teaching, and practically help break through the previous single-modal teaching model, further enrich the theoretical guidance of preschool teaching, and improve the quality of preschool classroom teaching. Then, from the perspective of human-machine synergy, this paper analyzes the advantages of artificial intelligence technology and teachers in the English classroom, puts forward the new roles of teachers and learners in the human-computer cooperation teaching environment, and discusses the significance and value of applying the four main modules of human-computer cooperation teaching, human-computer gesture mapping and human-computer cooperation manipulator control in the preschool classroom. According to the physical structure of hand joints, the human hand joint angles are obtained through the inverse kinematic solution, and the human hand joint angles correspond to the dexterous manipulator one by one so that the dexterous manipulator can be controlled to imitate the human hand to complete flexible gesture movements and realize the vision-based collaborative human-machine control of the dexterous manipulator. Combined with Gagne's nine teaching events, a model of the English teaching process based on human-computer collaboration was constructed. Based on this model, the "EasyDotWise English Teaching System" was designed to combine the basic lesson types of preschool classroom teaching and the secondary objectives of the English curriculum standards, including "reading text-reading aloud evaluation," "playing speech-sound recognition," and "presenting text-selection." We designed and implemented three types of teaching activities: "reading text-reading aloud assessment," "playing phonetic sounds-sound identification," and "presenting text-comprehension selection."}
}

@article{tuoConstructionApplicationHumanComputer2022a,
  title = {Construction and {{Application}} of a {{Human-Computer Collaborative Multimodal Practice Teaching Model}} for {{Preschool Education}}},
  author = {Tuo, M. and Long, B.},
  date = {2022},
  journaltitle = {Computational intelligence and neuroscience},
  volume = {2022},
  pages = {2973954},
  doi = {10.1155/2022/2973954},
  abstract = {This paper adopts the multimodal approach of human-computer collaboration to conduct an in-depth study and analysis of the practical teaching model of preschool education, and applies the designed model to the actual teaching process. The application of multimodal theory to preschool teaching is chosen to theoretically help expand the research scope of multimodal theory and enrich the research of preschool teaching, and practically help break through the previous single-modal teaching model, further enrich the theoretical guidance of preschool teaching, and improve the quality of preschool classroom teaching. Then, from the perspective of human-machine synergy, this paper analyzes the advantages of artificial intelligence technology and teachers in the English classroom, puts forward the new roles of teachers and learners in the human-computer cooperation teaching environment, and discusses the significance and value of applying the four main modules of human-computer cooperation teaching, human-computer gesture mapping and human-computer cooperation manipulator control in the preschool classroom. According to the physical structure of hand joints, the human hand joint angles are obtained through the inverse kinematic solution, and the human hand joint angles correspond to the dexterous manipulator one by one so that the dexterous manipulator can be controlled to imitate the human hand to complete flexible gesture movements and realize the vision-based collaborative human-machine control of the dexterous manipulator. Combined with Gagne's nine teaching events, a model of the English teaching process based on human-computer collaboration was constructed. Based on this model, the "EasyDotWise English Teaching System" was designed to combine the basic lesson types of preschool classroom teaching and the secondary objectives of the English curriculum standards, including "reading text-reading aloud evaluation," "playing speech-sound recognition," and "presenting text-selection." We designed and implemented three types of teaching activities: "reading text-reading aloud assessment," "playing phonetic sounds-sound identification," and "presenting text-comprehension selection."}
}

@article{ulhoiEmergenceSocialRobots2022,
  title = {The Emergence of Social Robots: {{Adding}} Physicality and Agency to Technology},
  shorttitle = {The Emergence of Social Robots},
  author = {Ulhøi, John P. and Nørskov, Sladjana},
  date = {2022-07},
  journaltitle = {Journal of Engineering and Technology Management},
  shortjournal = {Journal of Engineering and Technology Management},
  volume = {65},
  pages = {101703},
  issn = {09234748},
  doi = {10.1016/j.jengtecman.2022.101703},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0923474822000339},
  urldate = {2023-03-15},
  abstract = {This Perspective Paper discusses a special case of digitalization, namely social robots. Adding sociophysical and agentic properties to robots is likely to trigger new organizational and work dynamics. Despite high market expectations and increasing interest in robotics-related and broader interdisciplinary outlets, robotic technologies have attracted surprisingly little attention in the leading management outlets, thus leaving a gap in existing high-impact management literature. This paper tries to fill in some of this void by discussing the commercial relevance of robotics and by identifying three main roles that social robots fulfill in real-life organizations. These roles set the directions for future and rigorous studies. Practical and policy implications identify some concerns relevant for decision-makers who seek to shape and steer robotics development and implementation.},
  langid = {english},
  file = {/Volumes/WIP/library/1-s2.0-S0923474822000339-main.pdf}
}

@article{umarApplicationStructuralBuilding2016,
  title = {Application of Structural Building Information Modeling ({{S-BIM}}) for Sustainable Buildings Design and Waste Reduction: {{A}} Review},
  author = {Umar, U.A. and Shafiq, N. and Malakahmad, A. and Nuruddin, M.F. and Farhan, S.A. and Salihi, I.U.},
  date = {2016},
  journaltitle = {International Journal of Applied Engineering Research},
  volume = {11},
  number = {2},
  pages = {1523--1532},
  abstract = {Strategies of sustainable reasoning are in many ways historical. When buildings from some of the indigenous cultures are examined, it can be easily observed that they were highly competent at adapting the location and materials of the structures to the climate. As time passes and civilizations grew static, buildings took on different values. Structural Building Information Modeling (S-BIM) enables structural engineers and designers to develop structural models for steel, concrete and timber buildings with flexibility; examine engineering alternatives; create smarter well-informed design decisions; and anticipate costs and overall performance. By using Building Information Modeling (BIM), pre-requisites for drawings are reduced. Technical details are regularly updated and easily obtained from the model, which provide designers the platform to resolve design issues and allow team members access to view the plans. BIM stores data for all aspects of the building, which include structural; architectural; mechanical, electrical and plumbing (MEP); and landscape data before and during post-construction phases. The paper reviews advantages of S-BIM application for sustainable building design and waste reduction as acknowledged by experts from the construction industry and recommends anticipated outcomes for improvement to the Architecture, Engineering and Construction (AEC) industry.}
}

@article{umarApplicationStructuralBuilding2016a,
  title = {Application of Structural Building Information Modeling ({{S-BIM}}) for Sustainable Buildings Design and Waste Reduction: {{A}} Review},
  author = {Umar, U.A. and Shafiq, N. and Malakahmad, A. and Nuruddin, M.F. and Farhan, S.A. and Salihi, I.U.},
  date = {2016},
  journaltitle = {International Journal of Applied Engineering Research},
  volume = {11},
  number = {2},
  pages = {1523--1532},
  abstract = {Strategies of sustainable reasoning are in many ways historical. When buildings from some of the indigenous cultures are examined, it can be easily observed that they were highly competent at adapting the location and materials of the structures to the climate. As time passes and civilizations grew static, buildings took on different values. Structural Building Information Modeling (S-BIM) enables structural engineers and designers to develop structural models for steel, concrete and timber buildings with flexibility; examine engineering alternatives; create smarter well-informed design decisions; and anticipate costs and overall performance. By using Building Information Modeling (BIM), pre-requisites for drawings are reduced. Technical details are regularly updated and easily obtained from the model, which provide designers the platform to resolve design issues and allow team members access to view the plans. BIM stores data for all aspects of the building, which include structural; architectural; mechanical, electrical and plumbing (MEP); and landscape data before and during post-construction phases. The paper reviews advantages of S-BIM application for sustainable building design and waste reduction as acknowledged by experts from the construction industry and recommends anticipated outcomes for improvement to the Architecture, Engineering and Construction (AEC) industry.}
}

@inproceedings{Unhelkar20156183,
  title = {Human-Robot Co-Navigation Using Anticipatory Indicators of Human Walking Motion},
  author = {Unhelkar, V.V. and Pérez-D'Arpino, C. and Stirling, L. and Shah, J.A.},
  date = {2015},
  series = {Proceedings - {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  volume = {2015-June},
  number = {June},
  pages = {6183--6190},
  doi = {10.1109/ICRA.2015.7140067},
  art_number = {7140067}
}

@inproceedings{uwakwehFrameworkManagementConstruction1990,
  title = {A {{Framework}} for the {{Management}} of {{Construction Robotics}} and {{Automation}}},
  booktitle = {Proceedings of the 7th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} ({{ISARC}})},
  author = {Uwakweh, Ben Obinero},
  date = {1990-06},
  doi = {10.22260/isarc1990/0070},
  url = {http://www.iaarc.org/publications/proceedings_of_the_7th_isarc/a_framework_for_the_management_of_construction_robotics_and_automation.html}
}

@inproceedings{uwakwehFrameworkManagementConstruction1990a,
  title = {A {{Framework}} for the {{Management}} of {{Construction Robotics}} and {{Automation}}},
  booktitle = {Proceedings of the 7th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} ({{ISARC}})},
  author = {Uwakweh, Ben Obinero},
  date = {1990-06-07},
  doi = {10.22260/isarc1990/0070},
  url = {http://www.iaarc.org/publications/proceedings_of_the_7th_isarc/a_framework_for_the_management_of_construction_robotics_and_automation.html},
  file = {C:\Users\leemar\Zotero\storage\BKMCTP8B\A_framework_for_the_management_of_construction_robotics_and_automation.pdf}
}

@article{vachhaniHardwareefficientPredictioncorrectionbasedGeneralizedvoronoidiagram2008,
  title = {Hardware-Efficient Prediction-Correction-Based Generalized-Voronoi-Diagram Construction and {{FPGA}} Implementation},
  author = {Vachhani, L. and Sridharan, K.},
  date = {2008},
  journaltitle = {IEEE Transactions on Industrial Electronics},
  volume = {55},
  number = {4},
  pages = {1558--1569},
  doi = {10.1109/TIE.2008.917161},
  abstract = {Sensor-based construction of different geometric structures has been an important development in the domain of autonomous robot navigation. This paper presents a hardware-efficient scheme to construct one such geometric structure, namely, the generalized Voronoi diagram (GVD), using a prediction-and-correction strategy. In this paper, an architecture to construct the GVD for an indoor environment with multiple obstacles whose geometry and location are not known beforehand is presented. A feature of the proposed approach is that it does not involve operations that are expensive in hardware. Furthermore, no explicit angle computation circuitry is needed. An efficient architecture based on hardware reuse is presented. The design is shown to be space efficient and fits in a low-end field-programmable gate-array (FPGA) device (with a small number of system gates). Detailed experiments with a mobile robot fabricated locally with a Xilinx XC2S200E FPGA and eight ultrasonic sensors onboard validate the efficacy of the proposed approach for static as well as dynamic environments. © 2008 IEEE.}
}

@article{vachhaniHardwareefficientPredictioncorrectionbasedGeneralizedvoronoidiagram2008a,
  title = {Hardware-Efficient Prediction-Correction-Based Generalized-Voronoi-Diagram Construction and {{FPGA}} Implementation},
  author = {Vachhani, L. and Sridharan, K.},
  date = {2008},
  journaltitle = {IEEE Transactions on Industrial Electronics},
  volume = {55},
  number = {4},
  pages = {1558--1569},
  doi = {10.1109/TIE.2008.917161},
  abstract = {Sensor-based construction of different geometric structures has been an important development in the domain of autonomous robot navigation. This paper presents a hardware-efficient scheme to construct one such geometric structure, namely, the generalized Voronoi diagram (GVD), using a prediction-and-correction strategy. In this paper, an architecture to construct the GVD for an indoor environment with multiple obstacles whose geometry and location are not known beforehand is presented. A feature of the proposed approach is that it does not involve operations that are expensive in hardware. Furthermore, no explicit angle computation circuitry is needed. An efficient architecture based on hardware reuse is presented. The design is shown to be space efficient and fits in a low-end field-programmable gate-array (FPGA) device (with a small number of system gates). Detailed experiments with a mobile robot fabricated locally with a Xilinx XC2S200E FPGA and eight ultrasonic sensors onboard validate the efficacy of the proposed approach for static as well as dynamic environments. © 2008 IEEE.}
}

@article{vahdatArchitecturalEducationAge2020,
  title = {Architectural Education in the Age of the Intelligent Machine},
  author = {Vahdat, V. and Mansoori, M.},
  date = {2020},
  journaltitle = {New Design Ideas},
  volume = {4},
  number = {1},
  pages = {50--57},
  abstract = {The alliance of Robotics and Artificial Intelligence hints at a decline in the demand for architectural services in the future. On the other hand, the need to accommodate the rapid population growth around the world will inevitably change the current methods of design and construction to smarter, faster, data-driven, automated, and sustainable processes. The radical shift that architectural practice will face in the not-so-distant future, as well as the demise in the value of post-secondary education suggests that the future of architectural pedagogy will be very different from the current model. Citing the urgency of the “unprecedented social, political and ecological challenges” many have demanded a full curricular restructuring of the disciplines related to the built environment. While there is no doubt that the “content” of our contemporary architectural education is failing our students, our environment, and the generations to come, this paper looks at how the “forms” of design education will be affected by rapid technological developments.}
}

@article{vahdatArchitecturalEducationAge2020a,
  title = {Architectural Education in the Age of the Intelligent Machine},
  author = {Vahdat, V. and Mansoori, M.},
  date = {2020},
  journaltitle = {New Design Ideas},
  volume = {4},
  number = {1},
  pages = {50--57},
  abstract = {The alliance of Robotics and Artificial Intelligence hints at a decline in the demand for architectural services in the future. On the other hand, the need to accommodate the rapid population growth around the world will inevitably change the current methods of design and construction to smarter, faster, data-driven, automated, and sustainable processes. The radical shift that architectural practice will face in the not-so-distant future, as well as the demise in the value of post-secondary education suggests that the future of architectural pedagogy will be very different from the current model. Citing the urgency of the “unprecedented social, political and ecological challenges” many have demanded a full curricular restructuring of the disciplines related to the built environment. While there is no doubt that the “content” of our contemporary architectural education is failing our students, our environment, and the generations to come, this paper looks at how the “forms” of design education will be affected by rapid technological developments.}
}

@article{Valdesolo2010693,
  title = {The Rhythm of Joint Action: {{Synchrony}} Promotes Cooperative Ability},
  author = {Valdesolo, P. and Ouyang, J. and DeSteno, D.},
  date = {2010},
  journaltitle = {Journal of Experimental Social Psychology},
  volume = {46},
  number = {4},
  pages = {693--695},
  doi = {10.1016/j.jesp.2010.03.004}
}

@article{vanameijdeArchitectureMachineRevisited2019,
  title = {The Architecture Machine Revisited Experiments Exploring Computational Design-and-Build Strategies Based on Participation},
  author = {family=Ameijde, given=J., prefix=van, useprefix=true},
  date = {2019},
  journaltitle = {Spool},
  volume = {6},
  number = {1},
  pages = {17--34},
  doi = {10.7480/spool.2019.1.3890},
  abstract = {This article summarises a series of experiments at the Architectural Association between 2011 and 2017, which explore the intellectual notion of ‘the architecture machine’ as introduced by Nicholas Negroponte and the Architecture Machine Group at MIT in 1967. The group explored automated computational processes that could assist the process of generating architectural solutions by incorporating much greater levels of complexity at both large and small scales. A central idea to the mission of the Architecture Machine Group was to enable the future inhabitants to participate in the decision-making process on the spatial configurations. The group aimed to define architecture as a spatial system that could directly correlate with human social activities through the application of new computer technologies. Our research presented here focuses on technologies and workflows that trace and translate human activities into architectural structures in order to continue the research agenda set out by Negroponte and others in the 1970s. The research work discusses new scenarios for the creation of architectural structures, using mobile and low-cost fabrication devices, and generative design algorithms driven by sensory technologies. The research question focuses on how architects may script individual and unique processes for generating structures using rule-sets that organise materiality and spatial relationships in order to achieve a user-driven outcome. Our explorations follow a renewed interest in the paradigm where the architect is a ‘process designer’, aiming to generate emergent outcomes where the inherent complexity of the project is generated towards specific performance criteria related to human activities and inhabitation.}
}

@article{vanameijdeArchitectureMachineRevisited2019a,
  title = {The Architecture Machine Revisited Experiments Exploring Computational Design-and-Build Strategies Based on Participation},
  author = {family=Ameijde, given=J., prefix=van, useprefix=true},
  date = {2019},
  journaltitle = {Spool},
  volume = {6},
  number = {1},
  pages = {17--34},
  doi = {10.7480/spool.2019.1.3890},
  abstract = {This article summarises a series of experiments at the Architectural Association between 2011 and 2017, which explore the intellectual notion of ‘the architecture machine’ as introduced by Nicholas Negroponte and the Architecture Machine Group at MIT in 1967. The group explored automated computational processes that could assist the process of generating architectural solutions by incorporating much greater levels of complexity at both large and small scales. A central idea to the mission of the Architecture Machine Group was to enable the future inhabitants to participate in the decision-making process on the spatial configurations. The group aimed to define architecture as a spatial system that could directly correlate with human social activities through the application of new computer technologies. Our research presented here focuses on technologies and workflows that trace and translate human activities into architectural structures in order to continue the research agenda set out by Negroponte and others in the 1970s. The research work discusses new scenarios for the creation of architectural structures, using mobile and low-cost fabrication devices, and generative design algorithms driven by sensory technologies. The research question focuses on how architects may script individual and unique processes for generating structures using rule-sets that organise materiality and spatial relationships in order to achieve a user-driven outcome. Our explorations follow a renewed interest in the paradigm where the architect is a ‘process designer’, aiming to generate emergent outcomes where the inherent complexity of the project is generated towards specific performance criteria related to human activities and inhabitation.}
}

@article{vandisChatGPTFivePriorities2023,
  title = {{{ChatGPT}}: Five Priorities for Research},
  shorttitle = {{{ChatGPT}}},
  author = {Van Dis, Eva A. M. and Bollen, Johan and Zuidema, Willem and Van Rooij, Robert and Bockting, Claudi L.},
  date = {2023-02-09},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {614},
  number = {7947},
  pages = {224--226},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/d41586-023-00288-7},
  url = {https://www.nature.com/articles/d41586-023-00288-7},
  urldate = {2023-11-19},
  langid = {english}
}

@article{Varni2010576,
  title = {A System for Real-Time Multimodal Analysis of Nonverbal Affective Social Interaction in User-Centric Media},
  author = {Varni, G. and Volpe, G. and Camurri, A.},
  date = {2010},
  journaltitle = {IEEE Transactions on Multimedia},
  volume = {12},
  number = {6},
  pages = {576--590},
  doi = {10.1109/TMM.2010.2052592},
  art_number = {5571827}
}

@article{vartholomeosModelingGaitSequence2021,
  title = {Modeling, Gait Sequence Design, and Control Architecture of {{BADGER}} Underground Robot},
  author = {Vartholomeos, P. and Marantos, P. and Karras, G. and Menendez, E. and Rodriguez, M. and Martinez, S. and Balaguer, C.},
  date = {2021},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {1160--1167},
  doi = {10.1109/LRA.2021.3056068},
  abstract = {This letter presents the dynamic modeling, the gait sequence design, and the control architecture of the BADGER autonomous underground robot. BADGER is a modular and articulated robotic mechanism which employs inchworm biomimetic motion to drill and propel within the soil. It is used to drill and manoeuvre in the subsurface for building curved tunnels of small diameter in underground spaces, without the need for open-cut excavation. In order to design efficient motion control strategies, a model-based approach is followed. To this end, the kinematic and the lagrangian dynamic models are derived, which take into account the physical interaction of the robot drill-head with the environment, and are used for designing the inchworm gait sequence and for calculating the actuation torques and forces required to realise the trajectory profiles of the gait sequence. The motion control is executed on a simulation platform or on the actual robot hardware using a Robot Operating System (ROS) control architecture. The gait sequence and the motion controller are validated though an experiment where the BADGER is commanded to drill and follow a straight line path in the underground. The gait sequence for following a generic 3D curvilinear path in the underground is demonstrated in a simulation environment.}
}

@article{vartholomeosModelingGaitSequence2021a,
  title = {Modeling, Gait Sequence Design, and Control Architecture of {{BADGER}} Underground Robot},
  author = {Vartholomeos, P. and Marantos, P. and Karras, G. and Menendez, E. and Rodriguez, M. and Martinez, S. and Balaguer, C.},
  date = {2021},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {1160--1167},
  doi = {10.1109/LRA.2021.3056068},
  abstract = {This letter presents the dynamic modeling, the gait sequence design, and the control architecture of the BADGER autonomous underground robot. BADGER is a modular and articulated robotic mechanism which employs inchworm biomimetic motion to drill and propel within the soil. It is used to drill and manoeuvre in the subsurface for building curved tunnels of small diameter in underground spaces, without the need for open-cut excavation. In order to design efficient motion control strategies, a model-based approach is followed. To this end, the kinematic and the lagrangian dynamic models are derived, which take into account the physical interaction of the robot drill-head with the environment, and are used for designing the inchworm gait sequence and for calculating the actuation torques and forces required to realise the trajectory profiles of the gait sequence. The motion control is executed on a simulation platform or on the actual robot hardware using a Robot Operating System (ROS) control architecture. The gait sequence and the motion controller are validated though an experiment where the BADGER is commanded to drill and follow a straight line path in the underground. The gait sequence for following a generic 3D curvilinear path in the underground is demonstrated in a simulation environment.}
}

@article{vatsEarlyDetectionHuman2016,
  title = {Early Detection of Human Actions—{{A}} Hybrid Approach},
  author = {Vats, E. and Chan, C. S.},
  date = {2016},
  journaltitle = {Applied Soft Computing Journal},
  volume = {46},
  pages = {953--966},
  doi = {10.1016/j.asoc.2015.11.007},
  abstract = {Early detection of human actions is essential in a wide spectrum of applications ranging from video surveillance to health-care. While human action recognition has been extensively studied, little attention is paid to the problem of detecting ongoing human action early, i.e. detecting an action as soon as it begins, but before it finishes. This study aims at training a detector to be capable of recognizing a human action when only partial action sample is seen. To do so, a hybrid technique is proposed in this work which combines the benefits of computer vision as well as fuzzy set theory based on the fuzzy Bandler and Kohout's sub-triangle product (BK subproduct). The novelty lies in the construction of a frame-by-frame membership function for each kind of possible movement. Detection is triggered when a pre-defined threshold is reached in a suitable way. Experimental results on a publicly available dataset demonstrate the benefits and effectiveness of the proposed method.}
}

@article{vatsEarlyDetectionHuman2016a,
  title = {Early Detection of Human Actions—{{A}} Hybrid Approach},
  author = {Vats, E. and Chan, C.S.},
  date = {2016},
  journaltitle = {Applied Soft Computing Journal},
  volume = {46},
  pages = {953--966},
  doi = {10.1016/j.asoc.2015.11.007},
  abstract = {Early detection of human actions is essential in a wide spectrum of applications ranging from video surveillance to health-care. While human action recognition has been extensively studied, little attention is paid to the problem of detecting ongoing human action early, i.e. detecting an action as soon as it begins, but before it finishes. This study aims at training a detector to be capable of recognizing a human action when only partial action sample is seen. To do so, a hybrid technique is proposed in this work which combines the benefits of computer vision as well as fuzzy set theory based on the fuzzy Bandler and Kohout's sub-triangle product (BK subproduct). The novelty lies in the construction of a frame-by-frame membership function for each kind of possible movement. Detection is triggered when a pre-defined threshold is reached in a suitable way. Experimental results on a publicly available dataset demonstrate the benefits and effectiveness of the proposed method.}
}

@article{vazquezCollaborativeApproachDigital2015,
  title = {A Collaborative Approach to Digital Fabrication: {{A}} Case Study for the Design and Production of Concrete 'pop-up' Structures},
  author = {Vazquez, A.N. and Jabi, W.},
  date = {2015},
  journaltitle = {International Journal of Architectural Computing},
  volume = {13},
  number = {2},
  pages = {195--216},
  doi = {10.1260/1478-0771.13.2.195},
  abstract = {The research presented in this paper utilizes industrial robotic arms and new material technologies to model and explore a prototypical workflow for on-site robotic collaboration based on feedback loops.This workflow will ultimately allow for the construction of customized, free-form, on-site concrete structures without the need for complex formwork.The paper starts with an explanation of the relevance of collaborative robotics through history in the industry and in architecture.An argument is put forward for the need to move towards the development of collaborative processes based on feedback loops amongst the designer, the robot and the material, where they all inform each other continuously.This kind of process, with different degrees of autonomy and agency for each actor, is necessary for on-site deployment of robots.A test scenario is described using an innovative material named concrete canvas that exhibits hybrid soft fabric and rigid thin-shell tectonics.This research project illustrates the benefits of integrating information-embedded materials, masscustomization and feedback loops. Geometry scanning, parametric perforation pattern control, computational analysis and simulation, and robotic fabrication were integrated within a digital fabrication deployment scenario.The paper concludes with a detailed report of research findings and an outline for future work.}
}

@article{vazquezCollaborativeApproachDigital2015a,
  title = {A Collaborative Approach to Digital Fabrication: {{A}} Case Study for the Design and Production of Concrete 'pop-up' Structures},
  author = {Vazquez, A.N. and Jabi, W.},
  date = {2015},
  journaltitle = {International Journal of Architectural Computing},
  volume = {13},
  number = {2},
  pages = {195--216},
  doi = {10.1260/1478-0771.13.2.195},
  abstract = {The research presented in this paper utilizes industrial robotic arms and new material technologies to model and explore a prototypical workflow for on-site robotic collaboration based on feedback loops.This workflow will ultimately allow for the construction of customized, free-form, on-site concrete structures without the need for complex formwork.The paper starts with an explanation of the relevance of collaborative robotics through history in the industry and in architecture.An argument is put forward for the need to move towards the development of collaborative processes based on feedback loops amongst the designer, the robot and the material, where they all inform each other continuously.This kind of process, with different degrees of autonomy and agency for each actor, is necessary for on-site deployment of robots.A test scenario is described using an innovative material named concrete canvas that exhibits hybrid soft fabric and rigid thin-shell tectonics.This research project illustrates the benefits of integrating information-embedded materials, masscustomization and feedback loops. Geometry scanning, parametric perforation pattern control, computational analysis and simulation, and robotic fabrication were integrated within a digital fabrication deployment scenario.The paper concludes with a detailed report of research findings and an outline for future work.}
}

@article{vazquezPopupConcreteConstructions2017,
  title = {Pop-up Concrete Constructions: {{Forming}} Fabric Reinforced Concrete Sheets},
  author = {Vazquez, A.N. and Jabi, W.},
  date = {2017},
  journaltitle = {International Journal of Computational Methods and Experimental Measurements},
  volume = {5},
  number = {4},
  pages = {451--463},
  doi = {10.2495/CMEM-V5-N4-451-463},
  abstract = {New technologies and fabrication tools urge us to explore new materials and their potential for integration in architectural construction. One such material, Concrete Canvas, is explored in this paper for its hybrid characteristics that blend fabric and thin-shell tectonics. The potential of Concrete Canvas lies in its ability to modify itself from a flexible fabric that when activated with water becomes a rigid concrete structure. Combined with a digitally controlled workflow of on-site cutting and an iterative material feedback loop, the process can serve as a radical alternative to current concrete formwork fabrication techniques. This paper outlines a prototypical design process that combines a phase-changing material, physical computer simulations, robotic fabrication and scanning technologies on a feedback loop between the digital and the physical that allow for customized, free-form, on-site concrete structures to pop-up without the need of a complex formwork. In this process the architect sets the various parameters based on fabrication techniques and material properties and adjusts them iteratively in the physical and digital model during the ‘popping-up’ process until a balance between material properties, technical requirements and aesthetics is reached, exploring new potentials on digital fabrication processes. The paper outlines the proposed workflow including iterative experiments with robotic cutting of flat patterns, their ‘popping-up’ into 3D concrete shells, and material phase transitions during its forming process. The established feedback loop consisting of geometry scanning, parametric perforation pattern control, computational analysis and simulation, and robotic fabrication is described in detail. The paper concludes by exploring the potential of this process to enable a dialogue between digital architecture and the process of materialization and discusses the implications of this approach in relation to architectural design and fabrication workflows.}
}

@article{vazquezPopupConcreteConstructions2017a,
  title = {Pop-up Concrete Constructions: {{Forming}} Fabric Reinforced Concrete Sheets},
  author = {Vazquez, A.N. and Jabi, W.},
  date = {2017},
  journaltitle = {International Journal of Computational Methods and Experimental Measurements},
  volume = {5},
  number = {4},
  pages = {451--463},
  doi = {10.2495/CMEM-V5-N4-451-463},
  abstract = {New technologies and fabrication tools urge us to explore new materials and their potential for integration in architectural construction. One such material, Concrete Canvas, is explored in this paper for its hybrid characteristics that blend fabric and thin-shell tectonics. The potential of Concrete Canvas lies in its ability to modify itself from a flexible fabric that when activated with water becomes a rigid concrete structure. Combined with a digitally controlled workflow of on-site cutting and an iterative material feedback loop, the process can serve as a radical alternative to current concrete formwork fabrication techniques. This paper outlines a prototypical design process that combines a phase-changing material, physical computer simulations, robotic fabrication and scanning technologies on a feedback loop between the digital and the physical that allow for customized, free-form, on-site concrete structures to pop-up without the need of a complex formwork. In this process the architect sets the various parameters based on fabrication techniques and material properties and adjusts them iteratively in the physical and digital model during the ‘popping-up’ process until a balance between material properties, technical requirements and aesthetics is reached, exploring new potentials on digital fabrication processes. The paper outlines the proposed workflow including iterative experiments with robotic cutting of flat patterns, their ‘popping-up’ into 3D concrete shells, and material phase transitions during its forming process. The established feedback loop consisting of geometry scanning, parametric perforation pattern control, computational analysis and simulation, and robotic fabrication is described in detail. The paper concludes by exploring the potential of this process to enable a dialogue between digital architecture and the process of materialization and discusses the implications of this approach in relation to architectural design and fabrication workflows.}
}

@article{velizreyesNegotiatedMatterRobotic2019,
  title = {Negotiated Matter: A Robotic Exploration of Craft-Driven Innovation},
  author = {Veliz Reyes, A. and Jabi, W. and Gomaa, M. and Chatzivasileiadi, A. and Ahmad, L. and Wardhana, N.M.},
  date = {2019},
  journaltitle = {Architectural Science Review},
  volume = {62},
  number = {5},
  pages = {398--408},
  doi = {10.1080/00038628.2019.1651688},
  abstract = {In architectural design, crafts are often portrayed as a source of ornamental, figurative or historical inspiration. In this paper, instead, craft is framed as an open-ended process of making and material negotiations, involving material properties, diverging modes of knowledge production and representation, emergent tectonic configurations and embodied interaction with technology. By developing this framework, the paper aims to situate the exploratory nature of craft in the context of robotic architectural production. To achieve this, the paper develops a theoretical approach comprising notions of craft (Pye 1968. The nature and art of workmanship. Cambridge: Cambridge University Press), architectural tectonics (Frampton 2001. Studies in Tectonic Culture: The Poetics of Construction in Nineteenth and Twentieth Century Architecture. Cambridge, MA: MIT Press) and digital tectonics (Leach, Turnbull and Williams, 2004. Digital Tectonics. Wiley) in the context of robotic architectural production. Utilizing a mixed methods approach, the ongoing project ‘Computing Craft’ is presented as a case study illustrating the proposed framework in the context of cob construction. Finally, the project ‘Computing Craft’ instantiates the proposed framework and helps determine its applicability, impact and limitations.}
}

@article{velizreyesNegotiatedMatterRobotic2019a,
  title = {Negotiated Matter: A Robotic Exploration of Craft-Driven Innovation},
  author = {Veliz Reyes, A. and Jabi, W. and Gomaa, M. and Chatzivasileiadi, A. and Ahmad, L. and Wardhana, N.M.},
  date = {2019},
  journaltitle = {Architectural Science Review},
  volume = {62},
  number = {5},
  pages = {398--408},
  doi = {10.1080/00038628.2019.1651688},
  abstract = {In architectural design, crafts are often portrayed as a source of ornamental, figurative or historical inspiration. In this paper, instead, craft is framed as an open-ended process of making and material negotiations, involving material properties, diverging modes of knowledge production and representation, emergent tectonic configurations and embodied interaction with technology. By developing this framework, the paper aims to situate the exploratory nature of craft in the context of robotic architectural production. To achieve this, the paper develops a theoretical approach comprising notions of craft (Pye 1968. The nature and art of workmanship. Cambridge: Cambridge University Press), architectural tectonics (Frampton 2001. Studies in Tectonic Culture: The Poetics of Construction in Nineteenth and Twentieth Century Architecture. Cambridge, MA: MIT Press) and digital tectonics (Leach, Turnbull and Williams, 2004. Digital Tectonics. Wiley) in the context of robotic architectural production. Utilizing a mixed methods approach, the ongoing project ‘Computing Craft’ is presented as a case study illustrating the proposed framework in the context of cob construction. Finally, the project ‘Computing Craft’ instantiates the proposed framework and helps determine its applicability, impact and limitations.}
}

@article{Vesper2010998,
  title = {A Minimal Architecture for Joint Action},
  author = {Vesper, C. and Butterfill, S. and Knoblich, G. and Sebanz, N.},
  date = {2010},
  journaltitle = {Neural Networks},
  volume = {23},
  number = {8-9},
  pages = {998--1003},
  doi = {10.1016/j.neunet.2010.06.002}
}

@article{victorTwoRepresentationsHighdimensional2017,
  title = {Two Representations of a High-Dimensional Perceptual Space},
  author = {Victor, J. D. and Rizvi, S. M. and Conte, M. M.},
  date = {2017},
  journaltitle = {Vision Research},
  volume = {137},
  pages = {1--23},
  doi = {10.1016/j.visres.2017.05.003},
  abstract = {A perceptual space is a mental workspace of points in a sensory domain that supports similarity and difference judgments and enables further processing such as classification and naming. Perceptual spaces are present across sensory modalities; examples include colors, faces, auditory textures, and odors. Color is perhaps the best-studied perceptual space, but it is atypical in two respects. First, the dimensions of color space are directly linked to the three cone absorption spectra, but the dimensions of generic perceptual spaces are not as readily traceable to single-neuron properties. Second, generic perceptual spaces have more than three dimensions. This is important because representing each distinguishable point in a high-dimensional space by a separate neuron or population is unwieldy; combinatorial strategies may be needed to overcome this hurdle. To study the representation of a complex perceptual space, we focused on a well-characterized 10-dimensional domain of visual textures. Within this domain, we determine perceptual distances in a threshold task (segmentation) and a suprathreshold task (border salience comparison). In N = 4 human observers, we find both quantitative and qualitative differences between these sets of measurements. Quantitatively, observers’ segmentation thresholds were inconsistent with their uncertainty determined from border salience comparisons. Qualitatively, segmentation thresholds suggested that distances are determined by a coordinate representation with Euclidean geometry. Border salience comparisons, in contrast, indicated a global curvature of the space, and that distances are determined by activity patterns across broadly tuned elements. Thus, our results indicate two representations of this perceptual space, and suggest that they use differing combinatorial strategies. Significance Statement To move from sensory signals to decisions and actions, the brain carries out a sequence of transformations. An important stage in this process is the construction of a “perceptual space” – an internal workspace of sensory information that captures similarities and differences, and enables further processing, such as classification and naming. Perceptual spaces for color, faces, visual and haptic textures and shapes, sounds, and odors (among others) are known to exist. How such spaces are represented is at present unknown. Here, using visual textures as a model, we investigate this. Psychophysical measurements suggest roles for two combinatorial strategies: one based on projections onto coordinate-like axes, and one based on patterns of activity across broadly tuned elements scattered throughout the space.}
}

@article{victorTwoRepresentationsHighdimensional2017a,
  title = {Two Representations of a High-Dimensional Perceptual Space},
  author = {Victor, J.D. and Rizvi, S.M. and Conte, M.M.},
  date = {2017},
  journaltitle = {Vision Research},
  volume = {137},
  pages = {1--23},
  doi = {10.1016/j.visres.2017.05.003},
  abstract = {A perceptual space is a mental workspace of points in a sensory domain that supports similarity and difference judgments and enables further processing such as classification and naming. Perceptual spaces are present across sensory modalities; examples include colors, faces, auditory textures, and odors. Color is perhaps the best-studied perceptual space, but it is atypical in two respects. First, the dimensions of color space are directly linked to the three cone absorption spectra, but the dimensions of generic perceptual spaces are not as readily traceable to single-neuron properties. Second, generic perceptual spaces have more than three dimensions. This is important because representing each distinguishable point in a high-dimensional space by a separate neuron or population is unwieldy; combinatorial strategies may be needed to overcome this hurdle. To study the representation of a complex perceptual space, we focused on a well-characterized 10-dimensional domain of visual textures. Within this domain, we determine perceptual distances in a threshold task (segmentation) and a suprathreshold task (border salience comparison). In N~=~4 human observers, we find both quantitative and qualitative differences between these sets of measurements. Quantitatively, observers’ segmentation thresholds were inconsistent with their uncertainty determined from border salience comparisons. Qualitatively, segmentation thresholds suggested that distances are determined by a coordinate representation with Euclidean geometry. Border salience comparisons, in contrast, indicated a global curvature of the space, and that distances are determined by activity patterns across broadly tuned elements. Thus, our results indicate two representations of this perceptual space, and suggest that they use differing combinatorial strategies. Significance Statement To move from sensory signals to decisions and actions, the brain carries out a sequence of transformations. An important stage in this process is the construction of a “perceptual space” – an internal workspace of sensory information that captures similarities and differences, and enables further processing, such as classification and naming. Perceptual spaces for color, faces, visual and haptic textures and shapes, sounds, and odors (among others) are known to exist. How such spaces are represented is at present unknown. Here, using visual textures as a model, we investigate this. Psychophysical measurements suggest roles for two combinatorial strategies: one based on projections onto coordinate-like axes, and one based on patterns of activity across broadly tuned elements scattered throughout the space.}
}

@inproceedings{voroninFusionColorDepth2020,
  title = {Fusion of Color and Depth Information for Human Actions Recognition},
  booktitle = {Proceedings of {{SPIE}} - {{The International Society}} for {{Optical Engineering}}},
  author = {Voronin, V. and Zhdanova, M. and Semenishchev, E. and Zelensky, A. and Tokareva, O.},
  date = {2020},
  volume = {11423},
  doi = {10.1117/12.2560130},
  abstract = {The solution to the problem of recognizing human actions on video sequences is one of the key areas on the path to the development and implementation of computer vision systems in various spheres of life. Such areas as video surveillance systems, monitoring, contactless control interfaces, video processing as a preliminary stage of processing, etc. Most of the approaches published in the literature can be divided into two groups: approaches based on constructing a global descriptor or a description of local points, unrelated to the human skeleton; and approaches based on the construction of the feature points (joint) of the human skeleton. In most cases, only the second group of methods use depth sensors to obtain clear information about the human skeleton. While additional sources of information (such as depth sensors, thermal sensors) allow you to get more informative features, and thus increase the reliability and stability of recognition. In the article, we present the algorithm, combining information from visible cameras and depth sensors based on the PLIP model (parameterized model of logarithmic image processing) close to the perception of the human visual system, and the development of a global descriptor characterizing the action taking place in the frame. The proposed algorithm takes advantage of the fusion of various modalities that provide the construction of a more informative descriptor. Experimental results showed the effectiveness of the proposed algorithm.},
  isbn = {978-1-5106-3623-1}
}

@inproceedings{voroninFusionColorDepth2020a,
  title = {Fusion of Color and Depth Information for Human Actions Recognition},
  booktitle = {Proceedings of {{SPIE}} - {{The International Society}} for {{Optical Engineering}}},
  author = {Voronin, V. and Zhdanova, M. and Semenishchev, E. and Zelensky, A. and Tokareva, O.},
  date = {2020},
  volume = {11423},
  doi = {10.1117/12.2560130},
  abstract = {The solution to the problem of recognizing human actions on video sequences is one of the key areas on the path to the development and implementation of computer vision systems in various spheres of life. Such areas as video surveillance systems, monitoring, contactless control interfaces, video processing as a preliminary stage of processing, etc. Most of the approaches published in the literature can be divided into two groups: approaches based on constructing a global descriptor or a description of local points, unrelated to the human skeleton; and approaches based on the construction of the feature points (joint) of the human skeleton. In most cases, only the second group of methods use depth sensors to obtain clear information about the human skeleton. While additional sources of information (such as depth sensors, thermal sensors) allow you to get more informative features, and thus increase the reliability and stability of recognition. In the article, we present the algorithm, combining information from visible cameras and depth sensors based on the PLIP model (parameterized model of logarithmic image processing) close to the perception of the human visual system, and the development of a global descriptor characterizing the action taking place in the frame. The proposed algorithm takes advantage of the fusion of various modalities that provide the construction of a more informative descriptor. Experimental results showed the effectiveness of the proposed algorithm.},
  isbn = {978-1-5106-3623-1}
}

@article{wakeChatGPTEmpoweredLongStep2023,
  title = {{{ChatGPT Empowered Long-Step Robot Control}} in {{Various Environments}}: {{A Case Application}}},
  shorttitle = {{{ChatGPT Empowered Long-Step Robot Control}} in {{Various Environments}}},
  author = {Wake, Naoki and Kanehira, Atsushi and Sasabuchi, Kazuhiro and Takamatsu, Jun and Ikeuchi, Katsushi},
  date = {2023},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {11},
  pages = {95060--95078},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3310935},
  url = {https://ieeexplore.ieee.org/document/10235949/},
  urldate = {2023-11-14},
  file = {C:\Users\leemar\Zotero\storage\UW6TD933\Wake 等。 - 2023 - ChatGPT Empowered Long-Step Robot Control in Vario.pdf}
}

@article{wakisakaAutomatedConstructionSystem2000,
  title = {Automated Construction System for High-Rise Reinforced Concrete Buildings},
  author = {Wakisaka, T. and Furuya, N. and Inoue, Y. and Shiokawa, T.},
  date = {2000},
  journaltitle = {Automation in construction},
  volume = {9},
  number = {3},
  pages = {229--250},
  doi = {10.1016/S0926-5805(99)00039-4},
  abstract = {An all-weather automated construction system has been developed to reduce the total cost of high-rise reinforced concrete building construction. It was applied for the first time ever to the construction of a 26-story reinforced concrete condominium project located in the Tokyo Metropolitan area in 1995. This system incorporates four major elements: (a) a synchronously climbing all-weather temporary roof; (b) a parallel material delivery system; (c) prefabrication and unification of construction materials; and (d) a material management system. It ensures good quality; improves working and environmental conditions; reduces the construction period, manpower, and waste; and improves overall productivity.}
}

@article{wakisakaAutomatedConstructionSystem2000a,
  title = {Automated Construction System for High-Rise Reinforced Concrete Buildings},
  author = {Wakisaka, T. and Furuya, N. and Inoue, Y. and Shiokawa, T.},
  date = {2000},
  journaltitle = {Automation in construction},
  volume = {9},
  number = {3},
  pages = {229--250},
  doi = {10.1016/S0926-5805(99)00039-4},
  abstract = {An all-weather automated construction system has been developed to reduce the total cost of high-rise reinforced concrete building construction. It was applied for the first time ever to the construction of a 26-story reinforced concrete condominium project located in the Tokyo Metropolitan area in 1995. This system incorporates four major elements: (a) a synchronously climbing all-weather temporary roof; (b) a parallel material delivery system; (c) prefabrication and unification of construction materials; and (d) a material management system. It ensures good quality; improves working and environmental conditions; reduces the construction period, manpower, and waste; and improves overall productivity.}
}

@inproceedings{wangConstructionApplicationIndoor2018,
  title = {Construction and {{Application}} of {{Indoor Video Surveillance System Based}} on {{Human Activity Recognition}}},
  booktitle = {{{MATEC Web}} of {{Conferences}}},
  author = {Wang, Y. and Wang, M. and Tan, Z. and Zhang, J. and Li, Z. and Mu, J. and Zhou, Z. and Luo, L.},
  date = {2018},
  volume = {232},
  doi = {10.1051/matecconf/201823204024},
  abstract = {With the growth of building monitoring network, increasing human resource and funds have been invested into building monitoring system. Computer vision technology has been widely used in image recognition recently, and this technology has also been gradually applied to action recognition. There are still many disadvantages of traditional monitoring system. In this paper, a human activity recognition system which based on the convolution neural network is proposed. Using the 3D convolution neural network and the transfer learning technology, the human activity recognition engine is constructed. The Spring MVC framework is used to build the server end, and the system page is designed in HBuilder. The system not only enhances efficiency and functionality of building monitoring system, but also improves the level of building safety.}
}

@inproceedings{wangConstructionApplicationIndoor2018a,
  title = {Construction and {{Application}} of {{Indoor Video Surveillance System Based}} on {{Human Activity Recognition}}},
  booktitle = {{{MATEC Web}} of {{Conferences}}},
  author = {Wang, Y. and Wang, M. and Tan, Z. and Zhang, J. and Li, Z. and Mu, J. and Zhou, Z. and Luo, L.},
  date = {2018},
  volume = {232},
  doi = {10.1051/matecconf/201823204024},
  abstract = {With the growth of building monitoring network, increasing human resource and funds have been invested into building monitoring system. Computer vision technology has been widely used in image recognition recently, and this technology has also been gradually applied to action recognition. There are still many disadvantages of traditional monitoring system. In this paper, a human activity recognition system which based on the convolution neural network is proposed. Using the 3D convolution neural network and the transfer learning technology, the human activity recognition engine is constructed. The Spring MVC framework is used to build the server end, and the system page is designed in HBuilder. The system not only enhances efficiency and functionality of building monitoring system, but also improves the level of building safety.}
}

@article{wangDeepLearningSensorbased2019,
  title = {Deep Learning for Sensor-Based Activity Recognition: {{A}} Survey},
  author = {Wang, Jindong and Chen, Yiqiang and Hao, Shuji and Peng, Xiaohui and Hu, Lisha},
  date = {2019},
  journaltitle = {Pattern Recognition Letters},
  volume = {119},
  pages = {3--11},
  issn = {01678655},
  doi = {10.1016/j.patrec.2018.02.010},
  abstract = {Sensor-based activity recognition seeks the profound high-level knowledge about human activities from multitudes of low-level sensor readings. Conventional pattern recognition approaches have made tremendous progress in the past years. However, those methods often heavily rely on heuristic hand-crafted feature extraction, which could hinder their generalization performance. Additionally, existing methods are undermined for unsupervised and incremental learning tasks. Recently, the recent advancement of deep learning makes it possible to perform automatic high-level feature extraction thus achieves promising performance in many areas. Since then, deep learning based methods have been widely adopted for the sensor-based activity recognition tasks. This paper surveys the recent advance of deep learning based sensor-based activity recognition. We summarize existing literature from three aspects: sensor modality, deep model, and application. We also present detailed insights on existing work and propose grand challenges for future research.},
  keywords = {Activity recognition,Deep learning,Pattern recognition,Pervasive computing}
}

@article{wangDeepLearningSensorbased2019a,
  title = {Deep Learning for Sensor-Based Activity Recognition: {{A}} Survey},
  author = {Wang, Jindong and Chen, Yiqiang and Hao, Shuji and Peng, Xiaohui and Hu, Lisha},
  date = {2019},
  journaltitle = {Pattern Recognition Letters},
  volume = {119},
  eprint = {1707.03502},
  eprinttype = {arxiv},
  pages = {3--11},
  issn = {01678655},
  doi = {10.1016/j.patrec.2018.02.010},
  abstract = {Sensor-based activity recognition seeks the profound high-level knowledge about human activities from multitudes of low-level sensor readings. Conventional pattern recognition approaches have made tremendous progress in the past years. However, those methods often heavily rely on heuristic hand-crafted feature extraction, which could hinder their generalization performance. Additionally, existing methods are undermined for unsupervised and incremental learning tasks. Recently, the recent advancement of deep learning makes it possible to perform automatic high-level feature extraction thus achieves promising performance in many areas. Since then, deep learning based methods have been widely adopted for the sensor-based activity recognition tasks. This paper surveys the recent advance of deep learning based sensor-based activity recognition. We summarize existing literature from three aspects: sensor modality, deep model, and application. We also present detailed insights on existing work and propose grand challenges for future research.},
  keywords = {Activity recognition,Deep learning,Pattern recognition,Pervasive computing},
  file = {C:\Users\leemar\Zotero\storage\8LG3KV9Z\1707.03502.pdf}
}

@article{wangIndoorHumanFall2022,
  title = {Indoor {{Human Fall Detection Algorithm Based}} on {{Wireless Sensing}}},
  author = {Wang, C. and Tang, L. and Zhou, M. and Ding, Y. and Zhuang, X. and Wu, J.},
  date = {2022},
  journaltitle = {Tsinghua Science and Technology},
  volume = {27},
  number = {6},
  pages = {1002--1015},
  doi = {10.26599/TST.2022.9010011},
  abstract = {As the main health threat to the elderly living alone and performing indoor activities, falls have attracted great attention from institutions and society. Currently, fall detection systems are mainly based on wear sensors, environmental sensors, and computer vision, which need to be worn or require complex equipment construction. However, they have limitations and will interfere with the daily life of the elderly. On the basis of the indoor propagation theory of wireless signals, this paper proposes a conceptual verification module using Wi-Fi signals to identify human fall behavior. The module can detect falls without invading privacy and affecting human comfort and has the advantages of noninvasive, robustness, universality, and low price. The module combines digital signal processing technology and machine learning technology. This paper analyzes and processes the channel state information (CSI) data of wireless signals, and the local outlier factor algorithm is used to find the abnormal CSI sequence. The support vector machine and extreme gradient boosting algorithms are used for classification, recognition, and comparative research. Experimental results show that the average accuracy of fall detection based on wireless sensing is more than 90\%. This work has important social significance in ensuring the safety of the elderly.}
}

@article{wangIndoorHumanFall2022a,
  title = {Indoor {{Human Fall Detection Algorithm Based}} on {{Wireless Sensing}}},
  author = {Wang, C. and Tang, L. and Zhou, M. and Ding, Y. and Zhuang, X. and Wu, J.},
  date = {2022},
  journaltitle = {Tsinghua Science and Technology},
  volume = {27},
  number = {6},
  pages = {1002--1015},
  doi = {10.26599/TST.2022.9010011},
  abstract = {As the main health threat to the elderly living alone and performing indoor activities, falls have attracted great attention from institutions and society. Currently, fall detection systems are mainly based on wear sensors, environmental sensors, and computer vision, which need to be worn or require complex equipment construction. However, they have limitations and will interfere with the daily life of the elderly. On the basis of the indoor propagation theory of wireless signals, this paper proposes a conceptual verification module using Wi-Fi signals to identify human fall behavior. The module can detect falls without invading privacy and affecting human comfort and has the advantages of noninvasive, robustness, universality, and low price. The module combines digital signal processing technology and machine learning technology. This paper analyzes and processes the channel state information (CSI) data of wireless signals, and the local outlier factor algorithm is used to find the abnormal CSI sequence. The support vector machine and extreme gradient boosting algorithms are used for classification, recognition, and comparative research. Experimental results show that the average accuracy of fall detection based on wireless sensing is more than 90\%. This work has important social significance in ensuring the safety of the elderly.}
}

@book{wangMachineLearningHuman2010,
  title = {Machine {{Learning}} for {{Human Motion Analysis}}},
  editor = {Wang, Liang and Cheng, Li and Zhao, Guoying},
  date = {2010},
  publisher = {{IGI Global}},
  doi = {10.4018/978-1-60566-900-7},
  isbn = {978-1-60566-900-7}
}

@book{wangMachineLearningHuman2010a,
  title = {Machine {{Learning}} for {{Human Motion Analysis}}},
  editor = {Wang, Liang and Cheng, Li and Zhao, Guoying},
  date = {2010},
  publisher = {{IGI Global}},
  doi = {10.4018/978-1-60566-900-7},
  isbn = {978-1-60566-900-7}
}

@article{wangPredictingHumanIntentions2022,
  title = {Predicting {{Human Intentions}} in {{Human}}–{{Robot Hand-Over Tasks Through Multimodal Learning}}},
  author = {Wang, Weitian and Li, Rui and Chen, Yi and Sun, Yi and Jia, Yunyi},
  date = {2022-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {19},
  number = {3},
  pages = {2339--2353},
  issn = {1545-5955},
  doi = {10.1109/TASE.2021.3074873},
  url = {https://ieeexplore.ieee.org/document/9428016/},
  abstract = {In human-robot shared manufacturing contexts, product parts or tools hand-over between the robot and the human is an important collaborative task. Facilitating the robot to figure out and predict human hand-over intentions correctly to improve the task efficiency in human-robot collaboration is therefore a necessary issue to be addressed. In this study, a teaching-learning-prediction (TLP) framework is proposed for the robot to learn from its human partner's multimodal demonstrations and predict human hand-over intentions. In this approach, the robot can be programmed by the human through demonstrations utilizing natural language and wearable sensors according to task requirements and the human's working preferences. Then the robot learns from human hand-over demonstrations online via extreme learning machine (ELM) algorithms to update its cognition capacity, allowing the robot to use its learned policy to predict human intentions actively and assist its human companion in hand-over tasks. Experimental results and evaluations suggest that the human may program the robot easily by the proposed approach when the task changes, as the robot can effectively predict hand-over intentions with competitive accuracy to complete the hand-over tasks. Note to Practitioners - This article is motivated by human-robot hand-over problems in smart manufacturing contexts. Product parts or tools delivery in worker-robot partnerships is an important collaborative task. We develop a teaching-learning-prediction (TLP) framework for the robot to learn from its human partner's multimodal demonstrations and predict human hand-over intentions. The robot can be taught by human through natural language and wearable sensing information. The extreme learning machine (ELM) approach is employed for the robot to build its cognition capacity to predict human intentions actively and assist its human companion in hand-over tasks. We demonstrate that the proposed approach presents distinct and effective advantages to facilitate human-robot hand-over tasks in collaborative manufacturing contexts.}
}

@article{wangPredictingHumanIntentions2022a,
  title = {Predicting {{Human Intentions}} in {{Human}}–{{Robot Hand-Over Tasks Through Multimodal Learning}}},
  author = {Wang, Weitian and Li, Rui and Chen, Yi and Sun, Yi and Jia, Yunyi},
  date = {2022-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {19},
  number = {3},
  pages = {2339--2353},
  issn = {1545-5955},
  doi = {10.1109/TASE.2021.3074873},
  url = {https://ieeexplore.ieee.org/document/9428016/},
  abstract = {In human-robot shared manufacturing contexts, product parts or tools hand-over between the robot and the human is an important collaborative task. Facilitating the robot to figure out and predict human hand-over intentions correctly to improve the task efficiency in human-robot collaboration is therefore a necessary issue to be addressed. In this study, a teaching-learning-prediction (TLP) framework is proposed for the robot to learn from its human partner's multimodal demonstrations and predict human hand-over intentions. In this approach, the robot can be programmed by the human through demonstrations utilizing natural language and wearable sensors according to task requirements and the human's working preferences. Then the robot learns from human hand-over demonstrations online via extreme learning machine (ELM) algorithms to update its cognition capacity, allowing the robot to use its learned policy to predict human intentions actively and assist its human companion in hand-over tasks. Experimental results and evaluations suggest that the human may program the robot easily by the proposed approach when the task changes, as the robot can effectively predict hand-over intentions with competitive accuracy to complete the hand-over tasks. Note to Practitioners - This article is motivated by human-robot hand-over problems in smart manufacturing contexts. Product parts or tools delivery in worker-robot partnerships is an important collaborative task. We develop a teaching-learning-prediction (TLP) framework for the robot to learn from its human partner's multimodal demonstrations and predict human hand-over intentions. The robot can be taught by human through natural language and wearable sensing information. The extreme learning machine (ELM) approach is employed for the robot to build its cognition capacity to predict human intentions actively and assist its human companion in hand-over tasks. We demonstrate that the proposed approach presents distinct and effective advantages to facilitate human-robot hand-over tasks in collaborative manufacturing contexts.},
  file = {C:\Users\leemar\Zotero\storage\ASRTGGXS\Predicting_Human_Intentions_in_HumanRobot_Hand-Over_Tasks_Through_Multimodal_Learning.pdf}
}

@article{wangProbabilisticMovementModeling2013,
  title = {Probabilistic Movement Modeling for Intention Inference in Human-Robot Interaction},
  author = {Wang, Zhikun and Mülling, Katharina and Deisenroth, Marc Peter and Amor, Heni Ben and Vogt, David and Schölkopf, Bernhard and Peters, Jan},
  date = {2013},
  journaltitle = {International Journal of Robotics Research},
  volume = {32},
  number = {7},
  pages = {841--858},
  issn = {02783649},
  doi = {10.1177/0278364913478447},
  abstract = {Intention inference can be an essential step toward efficient human-robot interaction. For this purpose, we propose the Intention-Driven Dynamics Model (IDDM) to probabilistically model the generative process of movements that are directed by the intention. The IDDM allows the intention to be inferred from observed movements using Bayes' theorem. The IDDM simultaneously finds a latent state representation of noisy and high-dimensional observations, and models the intention-driven dynamics in the latent states. As most robotics applications are subject to real-time constraints, we develop an efficient online algorithm that allows for real-time intention inference. Two human-robot interaction scenarios, i.e. target prediction for robot table tennis and action recognition for interactive humanoid robots, are used to evaluate the performance of our inference algorithm. In both intention inference tasks, the proposed algorithm achieves substantial improvements over support vector machines and Gaussian processes. © The Author(s) 2013.},
  keywords = {Approximate inference,Gaussian process,intention inference}
}

@article{wangProbabilisticMovementModeling2013a,
  title = {Probabilistic Movement Modeling for Intention Inference in Human-Robot Interaction},
  author = {Wang, Zhikun and Mülling, Katharina and Deisenroth, Marc Peter and Ben Amor, Heni and Vogt, David and Schölkopf, Bernhard and Peters, Jan},
  date = {2013},
  journaltitle = {International Journal of Robotics Research},
  volume = {32},
  number = {7},
  pages = {841--858},
  issn = {02783649},
  doi = {10.1177/0278364913478447},
  abstract = {Intention inference can be an essential step toward efficient human-robot interaction. For this purpose, we propose the Intention-Driven Dynamics Model (IDDM) to probabilistically model the generative process of movements that are directed by the intention. The IDDM allows the intention to be inferred from observed movements using Bayes' theorem. The IDDM simultaneously finds a latent state representation of noisy and high-dimensional observations, and models the intention-driven dynamics in the latent states. As most robotics applications are subject to real-time constraints, we develop an efficient online algorithm that allows for real-time intention inference. Two human-robot interaction scenarios, i.e. target prediction for robot table tennis and action recognition for interactive humanoid robots, are used to evaluate the performance of our inference algorithm. In both intention inference tasks, the proposed algorithm achieves substantial improvements over support vector machines and Gaussian processes. © The Author(s) 2013.},
  keywords = {Approximate inference,Gaussian process,intention inference},
  file = {C:\Users\leemar\Zotero\storage\E28BYHDP\0278364913478447.pdf}
}

@article{wangSystematicReviewDigital2020,
  title = {A {{Systematic Review}} of {{Digital Technology Adoption}} in {{Off-Site Construction}}: {{Current Status}} and {{Future Direction}} towards {{Industry}} 4.0},
  author = {Wang, Mudan and Wang, Cynthia Changxin and Sepasgozar, Samad and Zlatanova, Sisi},
  date = {2020-11},
  journaltitle = {Buildings},
  volume = {10},
  number = {11},
  pages = {204},
  issn = {2075-5309},
  doi = {10.3390/buildings10110204},
  url = {https://www.mdpi.com/2075-5309/10/11/204},
  abstract = {Off-site construction (OSC) is known as an efficient construction method that could save time and cost, reduce waste of resources, and improve the overall productivity of projects. Coupled with digital technologies associated with the Industry 4.0 concept, OSC can offer a higher rate of productivity and safety. While there is a rich literature focusing on both OSC and Industry 4.0, the implementation of associated digital technologies in the OSC context has not been fully evaluated. This paper intends to evaluate the current literature of digital technology applications in OSC. Scientometric analyses and a systematic review were carried out evaluating fifteen typical digital technologies adopted by OSC projects, including building information modelling (BIM), radio frequency identification devices (RFID), global positioning systems (GPS), the Internet of Things (IoT), geographic information systems (GIS), sensors, augmented reality (AR), virtual reality (VR), photogrammetry, laser scanning, artificial intelligence (AI), 3D printing, robotics, big data, and blockchain. This review formulates a clear picture of the current practice of these digital technologies and summarizes the main area of application and limitations of each technology when utilized in OSC. The review also points out their potential and how they can be better adopted to improve OSC practice in the future.}
}

@article{wangSystematicReviewDigital2020a,
  title = {A {{Systematic Review}} of {{Digital Technology Adoption}}},
  author = {Wang, Mudan and Wang, Cynthia Changxin and Sepasgozar, Samad and Zlatanova, Sisi},
  date = {2020},
  journaltitle = {Buildings (MDPI)},
  volume = {2020},
  number = {10},
  pages = {1--29},
  abstract = {Off-site construction (OSC) is known as an efficient construction method that could save time and cost, reduce waste of resources, and improve the overall productivity of projects. Coupled with digital technologies associated with the Industry 4.0 concept, OSC can offer a higher rate of productivity and safety. While there is a rich literature focusing on both OSC and Industry 4.0, the implementation of associated digital technologies in the OSC context has not been fully evaluated. This paper intends to evaluate the current literature of digital technology applications in OSC. Scientometric analyses and a systematic review were carried out evaluating fifteen typical digital technologies adopted by OSC projects, including building information modelling (BIM), radio frequency identification devices (RFID), global positioning systems (GPS), the Internet of Things (IoT), geographic information systems (GIS), sensors, augmented reality (AR), virtual reality (VR), photogrammetry, laser scanning, artificial intelligence (AI), 3D printing, robotics, big data, and blockchain. This review formulates a clear picture of the current practice of these digital technologies and summarizes the main area of application and limitations of each technology when utilized in OSC. The review also points out their potential and how they can be better adopted to improve OSC practice in the future.},
  keywords = {bim,modular construction,prefabricated construction,prefabrication,technology adoption}
}

@article{wangSystematicReviewDigital2020b,
  title = {A {{Systematic Review}} of {{Digital Technology Adoption}}},
  author = {Wang, Mudan and Wang, Cynthia Changxin and Sepasgozar, Samad and Zlatanova, Sisi},
  date = {2020},
  journaltitle = {Buildings (MDPI)},
  volume = {2020},
  number = {10},
  pages = {1--29},
  abstract = {Off-site construction (OSC) is known as an efficient construction method that could save time and cost, reduce waste of resources, and improve the overall productivity of projects. Coupled with digital technologies associated with the Industry 4.0 concept, OSC can offer a higher rate of productivity and safety. While there is a rich literature focusing on both OSC and Industry 4.0, the implementation of associated digital technologies in the OSC context has not been fully evaluated. This paper intends to evaluate the current literature of digital technology applications in OSC. Scientometric analyses and a systematic review were carried out evaluating fifteen typical digital technologies adopted by OSC projects, including building information modelling (BIM), radio frequency identification devices (RFID), global positioning systems (GPS), the Internet of Things (IoT), geographic information systems (GIS), sensors, augmented reality (AR), virtual reality (VR), photogrammetry, laser scanning, artificial intelligence (AI), 3D printing, robotics, big data, and blockchain. This review formulates a clear picture of the current practice of these digital technologies and summarizes the main area of application and limitations of each technology when utilized in OSC. The review also points out their potential and how they can be better adopted to improve OSC practice in the future.},
  keywords = {bim,modular construction,prefabricated construction,prefabrication,technology adoption},
  file = {C:\Users\leemar\Zotero\storage\6MWCJ9XS\buildings-10-00204-v3.pdf}
}

@article{wangSystematicReviewDigital2020c,
  title = {A {{Systematic Review}} of {{Digital Technology Adoption}} in {{Off-Site Construction}}: {{Current Status}} and {{Future Direction}} towards {{Industry}} 4.0},
  author = {Wang, Mudan and Wang, Cynthia Changxin and Sepasgozar, Samad and Zlatanova, Sisi},
  date = {2020-11-13},
  journaltitle = {Buildings},
  volume = {10},
  number = {11},
  pages = {204},
  issn = {2075-5309},
  doi = {10.3390/buildings10110204},
  url = {https://www.mdpi.com/2075-5309/10/11/204},
  abstract = {Off-site construction (OSC) is known as an efficient construction method that could save time and cost, reduce waste of resources, and improve the overall productivity of projects. Coupled with digital technologies associated with the Industry 4.0 concept, OSC can offer a higher rate of productivity and safety. While there is a rich literature focusing on both OSC and Industry 4.0, the implementation of associated digital technologies in the OSC context has not been fully evaluated. This paper intends to evaluate the current literature of digital technology applications in OSC. Scientometric analyses and a systematic review were carried out evaluating fifteen typical digital technologies adopted by OSC projects, including building information modelling (BIM), radio frequency identification devices (RFID), global positioning systems (GPS), the Internet of Things (IoT), geographic information systems (GIS), sensors, augmented reality (AR), virtual reality (VR), photogrammetry, laser scanning, artificial intelligence (AI), 3D printing, robotics, big data, and blockchain. This review formulates a clear picture of the current practice of these digital technologies and summarizes the main area of application and limitations of each technology when utilized in OSC. The review also points out their potential and how they can be better adopted to improve OSC practice in the future.}
}

@article{wangTemporalSegmentNetworks2019,
  title = {Temporal {{Segment Networks}} for {{Action Recognition}} in {{Videos}}},
  author = {Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Gool, Luc Van},
  date = {2019},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {41},
  number = {11},
  eprint = {30183621},
  eprinttype = {pmid},
  pages = {2740--2755},
  issn = {19393539},
  doi = {10.1109/TPAMI.2018.2868668},
  abstract = {We present a general and flexible video-level framework for learning action models in videos. This method, called temporal segment network (TSN), aims to model long-range temporal structure with a new segment-based sampling and aggregation scheme. This unique design enables the TSN framework to efficiently learn action models by using the whole video. The learned models could be easily deployed for action recognition in both trimmed and untrimmed videos with simple average pooling and multi-scale temporal window integration, respectively. We also study a series of good practices for the implementation of the TSN framework given limited training samples. Our approach obtains the state-the-of-art performance on five challenging action recognition benchmarks: HMDB51 (71.0 percent), UCF101 (94.9 percent), THUMOS14 (80.1 percent), ActivityNet v1.2 (89.6 percent), and Kinetics400 (75.7 percent). In addition, using the proposed RGB difference as a simple motion representation, our method can still achieve competitive accuracy on UCF101 (91.0 percent) while running at 340 FPS. Furthermore, based on the proposed TSN framework, we won the video classification track at the ActivityNet challenge 2016 among 24 teams.},
  keywords = {Action recognition,ConvNets,good practices,temporal modeling,temporal segment networks}
}

@article{wangTemporalSegmentNetworks2019a,
  title = {Temporal {{Segment Networks}} for {{Action Recognition}} in {{Videos}}},
  author = {Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  date = {2019},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {41},
  number = {11},
  eprint = {30183621},
  eprinttype = {pmid},
  pages = {2740--2755},
  issn = {19393539},
  doi = {10.1109/TPAMI.2018.2868668},
  abstract = {We present a general and flexible video-level framework for learning action models in videos. This method, called temporal segment network (TSN), aims to model long-range temporal structure with a new segment-based sampling and aggregation scheme. This unique design enables the TSN framework to efficiently learn action models by using the whole video. The learned models could be easily deployed for action recognition in both trimmed and untrimmed videos with simple average pooling and multi-scale temporal window integration, respectively. We also study a series of good practices for the implementation of the TSN framework given limited training samples. Our approach obtains the state-the-of-art performance on five challenging action recognition benchmarks: HMDB51 (71.0 percent), UCF101 (94.9 percent), THUMOS14 (80.1 percent), ActivityNet v1.2 (89.6 percent), and Kinetics400 (75.7 percent). In addition, using the proposed RGB difference as a simple motion representation, our method can still achieve competitive accuracy on UCF101 (91.0 percent) while running at 340 FPS. Furthermore, based on the proposed TSN framework, we won the video classification track at the ActivityNet challenge 2016 among 24 teams.},
  keywords = {Action recognition,ConvNets,good practices,temporal modeling,temporal segment networks},
  file = {C:\Users\leemar\Zotero\storage\8CR7CXRX\1705.02953.pdf}
}

@article{wangVisionbasedMethodSemantic2022,
  title = {Vision-Based Method for Semantic Information Extraction in Construction by Integrating Deep Learning Object Detection and Image Captioning},
  author = {Wang, Y. and Xiao, B. and Bouferguene, A. and Al-Hussein, M. and Li, H.},
  date = {2022},
  journaltitle = {Advanced Engineering Informatics},
  volume = {53},
  doi = {10.1016/j.aei.2022.101699},
  abstract = {Recently, vision-based monitoring has been widely adopted in construction management to improve crew productivity, reduce safety risks, and facilitate site planning. However, automated retrieval of semantic information (e.g., objects, activities, and interactions between objects) from construction images remains challenging due to the complex nature of construction sites. This paper proposes a novel semantic information extraction method by integrating deep learning object detection and image captioning, which aims to explore salient information from construction images or videos. In the proposed method, object detection has been employed as an encoder to extract the feature maps of construction object zones and the holistic image. The image captioning has been selected as the decoder to extract the semantic information. A post-processing method has been proposed to parse the semantic information into a graph format for better accessibility and visualization. In experiments, the proposed method has achieved the Consensus-based Image Description Evaluation (CIDEr) of 1.84. By adopting the proposed method, semantic information behind construction images can be presented to construction managers to assist their decision-making.}
}

@article{wangVisionbasedMethodSemantic2022a,
  title = {Vision-Based Method for Semantic Information Extraction in Construction by Integrating Deep Learning Object Detection and Image Captioning},
  author = {Wang, Y. and Xiao, B. and Bouferguene, A. and Al-Hussein, M. and Li, H.},
  date = {2022},
  journaltitle = {Advanced Engineering Informatics},
  volume = {53},
  doi = {10.1016/j.aei.2022.101699},
  abstract = {Recently, vision-based monitoring has been widely adopted in construction management to improve crew productivity, reduce safety risks, and facilitate site planning. However, automated retrieval of semantic information (e.g., objects, activities, and interactions between objects) from construction images remains challenging due to the complex nature of construction sites. This paper proposes a novel semantic information extraction method by integrating deep learning object detection and image captioning, which aims to explore salient information from construction images or videos. In the proposed method, object detection has been employed as an encoder to extract the feature maps of construction object zones and the holistic image. The image captioning has been selected as the decoder to extract the semantic information. A post-processing method has been proposed to parse the semantic information into a graph format for better accessibility and visualization. In experiments, the proposed method has achieved the Consensus-based Image Description Evaluation (CIDEr) of 1.84. By adopting the proposed method, semantic information behind construction images can be presented to construction managers to assist their decision-making.}
}

@inproceedings{wardRecognisingCollaborativeActivities2016,
  title = {Towards Recognising Collaborative Activities Using Multiple On-Body Sensors},
  booktitle = {{{UbiComp}} 2016 {{Adjunct}} - {{Proceedings}} of the 2016 {{ACM International Joint Conference}} on {{Pervasive}} and {{Ubiquitous Computing}}},
  author = {Ward, J. A. and Hevesi, P. and Pirkl, G. and Lukowicz, P.},
  date = {2016},
  pages = {221--224},
  doi = {10.1145/2968219.2971429},
  abstract = {This paper describes the initial stages of a new work on recognising collaborative activities involving two or more people. In the experiment described a physically demanding construction task is completed by a team of 4 volunteers. The task, to build a large video wall, requires communication, coordination, and physical collaboration between group members. Minimal outside assistance is provided to better reflect the ad-hoc and loosely structured nature of real-world construction tasks. On-body inertial measurement units (IMU) record each subject's head and arm movements; a wearable eye-Tracker records gaze and egocentric video; and audio is recorded from each person's head and dominant arm. A first look at the data reveals promising correlations between, for example, the movement patterns of two people carrying a heavy object. Also revealed are clues on how complementary information from different sensor types, such as sound and vision, might further aid collaboration recognition.},
  isbn = {978-1-4503-4462-3}
}

@inproceedings{wardRecognisingCollaborativeActivities2016a,
  title = {Towards Recognising Collaborative Activities Using Multiple On-Body Sensors},
  booktitle = {{{UbiComp}} 2016 {{Adjunct}} - {{Proceedings}} of the 2016 {{ACM International Joint Conference}} on {{Pervasive}} and {{Ubiquitous Computing}}},
  author = {Ward, J.A. and Hevesi, P. and Pirkl, G. and Lukowicz, P.},
  date = {2016},
  pages = {221--224},
  doi = {10.1145/2968219.2971429},
  abstract = {This paper describes the initial stages of a new work on recognising collaborative activities involving two or more people. In the experiment described a physically demanding construction task is completed by a team of 4 volunteers. The task, to build a large video wall, requires communication, coordination, and physical collaboration between group members. Minimal outside assistance is provided to better reflect the ad-hoc and loosely structured nature of real-world construction tasks. On-body inertial measurement units (IMU) record each subject's head and arm movements; a wearable eye-Tracker records gaze and egocentric video; and audio is recorded from each person's head and dominant arm. A first look at the data reveals promising correlations between, for example, the movement patterns of two people carrying a heavy object. Also revealed are clues on how complementary information from different sensor types, such as sound and vision, might further aid collaboration recognition.},
  isbn = {978-1-4503-4462-3}
}

@inproceedings{weinzaepfelDeepFlowLargeDisplacement2013,
  title = {{{DeepFlow}}: {{Large}} Displacement Optical Flow with Deep Matching},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Weinzaepfel, P. and Revaud, J. and Harchaoui, Z. and Schmid, C.},
  date = {2013},
  pages = {1385--1392},
  doi = {10.1109/ICCV.2013.175},
  abstract = {Optical flow computation is a key component in many computer vision systems designed for tasks such as action detection or activity recognition. However, despite several major advances over the last decade, handling large displacement in optical flow remains an open problem. Inspired by the large displacement optical flow of Brox and Malik, our approach, termed Deep Flow, blends a matching algorithm with a variational approach for optical flow. We propose a descriptor matching algorithm, tailored to the optical flow problem, that allows to boost performance on fast motions. The matching algorithm builds upon a multi-stage architecture with 6 layers, interleaving convolutions and max-pooling, a construction akin to deep convolutional nets. Using dense sampling, it allows to efficiently retrieve quasi-dense correspondences, and enjoys a built-in smoothing effect on descriptors matches, a valuable asset for integration into an energy minimization framework for optical flow estimation. Deep Flow efficiently handles large displacements occurring in realistic videos, and shows competitive performance on optical flow benchmarks. Furthermore, it sets a new state-of-the-art on the MPI-Sintel dataset. © 2013 IEEE.},
  isbn = {978-1-4799-2839-2}
}

@inproceedings{weinzaepfelDeepFlowLargeDisplacement2013a,
  title = {{{DeepFlow}}: {{Large}} Displacement Optical Flow with Deep Matching},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Weinzaepfel, P. and Revaud, J. and Harchaoui, Z. and Schmid, C.},
  date = {2013},
  pages = {1385--1392},
  doi = {10.1109/ICCV.2013.175},
  abstract = {Optical flow computation is a key component in many computer vision systems designed for tasks such as action detection or activity recognition. However, despite several major advances over the last decade, handling large displacement in optical flow remains an open problem. Inspired by the large displacement optical flow of Brox and Malik, our approach, termed Deep Flow, blends a matching algorithm with a variational approach for optical flow. We propose a descriptor matching algorithm, tailored to the optical flow problem, that allows to boost performance on fast motions. The matching algorithm builds upon a multi-stage architecture with 6 layers, interleaving convolutions and max-pooling, a construction akin to deep convolutional nets. Using dense sampling, it allows to efficiently retrieve quasi-dense correspondences, and enjoys a built-in smoothing effect on descriptors matches, a valuable asset for integration into an energy minimization framework for optical flow estimation. Deep Flow efficiently handles large displacements occurring in realistic videos, and shows competitive performance on optical flow benchmarks. Furthermore, it sets a new state-of-the-art on the MPI-Sintel dataset. © 2013 IEEE.},
  isbn = {978-1-4799-2839-2}
}

@article{westonDesignModularWorkhandling1984,
  title = {Design of Modular Workhandling Systems},
  author = {Weston, R. and More, P. and Thatcher, T. and Miles, K.},
  date = {1984},
  journaltitle = {Microprocessors and Microsystems},
  volume = {8},
  number = {1},
  pages = {16--20},
  doi = {10.1016/0141-9331(84)90003-6},
  abstract = {The mechanical structure and control system architecture for pneumomechanical single-axis modular units are described. The units were designed as subsystems to allow the construction of robots with kinematics suitable for a wide range of workhandling tasks. The controls also demonstrate modularity with regard to both software and hardware. They have been designed to reduce the systems engineering required when user-defined manipulators are being constructed and to provide a user-friendly interface for operators. © 1984.}
}

@article{westonDesignModularWorkhandling1984a,
  title = {Design of Modular Workhandling Systems},
  author = {Weston, R. and More, P. and Thatcher, T. and Miles, K.},
  date = {1984},
  journaltitle = {Microprocessors and Microsystems},
  volume = {8},
  number = {1},
  pages = {16--20},
  doi = {10.1016/0141-9331(84)90003-6},
  abstract = {The mechanical structure and control system architecture for pneumomechanical single-axis modular units are described. The units were designed as subsystems to allow the construction of robots with kinematics suitable for a wide range of workhandling tasks. The controls also demonstrate modularity with regard to both software and hardware. They have been designed to reduce the systems engineering required when user-defined manipulators are being constructed and to provide a user-friendly interface for operators. © 1984.}
}

@online{whitePromptPatternCatalog2023,
  title = {A {{Prompt Pattern Catalog}} to {{Enhance Prompt Engineering}} with {{ChatGPT}}},
  author = {White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C.},
  date = {2023-02-21},
  eprint = {2302.11382},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.11382},
  urldate = {2023-11-19},
  abstract = {Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering},
  file = {C:\Users\leemar\Zotero\storage\C828ZHFN\White 等。 - 2023 - A Prompt Pattern Catalog to Enhance Prompt Enginee.pdf}
}

@online{whitePromptPatternCatalog2023a,
  title = {A {{Prompt Pattern Catalog}} to {{Enhance Prompt Engineering}} with {{ChatGPT}}},
  author = {White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C.},
  date = {2023-02-21},
  eprint = {2302.11382},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.11382},
  urldate = {2023-11-19},
  abstract = {Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering},
  file = {C:\Users\leemar\Zotero\storage\SYFPAMHU\White 等。 - 2023 - A Prompt Pattern Catalog to Enhance Prompt Enginee.pdf}
}

@article{wibranekUsingMateriallyComputed2019,
  title = {Using Materially Computed Geometry in a Man-Machine Collaborative Environment},
  author = {Wibranek, B.},
  date = {2019},
  journaltitle = {ArchiDOCT},
  volume = {6},
  number = {2},
  pages = {96--111},
  abstract = {In this research, we interweaved real-world geometry with computational tools for a manmachine collaborative assembly process. Current research for robotics in architecture aims to bridge the gap between digital design and fabrication, but rarely considers manipulation of real-world geometry by human actors. In contrast, we utilized material computed geometry as a physical interface. 3D scanned wooden lamellas served as input for computational tools to finalize a design and create toolpaths for the robotic placement of rods. The research combines methods of machine vision, physical interfaces and man-machine collaboration to restructure workflows in the process of design and construction. Consequently, real-world geometry was used as input to start the design process. The designer engaged with wooden lamellas and a computational tool to build a demonstrator, illustrating a clear division of tasks in a manmachine collaboration. Moving from parametric design tools directly to physical interfaces using real-world geometry, our research proposes a stronger participation of human actors within digital fabrication environments.}
}

@article{wibranekUsingMateriallyComputed2019a,
  title = {Using Materially Computed Geometry in a Man-Machine Collaborative Environment},
  author = {Wibranek, B.},
  date = {2019},
  journaltitle = {ArchiDOCT},
  volume = {6},
  number = {2},
  pages = {96--111},
  abstract = {In this research, we interweaved real-world geometry with computational tools for a manmachine collaborative assembly process. Current research for robotics in architecture aims to bridge the gap between digital design and fabrication, but rarely considers manipulation of real-world geometry by human actors. In contrast, we utilized material computed geometry as a physical interface. 3D scanned wooden lamellas served as input for computational tools to finalize a design and create toolpaths for the robotic placement of rods. The research combines methods of machine vision, physical interfaces and man-machine collaboration to restructure workflows in the process of design and construction. Consequently, real-world geometry was used as input to start the design process. The designer engaged with wooden lamellas and a computational tool to build a demonstrator, illustrating a clear division of tasks in a manmachine collaboration. Moving from parametric design tools directly to physical interfaces using real-world geometry, our research proposes a stronger participation of human actors within digital fabrication environments.}
}

@article{wilkinsonGalvanicVestibularStimulation2012,
  title = {Galvanic Vestibular Stimulation Modulates the Electrophysiological Response during Face Processing},
  author = {Wilkinson, D. and Ferguson, H. J. and Worley, A.},
  date = {2012},
  journaltitle = {Visual Neuroscience},
  volume = {29},
  number = {4-5},
  pages = {255--262},
  doi = {10.1017/S0952523812000235},
  abstract = {Although galvanic vestibular stimulation (GVS) is known to affect the speed and accuracy of visual judgments, the underlying electrophysiological response has not been explored. In the present study, we therefore investigated the effect of GVS on the N170 event-related potential, a marker commonly associated with early visual structural encoding. To elicit the waveform, participants distinguished famous from nonfamous faces that were presented in either upright or inverted orientation. Relative to a sham, stimulation increased the amplitude of the N170 and also elevated power spectra within the delta and theta frequency bands, components that have likewise been associated with face processing. This study constitutes the first attempt to model the effects of GVS on the electrophysiological response and, more specifically, indicates that unisensory visual processes linked to object construction are influenced by vestibular information. Given that reductions in the magnitude of both the N170 event-related potential and delta/theta activity accompany certain disease states, GVS may provide hitherto unreported therapeutic benefit. © Copyright © Cambridge University Press 2012.}
}

@article{wilkinsonGalvanicVestibularStimulation2012a,
  title = {Galvanic Vestibular Stimulation Modulates the Electrophysiological Response during Face Processing},
  author = {Wilkinson, D. and Ferguson, H.J. and Worley, A.},
  date = {2012},
  journaltitle = {Visual Neuroscience},
  volume = {29},
  number = {4-5},
  pages = {255--262},
  doi = {10.1017/S0952523812000235},
  abstract = {Although galvanic vestibular stimulation (GVS) is known to affect the speed and accuracy of visual judgments, the underlying electrophysiological response has not been explored. In the present study, we therefore investigated the effect of GVS on the N170 event-related potential, a marker commonly associated with early visual structural encoding. To elicit the waveform, participants distinguished famous from nonfamous faces that were presented in either upright or inverted orientation. Relative to a sham, stimulation increased the amplitude of the N170 and also elevated power spectra within the delta and theta frequency bands, components that have likewise been associated with face processing. This study constitutes the first attempt to model the effects of GVS on the electrophysiological response and, more specifically, indicates that unisensory visual processes linked to object construction are influenced by vestibular information. Given that reductions in the magnitude of both the N170 event-related potential and delta/theta activity accompany certain disease states, GVS may provide hitherto unreported therapeutic benefit. © Copyright © Cambridge University Press 2012.}
}

@article{willmannAerialRoboticConstruction2012,
  title = {Aerial Robotic Construction towards a New Field of Architectural Research},
  author = {Willmann, J. and Augugliaro, F. and Cadalbert, T. and D'Andrea, R. and Gramazio, F. and Kohler, M.},
  date = {2012},
  journaltitle = {International Journal of Architectural Computing},
  volume = {10},
  number = {3},
  pages = {439--460},
  doi = {10.1260/1478-0771.10.3.439},
  abstract = {This paper takes a first step in characterizing a novel field of architectural research - aerial robotic construction (ARC) - where aerial robotics is used not only for construction, but as a guiding principle in the design and fabrication process. Featuring autonomous flying vehicles that lift small building elements and position them according to a precise digital blueprint, ARC offers a comprehensive new approach to architecture research and technology. Developed by the research groups of Gramazio \& Kohler and Raffaello D'Andrea at ETH Zurich, ARC offers unique advantages over traditional approaches to building: it does not require scaffolding, it is easily scalable, and it offers digital integration and informational oversight across the entire design and building process. This paper considers 1) research parameters for the individual components of ARC (such as module design, connection methodologies, vehicle cooperation, and construction sequencing/synchronization), and 2) the architectural implications of integrating these discrete components into a systemic, unifying process at the earliest stages of design. Fidelity between the design concept and the full-scale construction is of particular concern.}
}

@article{willmannAerialRoboticConstruction2012a,
  title = {Aerial Robotic Construction towards a New Field of Architectural Research},
  author = {Willmann, J. and Augugliaro, F. and Cadalbert, T. and D'Andrea, R. and Gramazio, F. and Kohler, M.},
  date = {2012},
  journaltitle = {International Journal of Architectural Computing},
  volume = {10},
  number = {3},
  pages = {439--460},
  doi = {10.1260/1478-0771.10.3.439},
  abstract = {This paper takes a first step in characterizing a novel field of architectural research - aerial robotic construction (ARC) - where aerial robotics is used not only for construction, but as a guiding principle in the design and fabrication process. Featuring autonomous flying vehicles that lift small building elements and position them according to a precise digital blueprint, ARC offers a comprehensive new approach to architecture research and technology. Developed by the research groups of Gramazio \& Kohler and Raffaello D'Andrea at ETH Zurich, ARC offers unique advantages over traditional approaches to building: it does not require scaffolding, it is easily scalable, and it offers digital integration and informational oversight across the entire design and building process. This paper considers 1) research parameters for the individual components of ARC (such as module design, connection methodologies, vehicle cooperation, and construction sequencing/synchronization), and 2) the architectural implications of integrating these discrete components into a systemic, unifying process at the earliest stages of design. Fidelity between the design concept and the full-scale construction is of particular concern.}
}

@article{willmannRoboticTimberConstruction2016,
  title = {Robotic Timber Construction - {{Expanding}} Additive Fabrication to New Dimensions},
  author = {Willmann, J. and Knauss, M. and Bonwetsch, T. and Apolinarska, A.A. and Gramazio, F. and Kohler, M.},
  date = {2016},
  journaltitle = {Automation in Construction},
  volume = {61},
  pages = {16--23},
  doi = {10.1016/j.autcon.2015.09.011},
  abstract = {This paper presents a novel approach to non-standard timber assembly - Robotic Timber Construction (RTC) - where robotic fabrication is used to expand additive digital fabrication techniques towards industrial full scale dimensions. Featuring robotic systems that grasp, manipulate, and finally position building components according to a precise digital blueprint, RTC combines robotic assembly procedures and advanced digital design of non-standard timber structures. The resulting architectural morphologies allow for a convergence of aesthetic and functional concerns, enabling structural optimisation through the locally differentiated aggregation of material. Initiated by the group of Gramazio Kohler Research at ETH Zurich, this approach offers a new perspective on automated timber construction, where the focus is shifted from the processing of single parts towards the assembly of generic members in space. As such, RTC promotes unique advantages over conventional approaches to timber construction, such as, for example, CNC joinery and cutting: through the automated placement of material exactly where it is needed, RTC combines additive and largely waste-free construction with economic assembly procedures, it does not require additional external building reference, and it offers digital control across the entire building process, even when the design and assembly information are highly complex. This paper considers 1) research parameters for the individual components of RTC (such as computational design processes, construction methods and fabrication strategies), and 2) the architectural implications of integrating these components into a systemic, unifying process at the earliest stages of design. Overall, RTC leads to profound changes in the design, performance and expressive language of architecture and thus fosters the creation of architecture that profoundly reinvents its constructive repertoire.}
}

@article{willmannRoboticTimberConstruction2016a,
  title = {Robotic Timber Construction - {{Expanding}} Additive Fabrication to New Dimensions},
  author = {Willmann, J. and Knauss, M. and Bonwetsch, T. and Apolinarska, A.A. and Gramazio, F. and Kohler, M.},
  date = {2016},
  journaltitle = {Automation in Construction},
  volume = {61},
  pages = {16--23},
  doi = {10.1016/j.autcon.2015.09.011},
  abstract = {This paper presents a novel approach to non-standard timber assembly - Robotic Timber Construction (RTC) - where robotic fabrication is used to expand additive digital fabrication techniques towards industrial full scale dimensions. Featuring robotic systems that grasp, manipulate, and finally position building components according to a precise digital blueprint, RTC combines robotic assembly procedures and advanced digital design of non-standard timber structures. The resulting architectural morphologies allow for a convergence of aesthetic and functional concerns, enabling structural optimisation through the locally differentiated aggregation of material. Initiated by the group of Gramazio Kohler Research at ETH Zurich, this approach offers a new perspective on automated timber construction, where the focus is shifted from the processing of single parts towards the assembly of generic members in space. As such, RTC promotes unique advantages over conventional approaches to timber construction, such as, for example, CNC joinery and cutting: through the automated placement of material exactly where it is needed, RTC combines additive and largely waste-free construction with economic assembly procedures, it does not require additional external building reference, and it offers digital control across the entire building process, even when the design and assembly information are highly complex. This paper considers 1) research parameters for the individual components of RTC (such as computational design processes, construction methods and fabrication strategies), and 2) the architectural implications of integrating these components into a systemic, unifying process at the earliest stages of design. Overall, RTC leads to profound changes in the design, performance and expressive language of architecture and thus fosters the creation of architecture that profoundly reinvents its constructive repertoire.}
}

@article{willsonMARSOZDesignSimulated2005,
  title = {{{MARS-OZ}}: {{A}} Design for a Simulated {{Mars}} Base in the {{Australian}} Outback},
  author = {Willson, D. and Clarke, J.D.A. and Murphy, G.},
  date = {2005},
  journaltitle = {JBIS - Journal British Interplanetary Society},
  volume = {58},
  number = {9-10},
  pages = {282--293},
  abstract = {Mars Society Australia has developed the design of a simulated Mars base, MARS-OZ, for deployment in outback Australia. MARS-OZ will provide a platform for a diverse range of Mars analogue research in Australia. The simulated base consists of two mobile modules whose dimensions and shape approximate those of horizontally landed bent biconic spacecraft described in an earlier paper. The modules are designed to support field engineering, robotics, architectural, geological, biological and human factors research at varying levels of simulation fidelity. Non-Mars related research can also be accommodated, for example general field geology and biology, and engineering research associated with sustainable, low impact architecture. Crews of up to eight can be accommodated. In addition to its research function, the base also will serve as a centre of space education and outreach activities. The prime site for the MARS-OZ simulated base is located in the northern Flinders Ranges near Arkaroola in South Australia. This region contains many features that provide useful scientific analogues to known or possible past and present conditions on Mars from both a geological and biological perspective. The features will provide a wealth of study opportunities for crews. The very diverse terrain and regolith materials will provide ideal opportunities to field trial a range of equipment, sensors and exploration strategies. If needed, the prime site can be secured from casual visitors, allowing research into human interaction in isolation. Despite its relative isolation, the site is readily accessible by road and air from major Australian centres. This paper provides description of the configuration, design and construction of the proposed facility, its interior layout, equipment and systems fitouts, a detailed cost estimate, and its deployment. We estimate that the deployment of MARS-OZ could occur within nine months of securing funding.}
}

@article{willsonMARSOZDesignSimulated2005a,
  title = {{{MARS-OZ}}: {{A}} Design for a Simulated {{Mars}} Base in the {{Australian}} Outback},
  author = {Willson, D. and Clarke, J.D.A. and Murphy, G.},
  date = {2005},
  journaltitle = {JBIS - Journal British Interplanetary Society},
  volume = {58},
  number = {9-10},
  pages = {282--293},
  abstract = {Mars Society Australia has developed the design of a simulated Mars base, MARS-OZ, for deployment in outback Australia. MARS-OZ will provide a platform for a diverse range of Mars analogue research in Australia. The simulated base consists of two mobile modules whose dimensions and shape approximate those of horizontally landed bent biconic spacecraft described in an earlier paper. The modules are designed to support field engineering, robotics, architectural, geological, biological and human factors research at varying levels of simulation fidelity. Non-Mars related research can also be accommodated, for example general field geology and biology, and engineering research associated with sustainable, low impact architecture. Crews of up to eight can be accommodated. In addition to its research function, the base also will serve as a centre of space education and outreach activities. The prime site for the MARS-OZ simulated base is located in the northern Flinders Ranges near Arkaroola in South Australia. This region contains many features that provide useful scientific analogues to known or possible past and present conditions on Mars from both a geological and biological perspective. The features will provide a wealth of study opportunities for crews. The very diverse terrain and regolith materials will provide ideal opportunities to field trial a range of equipment, sensors and exploration strategies. If needed, the prime site can be secured from casual visitors, allowing research into human interaction in isolation. Despite its relative isolation, the site is readily accessible by road and air from major Australian centres. This paper provides description of the configuration, design and construction of the proposed facility, its interior layout, equipment and systems fitouts, a detailed cost estimate, and its deployment. We estimate that the deployment of MARS-OZ could occur within nine months of securing funding.}
}

@inproceedings{winterIndustrializationBuildingProcesses2018,
  title = {Industrialization of Building Processes - {{A}} Chance for Timber to Take the Lead},
  booktitle = {{{WCTE}} 2018 - {{World Conference}} on {{Timber Engineering}}},
  author = {Winter, S. and Köhler, C. and Lechner, M.},
  date = {2018},
  abstract = {All over the world the same phenomenon is observed: People are moving towards the cities. As a result, most of the cities are growing and suffer from sufficient housing capacities. Upon others this leads to prohibitive prices for flats compared to the income of most citizens. Therefore - especially for social housing - cheap and effective solutions to build more residential buildings are desperately needed but must be combined with acceptable and sustainable architecture! For building solutions, a real industrial standard is needed - useable by architects, engineers, developers and builders. Company-based solutions are not sufficient. In a recent research project, it is shown that at least 25\% of the building costs is related to additional and unnecessary design. As a result, a BIM based general design model based on 3D-planning and building units should be established. While timber is a perfect material for prefabrication and wood building industry is already trained in prefabrication including partly installation of building services, further development is a big chance for timber to take the lead in a future industrialization process of the building industry.}
}

@inproceedings{winterIndustrializationBuildingProcesses2018a,
  title = {Industrialization of Building Processes - {{A}} Chance for Timber to Take the Lead},
  booktitle = {{{WCTE}} 2018 - {{World Conference}} on {{Timber Engineering}}},
  author = {Winter, S. and Köhler, C. and Lechner, M.},
  date = {2018},
  abstract = {All over the world the same phenomenon is observed: People are moving towards the cities. As a result, most of the cities are growing and suffer from sufficient housing capacities. Upon others this leads to prohibitive prices for flats compared to the income of most citizens. Therefore - especially for social housing - cheap and effective solutions to build more residential buildings are desperately needed but must be combined with acceptable and sustainable architecture! For building solutions, a real industrial standard is needed - useable by architects, engineers, developers and builders. Company-based solutions are not sufficient. In a recent research project, it is shown that at least 25\% of the building costs is related to additional and unnecessary design. As a result, a BIM based general design model based on 3D-planning and building units should be established. While timber is a perfect material for prefabrication and wood building industry is already trained in prefabrication including partly installation of building services, further development is a big chance for timber to take the lead in a future industrialization process of the building industry.}
}

@article{witCraftDrivenRobotic2016,
  title = {Craft Driven Robotic Composites},
  author = {Wit, A.J. and Kim, S. and Ibañez, M. and Eisinger, D.},
  date = {2016},
  journaltitle = {3D Printing and Additive Manufacturing},
  volume = {3},
  number = {1},
  pages = {3--9},
  doi = {10.1089/3dp.2016.0008},
  abstract = {The manipulation of weaving as a traditional industrial process as a craft, and as a numerically controlled robotic winding procedure, was examined and evaluated through the construction of an architectural scale monocoque shelter. This wound carbon fiber prototypical structure represents a production method for quick deployment, flexibility in form, and lightness of material. The implications of this case study and its future goals are to be explored in relation to the rapid evolution of robotic fabrication and architectural design while being tested through the traditional craft of hand winding as a direct translation of computational information. The methodology and means in which the results are assessed are presented in this study. What is a related and beneficial by-product is the investigation of uniform and continuous winding that fulfills the technical requirements of monocoque and span, while allowing for additive layers of artistry or optical effects (Fig. 1). The oft-converging fields of craft and technology produce novel methods and tools for design, as technology adapts to unforeseen artistic impulse. Simultaneously, these new methods also require a reevaluation of both how art and architectural projects are evaluated.}
}

@article{witCraftDrivenRobotic2016a,
  title = {Craft Driven Robotic Composites},
  author = {Wit, A.J. and Kim, S. and Ibañez, M. and Eisinger, D.},
  date = {2016},
  journaltitle = {3D Printing and Additive Manufacturing},
  volume = {3},
  number = {1},
  pages = {3--9},
  doi = {10.1089/3dp.2016.0008},
  abstract = {The manipulation of weaving as a traditional industrial process as a craft, and as a numerically controlled robotic winding procedure, was examined and evaluated through the construction of an architectural scale monocoque shelter. This wound carbon fiber prototypical structure represents a production method for quick deployment, flexibility in form, and lightness of material. The implications of this case study and its future goals are to be explored in relation to the rapid evolution of robotic fabrication and architectural design while being tested through the traditional craft of hand winding as a direct translation of computational information. The methodology and means in which the results are assessed are presented in this study. What is a related and beneficial by-product is the investigation of uniform and continuous winding that fulfills the technical requirements of monocoque and span, while allowing for additive layers of artistry or optical effects (Fig. 1). The oft-converging fields of craft and technology produce novel methods and tools for design, as technology adapts to unforeseen artistic impulse. Simultaneously, these new methods also require a reevaluation of both how art and architectural projects are evaluated.}
}

@article{wuCloudbasedDesignManufacturing2015,
  title = {Cloud-Based Design and Manufacturing: {{A}} New Paradigm in Digital Manufacturing and Design Innovation},
  author = {Wu, Dazhong and Rosen, David W. and Wang, Lihui and Schaefer, Dirk},
  date = {2015},
  journaltitle = {CAD Computer Aided Design},
  volume = {59},
  pages = {1--14},
  publisher = {{Elsevier Ltd}},
  issn = {00104485},
  doi = {10.1016/j.cad.2014.07.006},
  abstract = {Cloud-based design manufacturing (CBDM) refers to a service-oriented networked product development model in which service consumers are enabled to configure, select, and utilize customized product realization resources and services ranging from computer-aided engineering software to reconfigurable manufacturing systems. An ongoing debate on CBDM in the research community revolves around several aspects such as definitions, key characteristics, computing architectures, communication and collaboration processes, crowdsourcing processes, information and communication infrastructure, programming models, data storage, and new business models pertaining to CBDM. One question, in particular, has often been raised: is cloud-based design and manufacturing actually a new paradigm, or is it just "old wine in new bottles"? To answer this question, we discuss and compare the existing definitions for CBDM, identify the essential characteristics of CBDM, define a systematic requirements checklist that an idealized CBDM system should satisfy, and compare CBDM to other relevant but more traditional collaborative design and distributed manufacturing systems such as web- and agent-based design and manufacturing systems. To justify the conclusion that CBDM can be considered as a new paradigm that is anticipated to drive digital manufacturing and design innovation, we present the development of a smart delivery drone as an idealized CBDM example scenario and propose a corresponding CBDM system architecture that incorporates CBDM-based design processes, integrated manufacturing services, information and supply chain management in a holistic sense. © 2014 Elsevier Ltd. All rights reserved.},
  keywords = {Cloud-based design and manufacturing,Collaborative design,Design innovation,Digital manufacturing,Distributed manufacturing}
}

@article{wuCloudbasedDesignManufacturing2015a,
  title = {Cloud-Based Design and Manufacturing: {{A}} New Paradigm in Digital Manufacturing and Design Innovation},
  author = {Wu, Dazhong and Rosen, David W. and Wang, Lihui and Schaefer, Dirk},
  date = {2015},
  journaltitle = {CAD Computer Aided Design},
  volume = {59},
  pages = {1--14},
  publisher = {{Elsevier Ltd}},
  issn = {00104485},
  doi = {10.1016/j.cad.2014.07.006},
  abstract = {Cloud-based design manufacturing (CBDM) refers to a service-oriented networked product development model in which service consumers are enabled to configure, select, and utilize customized product realization resources and services ranging from computer-aided engineering software to reconfigurable manufacturing systems. An ongoing debate on CBDM in the research community revolves around several aspects such as definitions, key characteristics, computing architectures, communication and collaboration processes, crowdsourcing processes, information and communication infrastructure, programming models, data storage, and new business models pertaining to CBDM. One question, in particular, has often been raised: is cloud-based design and manufacturing actually a new paradigm, or is it just "old wine in new bottles"? To answer this question, we discuss and compare the existing definitions for CBDM, identify the essential characteristics of CBDM, define a systematic requirements checklist that an idealized CBDM system should satisfy, and compare CBDM to other relevant but more traditional collaborative design and distributed manufacturing systems such as web- and agent-based design and manufacturing systems. To justify the conclusion that CBDM can be considered as a new paradigm that is anticipated to drive digital manufacturing and design innovation, we present the development of a smart delivery drone as an idealized CBDM example scenario and propose a corresponding CBDM system architecture that incorporates CBDM-based design processes, integrated manufacturing services, information and supply chain management in a holistic sense. © 2014 Elsevier Ltd. All rights reserved.},
  keywords = {Cloud-based design and manufacturing,Collaborative design,Design innovation,Digital manufacturing,Distributed manufacturing},
  file = {C:\Users\leemar\Zotero\storage\CTWYLPCY\1-s2.0-S0010448514001560-main.pdf}
}

@article{wuDesignControlExperimental2021,
  title = {Design, Control, and Experimental Verification of a Soft Knee Exoskeleton for Rehabilitation during Walking},
  author = {Wu, Q. and Zhang, Y. and Chen, Y.},
  date = {2021},
  journaltitle = {Proceedings of the Institution of Mechanical Engineers. Part I: Journal of Systems and Control Engineering},
  doi = {10.1177/09596518211014325},
  abstract = {Since the rigid constructions of the traditional exoskeletons are liable to increase inertia of the joint and limit wearer flexibility, the soft-type exoskeletons have been developed in recent years, which can reduce system inertia, increase interaction compliance, and ensure operation safety. In this article, we present the detailed design and preliminary control of a soft body-worn and tendon-sheath-driven exoskeleton that can apply appropriate torques to the biological knee joints during rehabilitation training. This article focuses on the design of compliance tendon-sheath actuation system based on Hill muscle model, which utilizes multi-wrap pulleys and Hill-based series elastic actuator to transmit effective forces. Besides, the overall control system and strategy architectures of knee soft exoskeleton are also proposed. A fuzzy proportional–integral–derivative controller is developed for the passive rehabilitation training. On this basis, a back-propagation-neural-network-based adaptive impedance control scheme is presented to provide adaptive force based on the disease condition of the patient. Finally, preliminary experiments are conducted to demonstrate the effectiveness of proposed exoskeleton and control strategies.}
}

@article{wuDesignControlExperimental2021a,
  title = {Design, Control, and Experimental Verification of a Soft Knee Exoskeleton for Rehabilitation during Walking},
  author = {Wu, Q. and Zhang, Y. and Chen, Y.},
  date = {2021},
  journaltitle = {Proceedings of the Institution of Mechanical Engineers. Part I: Journal of Systems and Control Engineering},
  doi = {10.1177/09596518211014325},
  abstract = {Since the rigid constructions of the traditional exoskeletons are liable to increase inertia of the joint and limit wearer flexibility, the soft-type exoskeletons have been developed in recent years, which can reduce system inertia, increase interaction compliance, and ensure operation safety. In this article, we present the detailed design and preliminary control of a soft body-worn and tendon-sheath-driven exoskeleton that can apply appropriate torques to the biological knee joints during rehabilitation training. This article focuses on the design of compliance tendon-sheath actuation system based on Hill muscle model, which utilizes multi-wrap pulleys and Hill-based series elastic actuator to transmit effective forces. Besides, the overall control system and strategy architectures of knee soft exoskeleton are also proposed. A fuzzy proportional–integral–derivative controller is developed for the passive rehabilitation training. On this basis, a back-propagation-neural-network-based adaptive impedance control scheme is presented to provide adaptive force based on the disease condition of the patient. Finally, preliminary experiments are conducted to demonstrate the effectiveness of proposed exoskeleton and control strategies.}
}

@article{wuEvaluationOpticalMyography2019,
  title = {Evaluation of Optical Myography Sensor as Predictor of Hand Postures},
  author = {Wu, Y. T. and Fujiwara, E. and Suzuki, C. K.},
  date = {2019},
  journaltitle = {IEEE Sensors Journal},
  volume = {19},
  number = {13},
  pages = {5299--5306},
  doi = {10.1109/JSEN.2019.2905229},
  abstract = {Optical myography stands as one of many techniques to assess hand postures. As a combination of computer vision and muscular activity analysis, it differs from conventional gesture recognition techniques, such as instrumented gloves or optical tracking, by not relying on the existence of a healthy hand, so it is able to detect the hand motion as well as the motion intent. In this aspect, optical myography is like well-established myographic approaches, such as surface electromyography or force myography, but it is simpler, more comfortable, and inexpensive. This recent technology is hereby evaluated upon the construction of a feasible and low-cost sensor that monitors both the front and the back of the forearm. The results are organized into two sections: the first validates the sensor and the second evaluates its performance as a predictor of eight static postures, including the thumb and the fingers motion. In the end, the sensor proved to be comparable to more mature techniques with an F-score of 92.2\% and 71.5\% for front- and back-side analysis, respectively.}
}

@article{wuEvaluationOpticalMyography2019a,
  title = {Evaluation of Optical Myography Sensor as Predictor of Hand Postures},
  author = {Wu, Y.T. and Fujiwara, E. and Suzuki, C.K.},
  date = {2019},
  journaltitle = {IEEE Sensors Journal},
  volume = {19},
  number = {13},
  pages = {5299--5306},
  doi = {10.1109/JSEN.2019.2905229},
  abstract = {Optical myography stands as one of many techniques to assess hand postures. As a combination of computer vision and muscular activity analysis, it differs from conventional gesture recognition techniques, such as instrumented gloves or optical tracking, by not relying on the existence of a healthy hand, so it is able to detect the hand motion as well as the motion intent. In this aspect, optical myography is like well-established myographic approaches, such as surface electromyography or force myography, but it is simpler, more comfortable, and inexpensive. This recent technology is hereby evaluated upon the construction of a feasible and low-cost sensor that monitors both the front and the back of the forearm. The results are organized into two sections: the first validates the sensor and the second evaluates its performance as a predictor of eight static postures, including the thumb and the fingers motion. In the end, the sensor proved to be comparable to more mature techniques with an F-score of 92.2\% and 71.5\% for front- and back-side analysis, respectively.}
}

@article{wuSurveyTeachingWorkplace2022,
  title = {A Survey on Teaching Workplace Skills to Construction Robots},
  author = {Wu, Haitao and Li, Heng and Fang, Xin and Luo, Xiaochun},
  date = {2022-11-01},
  journaltitle = {Expert Systems with Applications},
  volume = {205},
  publisher = {{Elsevier Ltd}},
  issn = {09574174},
  doi = {10.1016/j.eswa.2022.117658},
  abstract = {The construction industry is seeking a robotic revolution to meet increasing demands for productivity, quality, and safety. Typically, construction robots are usually pre-programmed for a single task, such as painting. Their behavior is fixed when they leave the factory. However, it is difficult to pre-program all capabilities (referred to as workplace skills) that construction workers may require. Construction robots are expected to have the same ability of skill learning as human apprentices, allowing them to acquire a wide range of workplace skills from experienced workers and eventually complete relevant construction tasks autonomously. However, workplace skill learning of robots has rarely been investigated in the construction industry. This survey reviews state-of-the-art approaches to help robots learn skills from human demonstrations. To begin, the workplace skill is represented as ‘Know That’ and ‘Know How’ problems. ‘Know That’ is a high-level task planning ability aimed at understanding human activities from demonstrations. ‘Know How’ refers to the ability to learn specific actions for completing the construction task. Sematic methods and learn from demonstration (LfD) methods are reviewed to tackle these two problems. Finally, we discuss the open issues of past research, present future directions, and highlight the survey's knowledge contributions. We believe that this survey will provide a new perspective on robots in the construction industry and inspire more discussions about skill learning of construction robots.},
  keywords = {★,Construction robots,Learning from demonstrations,Robot skill learning,Semantic methods,Workplace skill},
  file = {C:\Users\leemar\Zotero\storage\NXTHAVDN\1-s2.0-S0957417422009605-main.pdf}
}

@article{xiaoDeepLearningImage2022,
  title = {Deep {{Learning Image Captioning}} in {{Construction Management}}: {{A Feasibility Study}}},
  author = {Xiao, B. and Wang, Y. and Kang, S.-C.},
  date = {2022},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {148},
  number = {7},
  doi = {10.1061/(ASCE)CO.1943-7862.0002297},
  abstract = {Deep learning image captioning methods are able to generate one or several natural sentences to describe the contents of construction images. By deconstructing these sentences, the construction object and activity information can be retrieved integrally for automated scene analysis. However, the feasibility of deep learning image captioning in construction remains unclear. To fill this gap, this research investigates the feasibility of deep learning image captioning methods in construction management. First, a linguistic schema for annotating construction machine images was established, and a captioning data set was developed. Then, six deep learning image captioning methods from the computer vision community were selected and tested on the construction captioning data set. In the sentence-level evaluation, the transformer-self-critical sequence training (Tsfm-SCST) method has obtained the best performance among six methods with the bilingual evaluation (BLEU)-1 score of 0.606, BLEU-2 of 0.506, BLEU-3 of 0.427, BLEU-4 of 0.349, metric for evaluation of translation with explicit ordering (METEOR) of 0.287, recall-oriented understudy for gisting evaluation (ROUGE) of 0.585, consensus-based image description evaluation (CIDEr) of 1.715, and semantic propositional image caption evaluation (SPICE) score of 0.422. In the element-level evaluation, the Tsfm-SCST method achieved an average precision of 91.1\%, recall of 83.3\%, and an F1 score of 86.6\% for recognition of construction machine objects by deconstructing the generated sentences. This research indicates that deep learning image captioning is feasible as a method of generating accurate and precise text descriptions from construction images, with potential applications in construction scene analysis and image documentation.}
}

@article{xiaoDeepLearningImage2022a,
  title = {Deep {{Learning Image Captioning}} in {{Construction Management}}: {{A Feasibility Study}}},
  author = {Xiao, B. and Wang, Y. and Kang, S.-C.},
  date = {2022},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {148},
  number = {7},
  doi = {10.1061/(ASCE)CO.1943-7862.0002297},
  abstract = {Deep learning image captioning methods are able to generate one or several natural sentences to describe the contents of construction images. By deconstructing these sentences, the construction object and activity information can be retrieved integrally for automated scene analysis. However, the feasibility of deep learning image captioning in construction remains unclear. To fill this gap, this research investigates the feasibility of deep learning image captioning methods in construction management. First, a linguistic schema for annotating construction machine images was established, and a captioning data set was developed. Then, six deep learning image captioning methods from the computer vision community were selected and tested on the construction captioning data set. In the sentence-level evaluation, the transformer-self-critical sequence training (Tsfm-SCST) method has obtained the best performance among six methods with the bilingual evaluation (BLEU)-1 score of 0.606, BLEU-2 of 0.506, BLEU-3 of 0.427, BLEU-4 of 0.349, metric for evaluation of translation with explicit ordering (METEOR) of 0.287, recall-oriented understudy for gisting evaluation (ROUGE) of 0.585, consensus-based image description evaluation (CIDEr) of 1.715, and semantic propositional image caption evaluation (SPICE) score of 0.422. In the element-level evaluation, the Tsfm-SCST method achieved an average precision of 91.1\%, recall of 83.3\%, and an F1 score of 86.6\% for recognition of construction machine objects by deconstructing the generated sentences. This research indicates that deep learning image captioning is feasible as a method of generating accurate and precise text descriptions from construction images, with potential applications in construction scene analysis and image documentation.}
}

@article{xiaoDevelopmentWearableFeedback2014,
  title = {Towards the Development of a Wearable Feedback System for Monitoring the Activities of the Upper-Extremities},
  author = {Xiao, Zhen G and Menon, Carlo},
  date = {2014},
  journaltitle = {Journal of NeuroEngineering and Rehabilitation},
  shortjournal = {J NeuroEngineering Rehabil},
  volume = {11},
  number = {1},
  pages = {2},
  issn = {1743-0003},
  doi = {10.1186/1743-0003-11-2},
  url = {http://jneuroengrehab.biomedcentral.com/articles/10.1186/1743-0003-11-2},
  urldate = {2023-11-13},
  abstract = {Background: Body motion data registered by wearable sensors can provide objective feedback to patients on the effectiveness of the rehabilitation interventions they undergo. Such a feedback may motivate patients to keep increasing the amount of exercise they perform, thus facilitating their recovery during physical rehabilitation therapy. In this work, we propose a novel wearable and affordable system which can predict different postures of the upper-extremities by classifying force myographic (FMG) signals of the forearm in real-time. Methods: An easy to use force sensor resistor (FSR) strap to extract the upper-extremities FMG signals was prototyped. The FSR strap was designed to be placed on the proximal portion of the forearm and capture the activities of the main muscle groups with eight force input channels. The non-kernel based extreme learning machine (ELM) classifier with sigmoid based function was implemented for real-time classification due to its fast learning characteristics. A test protocol was designed to classify in real-time six upper-extremities postures that are needed to successfully complete a drinking task, which is a functional exercise often used in constraint-induced movement therapy. Six healthy volunteers participated in the test. Each participant repeated the drinking task three times. FMG data and classification results were recorded for analysis. Results: The obtained results confirmed that the FMG data captured from the FSR strap produced distinct patterns for the selected upper-extremities postures of the drinking task. With the use of the non-kernel based ELM, the postures associated to the drinking task were predicted in real-time with an average overall accuracy of 92.33\% and standard deviation of 3.19\%. Conclusions: This study showed that the proposed wearable FSR strap was able to detect eight FMG signals from the forearm. In addition, the implemented ELM algorithm was able to correctly classify in real-time six postures associated to the drinking task. The obtained results therefore point out that the proposed system has potential for providing instant feedback during functional rehabilitation exercises.},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\E276DDMB\Xiao 與 Menon - 2014 - Towards the development of a wearable feedback sys.pdf}
}

@inproceedings{xieEmbeddingSymbolicTemporal2021,
  title = {Embedding {{Symbolic Temporal Knowledge Into Deep Sequential Models}}},
  booktitle = {Proceedings - {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Xie, Y. and Zhou, F. and Soh, H.},
  date = {2021},
  volume = {2021-May},
  pages = {4267--4273},
  doi = {10.1109/ICRA48506.2021.9561952},
  abstract = {Sequences and time-series often arise in robot tasks, e.g., in activity recognition and imitation learning. In recent years, deep neural networks (DNNs) have emerged as an effective data-driven methodology for processing sequences given sufficient training data and compute resources. However, when data is limited, simpler models such as logic/rule-based methods work surprisingly well, especially when relevant prior knowledge is applied in their construction. However, unlike DNNs, these “structured” models can be difficult to extend, and do not work well with raw unstructured data. In this work, we seek to learn flexible DNNs, yet leverage prior temporal knowledge when available. Our approach is to embed symbolic knowledge expressed as linear temporal logic (LTL) and use these embeddings to guide the training of deep models. Specifically, we construct semantic-based embeddings of automata generated from LTL formula via a Graph Neural Network. Experiments show that these learnt embeddings can lead to improvements on downstream robot tasks such as sequential action recognition and imitation learning.},
  isbn = {978-1-72819-077-8}
}

@inproceedings{xieEmbeddingSymbolicTemporal2021a,
  title = {Embedding {{Symbolic Temporal Knowledge Into Deep Sequential Models}}},
  booktitle = {Proceedings - {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Xie, Y. and Zhou, F. and Soh, H.},
  date = {2021},
  volume = {2021-May},
  pages = {4267--4273},
  doi = {10.1109/ICRA48506.2021.9561952},
  abstract = {Sequences and time-series often arise in robot tasks, e.g., in activity recognition and imitation learning. In recent years, deep neural networks (DNNs) have emerged as an effective data-driven methodology for processing sequences given sufficient training data and compute resources. However, when data is limited, simpler models such as logic/rule-based methods work surprisingly well, especially when relevant prior knowledge is applied in their construction. However, unlike DNNs, these “structured” models can be difficult to extend, and do not work well with raw unstructured data. In this work, we seek to learn flexible DNNs, yet leverage prior temporal knowledge when available. Our approach is to embed symbolic knowledge expressed as linear temporal logic (LTL) and use these embeddings to guide the training of deep models. Specifically, we construct semantic-based embeddings of automata generated from LTL formula via a Graph Neural Network. Experiments show that these learnt embeddings can lead to improvements on downstream robot tasks such as sequential action recognition and imitation learning.},
  isbn = {978-1-72819-077-8}
}

@book{xueEfficientAmbientIntelligent2020,
  title = {An Efficient Ambient Intelligent–Assisted People Searching for {{Internet}} of {{Things}}–Based Health-Care System},
  author = {Xue, D. and Cheng, Y. and Gope, P.},
  date = {2020},
  journaltitle = {Assistive Technology for the Elderly},
  doi = {10.1016/B978-0-12-818546-9.00002-6},
  abstract = {As the life expectancy continues to rise in recent years, our society is facing more and more challenges of elderly well-being and health-care worker shortage. Smart robot is one of the potential solutions to relieve these social problems. A smart robot can work for 24 hours, help human health-care workers in daily tasks, take care of the residents in hospitals or nursing houses for promoting their health, and enable them to take part in the positive social activities. However, in an unstructured environment, designing a long-term autonomous smart robot is particularly challenging. Though the users hold very high expectations on the intelligent android that can understand human intentions and respond properly, a full-functional smart robot is expensive and hard to achieve. There is a trade-off between the contradictory threefold goals of safety, performance, and cost-efficiency during the design. If one of these design goals is approached further, it usually leads to a recession of one or even both of the other goals. In this chapter the ambient intelligence (AmI) technology is applied to optimize all the designing goals simultaneously by shifting the computation complexity away from the local sensor systems on the robots to the external sensors distributed in the workspace. In such a solution the external sensors can provide robots with a wide overview of the environment, and the robot can be adequately prepared to tackle the upcoming tasks. Benefitted to the robotic functionalities embedded and shared within the AmI environment, the system design is simplified, and the system expenses are also decreased. Meanwhile, the system safety is always the top priority; the security mechanisms are crucially important and need more of our attentions when the information is spreading within AmI environment.},
  isbn = {978-0-12-818546-9},
  pagetotal = {45-58}
}

@book{xueEfficientAmbientIntelligent2020a,
  title = {An Efficient Ambient Intelligent–Assisted People Searching for {{Internet}} of {{Things}}–Based Health-Care System},
  author = {Xue, D. and Cheng, Y. and Gope, P.},
  date = {2020},
  journaltitle = {Assistive Technology for the Elderly},
  doi = {10.1016/B978-0-12-818546-9.00002-6},
  abstract = {As the life expectancy continues to rise in recent years, our society is facing more and more challenges of elderly well-being and health-care worker shortage. Smart robot is one of the potential solutions to relieve these social problems. A smart robot can work for 24 hours, help human health-care workers in daily tasks, take care of the residents in hospitals or nursing houses for promoting their health, and enable them to take part in the positive social activities. However, in an unstructured environment, designing a long-term autonomous smart robot is particularly challenging. Though the users hold very high expectations on the intelligent android that can understand human intentions and respond properly, a full-functional smart robot is expensive and hard to achieve. There is a trade-off between the contradictory threefold goals of safety, performance, and cost-efficiency during the design. If one of these design goals is approached further, it usually leads to a recession of one or even both of the other goals. In this chapter the ambient intelligence (AmI) technology is applied to optimize all the designing goals simultaneously by shifting the computation complexity away from the local sensor systems on the robots to the external sensors distributed in the workspace. In such a solution the external sensors can provide robots with a wide overview of the environment, and the robot can be adequately prepared to tackle the upcoming tasks. Benefitted to the robotic functionalities embedded and shared within the AmI environment, the system design is simplified, and the system expenses are also decreased. Meanwhile, the system safety is always the top priority; the security mechanisms are crucially important and need more of our attentions when the information is spreading within AmI environment.},
  isbn = {978-0-12-818546-9},
  pagetotal = {45-58}
}

@article{xuHybridPrintingMechanically2013,
  title = {Hybrid Printing of Mechanically and Biologically Improved Constructs for Cartilage Tissue Engineering Applications},
  author = {Xu, T. and Binder, K.W. and Albanna, M.Z. and Dice, D. and Zhao, W. and Yoo, J.J. and Atala, A.},
  date = {2013},
  journaltitle = {Biofabrication},
  volume = {5},
  number = {1},
  doi = {10.1088/1758-5082/5/1/015001},
  abstract = {Bioprinting is an emerging technique used to fabricate viable, 3D tissue constructs through the precise deposition of cells and hydrogels in a layer-by-layer fashion. Despite the ability to mimic the native properties of tissue, printed 3D constructs that are composed of naturally-derived biomaterials still lack structural integrity and adequate mechanical properties for use in vivo, thus limiting their development for use in load-bearing tissue engineering applications, such as cartilage. Fabrication of viable constructs using a novel multi-head deposition system provides the ability to combine synthetic polymers, which have higher mechanical strength than natural materials, with the favorable environment for cell growth provided by traditional naturally-derived hydrogels. However, the complexity and high cost associated with constructing the required robotic system hamper the widespread application of this approach. Moreover, the scaffolds fabricated by these robotic systems often lack flexibility, which further restrict their applications. To address these limitations, advanced fabrication techniques are necessary to generate complex constructs with controlled architectures and adequate mechanical properties. In this study, we describe the construction of a hybrid inkjet printing/electrospinning system that can be used to fabricate viable tissues for cartilage tissue engineering applications. Electrospinning of polycaprolactone fibers was alternated with inkjet printing of rabbit elastic chondrocytes suspended in a fibrin-collagen hydrogel in order to fabricate a five-layer tissue construct of 1 mm thickness. The chondrocytes survived within the printed hybrid construct with more than 80\% viability one week after printing. In addition, the cells proliferated and maintained their basic biological properties within the printed layered constructs. Furthermore, the fabricated constructs formed cartilage-like tissues both in vitro and in vivo as evidenced by the deposition of type II collagen and glycosaminoglycans. Moreover, the printed hybrid scaffolds demonstrated enhanced mechanical properties compared to printed alginate or fibrin-collagen gels alone. This study demonstrates the feasibility of constructing a hybrid inkjet printing system using off-the-shelf components to produce cartilage constructs with improved biological and mechanical properties. © 2013 IOP Publishing Ltd.}
}

@article{xuHybridPrintingMechanically2013a,
  title = {Hybrid Printing of Mechanically and Biologically Improved Constructs for Cartilage Tissue Engineering Applications},
  author = {Xu, T. and Binder, K.W. and Albanna, M.Z. and Dice, D. and Zhao, W. and Yoo, J.J. and Atala, A.},
  date = {2013},
  journaltitle = {Biofabrication},
  volume = {5},
  number = {1},
  doi = {10.1088/1758-5082/5/1/015001},
  abstract = {Bioprinting is an emerging technique used to fabricate viable, 3D tissue constructs through the precise deposition of cells and hydrogels in a layer-by-layer fashion. Despite the ability to mimic the native properties of tissue, printed 3D constructs that are composed of naturally-derived biomaterials still lack structural integrity and adequate mechanical properties for use in vivo, thus limiting their development for use in load-bearing tissue engineering applications, such as cartilage. Fabrication of viable constructs using a novel multi-head deposition system provides the ability to combine synthetic polymers, which have higher mechanical strength than natural materials, with the favorable environment for cell growth provided by traditional naturally-derived hydrogels. However, the complexity and high cost associated with constructing the required robotic system hamper the widespread application of this approach. Moreover, the scaffolds fabricated by these robotic systems often lack flexibility, which further restrict their applications. To address these limitations, advanced fabrication techniques are necessary to generate complex constructs with controlled architectures and adequate mechanical properties. In this study, we describe the construction of a hybrid inkjet printing/electrospinning system that can be used to fabricate viable tissues for cartilage tissue engineering applications. Electrospinning of polycaprolactone fibers was alternated with inkjet printing of rabbit elastic chondrocytes suspended in a fibrin-collagen hydrogel in order to fabricate a five-layer tissue construct of 1 mm thickness. The chondrocytes survived within the printed hybrid construct with more than 80\% viability one week after printing. In addition, the cells proliferated and maintained their basic biological properties within the printed layered constructs. Furthermore, the fabricated constructs formed cartilage-like tissues both in vitro and in vivo as evidenced by the deposition of type II collagen and glycosaminoglycans. Moreover, the printed hybrid scaffolds demonstrated enhanced mechanical properties compared to printed alginate or fibrin-collagen gels alone. This study demonstrates the feasibility of constructing a hybrid inkjet printing system using off-the-shelf components to produce cartilage constructs with improved biological and mechanical properties. © 2013 IOP Publishing Ltd.}
}

@article{yabanigulProductionGyroidlikeModular2021,
  title = {Production of {{Gyroid-like}} Modular Systems with Non-Linear Robotic Hotwire Cutting},
  author = {Yabanigül, M.N. and Yazar, T.},
  date = {2021},
  journaltitle = {Automation in Construction},
  volume = {126},
  doi = {10.1016/j.autcon.2021.103671},
  abstract = {Robotic arms are being used by construction firms and schools of architecture around the world in design/build researches and material studies. Robotic hotwire cutting (RHC) is a commonly used technique in these studies. This technique has limitations on the production of free-form objects. This paper addresses this limitation by proposing an alternative non-linear robotic hotwire cutting (NL-RHC) workflow. The original contribution of this workflow is the usage of a shape memory alloy (SMA) as a cutting wire, that enables the production of curved forms. The workflow was tested on the production of a Gyroid-like modular system to reveal its advantages and limits. Several attempts were made to find the most accurate approximation of the Gyroid. The result suggested that NL-RHC would be an efficient solution for the production of curved surfaces if the SMA is trained and the robot path is calculated correctly}
}

@article{yabanigulProductionGyroidlikeModular2021a,
  title = {Production of {{Gyroid-like}} Modular Systems with Non-Linear Robotic Hotwire Cutting},
  author = {Yabanigül, M.N. and Yazar, T.},
  date = {2021},
  journaltitle = {Automation in Construction},
  volume = {126},
  doi = {10.1016/j.autcon.2021.103671},
  abstract = {Robotic arms are being used by construction firms and schools of architecture around the world in design/build researches and material studies. Robotic hotwire cutting (RHC) is a commonly used technique in these studies. This technique has limitations on the production of free-form objects. This paper addresses this limitation by proposing an alternative non-linear robotic hotwire cutting (NL-RHC) workflow. The original contribution of this workflow is the usage of a shape memory alloy (SMA) as a cutting wire, that enables the production of curved forms. The workflow was tested on the production of a Gyroid-like modular system to reveal its advantages and limits. Several attempts were made to find the most accurate approximation of the Gyroid. The result suggested that NL-RHC would be an efficient solution for the production of curved surfaces if the SMA is trained and the robot path is calculated correctly}
}

@article{yamadaDomainAdaptationStructured2014,
  title = {Domain Adaptation for Structured Regression},
  author = {Yamada, M. and Sigal, L. and Chang, Y.},
  date = {2014},
  journaltitle = {International Journal of Computer Vision},
  volume = {109},
  number = {1-2},
  pages = {126--145},
  doi = {10.1007/s11263-013-0689-x},
  abstract = {Discriminative regression models have proved effective for many vision applications (here we focus on 3D full-body and head pose estimation from image and depth data). However, dataset bias is common and is able to significantly degrade the performance of a trained model on target test sets. As we show, covariate shift, a form of unsupervised domain adaptation (USDA), can be used to address certain biases in this setting, but is unable to deal with more severe structural biases in the data. We propose an effective and efficient semi-supervised domain adaptation (SSDA) approach for addressing such more severe biases in the data. Proposed SSDA is a generalization of USDA, that is able to effectively leverage labeled data in the target domain when available. Our method amounts to projecting input features into a higher dimensional space (by construction well suited for domain adaptation) and estimating weights for the training samples based on the ratio of test and train marginals in that space. The resulting augmented weighted samples can then be used to learn a model of choice, alleviating the problems of bias in the data; as an example, we introduce SSDA twin Gaussian process regression (SSDA-TGP) model. With this model we also address the issue of data sharing, where we are able to leverage samples from certain activities (e.g.; walking, jogging) to improve predictive performance on very different activities (e.g.; boxing). In addition, we analyze the relationship between domain similarity and effectiveness of proposed USDA versus SSDA methods. Moreover, we propose a computationally efficient alternative to TGP (Bo and Sminchisescu 2010), and it's variants, called the direct TGP. We show that our model outperforms a number of baselines, on two public datasets: HumanEva and ETH Face Pose Range Image Dataset. We can also achieve 8-15 times speedup in computation time, over the traditional formulation of TGP, using the proposed direct formulation, with little to no loss in performance. © 2013 Springer Science+Business Media New York.}
}

@article{yamadaDomainAdaptationStructured2014a,
  title = {Domain Adaptation for Structured Regression},
  author = {Yamada, M. and Sigal, L. and Chang, Y.},
  date = {2014},
  journaltitle = {International Journal of Computer Vision},
  volume = {109},
  number = {1-2},
  pages = {126--145},
  doi = {10.1007/s11263-013-0689-x},
  abstract = {Discriminative regression models have proved effective for many vision applications (here we focus on 3D full-body and head pose estimation from image and depth data). However, dataset bias is common and is able to significantly degrade the performance of a trained model on target test sets. As we show, covariate shift, a form of unsupervised domain adaptation (USDA), can be used to address certain biases in this setting, but is unable to deal with more severe structural biases in the data. We propose an effective and efficient semi-supervised domain adaptation (SSDA) approach for addressing such more severe biases in the data. Proposed SSDA is a generalization of USDA, that is able to effectively leverage labeled data in the target domain when available. Our method amounts to projecting input features into a higher dimensional space (by construction well suited for domain adaptation) and estimating weights for the training samples based on the ratio of test and train marginals in that space. The resulting augmented weighted samples can then be used to learn a model of choice, alleviating the problems of bias in the data; as an example, we introduce SSDA twin Gaussian process regression (SSDA-TGP) model. With this model we also address the issue of data sharing, where we are able to leverage samples from certain activities (e.g.; walking, jogging) to improve predictive performance on very different activities (e.g.; boxing). In addition, we analyze the relationship between domain similarity and effectiveness of proposed USDA versus SSDA methods. Moreover, we propose a computationally efficient alternative to TGP (Bo and Sminchisescu 2010), and it's variants, called the direct TGP. We show that our model outperforms a number of baselines, on two public datasets: HumanEva and ETH Face Pose Range Image Dataset. We can also achieve 8-15 times speedup in computation time, over the traditional formulation of TGP, using the proposed direct formulation, with little to no loss in performance. © 2013 Springer Science+Business Media New York.}
}

@inproceedings{yamamotoDevelopmentSmartDevice2020,
  title = {Development of Smart Device Interlocked Robot Partners for Information Support and Smart Recommendation},
  booktitle = {{{IEEE International Conference}} on {{Fuzzy Systems}}},
  author = {Yamamoto, S. and Kubota, N.},
  date = {2020},
  volume = {2020-July},
  doi = {10.1109/FUZZ48607.2020.9177534},
  abstract = {Recently, various types of communication robots have been developed all over the world to make up for a lack of human labor. The purpose of communication robots is to provide services such as information support including facility guide and recommendation at airports and shopping centers, nursing homes for elderly people. In general, the effective integration of various modules is important to aim for rapid practical application in an aging society. However, it takes much cost to introduce communication robots because of software customization and contents design for information service in addition to the maintenance cost of software and hardware. Furthermore, we have to pay attention to safe physical interaction and considerable communication of communication robots with people. In this paper, we develop a robot partner for information support and propose a new method to recommend various information flexibly according to human intention.},
  isbn = {978-1-72816-932-3}
}

@inproceedings{yamamotoDevelopmentSmartDevice2020a,
  title = {Development of Smart Device Interlocked Robot Partners for Information Support and Smart Recommendation},
  booktitle = {{{IEEE International Conference}} on {{Fuzzy Systems}}},
  author = {Yamamoto, S. and Kubota, N.},
  date = {2020},
  volume = {2020-July},
  doi = {10.1109/FUZZ48607.2020.9177534},
  abstract = {Recently, various types of communication robots have been developed all over the world to make up for a lack of human labor. The purpose of communication robots is to provide services such as information support including facility guide and recommendation at airports and shopping centers, nursing homes for elderly people. In general, the effective integration of various modules is important to aim for rapid practical application in an aging society. However, it takes much cost to introduce communication robots because of software customization and contents design for information service in addition to the maintenance cost of software and hardware. Furthermore, we have to pay attention to safe physical interaction and considerable communication of communication robots with people. In this paper, we develop a robot partner for information support and propose a new method to recommend various information flexibly according to human intention.},
  isbn = {978-1-72816-932-3}
}

@inproceedings{yangAutomaticRecognitionConstruction2015,
  title = {Automatic Recognition of Construction Worker Activities Using Dense Trajectories},
  booktitle = {32nd {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} and {{Mining}}: {{Connected}} to the {{Future}}, {{Proceedings}}},
  author = {Yang, J. and Shi, Z. and Wu, Z.},
  date = {2015},
  doi = {10.22260/isarc2015/0007},
  abstract = {Wide spread monitoring cameras on construction sites provide large amount of information for construction management. The emerging of computer vision and machine learning technologies enables automatic recognition of construction activities from videos. As the executors of construction, the activities of construction workers have strong impact on productivity and progress. Compared to machine work, manual work is more subjective and may differ largely in operation flow and productivity from one worker to another. Hence only a handful of work study on vision based activity recognition of construction workers. Lacking of publicly available datasets is one of the main reasons that currently hinder advancement. The paper studies manual work of construction workers comprehensively, selects 11 common types of activities and establishes a new real world video dataset with 1176 instances. For activity recognition, a cutting-edge video description method, dense trajectories, has been applied. Support vector machines are integrated with a bag-of-features pipeline for activity learning and classification. Performance on multiple types of descriptors (Histograms of Oriented Gradients-HOG, Histograms of Optical Flow-HOF, Motion Boundary Histogram-MBH) and their combination has been evaluated. Experimental results show that the proposed system has achieved a state-of-art performance on the new dataset.},
  isbn = {978-951-758-597-2}
}

@inproceedings{yangAutomaticRecognitionConstruction2015a,
  title = {Automatic Recognition of Construction Worker Activities Using Dense Trajectories},
  booktitle = {32nd {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} and {{Mining}}: {{Connected}} to the {{Future}}, {{Proceedings}}},
  author = {Yang, J. and Shi, Z. and Wu, Z.},
  date = {2015},
  doi = {10.22260/isarc2015/0007},
  abstract = {Wide spread monitoring cameras on construction sites provide large amount of information for construction management. The emerging of computer vision and machine learning technologies enables automatic recognition of construction activities from videos. As the executors of construction, the activities of construction workers have strong impact on productivity and progress. Compared to machine work, manual work is more subjective and may differ largely in operation flow and productivity from one worker to another. Hence only a handful of work study on vision based activity recognition of construction workers. Lacking of publicly available datasets is one of the main reasons that currently hinder advancement. The paper studies manual work of construction workers comprehensively, selects 11 common types of activities and establishes a new real world video dataset with 1176 instances. For activity recognition, a cutting-edge video description method, dense trajectories, has been applied. Support vector machines are integrated with a bag-of-features pipeline for activity learning and classification. Performance on multiple types of descriptors (Histograms of Oriented Gradients-HOG, Histograms of Optical Flow-HOF, Motion Boundary Histogram-MBH) and their combination has been evaluated. Experimental results show that the proposed system has achieved a state-of-art performance on the new dataset.},
  isbn = {978-951-758-597-2}
}

@article{yangDeepConvolutionalNeural2015,
  title = {Deep Convolutional Neural Networks on Multichannel Time Series for Human Activity Recognition},
  author = {Yang, Jian Bo and Nguyen, Minh Nhut and San, Phyo Phyo and Li, Xiao Li and Krishnaswamy, Shonali},
  date = {2015},
  journaltitle = {IJCAI International Joint Conference on Artificial Intelligence},
  volume = {2015-Janua},
  pages = {3995--4001},
  issn = {10450823},
  abstract = {This paper focuses on human activity recognition (HAR) problem, in which inputs are multichannel time series signals acquired from a set of body-worn inertial sensors and outputs are predefined human activities. In this problem, extracting effective features for identifying activities is a critical but challenging task. Most existing work relies on heuristic hand-crafted feature design and shallow feature learning architectures, which cannot find those distinguishing features to accurately classify different activities. In this paper, we propose a systematic feature learning method for HAR problem. This method adopts a deep convolutional neural networks (CNN) to automate feature learning from the raw inputs in a systematic way. Through the deep architecture, the learned features are deemed as the higher level abstract representation of low level raw time series signals. By leveraging the labelled information via supervised learning, the learned features are endowed with more discriminative power. Unified in one model, feature learning and classification are mutually enhanced. All these unique advantages of the CNN make it outperform other HAR algorithms, as verified in the experiments on the Opportunity Activity Recognition Challenge and other benchmark datasets.},
  isbn = {9781577357384},
  issue = {Ijcai},
  keywords = {Special Track on Machine Learning}
}

@article{yangDeepConvolutionalNeural2015a,
  title = {Deep Convolutional Neural Networks on Multichannel Time Series for Human Activity Recognition},
  author = {Yang, Jian Bo and Nguyen, Minh Nhut and San, Phyo Phyo and Li, Xiao Li and Krishnaswamy, Shonali},
  date = {2015},
  journaltitle = {IJCAI International Joint Conference on Artificial Intelligence},
  volume = {2015-Janua},
  pages = {3995--4001},
  issn = {10450823},
  abstract = {This paper focuses on human activity recognition (HAR) problem, in which inputs are multichannel time series signals acquired from a set of body-worn inertial sensors and outputs are predefined human activities. In this problem, extracting effective features for identifying activities is a critical but challenging task. Most existing work relies on heuristic hand-crafted feature design and shallow feature learning architectures, which cannot find those distinguishing features to accurately classify different activities. In this paper, we propose a systematic feature learning method for HAR problem. This method adopts a deep convolutional neural networks (CNN) to automate feature learning from the raw inputs in a systematic way. Through the deep architecture, the learned features are deemed as the higher level abstract representation of low level raw time series signals. By leveraging the labelled information via supervised learning, the learned features are endowed with more discriminative power. Unified in one model, feature learning and classification are mutually enhanced. All these unique advantages of the CNN make it outperform other HAR algorithms, as verified in the experiments on the Opportunity Activity Recognition Challenge and other benchmark datasets.},
  isbn = {9781577357384},
  issue = {Ijcai},
  keywords = {Special Track on Machine Learning},
  file = {C:\Users\leemar\Zotero\storage\X7QTHTZW\561.pdf}
}

@book{yangHydraulicExcavatorsRecognition2014,
  title = {Hydraulic Excavators Recognition Based on Inverse "{{V}}" Feature of Mechanical Arm},
  author = {Yang, W. and Li, D. and Sun, D. and Liao, Q.},
  date = {2014},
  journaltitle = {Communications in Computer and Information Science},
  volume = {484},
  doi = {10.1007/978-3-662-45643-9_57},
  abstract = {Detecting hydraulic excavators in videos can increase the confidence coefficient of illegal construction in nationalized land. Hydraulic Excavators have multifarious working postures making them a difficult target using even state of the art object recognition algorithms.The contribution of this paper is to propose an inverse "V" model for hydraulic excavator detection. In this paper, we describe an hydraulic excavator detection system based on inverse "V" feature of mechanical arm which is formed by boom and dipper and show a detection system.Then a real-time video processing method is presented which is used for monitoring illegal construction activities on a land of state-ownership.},
  isbn = {978-3-662-45642-2},
  pagetotal = {536-544}
}

@book{yangHydraulicExcavatorsRecognition2014a,
  title = {Hydraulic Excavators Recognition Based on Inverse "{{V}}" Feature of Mechanical Arm},
  author = {Yang, W. and Li, D. and Sun, D. and Liao, Q.},
  date = {2014},
  journaltitle = {Communications in Computer and Information Science},
  volume = {484},
  doi = {10.1007/978-3-662-45643-9_57},
  abstract = {Detecting hydraulic excavators in videos can increase the confidence coefficient of illegal construction in nationalized land. Hydraulic Excavators have multifarious working postures making them a difficult target using even state of the art object recognition algorithms.The contribution of this paper is to propose an inverse "V" model for hydraulic excavator detection. In this paper, we describe an hydraulic excavator detection system based on inverse "V" feature of mechanical arm which is formed by boom and dipper and show a detection system.Then a real-time video processing method is presented which is used for monitoring illegal construction activities on a land of state-ownership.},
  isbn = {978-3-662-45642-2},
  pagetotal = {536-544}
}

@inproceedings{yangLowcostSmartIMU2019,
  title = {A Low-Cost and Smart {{IMU}} Tool for Tracking Construction Activities},
  booktitle = {Proceedings of the 36th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2019},
  author = {Yang, Xincong and Wang, Fenglai and Zhai, Ximei and Li, Heng and Yu, Yantao and Luo, Xiaochun},
  date = {2019-05},
  pages = {35--41},
  doi = {10.22260/isarc2019/0005},
  url = {http://www.iaarc.org/publications/2019_proceedings_of_the_36th_isarc/a_low_cost_and_smart_imu_tool_for_tracking_construction_activities.html},
  abstract = {Real-time activity monitoring is becoming one of the most significant technologies on construction sites because it can be applied to a variety of management problems, such as productivity formula and safety monitoring. However, current monitoring technologies are limited to recognizing postures in an ideal environment rather than dealing with the ambient occlusion and people-intensive situations on real construction sites. Therefore, this study develops a low-cost, non-intrusion and portable tool system in order to trace and track construction activities on complex and crowed construction sites. This system is composed of wireless sensors and a smart algorithm. Each sensor consists of an inertial measurement unit, a communication sensor (bluetooth low energy sensor) and several environmental sensors, which broadcasts the identification, acceleration, palstance and environmental measurements at a constant frequency. Since the dimension of the sensor is only 20 x 15 x 2 mm, it can be easily attached or screwed on to the hand tools as well as integrated with power tools. When a laptop or cell phone receives from these sensors, the construction activities are derived by the artificial intelligence algorithm in a timely manner, providing an visual posture monitoring as well as an automatic record of project progress. In the end, practical experiments of a concrete vibrator and a hammer prove the feasibility and effectiveness of the proposed IMU-based tool tracing and tracking system.},
  keywords = {Activity recognition,Construction tools,Inertial measurement unit,Low-cost,Non-intrusive}
}

@inproceedings{yangLowcostSmartIMU2019a,
  title = {A Low-Cost and Smart {{IMU}} Tool for Tracking Construction Activities},
  booktitle = {Proceedings of the 36th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2019},
  author = {Yang, Xincong and Wang, Fenglai and Zhai, Ximei and Li, Heng and Yu, Yantao and Luo, Xiaochun},
  date = {2019-05-24},
  pages = {35--41},
  doi = {10.22260/isarc2019/0005},
  url = {http://www.iaarc.org/publications/2019_proceedings_of_the_36th_isarc/a_low_cost_and_smart_imu_tool_for_tracking_construction_activities.html},
  abstract = {Real-time activity monitoring is becoming one of the most significant technologies on construction sites because it can be applied to a variety of management problems, such as productivity formula and safety monitoring. However, current monitoring technologies are limited to recognizing postures in an ideal environment rather than dealing with the ambient occlusion and people-intensive situations on real construction sites. Therefore, this study develops a low-cost, non-intrusion and portable tool system in order to trace and track construction activities on complex and crowed construction sites. This system is composed of wireless sensors and a smart algorithm. Each sensor consists of an inertial measurement unit, a communication sensor (bluetooth low energy sensor) and several environmental sensors, which broadcasts the identification, acceleration, palstance and environmental measurements at a constant frequency. Since the dimension of the sensor is only 20 x 15 x 2 mm, it can be easily attached or screwed on to the hand tools as well as integrated with power tools. When a laptop or cell phone receives from these sensors, the construction activities are derived by the artificial intelligence algorithm in a timely manner, providing an visual posture monitoring as well as an automatic record of project progress. In the end, practical experiments of a concrete vibrator and a hammer prove the feasibility and effectiveness of the proposed IMU-based tool tracing and tracking system.},
  keywords = {Activity recognition,Construction tools,Inertial measurement unit,Low-cost,Non-intrusive},
  file = {C:\Users\leemar\Zotero\storage\5KJIIZKR\ISARC_2019_Paper_7.pdf}
}

@inproceedings{yangManipulationActionTree2014,
  title = {Manipulation Action Tree Bank: {{A}} Knowledge Resource for Humanoids},
  shorttitle = {Manipulation Action Tree Bank},
  booktitle = {2014 {{IEEE-RAS International Conference}} on {{Humanoid Robots}}},
  author = {Yang, Yezhou and Guha, Anupam and Fermuller, Cornelia and Aloimonos, Yiannis},
  date = {2014-11},
  pages = {987--992},
  publisher = {{IEEE}},
  location = {{Madrid, Spain}},
  doi = {10.1109/HUMANOIDS.2014.7041483},
  url = {http://ieeexplore.ieee.org/document/7041483/},
  urldate = {2023-03-23},
  eventtitle = {2014 {{IEEE-RAS}} 14th {{International Conference}} on {{Humanoid Robots}} ({{Humanoids}} 2014)},
  isbn = {978-1-4799-7174-9}
}

@article{yangManipulationActionTree2015,
  title = {Manipulation Action Tree Bank: {{A}} Knowledge Resource for Humanoids},
  author = {Yang, Yezhou and Guha, Anupam and Fermüller, Cornelia and Aloimonos, Yiannis},
  date = {2015},
  journaltitle = {IEEE-RAS International Conference on Humanoid Robots},
  volume = {2015-Febru},
  pages = {987--992},
  issn = {21640580},
  doi = {10.1109/HUMANOIDS.2014.7041483},
  abstract = {Our premise is that actions of manipulation are represented at multiple levels of abstraction. At the high level a grammatical structure represents symbolic information (objects, actions, tools, body parts) and their interaction in a temporal sequence, and at lower levels the symbolic quantities are grounded in perception. In this paper we create symbolic high-level representations in the form of manipulation action tree banks, which are parsed from annotated action corpora. A context free grammar provides the grammatical description for the creation of the semantic trees. Experiments conducted on the tree banks show that they allow to 1) generate so-called visual semantic graphs (VSGs), 2) compare the semantic distance between steps of activities and 3) discover the underlying semantic space of an activity. We believe that tree banks are an effective and practical way to organize semantic structures of manipulation actions for humanoids applications. They could be used as basis for 1) automatic manipulation action understanding and execution and 2) reasoning and prediction during both observation and execution. The knowledge resource follows the widely used Penn Tree Bank format.},
  isbn = {9781479971749}
}

@article{yangManipulationActionTree2015a,
  title = {Manipulation Action Tree Bank: {{A}} Knowledge Resource for Humanoids},
  author = {Yang, Yezhou and Guha, Anupam and Fermüller, Cornelia and Aloimonos, Yiannis},
  date = {2015},
  journaltitle = {IEEE-RAS International Conference on Humanoid Robots},
  volume = {2015-Febru},
  pages = {987--992},
  issn = {21640580},
  doi = {10.1109/HUMANOIDS.2014.7041483},
  abstract = {Our premise is that actions of manipulation are represented at multiple levels of abstraction. At the high level a grammatical structure represents symbolic information (objects, actions, tools, body parts) and their interaction in a temporal sequence, and at lower levels the symbolic quantities are grounded in perception. In this paper we create symbolic high-level representations in the form of manipulation action tree banks, which are parsed from annotated action corpora. A context free grammar provides the grammatical description for the creation of the semantic trees. Experiments conducted on the tree banks show that they allow to 1) generate so-called visual semantic graphs (VSGs), 2) compare the semantic distance between steps of activities and 3) discover the underlying semantic space of an activity. We believe that tree banks are an effective and practical way to organize semantic structures of manipulation actions for humanoids applications. They could be used as basis for 1) automatic manipulation action understanding and execution and 2) reasoning and prediction during both observation and execution. The knowledge resource follows the widely used Penn Tree Bank format.},
  isbn = {9781479971749},
  keywords = {★},
  file = {C:\Users\leemar\Zotero\storage\NW83AUFL\Manipulation_action_tree_bank_A_knowledge_resource_for_humanoids.pdf}
}

@inproceedings{yangParametricModellingAsbuilt2017,
  title = {Parametric Modelling of As-Built Beam Framed Structure in Bim Environment},
  booktitle = {International {{Archives}} of the {{Photogrammetry}}, {{Remote Sensing}} and {{Spatial Information Sciences}} - {{ISPRS Archives}}},
  author = {Yang, X. and Koehl, M. and Grussenmeyer, P.},
  date = {2017},
  volume = {42},
  pages = {651--657},
  doi = {10.5194/isprs-archives-XLII-2-W3-651-2017},
  abstract = {A complete documentation and conservation of a historic timber roof requires the integration of geometry modelling, attributional and dynamic information management and results of structural analysis. Recently developed as-built Building Information Modelling (BIM) technique has the potential to provide a uniform platform, which provides possibility to integrate the traditional geometry modelling, parametric elements management and structural analysis together. The main objective of the project presented in this paper is to develop a parametric modelling tool for a timber roof structure whose elements are leaning and crossing beam frame. Since Autodesk Revit, as the typical BIM software, provides the platform for parametric modelling and information management, an API plugin, able to automatically create the parametric beam elements and link them together with strict relationship, was developed. The plugin under development is introduced in the paper, which can obtain the parametric beam model via Autodesk Revit API from total station points and terrestrial laser scanning data. The results show the potential of automatizing the parametric modelling by interactive API development in BIM environment. It also integrates the separate data processing and different platforms into the uniform Revit software.},
  issue = {2W3},
  file = {C:\Users\leemar\Zotero\storage\YB7XSX4L\Parametric-modelling-of-asbuilt-beam-framed-structure-in-bim-environmentInternational-Archives-of-the-Photogrammetry-Remote-Sensing-and-Spatial-Information-Sciences--ISPRS-Archives.pdf}
}

@inproceedings{yangParametricModellingAsbuilt2017a,
  title = {Parametric Modelling of As-Built Beam Framed Structure in Bim Environment},
  booktitle = {International {{Archives}} of the {{Photogrammetry}}, {{Remote Sensing}} and {{Spatial Information Sciences}} - {{ISPRS Archives}}},
  author = {Yang, X. and Koehl, M. and Grussenmeyer, P.},
  date = {2017},
  volume = {42},
  pages = {651--657},
  doi = {10.5194/isprs-archives-XLII-2-W3-651-2017},
  abstract = {A complete documentation and conservation of a historic timber roof requires the integration of geometry modelling, attributional and dynamic information management and results of structural analysis. Recently developed as-built Building Information Modelling (BIM) technique has the potential to provide a uniform platform, which provides possibility to integrate the traditional geometry modelling, parametric elements management and structural analysis together. The main objective of the project presented in this paper is to develop a parametric modelling tool for a timber roof structure whose elements are leaning and crossing beam frame. Since Autodesk Revit, as the typical BIM software, provides the platform for parametric modelling and information management, an API plugin, able to automatically create the parametric beam elements and link them together with strict relationship, was developed. The plugin under development is introduced in the paper, which can obtain the parametric beam model via Autodesk Revit API from total station points and terrestrial laser scanning data. The results show the potential of automatizing the parametric modelling by interactive API development in BIM environment. It also integrates the separate data processing and different platforms into the uniform Revit software.},
  issue = {2W3},
  file = {C:\Users\leemar\Zotero\storage\KPSM8J33\Parametric-modelling-of-asbuilt-beam-framed-structure-in-bim-environmentInternational-Archives-of-the-Photogrammetry-Remote-Sensing-and-Spatial-Information-Sciences--ISPRS-Archives.pdf}
}

@book{yangSurveyMediaInteraction2015,
  title = {A Survey on Media Interaction in Social Robotics},
  author = {Yang, L. and Cheng, H. and Hao, J. and Ji, Y. and Kuang, Y.},
  date = {2015},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {9315},
  doi = {10.1007/978-3-319-24078-7_18},
  abstract = {Social robots have attracted increasing research interests in academic and industry communities. The emerging media technologies greatly inspired human-robot interaction approaches, which aimed to tackle important challenges in practical applications. This paper presents a survey of recent works on media interaction in social robotics. We first introduce the state-of-the-art social robots and the related concepts. Then, we review the visual interaction approaches through various human actions such as facial expression, hand gesture and body motion, which have been widely considered as effective media interaction ways with robots. Furthermore, we summarize the event detection approaches which are crucial for robots to understand the environment and human intentions. While the emphasis is on vision-based interaction approaches, the multimodal interaction works are also briefly summarized for practitioners.},
  isbn = {978-3-319-24077-0},
  pagetotal = {181-190}
}

@book{yangSurveyMediaInteraction2015a,
  title = {A Survey on Media Interaction in Social Robotics},
  author = {Yang, L. and Cheng, H. and Hao, J. and Ji, Y. and Kuang, Y.},
  date = {2015},
  journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {9315},
  doi = {10.1007/978-3-319-24078-7_18},
  abstract = {Social robots have attracted increasing research interests in academic and industry communities. The emerging media technologies greatly inspired human-robot interaction approaches, which aimed to tackle important challenges in practical applications. This paper presents a survey of recent works on media interaction in social robotics. We first introduce the state-of-the-art social robots and the related concepts. Then, we review the visual interaction approaches through various human actions such as facial expression, hand gesture and body motion, which have been widely considered as effective media interaction ways with robots. Furthermore, we summarize the event detection approaches which are crucial for robots to understand the environment and human intentions. While the emphasis is on vision-based interaction approaches, the multimodal interaction works are also briefly summarized for practitioners.},
  isbn = {978-3-319-24077-0},
  pagetotal = {181-190}
}

@article{yangVisionbasedActionRecognition2016,
  title = {Vision-Based Action Recognition of Construction Workers Using Dense Trajectories},
  author = {Yang, J. and Shi, Z. and Wu, Z.},
  date = {2016},
  journaltitle = {Advanced Engineering Informatics},
  volume = {30},
  number = {3},
  pages = {327--336},
  doi = {10.1016/j.aei.2016.04.009},
  abstract = {Wide spread monitoring cameras on construction sites provide large amount of information for construction management. The emerging of computer vision and machine learning technologies enables automated recognition of construction activities from videos. As the executors of construction, the activities of construction workers have strong impact on productivity and progress. Compared to machine work, manual work is more subjective and may differ largely in operation flow and productivity among different individuals. Hence only a handful of work studies on vision based action recognition of construction workers. Lacking of publicly available datasets is one of the main reasons that currently hinder advancement. The paper studies worker actions comprehensively, abstracts 11 common types of actions from 5 kinds of trades and establishes a new real world video dataset with 1176 instances. For action recognition, a cutting-edge video description method, dense trajectories, has been applied. Support vector machines are integrated with a bag-of-features pipeline for action learning and classification. Performances on multiple types of descriptors (Histograms of Oriented Gradients - HOG, Histograms of Optical Flow - HOF, Motion Boundary Histogram - MBH) and their combination have been evaluated. Discussion on different parameter settings and comparison to the state-of-the-art method are provided. Experimental results show that the system with codebook size 500 and MBH descriptor has achieved an average accuracy of 59\% for worker action recognition, outperforming the state-of-the-art result by 24\%.}
}

@article{yangVisionbasedActionRecognition2016a,
  title = {Vision-Based Action Recognition of Construction Workers Using Dense Trajectories},
  author = {Yang, J. and Shi, Z. and Wu, Z.},
  date = {2016},
  journaltitle = {Advanced Engineering Informatics},
  volume = {30},
  number = {3},
  pages = {327--336},
  doi = {10.1016/j.aei.2016.04.009},
  abstract = {Wide spread monitoring cameras on construction sites provide large amount of information for construction management. The emerging of computer vision and machine learning technologies enables automated recognition of construction activities from videos. As the executors of construction, the activities of construction workers have strong impact on productivity and progress. Compared to machine work, manual work is more subjective and may differ largely in operation flow and productivity among different individuals. Hence only a handful of work studies on vision based action recognition of construction workers. Lacking of publicly available datasets is one of the main reasons that currently hinder advancement. The paper studies worker actions comprehensively, abstracts 11 common types of actions from 5 kinds of trades and establishes a new real world video dataset with 1176 instances. For action recognition, a cutting-edge video description method, dense trajectories, has been applied. Support vector machines are integrated with a bag-of-features pipeline for action learning and classification. Performances on multiple types of descriptors (Histograms of Oriented Gradients - HOG, Histograms of Optical Flow - HOF, Motion Boundary Histogram - MBH) and their combination have been evaluated. Discussion on different parameter settings and comparison to the state-of-the-art method are provided. Experimental results show that the system with codebook size 500 and MBH descriptor has achieved an average accuracy of 59\% for worker action recognition, outperforming the state-of-the-art result by 24\%.}
}

@inproceedings{yangVisionbasedCraneTracking2011,
  title = {Vision-Based Crane Tracking for Understanding Construction Activity},
  booktitle = {Congress on {{Computing}} in {{Civil Engineering}}, {{Proceedings}}},
  author = {Yang, J. and Vela, P. A. and Teizer, J. and Shi, Z. K.},
  date = {2011},
  pages = {258--265},
  doi = {10.1061/41182(416)32},
  abstract = {Visual monitoring of construction work sites through the installation of surveillance cameras has become prevalent in the construction industry. Cameras also have practical utility for automatic observation of construction events and activities. This paper demonstrates the use of a surveillance camera for assessing tower crane activities during the course of a work day. The jib angle and the trolley position are tracked using 2D-3D rigid pose estimation and density-based tracking algorithms, respectively. A finite-state machine model for crane activity is designed to process the track signals and recognize crane activity as belonging to one of the two categories: concrete pouring and non-concrete material movement. Experimental results from a construction surveillance camera show that crane activities are correctly identified. © 2011 ASCE.}
}

@inproceedings{yangVisionbasedCraneTracking2011a,
  title = {Vision-Based Crane Tracking for Understanding Construction Activity},
  booktitle = {Congress on {{Computing}} in {{Civil Engineering}}, {{Proceedings}}},
  author = {Yang, J. and Vela, P.A. and Teizer, J. and Shi, Z.K.},
  date = {2011},
  pages = {258--265},
  doi = {10.1061/41182(416)32},
  abstract = {Visual monitoring of construction work sites through the installation of surveillance cameras has become prevalent in the construction industry. Cameras also have practical utility for automatic observation of construction events and activities. This paper demonstrates the use of a surveillance camera for assessing tower crane activities during the course of a work day. The jib angle and the trolley position are tracked using 2D-3D rigid pose estimation and density-based tracking algorithms, respectively. A finite-state machine model for crane activity is designed to process the track signals and recognize crane activity as belonging to one of the two categories: concrete pouring and non-concrete material movement. Experimental results from a construction surveillance camera show that crane activities are correctly identified. © 2011 ASCE.}
}

@article{yanSystemRealizationPath2021,
  title = {System Realization Path of Visual Sorting Robot System under Big Data Ecological Environment},
  author = {Yan, Z. and Liu, H. and Cao, Q. and Yan, Z.},
  date = {2021},
  journaltitle = {Fresenius Environmental Bulletin},
  volume = {30},
  number = {5},
  pages = {4953--4961},
  abstract = {Big data ecological environment is the key direction of global science and technology develop-ment, which will be conducive to the construction of global science and technology ecosystem. Industrial intelligence has become the development trend of various countries' industries, and the application of machine vision technology to industrial robots has become an important way of industrial intelligence. The main breakthrough point of industrial robot maÂchine vision technology lies in the intelligent classiÂfication and positioning of targets. Most of the existAîng visual industrial robots perform simple work-piece classification based on traditional graphics processing technology. This article introduces the principle and architecture of big data Hadoop techÂnology, designs the motion model and positioning navigation model of the visual sorting robot, proÂposes the process path to realize the positioning and navigation algorithm of the visual sorting robot, and finally gives the overall implementation and reÂmotely control the operation of the visual sorting roÂbot. At the same time, the hardware design of the visAûal sorting robot is introduced, the realization path of the image processing of the sorting robot system is discussed, and theoretical research and practical testing are carried out. There are two core problems in the visual robot sorting system, one is image recognition and target tracking based on image proÂcessing, and the other is the capture and sorting control strategy based on actual industrial robots. The target to be recognized is goods. This article also expounds the overall scheme of the intelligent sorting process, expounds the functional principle of the system, and verifies the feasibility of the system through specific practices. The experimental results show that the visual sorting system can sort workpieces placed at any position in the working area, with a maximum positioning error of 0.65mm, and the sortAîng effect is good, meeting the sorting requirements. This study can provide a reliable reference for the construction of global science and technology eco-system.}
}

@article{yanSystemRealizationPath2021a,
  title = {System Realization Path of Visual Sorting Robot System under Big Data Ecological Environment},
  author = {Yan, Z. and Liu, H. and Cao, Q. and Yan, Z.},
  date = {2021},
  journaltitle = {Fresenius Environmental Bulletin},
  volume = {30},
  number = {5},
  pages = {4953--4961},
  abstract = {Big data ecological environment is the key direction of global science and technology develop-ment, which will be conducive to the construction of global science and technology ecosystem. Industrial intelligence has become the development trend of various countries' industries, and the application of machine vision technology to industrial robots has become an important way of industrial intelligence. The main breakthrough point of industrial robot maÂchine vision technology lies in the intelligent classiÂfication and positioning of targets. Most of the existAîng visual industrial robots perform simple work-piece classification based on traditional graphics processing technology. This article introduces the principle and architecture of big data Hadoop techÂnology, designs the motion model and positioning navigation model of the visual sorting robot, proÂposes the process path to realize the positioning and navigation algorithm of the visual sorting robot, and finally gives the overall implementation and reÂmotely control the operation of the visual sorting roÂbot. At the same time, the hardware design of the visAûal sorting robot is introduced, the realization path of the image processing of the sorting robot system is discussed, and theoretical research and practical testing are carried out. There are two core problems in the visual robot sorting system, one is image recognition and target tracking based on image proÂcessing, and the other is the capture and sorting control strategy based on actual industrial robots. The target to be recognized is goods. This article also expounds the overall scheme of the intelligent sorting process, expounds the functional principle of the system, and verifies the feasibility of the system through specific practices. The experimental results show that the visual sorting system can sort workpieces placed at any position in the working area, with a maximum positioning error of 0.65mm, and the sortAîng effect is good, meeting the sorting requirements. This study can provide a reliable reference for the construction of global science and technology eco-system.}
}

@book{yarramsettyReductionAnnualEnergy2021,
  title = {Reduction of {{Annual Energy Consumption}} of {{Multifamily Dwellings Using BIM}} and {{Simulation Tools}}},
  author = {Yarramsetty, S. and Sivakumar, M. V. N. and Raj, P. Anand},
  date = {2021},
  journaltitle = {RILEM Bookseries},
  volume = {29},
  doi = {10.1007/978-3-030-51485-3_19},
  abstract = {Designing and constructing a Sustainable building is an emerging area of interest with AECOO (Architectural, Engineering, and Construction, Owner and Operator) trades, which is evidenced by the increased use of the green building rating systems throughout the world. Building information modeling (BIM) is one of the effective ways of deciding the suitable building orientation and envelope that controls project cost, time and energy. In this study, multifamily residential building is taken as a case study, which is located in Afghanistan. Energy consumption analysis was conducted by using building energy performance tools. The building is modeled in Autodesk-Revit and different orientations, building envelopes and Wall to window ratio analysis were carried out to find the minimal energy consumption scenario. A total of 126 simulations were conducted. Ultimately, the most energy-efficient option in the context of Afghan dwellings was figured out. Locally available building materials were used in the study. The best energy efficient orientation of the building is evaluated by rotating the building in 15° rotation each time. Furthermore, varying the glazing area from 10 to 60\% for energy-efficient WWR ratio. 10\% glazing consumes minimal energy consumption for the C48 (combination 48) with wall type (W3)—Adobe brick wall, roof type (R4)—Mud Roof with timber as core structure and Floor type (F4)—Mud floor with timber as structure, was the best option which consumes the least amount of energy leading to reduction in annual electricity demand.},
  isbn = {978-3-030-51484-6},
  pagetotal = {285-297}
}

@incollection{yarramsettyReductionAnnualEnergy2021a,
  title = {Reduction of {{Annual Energy Consumption}} of {{Multifamily Dwellings Using BIM}} and {{Simulation Tools}}},
  booktitle = {{{RILEM Bookseries}}},
  author = {Yarramsetty, Subbarao and Sivakumar, M. V. N. and Anand Raj, P.},
  date = {2021},
  volume = {29},
  pages = {285--297},
  doi = {10.1007/978-3-030-51485-3_19},
  url = {http://link.springer.com/10.1007/978-3-030-51485-3_19},
  abstract = {Designing and constructing a Sustainable building is an emerging area of interest with AECOO (Architectural, Engineering, and Construction, Owner and Operator) trades, which is evidenced by the increased use of the green building rating systems throughout the world. Building information modeling (BIM) is one of the effective ways of deciding the suitable building orientation and envelope that controls project cost, time and energy. In this study, multifamily residential building is taken as a case study, which is located in Afghanistan. Energy consumption analysis was conducted by using building energy performance tools. The building is modeled in Autodesk-Revit and different orientations, building envelopes and Wall to window ratio analysis were carried out to find the minimal energy consumption scenario. A total of 126 simulations were conducted. Ultimately, the most energy-efficient option in the context of Afghan dwellings was figured out. Locally available building materials were used in the study. The best energy efficient orientation of the building is evaluated by rotating the building in 15° rotation each time. Furthermore, varying the glazing area from 10 to 60\% for energy-efficient WWR ratio. 10\% glazing consumes minimal energy consumption for the C48 (combination 48) with wall type (W3)—Adobe brick wall, roof type (R4)—Mud Roof with timber as core structure and Floor type (F4)—Mud floor with timber as structure, was the best option which consumes the least amount of energy leading to reduction in annual electricity demand.},
  isbn = {978-3-030-51484-6}
}

@book{yarramsettyReductionAnnualEnergy2021b,
  title = {Reduction of {{Annual Energy Consumption}} of {{Multifamily Dwellings Using BIM}} and {{Simulation Tools}}},
  author = {Yarramsetty, S. and Sivakumar, M.V.N. and Anand Raj, P.},
  date = {2021},
  journaltitle = {RILEM Bookseries},
  volume = {29},
  doi = {10.1007/978-3-030-51485-3_19},
  abstract = {Designing and constructing a Sustainable building is an emerging area of interest with AECOO (Architectural, Engineering, and Construction, Owner and Operator) trades, which is evidenced by the increased use of the green building rating systems throughout the world. Building information modeling (BIM) is one of the effective ways of deciding the suitable building orientation and envelope that controls project cost, time and energy. In this study, multifamily residential building is taken as a case study, which is located in Afghanistan. Energy consumption analysis was conducted by using building energy performance tools. The building is modeled in Autodesk-Revit and different orientations, building envelopes and Wall to window ratio analysis were carried out to find the minimal energy consumption scenario. A total of 126 simulations were conducted. Ultimately, the most energy-efficient option in the context of Afghan dwellings was figured out. Locally available building materials were used in the study. The best energy efficient orientation of the building is evaluated by rotating the building in 15° rotation each time. Furthermore, varying the glazing area from 10 to 60\% for energy-efficient WWR ratio. 10\% glazing consumes minimal energy consumption for the C48 (combination 48) with wall type (W3)—Adobe brick wall, roof type (R4)—Mud Roof with timber as core structure and Floor type (F4)—Mud floor with timber as structure, was the best option which consumes the least amount of energy leading to reduction in annual electricity demand.},
  isbn = {978-3-030-51484-6},
  pagetotal = {285-297}
}

@article{yeImprovedTrustHumanRobot2023,
  title = {Improved {{Trust}} in {{Human-Robot Collaboration With ChatGPT}}},
  author = {Ye, Yang and You, Hengxu and Du, Jing},
  date = {2023},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {11},
  pages = {55748--55754},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3282111},
  url = {https://ieeexplore.ieee.org/document/10141597/},
  urldate = {2023-11-14},
  file = {C:\Users\leemar\Zotero\storage\YP7ANKRR\Ye 等。 - 2023 - Improved Trust in Human-Robot Collaboration With C.pdf}
}

@inproceedings{yeohOntologyBasedFrameworkChecking2019,
  title = {Ontology-{{Based Framework}} for {{Checking}} the {{Constructability}} of {{Concrete Volumetric Construction Submodules}} from {{BIM}}},
  booktitle = {Computing in {{Civil Engineering}} 2019: {{Visualization}}, {{Information Modeling}}, and {{Simulation}} - {{Selected Papers}} from the {{ASCE International Conference}} on {{Computing}} in {{Civil Engineering}} 2019},
  author = {Yeoh, J.K.W. and Jiao, R.},
  date = {2019},
  pages = {279--285},
  doi = {10.1061/9780784482421.036},
  abstract = {Volumetric construction, of which prefabricated prefinished volumetric construction (PPVC) is a specific type, offers numerous advantages such as reduced project duration, decreased on-site manpower, and better project quality over traditional construction methods. Additionally, in regions of high humidity, concrete volumetric construction modules offer greater maintainability than steel or timber. Hence, concrete volumetric construction is widely adopted in tropical built-up areas. However, concrete modules are heavy and methods to reduce the lifting weight are necessary. One such method is to partition concrete modules into smaller submodules or components that can then be joined onsite. Such a method offers a compromise in terms of faster installation, as well as smaller crane requirements. Despite the advantages, determining any optimal partition is computationally hard. Moreover, not all submodules are constructible; several constraints such as transportation, crane lifting capacity, and structural rigidity exist. To determine the constructability of a volumetric construction submodule, an ontology-based representation is developed from its building information model (BIM). Rules are defined to identify the constructible submodules from the ontology-based representation. The rules are validated using test cases against expert judgement, and shown to be accurate in identifying constructible concrete volumetric construction partitions.},
  isbn = {978-0-7844-8242-1}
}

@inproceedings{yeohOntologyBasedFrameworkChecking2019a,
  title = {Ontology-{{Based Framework}} for {{Checking}} the {{Constructability}} of {{Concrete Volumetric Construction Submodules}} from {{BIM}}},
  booktitle = {Computing in {{Civil Engineering}} 2019: {{Visualization}}, {{Information Modeling}}, and {{Simulation}} - {{Selected Papers}} from the {{ASCE International Conference}} on {{Computing}} in {{Civil Engineering}} 2019},
  author = {Yeoh, J.K.W. and Jiao, R.},
  date = {2019},
  pages = {279--285},
  doi = {10.1061/9780784482421.036},
  abstract = {Volumetric construction, of which prefabricated prefinished volumetric construction (PPVC) is a specific type, offers numerous advantages such as reduced project duration, decreased on-site manpower, and better project quality over traditional construction methods. Additionally, in regions of high humidity, concrete volumetric construction modules offer greater maintainability than steel or timber. Hence, concrete volumetric construction is widely adopted in tropical built-up areas. However, concrete modules are heavy and methods to reduce the lifting weight are necessary. One such method is to partition concrete modules into smaller submodules or components that can then be joined onsite. Such a method offers a compromise in terms of faster installation, as well as smaller crane requirements. Despite the advantages, determining any optimal partition is computationally hard. Moreover, not all submodules are constructible; several constraints such as transportation, crane lifting capacity, and structural rigidity exist. To determine the constructability of a volumetric construction submodule, an ontology-based representation is developed from its building information model (BIM). Rules are defined to identify the constructible submodules from the ontology-based representation. The rules are validated using test cases against expert judgement, and shown to be accurate in identifying constructible concrete volumetric construction partitions.},
  isbn = {978-0-7844-8242-1}
}

@article{yiRoboticsApplicationAdvanced2021,
  title = {Robotics Application for the Advanced Integration of Design and Technology in Architecture},
  author = {Yi, H.},
  date = {2021},
  journaltitle = {Computer Applications in Engineering Education},
  volume = {29},
  number = {5},
  pages = {1146--1162},
  doi = {10.1002/cae.22370},
  abstract = {This study reports and analyzes the first architectural robotics class regularly organized in a professional college~in South Korea. The course consists of two modules: (i) design experimentation with kinetic (responsive) building prototyping~and (ii) construction automation of a complex building form using an industrial robot arm. Both modules are structured to provide undergraduates with applied knowledge of kinematics and mechanisms. Along with introducing tools and content of robotics learning in architecture, the course development and students' perception of learning progress and intellectual achievement have been systematically assessed by adapting theoretical course analysis models (of Richards and of Kirkpatrick). The results reveal that learning motivation affects self-satisfaction and achievement. This suggests that the background, goals, and methods of teaching robotics engineering need to be carefully coordinated over the entire curricular context of building design education.}
}

@article{yiRoboticsApplicationAdvanced2021a,
  title = {Robotics Application for the Advanced Integration of Design and Technology in Architecture},
  author = {Yi, H.},
  date = {2021},
  journaltitle = {Computer Applications in Engineering Education},
  volume = {29},
  number = {5},
  pages = {1146--1162},
  doi = {10.1002/cae.22370},
  abstract = {This study reports and analyzes the first architectural robotics class regularly organized in a professional college~in South Korea. The course consists of two modules: (i) design experimentation with kinetic (responsive) building prototyping~and (ii) construction automation of a complex building form using an industrial robot arm. Both modules are structured to provide undergraduates with applied knowledge of kinematics and mechanisms. Along with introducing tools and content of robotics learning in architecture, the course development and students' perception of learning progress and intellectual achievement have been systematically assessed by adapting theoretical course analysis models (of Richards and of Kirkpatrick). The results reveal that learning motivation affects self-satisfaction and achievement. This suggests that the background, goals, and methods of teaching robotics engineering need to be carefully coordinated over the entire curricular context of building design education.}
}

@article{yiRoboticsKineticDesign2019,
  title = {Robotics and Kinetic Design for Underrepresented Minority ({{URM}}) Students in Building Education: {{Challenges}} and Opportunities},
  author = {Yi, H.},
  date = {2019},
  journaltitle = {Computer Applications in Engineering Education},
  volume = {27},
  number = {2},
  pages = {351--370},
  doi = {10.1002/cae.22080},
  abstract = {Owing to the widespread distribution of open-source robotic software and cheaper hardware, design education in architecture and engineering is evolving to emphasize interactive and dynamic geometries, using new digital media and technologies. However, ethnic minority groups are still underrepresented in technology-driven changes in architecture, and their career is at risk in the growing tech-related job markets of the architecture, construction, and engineering (ACE) industry. In this context, the paper addresses college-level pedagogical issues and learning performance related to introductory robotics education in architectural design studios for the underrepresented minority (URM) students. This article presents the organization of curriculum activities, technical experiments in learning, and teaching experiences in the largest Hispanic-serving institution (HSI) in the U.S. The academic projects presented exhibit both technical challenges and achievements for URM students to build design competency and tool fluency in a streamlined prototyping of responsive kinetic building fabrication. The effectiveness of computer-aided design (CAD) technologies (3D printing, sensing, microcontrollers, etc.) for the advancement of minority-serving design education is discussed to promote design-learning possibilities and interdisciplinary collaborations associated with science and engineering. Expectations from course objectives are compared with final outcomes to suggest efficient learning strategies and teaching solutions of kinetic architecture.}
}

@article{yiRoboticsKineticDesign2019a,
  title = {Robotics and Kinetic Design for Underrepresented Minority ({{URM}}) Students in Building Education: {{Challenges}} and Opportunities},
  author = {Yi, H.},
  date = {2019},
  journaltitle = {Computer Applications in Engineering Education},
  volume = {27},
  number = {2},
  pages = {351--370},
  doi = {10.1002/cae.22080},
  abstract = {Owing to the widespread distribution of open-source robotic software and cheaper hardware, design education in architecture and engineering is evolving to emphasize interactive and dynamic geometries, using new digital media and technologies. However, ethnic minority groups are still underrepresented in technology-driven changes in architecture, and their career is at risk in the growing tech-related job markets of the architecture, construction, and engineering (ACE) industry. In this context, the paper addresses college-level pedagogical issues and learning performance related to introductory robotics education in architectural design studios for the underrepresented minority (URM) students. This article presents the organization of curriculum activities, technical experiments in learning, and teaching experiences in the largest Hispanic-serving institution (HSI) in the U.S. The academic projects presented exhibit both technical challenges and achievements for URM students to build design competency and tool fluency in a streamlined prototyping of responsive kinetic building fabrication. The effectiveness of computer-aided design (CAD) technologies (3D printing, sensing, microcontrollers, etc.) for the advancement of minority-serving design education is discussed to promote design-learning possibilities and interdisciplinary collaborations associated with science and engineering. Expectations from course objectives are compared with final outcomes to suggest efficient learning strategies and teaching solutions of kinetic architecture.}
}

@inproceedings{yu3DPostureEstimation2019,
  title = {{{3D}} Posture Estimation from {{2D}} Posture Data for Construction Workers},
  booktitle = {Proceedings of the 36th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2019},
  author = {Yu, Y. and Li, H. and Yang, X.},
  date = {2019-05},
  pages = {26--34},
  doi = {10.22260/isarc2019/0004},
  url = {http://www.iaarc.org/publications/2019_proceedings_of_the_36th_isarc/3d_posture_estimation_from_2d_posture_data_for_construction_workers.html},
  abstract = {Construction workers’ behaviour is important for safety, health and productivity management. Workers’ 3D postures are the data foundation of their behaviours. This paper established a preliminary 3D posture dataset of construction tasks and provided a 3D posture estimation method based on 2D joint locations. The results showed that the method could estimate 3D postures accurately and timely. The mean joint error and estimation time of each frame were 1.10 cm and 0.12 ms respectively. This method makes it possible to estimate construction workers’ 3D postures from construction site images and contributes to a data-based construction workers’ behaviour management.},
  keywords = {Behavior management,Construction worker,Posture estimation}
}

@inproceedings{yu3DPostureEstimation2019a,
  title = {{{3D}} Posture Estimation from {{2D}} Posture Data for Construction Workers},
  booktitle = {Proceedings of the 36th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}, {{ISARC}} 2019},
  author = {Yu, Y. and Li, H. and Yang, X.},
  date = {2019-05-24},
  pages = {26--34},
  doi = {10.22260/isarc2019/0004},
  url = {http://www.iaarc.org/publications/2019_proceedings_of_the_36th_isarc/3d_posture_estimation_from_2d_posture_data_for_construction_workers.html},
  abstract = {Construction workers’ behaviour is important for safety, health and productivity management. Workers’ 3D postures are the data foundation of their behaviours. This paper established a preliminary 3D posture dataset of construction tasks and provided a 3D posture estimation method based on 2D joint locations. The results showed that the method could estimate 3D postures accurately and timely. The mean joint error and estimation time of each frame were 1.10 cm and 0.12 ms respectively. This method makes it possible to estimate construction workers’ 3D postures from construction site images and contributes to a data-based construction workers’ behaviour management.},
  keywords = {Behavior management,Construction worker,Posture estimation},
  file = {C:\Users\leemar\Zotero\storage\VGMEZJSE\ISARC_2019_Paper_6.pdf}
}

@article{yuanCollaborativeNetworksRobotic2020,
  title = {Collaborative {{Networks}} of {{Robotic Construction}}},
  author = {Yuan, P.F. and Yan, C.},
  date = {2020},
  journaltitle = {Architectural Design},
  volume = {90},
  number = {2},
  pages = {74--81},
  doi = {10.1002/ad.2549},
  abstract = {Constructing architecture today is a matter of many parallel dialogues between humanity and machines. Professor Philip F Yuan and postdoctoral researcher Chao Yan, of Tongji University, discuss the products and aspirations of Shanghai-based Archi-Union Architects and Fab-Union Technology, founded by Yuan, and their search for ever more dynamic communication between them and their digitally enabled, robotic co-workers.}
}

@article{yuanCollaborativeNetworksRobotic2020a,
  title = {Collaborative {{Networks}} of {{Robotic Construction}}},
  author = {Yuan, P.F. and Yan, C.},
  date = {2020},
  journaltitle = {Architectural Design},
  volume = {90},
  number = {2},
  pages = {74--81},
  doi = {10.1002/ad.2549},
  abstract = {Constructing architecture today is a matter of many parallel dialogues between humanity and machines. Professor Philip F Yuan and postdoctoral researcher Chao Yan, of Tongji University, discuss the products and aspirations of Shanghai-based Archi-Union Architects and Fab-Union Technology, founded by Yuan, and their search for ever more dynamic communication between them and their digitally enabled, robotic co-workers.}
}

@article{yuHiddenSemiMarkovModels2010,
  title = {Hidden Semi-{{Markov}} Models},
  author = {Yu, Shun Zheng},
  date = {2010-02},
  journaltitle = {Artificial Intelligence},
  volume = {174},
  number = {2},
  pages = {215--243},
  issn = {00043702},
  doi = {10.1016/j.artint.2009.11.011},
  abstract = {As an extension to the popular hidden Markov model (HMM), a hidden semi-Markov model (HSMM) allows the underlying stochastic process to be a semi-Markov chain. Each state has variable duration and a number of observations being produced while in the state. This makes it suitable for use in a wider range of applications. Its forward-backward algorithms can be used to estimate/update the model parameters, determine the predicted, filtered and smoothed probabilities, evaluate goodness of an observation sequence fitting to the model, and find the best state sequence of the underlying stochastic process. Since the HSMM was initially introduced in 1980 for machine recognition of speech, it has been applied in thirty scientific and engineering areas, such as speech recognition/synthesis, human activity recognition/prediction, handwriting recognition, functional MRI brain mapping, and network anomaly detection. There are about three hundred papers published in the literature. An overview of HSMMs is presented in this paper, including modelling, inference, estimation, implementation and applications. It first provides a unified description of various HSMMs and discusses the general issues behind them. The boundary conditions of HSMM are extended. Then the conventional models, including the explicit duration, variable transition, and residential time of HSMM, are discussed. Various duration distributions and observation models are presented. Finally, the paper draws an outline of the applications. © 2009 Elsevier B.V. All rights reserved.},
  keywords = {Explicit duration HMM,Forward-backward (FB) algorithm,Hidden Markov model (HMM),Hidden semi-Markov model (HSMM),Variable duration HMM,Viterbi algorithm},
  file = {C:\Users\leemar\Zotero\storage\6WAHVRDV\1-s2.0-S0004370209001416-main.pdf}
}

@article{zakiaHumanRobotCollaboration2022,
  title = {Human–{{Robot Collaboration}} in {{3D}} via {{Force Myography Based Interactive Force Estimations Using Cross-Domain Generalization}}},
  author = {Zakia, Umme and Menon, Carlo},
  date = {2022},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {10},
  pages = {35835--35845},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3164103},
  url = {https://ieeexplore.ieee.org/document/9745957/},
  urldate = {2023-11-13},
  abstract = {In this study, human robot collaboration (HRC) via force myography (FMG) bio-signal was investigated. Interactive hand force was estimated during moving a wooden rod in 3D with a Kuka robot. A baseline FMG-based deep convolutional neural network (FMG-DCNN) model could moderately estimate applied forces during the HRC task. Model performance can be improved with additional training data; however, collection of it was impractical and time-consuming. Available long-term multiple source data (32 feature spaces) during human robot interaction (HRI) with a linear robot collected over a long time period might be useful. Therefore, we explored a cross-domain generalization (CDG) technique that allowed pretraining a model to transfer knowledge between two unrelated source (2D-HRI) and target data (3D-HRC) for the first time. An FMG-based transfer learning with CDG (TL-CDG) model trained with these multiple source domains was examined in estimating applied forces from 16-channel FMG data during interactions with the Kuka robot. Two target scenarios were evaluated: case i) collaborative task of moving the wooden rod in 3D, and case ii) grasping interactions in 1D. In both cases, few calibration data finetuned the TL-CDG model and improved recognizing out-of-domain target data (case i: R2 ≈60-63\%, and case ii: R2 ≈79-87\%) compared to the baseline FMG-DCNN model. Hence, cross-domain generalization could be useful in platform-independent FMG-based HRI applications.},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\WSM9WQRK\Zakia 與 Menon - 2022 - Human–Robot Collaboration in 3D via Force Myograph.pdf}
}

@book{zavadskas25thInternationalSymposium2010,
  title = {25th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  author = {Zavadskas, Edmundas Kazimieras},
  date = {2010},
  journaltitle = {Automation in Construction},
  volume = {19},
  number = {3},
  issn = {09265805},
  doi = {10.1016/j.autcon.2009.12.010},
  isbn = {978-952-69524-1-3},
  pagetotal = {285}
}

@book{zavadskas25thInternationalSymposium2010a,
  title = {25th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  author = {Zavadskas, Edmundas Kazimieras},
  date = {2010},
  journaltitle = {Automation in Construction},
  volume = {19},
  number = {3},
  issn = {09265805},
  doi = {10.1016/j.autcon.2009.12.010},
  isbn = {978-952-69524-1-3},
  pagetotal = {285}
}

@article{zhanDynamicConstructionReduced2019,
  title = {Dynamic {{Construction}} of {{Reduced Representations}} in the {{Brain}} for {{Perceptual Decision Behavior}}},
  author = {Zhan, J. and Ince, R. A. A. and family=Rijsbergen, given=N., prefix=van, useprefix=false and Schyns, P. G.},
  date = {2019},
  journaltitle = {Current Biology},
  volume = {29},
  number = {2},
  pages = {319-326.e4},
  doi = {10.1016/j.cub.2018.11.049},
  abstract = {In a decision task, Zhan et al. visualize within a new information theoretic framework the dynamic representation of visual information in brain activity. They demonstrate rapid reduction of behaviorally irrelevant information in the occipital cortex and a combination of the features that supports distinct decisions in the right fusiform gyrus.SCOPUS\_ABS\_SEPARATOROver the past decade, extensive studies of the brain regions that support face, object, and scene recognition suggest that these regions have a hierarchically organized architecture that spans the occipital and temporal lobes [1–14], where visual categorizations unfold over the first 250 ms of processing [15–19]. This same architecture is flexibly involved in multiple tasks that require task-specific representations—e.g. categorizing the same object as “a car” or “a Porsche.” While we partly understand where and when these categorizations happen in the occipito-ventral pathway, the next challenge is to unravel how these categorizations happen. That is, how does high-dimensional input collapse in the occipito-ventral pathway to become low dimensional representations that guide behavior? To address this, we investigated what information the brain processes in a visual perception task and visualized the dynamic representation of this information in brain activity. To do so, we developed stimulus information representation (SIR), an information theoretic framework, to tease apart stimulus information that supports behavior from that which does not. We then tracked the dynamic representations of both in magneto-encephalographic (MEG) activity. Using SIR, we demonstrate that a rapid (∼170 ms) reduction of behaviorally irrelevant information occurs in the occipital cortex and that representations of the information that supports distinct behaviors are constructed in the right fusiform gyrus (rFG). Our results thus highlight how SIR can be used to investigate the component processes of the brain by considering interactions between three variables (stimulus information, brain activity, behavior), rather than just two, as is the current norm.}
}

@article{zhanDynamicConstructionReduced2019a,
  title = {Dynamic {{Construction}} of {{Reduced Representations}} in the {{Brain}} for {{Perceptual Decision Behavior}}},
  author = {Zhan, J. and Ince, R.A.A. and family=Rijsbergen, given=N., prefix=van, useprefix=true and Schyns, P.G.},
  date = {2019},
  journaltitle = {Current Biology},
  volume = {29},
  number = {2},
  pages = {319-326.e4},
  doi = {10.1016/j.cub.2018.11.049},
  abstract = {In a decision task, Zhan et al. visualize within a new information theoretic framework the dynamic representation of visual information in brain activity. They demonstrate rapid reduction of behaviorally irrelevant information in the occipital cortex and a combination of the features that supports distinct decisions in the right fusiform gyrus.SCOPUS\_ABS\_SEPARATOROver the past decade, extensive studies of the brain regions that support face, object, and scene recognition suggest that these regions have a hierarchically organized architecture that spans the occipital and temporal lobes [1–14], where visual categorizations unfold over the first 250 ms of processing [15–19]. This same architecture is flexibly involved in multiple tasks that require task-specific representations—e.g. categorizing the same object as “a car” or “a Porsche.” While we partly understand where and when these categorizations happen in the occipito-ventral pathway, the next challenge is to unravel how these categorizations happen. That is, how does high-dimensional input collapse in the occipito-ventral pathway to become low dimensional representations that guide behavior? To address this, we investigated what information the brain processes in a visual perception task and visualized the dynamic representation of this information in brain activity. To do so, we developed stimulus information representation (SIR), an information theoretic framework, to tease apart stimulus information that supports behavior from that which does not. We then tracked the dynamic representations of both in magneto-encephalographic (MEG) activity. Using SIR, we demonstrate that a rapid (∼170 ms) reduction of behaviorally irrelevant information occurs in the occipital cortex and that representations of the information that supports distinct behaviors are constructed in the right fusiform gyrus (rFG). Our results thus highlight how SIR can be used to investigate the component processes of the brain by considering interactions between three variables (stimulus information, brain activity, behavior), rather than just two, as is the current norm.}
}

@article{zhangDigitalTwinComputational2021,
  title = {Digital Twin in Computational Design and Robotic Construction of Wooden Architecture},
  author = {Zhang, Y. and Meina, A. and Lin, X. and Zhang, K. and Xu, Z.},
  date = {2021},
  journaltitle = {Advances in Civil Engineering},
  volume = {2021},
  doi = {10.1155/2021/8898997},
  abstract = {This study proposes a cyber-physical interconnection method for computational design and robotic construction in a wooden architectural realm. It aims to provide a highly efficient, flexible, and adaptive design-construction approach by continuously updating digital models and physical operations according to the locally sourced materials. A perception-modeling system to scan the source materials on-site and send their data simultaneously to design software was developed by using physical sensors and computational technologies in an innovative manner. The data was used for architectural programs to generate design outcomes and guide the robotic construction. The novelty of this study is to establish a real-time, bidirectional interaction mechanism between digital design and physical construction. The design outcome is no longer a fixed, predefined geometric model but a dynamic, data-driven model which would be updated by material conditions on-site. The construction robot is able to make synchronous adjustment automatically in coordination with the dynamic design. The success of the iterative perceiving-simulating-updating loop was demonstrated by building two pavilions.}
}

@article{zhangDigitalTwinComputational2021a,
  title = {Digital Twin in Computational Design and Robotic Construction of Wooden Architecture},
  author = {Zhang, Y. and Meina, A. and Lin, X. and Zhang, K. and Xu, Z.},
  date = {2021},
  journaltitle = {Advances in Civil Engineering},
  volume = {2021},
  doi = {10.1155/2021/8898997},
  abstract = {This study proposes a cyber-physical interconnection method for computational design and robotic construction in a wooden architectural realm. It aims to provide a highly efficient, flexible, and adaptive design-construction approach by continuously updating digital models and physical operations according to the locally sourced materials. A perception-modeling system to scan the source materials on-site and send their data simultaneously to design software was developed by using physical sensors and computational technologies in an innovative manner. The data was used for architectural programs to generate design outcomes and guide the robotic construction. The novelty of this study is to establish a real-time, bidirectional interaction mechanism between digital design and physical construction. The design outcome is no longer a fixed, predefined geometric model but a dynamic, data-driven model which would be updated by material conditions on-site. The construction robot is able to make synchronous adjustment automatically in coordination with the dynamic design. The success of the iterative perceiving-simulating-updating loop was demonstrated by building two pavilions.}
}

@inproceedings{zhangHowCanChatGPT2023,
  title = {How {{Can ChatGPT Help}} in {{Automated Building Code Compliance Checking}}?},
  author = {Zhang, Jiansong},
  date = {2023-07-07},
  location = {{Chennai, India}},
  doi = {10.22260/ISARC2023/0011},
  url = {http://www.iaarc.org/publications/2023_proceedings_of_the_40th_isarc_chennai_india/how_can_chatgpt_help_in_automated_building_code_compliance_checking.html},
  urldate = {2023-09-03},
  abstract = {One main challenge in the full automation of building code compliance checking is in the extraction and transformation of building code requirements into computable representations. Semantic rulebased approach has been taken mainly due to its expected better performance than machine learningbased approach on this particular task. With the recent advancement in deep learning AI, particularly the launch of ChatGPT by OpenAI, there is a potential for this landscape to be shifted given the highly regarded capabilities of ChatGPT in processing (i.e., understanding and generating) natural language texts and computer codes. In this paper, the author preliminarily explored the use of ChatGPT in converting (i.e., extracting and transforming) building code requirements into computer codes, and compared it with the results from cutting-edge semantic rule-based approach. It was found that comparing to the semantic rule-based approach, the conversion results from ChatGPT still has limitations, but there is a great potential for it to help speed up the implementation and scale-up of automated building code compliance checking systems.},
  eventtitle = {40th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\58Q34YV4\Zhang - 2023 - How Can ChatGPT Help in Automated Building Code Co.pdf}
}

@inproceedings{zhangHowCanChatGPT2023a,
  title = {How {{Can ChatGPT Help}} in {{Automated Building Code Compliance Checking}}?},
  author = {Zhang, Jiansong},
  date = {2023-07-07},
  location = {{Chennai, India}},
  doi = {10.22260/ISARC2023/0011},
  url = {http://www.iaarc.org/publications/2023_proceedings_of_the_40th_isarc_chennai_india/how_can_chatgpt_help_in_automated_building_code_compliance_checking.html},
  urldate = {2023-11-19},
  abstract = {One main challenge in the full automation of building code compliance checking is in the extraction and transformation of building code requirements into computable representations. Semantic rulebased approach has been taken mainly due to its expected better performance than machine learningbased approach on this particular task. With the recent advancement in deep learning AI, particularly the launch of ChatGPT by OpenAI, there is a potential for this landscape to be shifted given the highly regarded capabilities of ChatGPT in processing (i.e., understanding and generating) natural language texts and computer codes. In this paper, the author preliminarily explored the use of ChatGPT in converting (i.e., extracting and transforming) building code requirements into computer codes, and compared it with the results from cutting-edge semantic rule-based approach. It was found that comparing to the semantic rule-based approach, the conversion results from ChatGPT still has limitations, but there is a great potential for it to help speed up the implementation and scale-up of automated building code compliance checking systems.},
  eventtitle = {40th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\NLICBXNG\Zhang - 2023 - How Can ChatGPT Help in Automated Building Code Co.pdf}
}

@article{zhangHumanRobotCollaboration2023,
  title = {Human–Robot Collaboration for on-Site Construction},
  author = {Zhang, Ming and Xu, Rui and Wu, Haitao and Pan, Jia and Luo, Xiaowei},
  date = {2023-06},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {150},
  pages = {104812},
  issn = {09265805},
  doi = {10.1016/j.autcon.2023.104812},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0926580523000729},
  urldate = {2023-04-21},
  langid = {english}
}

@inproceedings{zhangIntegratedHumanMachineIntelligence2022,
  title = {Toward {{Integrated Human-Machine Intelligence}} for {{Civil Engineering}}: {{An Interdisciplinary Perspective}}},
  shorttitle = {Toward {{Integrated Human-Machine Intelligence}} for {{Civil Engineering}}},
  booktitle = {Computing in {{Civil Engineering}} 2021},
  author = {Zhang, Cheng and Kim, Jinwoo and Jeon, JungHo and Xing, Jinding and Ahn, Changbum and Tang, Pingbo and Cai, Hubo},
  date = {2022-05-24},
  pages = {279--286},
  publisher = {{American Society of Civil Engineers}},
  location = {{Orlando, Florida}},
  doi = {10.1061/9780784483893.035},
  url = {http://ascelibrary.org/doi/10.1061/9780784483893.035},
  urldate = {2023-03-20},
  eventtitle = {{{ASCE International Conference}} on {{Computing}} in {{Civil Engineering}} 2021},
  isbn = {978-0-7844-8389-3},
  langid = {english},
  file = {C:\Users\leemar\Zotero\storage\6XEQNWAI\Zhang 等。 - 2022 - Toward Integrated Human-Machine Intelligence for C.pdf}
}

@article{zhangQualityDriverSustainable2020,
  title = {Quality as Driver for Sustainable Construction-{{Holistic}} Quality Model and Assessment},
  author = {Zhang, L. and Balangé, L. and Braun, K. and Di Bari, R. and Horn, R. and Hos, D. and Kropp, C. and Leistner, P. and Schwieger, V.},
  date = {2020},
  journaltitle = {Sustainability (Switzerland)},
  volume = {12},
  number = {19},
  doi = {10.3390/SU12197847},
  abstract = {Facing rising building demands due to a fast-growing world population and significant environmental challenges at the same time, the building sector urgently requires innovation. The Cluster of Excellence Integrative Computational Design and Construction for Architecture at the University of Stuttgart tackles these challenges through a Co-Design approach for integrating computational design and engineering and robotic construction. Within this research framework, a Holistic Quality Model is developed to ensure the technical, environmental, and social quality of Co-Design processes and products. Up to now, quality models that consider and integrate all these three aspects throughout the life cycle of buildings are still missing. The article outlines the concept of holistic quality assessment based on a Holistic Quality Model for sustainable construction. A key mechanism for sustainable quality assessment in the Holistic Quality Model is the definition of control and decision points in the construction process where critical decisions are made that will affect the quality of the building throughout its entire life-cycle. Firstly, subject-specific quality concepts are defined and their interrelations are conceptualized. Subsequently, these interrelations and their effects on the overall Co-Design construction processes and products are explained using the example of the semi-robotic production of concrete slabs. Examples for control and decision points are given as well. The outline presented here serves as a basis for further advancing and concretizing the Holistic Quality Model and its applications in Co-Design for a functioning, liveable, and sustainable high-quality construction and building culture.}
}

@article{zhangQualityDriverSustainable2020a,
  title = {Quality as Driver for Sustainable Construction-{{Holistic}} Quality Model and Assessment},
  author = {Zhang, L. and Balangé, L. and Braun, K. and Di Bari, R. and Horn, R. and Hos, D. and Kropp, C. and Leistner, P. and Schwieger, V.},
  date = {2020},
  journaltitle = {Sustainability (Switzerland)},
  volume = {12},
  number = {19},
  doi = {10.3390/SU12197847},
  abstract = {Facing rising building demands due to a fast-growing world population and significant environmental challenges at the same time, the building sector urgently requires innovation. The Cluster of Excellence Integrative Computational Design and Construction for Architecture at the University of Stuttgart tackles these challenges through a Co-Design approach for integrating computational design and engineering and robotic construction. Within this research framework, a Holistic Quality Model is developed to ensure the technical, environmental, and social quality of Co-Design processes and products. Up to now, quality models that consider and integrate all these three aspects throughout the life cycle of buildings are still missing. The article outlines the concept of holistic quality assessment based on a Holistic Quality Model for sustainable construction. A key mechanism for sustainable quality assessment in the Holistic Quality Model is the definition of control and decision points in the construction process where critical decisions are made that will affect the quality of the building throughout its entire life-cycle. Firstly, subject-specific quality concepts are defined and their interrelations are conceptualized. Subsequently, these interrelations and their effects on the overall Co-Design construction processes and products are explained using the example of the semi-robotic production of concrete slabs. Examples for control and decision points are given as well. The outline presented here serves as a basis for further advancing and concretizing the Holistic Quality Model and its applications in Co-Design for a functioning, liveable, and sustainable high-quality construction and building culture.}
}

@article{zhangRealTimeScanningModeling2020,
  title = {Real {{Time Scanning-Modeling System}} for {{Architecture Design}} and {{Construction}}},
  author = {Zhang, Y. and Zhang, K. and Chen, K. and Xu, Z.},
  date = {2020},
  journaltitle = {Advances in Technology Innovation},
  volume = {5},
  number = {4},
  pages = {248--258},
  doi = {10.46604/aiti.2020.5385},
  abstract = {The disconnection between architectural form and materiality has become an important issue in recent years. Architectural form is mainly decided by the designer, while material data is often treated as an afterthought which doesn't factor in decision-making directly. This study proposes a new, real-time scanning-modeling system for computational design and autonomous robotic construction. By using cameras to scan the raw materials, this system would get related data and build 3D models in real time. These data would be used by a computer to calculate rational outcomes and help a robot make decisions about its construction paths and methods. The result of an application pavilion shows that data of raw materials, architectural design, and robotic construction can be integrated into a digital chain. The method and gain of the material-oriented design approach are discussed and future research on using different source materials is laid out.}
}

@article{zhangRealTimeScanningModeling2020a,
  title = {Real {{Time Scanning-Modeling System}} for {{Architecture Design}} and {{Construction}}},
  author = {Zhang, Y. and Zhang, K. and Chen, K. and Xu, Z.},
  date = {2020},
  journaltitle = {Advances in Technology Innovation},
  volume = {5},
  number = {4},
  pages = {248--258},
  doi = {10.46604/aiti.2020.5385},
  abstract = {The disconnection between architectural form and materiality has become an important issue in recent years. Architectural form is mainly decided by the designer, while material data is often treated as an afterthought which doesn't factor in decision-making directly. This study proposes a new, real-time scanning-modeling system for computational design and autonomous robotic construction. By using cameras to scan the raw materials, this system would get related data and build 3D models in real time. These data would be used by a computer to calculate rational outcomes and help a robot make decisions about its construction paths and methods. The result of an application pavilion shows that data of raw materials, architectural design, and robotic construction can be integrated into a digital chain. The method and gain of the material-oriented design approach are discussed and future research on using different source materials is laid out.}
}

@inproceedings{zhangResearchNumericalCompensation2020,
  title = {Research on Numerical Compensation Method of Tandem Force Sensor Installed at the End of Industrial Robot},
  booktitle = {Proceedings - 5th {{International Conference}} on {{Automation}}, {{Control}} and {{Robotics Engineering}}, {{CACRE}} 2020},
  author = {Zhang, Z. and Chen, Y. and Zhang, D. and Tong, Q.},
  date = {2020},
  pages = {725--731},
  doi = {10.1109/CACRE50138.2020.9230141},
  abstract = {Tandem force sensor is an important sensor in human-robot collaboration and learning from demonstration, equipped with which robot can perceive the environment state and human attention simultaneously. The posture of a tandem force sensor changes with robot's posture, which leads to the output of the sensor cannot accurately reflect the environmental states and human intention. In order to compensate the measurement error caused by attitude change, the numerical compensation method of tandem force sensor based on deep learning is proposed in this paper. And the experimental results of numerical compensation show that this method can effectively eliminate the influence of attitude change on the measurement of the sensor.},
  isbn = {978-1-72819-888-0}
}

@inproceedings{zhangResearchNumericalCompensation2020a,
  title = {Research on Numerical Compensation Method of Tandem Force Sensor Installed at the End of Industrial Robot},
  booktitle = {Proceedings - 5th {{International Conference}} on {{Automation}}, {{Control}} and {{Robotics Engineering}}, {{CACRE}} 2020},
  author = {Zhang, Z. and Chen, Y. and Zhang, D. and Tong, Q.},
  date = {2020},
  pages = {725--731},
  doi = {10.1109/CACRE50138.2020.9230141},
  abstract = {Tandem force sensor is an important sensor in human-robot collaboration and learning from demonstration, equipped with which robot can perceive the environment state and human attention simultaneously. The posture of a tandem force sensor changes with robot's posture, which leads to the output of the sensor cannot accurately reflect the environmental states and human intention. In order to compensate the measurement error caused by attitude change, the numerical compensation method of tandem force sensor based on deep learning is proposed in this paper. And the experimental results of numerical compensation show that this method can effectively eliminate the influence of attitude change on the measurement of the sensor.},
  isbn = {978-1-72819-888-0}
}

@inproceedings{zhangSurveillanceSystemPower2014,
  title = {Surveillance System of Power Transmission Line via Object Recognition and {{3D}} Vision Computation},
  booktitle = {Proceedings of {{SPIE}} - {{The International Society}} for {{Optical Engineering}}},
  author = {Zhang, Y. and Mou, X.},
  date = {2014},
  volume = {9023},
  doi = {10.1117/12.2041412},
  abstract = {Surveillance systems have been widely applied on power transmission system for security precaution of the major risk factor that is the construction activity in the vicinity of power transmission line. However, currently used automatic object detection in surveillance systems suffers from high error rate and has at least two limitations: first, the type of the object can™t be recognized; second, the dangerous strength of the object cannot be identified. In this paper, we propose a video surveillance method for the security precaution of power transmission line via the techniques of object recognition and 3D spatial location detection so that the motion objects are recognized and the position and size of the object are determined to identify the dangerous strength. Experimental results show that the developed system based on our proposed method is feasible and practical. © 2014 SPIE-IS and T.},
  isbn = {978-0-8194-9940-0}
}

@inproceedings{zhangSurveillanceSystemPower2014a,
  title = {Surveillance System of Power Transmission Line via Object Recognition and {{3D}} Vision Computation},
  booktitle = {Proceedings of {{SPIE}} - {{The International Society}} for {{Optical Engineering}}},
  author = {Zhang, Y. and Mou, X.},
  date = {2014},
  volume = {9023},
  doi = {10.1117/12.2041412},
  abstract = {Surveillance systems have been widely applied on power transmission system for security precaution of the major risk factor that is the construction activity in the vicinity of power transmission line. However, currently used automatic object detection in surveillance systems suffers from high error rate and has at least two limitations: first, the type of the object can™t be recognized; second, the dangerous strength of the object cannot be identified. In this paper, we propose a video surveillance method for the security precaution of power transmission line via the techniques of object recognition and 3D spatial location detection so that the motion objects are recognized and the position and size of the object are determined to identify the dangerous strength. Experimental results show that the developed system based on our proposed method is feasible and practical. © 2014 SPIE-IS and T.},
  isbn = {978-0-8194-9940-0}
}

@article{zhangVirtualRealitySupported2021,
  title = {Virtual Reality Supported Interactive Tower Crane Layout Planning for High-Rise Modular Integrated Construction},
  author = {Zhang, Zhiqian and Pan, Wei},
  date = {2021-10},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {130},
  pages = {103854},
  issn = {09265805},
  doi = {10.1016/j.autcon.2021.103854},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0926580521003058},
  urldate = {2023-09-19},
  langid = {english}
}

@inproceedings{zhangVisionbasedExcavatorActivity2021,
  title = {Vision-Based {{Excavator Activity Analysis}} and {{Safety Monitoring System}}},
  booktitle = {Proceedings of the {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  author = {Zhang, S. and Zhang, L.},
  date = {2021},
  volume = {2021-Novem},
  pages = {49--56},
  abstract = {In this paper, we propose an excavator activity analysis and safety monitoring system, leveraging recent advancements in deep learning and computer vision. Our proposed system detects the surrounding environment and the excavators while estimating the poses and actions of the excavators. Compared to previous systems, our method achieves higher accuracy in object detection, pose estimation, and action recognition tasks. In addition, we build an excavator dataset using the Autonomous Excavator System (AES) on the waste disposal recycle scene to demonstrate the effectiveness of our system. We also evaluate our method on a benchmark construction dataset. The experimental results show that the proposed action recognition approach outperforms the state-of-the-art approaches on top-1 accuracy by about 5.18\%.},
  isbn = {978-952-69524-1-3}
}

@inproceedings{zhangVisionbasedExcavatorActivity2021a,
  title = {Vision-Based {{Excavator Activity Analysis}} and {{Safety Monitoring System}}},
  booktitle = {Proceedings of the {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  author = {Zhang, S. and Zhang, L.},
  date = {2021},
  volume = {2021-Novem},
  pages = {49--56},
  abstract = {In this paper, we propose an excavator activity analysis and safety monitoring system, leveraging recent advancements in deep learning and computer vision. Our proposed system detects the surrounding environment and the excavators while estimating the poses and actions of the excavators. Compared to previous systems, our method achieves higher accuracy in object detection, pose estimation, and action recognition tasks. In addition, we build an excavator dataset using the Autonomous Excavator System (AES) on the waste disposal recycle scene to demonstrate the effectiveness of our system. We also evaluate our method on a benchmark construction dataset. The experimental results show that the proposed action recognition approach outperforms the state-of-the-art approaches on top-1 accuracy by about 5.18\%.},
  isbn = {978-952-69524-1-3}
}

@inproceedings{zhangVisionbasedExcavatorActivity2021b,
  title = {Vision-Based {{Excavator Activity Analysis}} and {{Safety Monitoring System}}},
  author = {Zhang, Sibo and Zhang, Liangjun},
  date = {2021-11-02},
  location = {{Dubai, UAE}},
  doi = {10.22260/ISARC2021/0009},
  url = {http://www.iaarc.org/publications/2021_proceedings_of_the_38th_isarc/vision_based_excavator_activity_analysis_and_safety_monitoring_system.html},
  urldate = {2023-03-15},
  abstract = {In this paper, we propose an excavator activity analysis and safety monitoring system, leveraging recent advancements in deep learning and computer vision. Our proposed system detects the surrounding environment and the excavators while estimating the poses and actions of the excavators. Compared to previous systems, our method achieves higher accuracy in object detection, pose estimation, and action recognition tasks. In addition, we build an excavator dataset using the Autonomous Excavator System (AES) on the waste disposal recycle scene to demonstrate the effectiveness of our system. We also evaluate our method on a benchmark construction dataset. The experimental results show that the proposed action recognition approach outperforms the state-of-the-art approaches on top-1 accuracy by about 5.18\%.},
  eventtitle = {38th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  langid = {english},
  file = {/Volumes/WIP/library/007 ISARC 2021 Paper 106.pdf}
}

@article{zhaoCPGControlHarmonic2020,
  title = {{{CPG Control}} for {{Harmonic Motion}} of {{Assistive Robot}} with {{Human Motor Control Identification}}},
  author = {Zhao, J. and Iwasaki, T.},
  date = {2020},
  journaltitle = {IEEE Transactions on Control Systems Technology},
  volume = {28},
  number = {4},
  pages = {1323--1336},
  doi = {10.1109/TCST.2019.2910160},
  abstract = {Various movements in human life, such as walking, bicycling, cleaning, chewing, swimming, and so on, are periodic or repetitive. This paper proposes a method for designing a feedback controller for a robotic system to help a human with periodic (harmonic, in particular) motion tasks. The control objective is to stabilize a human-intended oscillatory movement while reducing the required human effort. For the control architecture, we adopt the central pattern generator (CPG), which is a neuronal circuit for rhythmic motor pattern. Animal locomotions under CPG control are capable of complying with various environment dynamics to yield different oscillatory movements. We take advantage of this adaptation property of the CPG controller that acts as a nonlinear damping compensator and removes part of the resistive forces in the system, thereby reducing the human effort without interfering with the human intention. It is shown that the resulting human-intended oscillation is a locally stable harmonic solution of the closed-loop human-robot CPG system, assuming a simple model of the human motor control. The proposed control method is experimentally validated for a simple robotic arm, with a system identification of the human motor control.}
}

@article{zhaoCPGControlHarmonic2020a,
  title = {{{CPG Control}} for {{Harmonic Motion}} of {{Assistive Robot}} with {{Human Motor Control Identification}}},
  author = {Zhao, J. and Iwasaki, T.},
  date = {2020},
  journaltitle = {IEEE Transactions on Control Systems Technology},
  volume = {28},
  number = {4},
  pages = {1323--1336},
  doi = {10.1109/TCST.2019.2910160},
  abstract = {Various movements in human life, such as walking, bicycling, cleaning, chewing, swimming, and so on, are periodic or repetitive. This paper proposes a method for designing a feedback controller for a robotic system to help a human with periodic (harmonic, in particular) motion tasks. The control objective is to stabilize a human-intended oscillatory movement while reducing the required human effort. For the control architecture, we adopt the central pattern generator (CPG), which is a neuronal circuit for rhythmic motor pattern. Animal locomotions under CPG control are capable of complying with various environment dynamics to yield different oscillatory movements. We take advantage of this adaptation property of the CPG controller that acts as a nonlinear damping compensator and removes part of the resistive forces in the system, thereby reducing the human effort without interfering with the human intention. It is shown that the resulting human-intended oscillation is a locally stable harmonic solution of the closed-loop human-robot CPG system, assuming a simple model of the human motor control. The proposed control method is experimentally validated for a simple robotic arm, with a system identification of the human motor control.}
}

@article{zhaoInnovativeApplicationsComputerAssisted2021,
  title = {Innovative {{Applications}} of {{Computer-Assisted Technology}} in {{English Learning}} under {{Constructivism}}},
  author = {Zhao, D.},
  date = {2021},
  journaltitle = {Mobile Information Systems},
  volume = {2021},
  doi = {10.1155/2021/1676197},
  abstract = {In order to improve the effect of college English classroom teaching, this paper combines optical recognition to improve machine vision algorithms and uses computer optical vision technology to process teaching images. The system designed in this paper can be applied to philosophical teaching in college English classrooms. Moreover, the system can optimize teaching resources, manage teaching classrooms through the improved machine vision algorithm in this paper, and have a formative evaluation effect. In addition, taking into account the psychological activities of students in the classroom, this paper integrates the emotional recognition of college students in the construction of the system. Furthermore, it combines the actual teaching process to build a college English classroom teaching system based on constructivism. Finally, this paper designs an experiment to analyze the effect of the teaching model. From the research results, it can be known that the teaching system meets the demands of teaching.}
}

@article{zhaoInnovativeApplicationsComputerAssisted2021a,
  title = {Innovative {{Applications}} of {{Computer-Assisted Technology}} in {{English Learning}} under {{Constructivism}}},
  author = {Zhao, D.},
  date = {2021},
  journaltitle = {Mobile Information Systems},
  volume = {2021},
  doi = {10.1155/2021/1676197},
  abstract = {In order to improve the effect of college English classroom teaching, this paper combines optical recognition to improve machine vision algorithms and uses computer optical vision technology to process teaching images. The system designed in this paper can be applied to philosophical teaching in college English classrooms. Moreover, the system can optimize teaching resources, manage teaching classrooms through the improved machine vision algorithm in this paper, and have a formative evaluation effect. In addition, taking into account the psychological activities of students in the classroom, this paper integrates the emotional recognition of college students in the construction of the system. Furthermore, it combines the actual teaching process to build a college English classroom teaching system based on constructivism. Finally, this paper designs an experiment to analyze the effect of the teaching model. From the research results, it can be known that the teaching system meets the demands of teaching.}
}

@inproceedings{zhaoPsychologicalCognitionThinking2021,
  title = {Psychological {{Cognition}} and {{Thinking Needs}} in {{Visual Communication Design}}},
  booktitle = {{{E3S Web}} of {{Conferences}}},
  author = {Zhao, D. and Pan, B.},
  date = {2021},
  volume = {236},
  doi = {10.1051/e3sconf/202123605070},
  abstract = {The visual information design refers to the communication and exchange with the real world through the graphic signification. The understanding of a graph is a visual recognition process of the graphic object. The audience can feel the intangibility of the design work behind the tangibility during the transmission, perception, communication and resonance processes. The unconscious mind of the audience is aroused under the visual impact, thus reaching the goal of transmitting the concept of information appeal. Influenced by the holistic view of the Gestalt Psychology, the modern cognitive psychology highlights the comprehensive analysis of human cognitive process, while Gestalt psychologists lay the emphasis on the integrity of experience and behavior. According to the principle of Gestalt Psychology, the form perceived is not the direct imitation of an objective thing, but instead, it is the perceptual construction activity when eyes capture the thing. As a manifestation system in the visual perception research field, the Gestalt Psychology teases the related perceptual organization principles for the human cognitive process and promotes the development of the visual perception researches. Based on the Gestalt Psychology, it is proposed in this research to study psychological phenomena from the holistic dynamic structure, explore the visual information design, and exploit the design field of view and creative thinking, in an effort to form a new design philosophy which will play an important role in improving the aesthetic effect and visual impact of the design work.}
}

@inproceedings{zhaoPsychologicalCognitionThinking2021a,
  title = {Psychological {{Cognition}} and {{Thinking Needs}} in {{Visual Communication Design}}},
  booktitle = {{{E3S Web}} of {{Conferences}}},
  author = {Zhao, D. and Pan, B.},
  date = {2021},
  volume = {236},
  doi = {10.1051/e3sconf/202123605070},
  abstract = {The visual information design refers to the communication and exchange with the real world through the graphic signification. The understanding of a graph is a visual recognition process of the graphic object. The audience can feel the intangibility of the design work behind the tangibility during the transmission, perception, communication and resonance processes. The unconscious mind of the audience is aroused under the visual impact, thus reaching the goal of transmitting the concept of information appeal. Influenced by the holistic view of the Gestalt Psychology, the modern cognitive psychology highlights the comprehensive analysis of human cognitive process, while Gestalt psychologists lay the emphasis on the integrity of experience and behavior. According to the principle of Gestalt Psychology, the form perceived is not the direct imitation of an objective thing, but instead, it is the perceptual construction activity when eyes capture the thing. As a manifestation system in the visual perception research field, the Gestalt Psychology teases the related perceptual organization principles for the human cognitive process and promotes the development of the visual perception researches. Based on the Gestalt Psychology, it is proposed in this research to study psychological phenomena from the holistic dynamic structure, explore the visual information design, and exploit the design field of view and creative thinking, in an effort to form a new design philosophy which will play an important role in improving the aesthetic effect and visual impact of the design work.}
}

@article{zhaoSmartRoboticWalker2020,
  title = {A {{Smart Robotic Walker With Intelligent Close-Proximity Interaction Capabilities}} for {{Elderly Mobility Safety}}},
  author = {Zhao, X. and Zhu, Z. and Liu, M. and Zhao, C. and Zhao, Y. and Pan, J. and Wang, Z. and Wu, C.},
  date = {2020},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {14},
  doi = {10.3389/fnbot.2020.575889},
  abstract = {The elderly population has rapidly increased in past years, bringing huge demands for elderly serving devices, especially for those with mobility impairment. Present assistant walkers designed for elderly users are primitive with limited user interactivity and intelligence. We propose a novel smart robotic walker that targets a convenient-to-use indoor walking aid for the elderly. The walker supports multiple modes of interactions through voice, gait or haptic touch, and allows intelligent control via learning-based methods to achieve mobility safety. Our design enables a flexible, initiative and reliable walker due to the following: (1) we take a hybrid approach by combining the conventional mobile robotic platform with the existing rollator design, to achieve a novel robotic system that fulfills expected functionalities; (2) our walker tracks users in front by detecting lower limb gait, while providing close-proximity walking safety support; (3) our walker can detect human intentions and predict emergency events, e.g., falling, by monitoring force pressure on a specially designed soft-robotic interface on the handle; (4) our walker performs reinforcement learning-based sound source localization to locate and navigate to the user based on his/her voice signals. Experiment results demonstrate the sturdy mechanical structure, the reliability of multiple novel interactions, and the efficiency of the intelligent control algorithms implemented. The demonstration video is available at: https://sites.google.com/view/smart-walker-hku.}
}

@article{zhaoSmartRoboticWalker2020a,
  title = {A {{Smart Robotic Walker With Intelligent Close-Proximity Interaction Capabilities}} for {{Elderly Mobility Safety}}},
  author = {Zhao, X. and Zhu, Z. and Liu, M. and Zhao, C. and Zhao, Y. and Pan, J. and Wang, Z. and Wu, C.},
  date = {2020},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {14},
  doi = {10.3389/fnbot.2020.575889},
  abstract = {The elderly population has rapidly increased in past years, bringing huge demands for elderly serving devices, especially for those with mobility impairment. Present assistant walkers designed for elderly users are primitive with limited user interactivity and intelligence. We propose a novel smart robotic walker that targets a convenient-to-use indoor walking aid for the elderly. The walker supports multiple modes of interactions through voice, gait or haptic touch, and allows intelligent control via learning-based methods to achieve mobility safety. Our design enables a flexible, initiative and reliable walker due to the following: (1) we take a hybrid approach by combining the conventional mobile robotic platform with the existing rollator design, to achieve a novel robotic system that fulfills expected functionalities; (2) our walker tracks users in front by detecting lower limb gait, while providing close-proximity walking safety support; (3) our walker can detect human intentions and predict emergency events, e.g., falling, by monitoring force pressure on a specially designed soft-robotic interface on the handle; (4) our walker performs reinforcement learning-based sound source localization to locate and navigate to the user based on his/her voice signals. Experiment results demonstrate the sturdy mechanical structure, the reliability of multiple novel interactions, and the efficiency of the intelligent control algorithms implemented. The demonstration video is available at: https://sites.google.com/view/smart-walker-hku.}
}

@article{zhaWebbasedKnowledgeintensiveSupport2002,
  title = {Web-Based Knowledge-Intensive Support Framework for Collaborative Design of {{MEMS}}},
  author = {Zha, X.F. and Du, H.},
  date = {2002},
  journaltitle = {Journal of Micromechanics and Microengineering},
  volume = {12},
  number = {5},
  pages = {512--524},
  doi = {10.1088/0960-1317/12/5/302},
  abstract = {Microelectromechanical systems (MEMS) design and manufacturing are inherently multi-physical and multi-disciplinary; no single person is able to perform a full development process for a MEM device or system. In this paper we develop a WWW-based design platform for collaborative design of MEMS. The proposed web-based distributed object modeling and evaluation framework with client-knowledge server architecture, KS-WebDOME, allows multi-users/designers in different locations to participate in the same design process. Under this framework, concurrent integrated MEMS design and simulation models can be built using both local and distributed resources, and the design collaboration can be realized by exchanging services between modules based upon CORBA standard communication protocol. To facilitate the rapid construction of the concurrent integrated design models for MEMS, a prototype design system, Web-MEMS Designer, is implemented through concurrent integration of multiple distributed and cooperative knowledge sources and software. By use of the developed prototype system, MEMS design and simulation can be carried out simultaneously and intelligently in an integrated but open design environment on the web. The case of a microgripper design for micro-robotic assembly systems is provided to illustrate how designers in different teams and organizations may participate and collaborate in MEMS design.}
}

@article{zhaWebbasedKnowledgeintensiveSupport2002a,
  title = {Web-Based Knowledge-Intensive Support Framework for Collaborative Design of {{MEMS}}},
  author = {Zha, X.F. and Du, H.},
  date = {2002},
  journaltitle = {Journal of Micromechanics and Microengineering},
  volume = {12},
  number = {5},
  pages = {512--524},
  doi = {10.1088/0960-1317/12/5/302},
  abstract = {Microelectromechanical systems (MEMS) design and manufacturing are inherently multi-physical and multi-disciplinary; no single person is able to perform a full development process for a MEM device or system. In this paper we develop a WWW-based design platform for collaborative design of MEMS. The proposed web-based distributed object modeling and evaluation framework with client-knowledge server architecture, KS-WebDOME, allows multi-users/designers in different locations to participate in the same design process. Under this framework, concurrent integrated MEMS design and simulation models can be built using both local and distributed resources, and the design collaboration can be realized by exchanging services between modules based upon CORBA standard communication protocol. To facilitate the rapid construction of the concurrent integrated design models for MEMS, a prototype design system, Web-MEMS Designer, is implemented through concurrent integration of multiple distributed and cooperative knowledge sources and software. By use of the developed prototype system, MEMS design and simulation can be carried out simultaneously and intelligently in an integrated but open design environment on the web. The case of a microgripper design for micro-robotic assembly systems is provided to illustrate how designers in different teams and organizations may participate and collaborate in MEMS design.}
}

@article{zhengOptimisingAutomaticText2022,
  title = {Optimising {{Automatic Text Classification Approach}} in {{Adaptive Online Collaborative Discussion}} - {{A}} Perspective of {{Attention Mechanism-Based Bi-LSTM}}},
  author = {Zheng, Y. and Gao, Z. and Shen, J. and Zhai, X.},
  date = {2022},
  journaltitle = {IEEE Transactions on Learning Technologies},
  doi = {10.1109/TLT.2022.3192116},
  abstract = {A text semantic classification is an essential approach to recognising the verbal intention of online learners, empowering reliable understanding and inquiry for the regulations of knowledge construction amongst students. However, online learning is increasingly switching from static watching patterns to the collaborative discussion. The current deep learning models, such as CNN and RNN, are ineffective in classifying verbal content contextually. Moreover, the contribution of verbal elements to semantics is often considerably varied, requiring the attachment of weights to these elements to increase verbal recognition precision. The Bi-LSTM is considered to be an adaptive model to investigate semantic relations according to the context. Moreover, the attention mechanism in deep learning simulating human vision could assign weights to target texts effectively. This study proposed to construct a deep learning model combining Bi-LSTM and attention mechanism, in which Bi-LSTM obtained the verbal features and keywords, and the generated keywords were weighed in accordance with the attention mechanism. A total of 12,000 sentences generated in online collaborative discussion activities have been classified into six categories, namely statement, negotiation, question, management, emotion and others. Results showed that the classification accuracy of Attention-Bi-LSTM reached 81.50\&\#x0025;, which is higher than that of the baseline Bi-LSTM model. This study theoretically uncovers the features of collaborative discussion of onliners and practically provides an effective approach to automatic behaviour analysis in an online context.}
}

@article{zhengOptimisingAutomaticText2022a,
  title = {Optimising {{Automatic Text Classification Approach}} in {{Adaptive Online Collaborative Discussion}} - {{A}} Perspective of {{Attention Mechanism-Based Bi-LSTM}}},
  author = {Zheng, Y. and Gao, Z. and Shen, J. and Zhai, X.},
  date = {2022},
  journaltitle = {IEEE Transactions on Learning Technologies},
  doi = {10.1109/TLT.2022.3192116},
  abstract = {A text semantic classification is an essential approach to recognising the verbal intention of online learners, empowering reliable understanding and inquiry for the regulations of knowledge construction amongst students. However, online learning is increasingly switching from static watching patterns to the collaborative discussion. The current deep learning models, such as CNN and RNN, are ineffective in classifying verbal content contextually. Moreover, the contribution of verbal elements to semantics is often considerably varied, requiring the attachment of weights to these elements to increase verbal recognition precision. The Bi-LSTM is considered to be an adaptive model to investigate semantic relations according to the context. Moreover, the attention mechanism in deep learning simulating human vision could assign weights to target texts effectively. This study proposed to construct a deep learning model combining Bi-LSTM and attention mechanism, in which Bi-LSTM obtained the verbal features and keywords, and the generated keywords were weighed in accordance with the attention mechanism. A total of 12,000 sentences generated in online collaborative discussion activities have been classified into six categories, namely statement, negotiation, question, management, emotion and others. Results showed that the classification accuracy of Attention-Bi-LSTM reached 81.50\&\#x0025;, which is higher than that of the baseline Bi-LSTM model. This study theoretically uncovers the features of collaborative discussion of onliners and practically provides an effective approach to automatic behaviour analysis in an online context.}
}

@article{zhengPatternRecognitionWood2020,
  title = {Pattern Recognition of Wood Structure Design Parameters under External Interference Based on Artificial Neural Network with {{BIM}} Environment},
  author = {Zheng, Q. and Yang, K. and Xu, Q. and Zhang, C. and Wang, L.},
  date = {2020},
  journaltitle = {Journal of Intelligent and Fuzzy Systems},
  volume = {39},
  number = {6},
  pages = {8723--8729},
  doi = {10.3233/JIFS-189268},
  abstract = {Under the influence of novel corona virus pneumonia, the staff are controlled. Therefore, it is a difficult problem to measure the parameters of wood structure building on site. The measurement error of traditional wood structure parameters in complex environment is large, so an efficient and accurate measurement and recognition method is needed. In this paper, a method combining random decrement method and ITD method is proposed to measure the frequency, damping ratio and other structural dynamic parameters of ancient building timber structure under crowd random load excitation. In this paper, the frequency and damping ratio of the typical ancient building timber structure are predicted by using the artificial neural network model trained by the known data. The experimental results show that the population density has a great influence on the measurement of the dynamic parameters of the wooden structure of ancient buildings. Using this method, combined with the long-term monitoring data of temperature and humidity, the influence of various environmental factors on the dynamic characteristics of the structure can be analyzed. This provides data support for structural damage identification and health monitoring.}
}

@article{zhengPatternRecognitionWood2020a,
  title = {Pattern Recognition of Wood Structure Design Parameters under External Interference Based on Artificial Neural Network with {{BIM}} Environment},
  author = {Zheng, Q. and Yang, K. and Xu, Q. and Zhang, C. and Wang, L.},
  date = {2020},
  journaltitle = {Journal of Intelligent and Fuzzy Systems},
  volume = {39},
  number = {6},
  pages = {8723--8729},
  doi = {10.3233/JIFS-189268},
  abstract = {Under the influence of novel corona virus pneumonia, the staff are controlled. Therefore, it is a difficult problem to measure the parameters of wood structure building on site. The measurement error of traditional wood structure parameters in complex environment is large, so an efficient and accurate measurement and recognition method is needed. In this paper, a method combining random decrement method and ITD method is proposed to measure the frequency, damping ratio and other structural dynamic parameters of ancient building timber structure under crowd random load excitation. In this paper, the frequency and damping ratio of the typical ancient building timber structure are predicted by using the artificial neural network model trained by the known data. The experimental results show that the population density has a great influence on the measurement of the dynamic parameters of the wooden structure of ancient buildings. Using this method, combined with the long-term monitoring data of temperature and humidity, the influence of various environmental factors on the dynamic characteristics of the structure can be analyzed. This provides data support for structural damage identification and health monitoring.}
}

@article{zhongMultiobjectiveOptimizationModel2019,
  title = {A Multiobjective Optimization Model for Locating Affordable Housing Investments While Maximizing Accessibility to Jobs by Public Transportation},
  author = {Zhong, Qing and Karner, Alex and Kuby, Michael and Golub, Aaron},
  date = {2019-03},
  journaltitle = {Environment and Planning B: Urban Analytics and City Science},
  shortjournal = {Environment and Planning B: Urban Analytics and City Science},
  volume = {46},
  number = {3},
  pages = {490--510},
  issn = {2399-8083, 2399-8091},
  doi = {10.1177/2399808317719708},
  url = {http://journals.sagepub.com/doi/10.1177/2399808317719708},
  urldate = {2023-09-17},
  abstract = {This paper develops a new optimal location model for siting affordable housing units to maximize the accessibility of low-income workers to appropriate jobs by public transportation. Transit-accessible housing allows disadvantaged populations to reduce their reliance on automobiles, which can lead to savings on transportation-related expenditures. The housing location model developed here maximizes transit accessibility while reducing the clustering of affordable housing units in space. Accessibility is maximized using a high-resolution space-time metric of public transit accessibility, originally developed for service equity analysis. The second objective disperses subsidized housing projects across space using a new minimax dispersion model based on spatial interaction principles. The multiobjective model trades off accessibility maximization and affordable housing dispersion, subject to upper and lower bounds on the land acquisition and construction budget. The model is tested using data for Tempe, AZ including actual data for vacant parcels, travel times by light rail and bus, and the location of low-wage jobs. This model or similar variants could provide insightful spatial decision support to affordable-housing providers or tax-credit administrators, facilitating the design of flexible strategies that address multiple social goals.},
  langid = {english}
}

@inproceedings{zhouBilateralDualarmTeleoperation2021,
  title = {A Bilateral Dual-Arm Teleoperation Robot System with a Unified Control Architecture},
  booktitle = {2021 30th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}}, {{RO-MAN}} 2021},
  author = {Zhou, C. and Zhao, L. and Wang, H. and Chen, L. and Zheng, Y.},
  date = {2021},
  pages = {495--502},
  doi = {10.1109/RO-MAN50785.2021.9515523},
  abstract = {The teleoperation system can transmit human intention to the remote robot, so that the system combines excellent robot operation performance and human intelligence. In this article, we have established a bilateral teleoperation system with force feedback from the arm and gripper. That is, the slave robot system can provide force feedback on both the wrist and the fingers, while the master robot system can render the slave feedback force and human interaction force, and control the slave robot accordingly. In addition, this paper also proposes the framework of the robot's four-channel bilateral teleoperation control system, which is attributed to two situations: impedance control or admittance control. Finally, single-arm/single-arm, dual-arm/dual-arm bilateral teleoperation experiments prove the effectiveness of the bilateral teleoperation system and the four-channel controller architecture proposed in this paper.},
  isbn = {978-1-66540-492-1}
}

@inproceedings{zhouBilateralDualarmTeleoperation2021a,
  title = {A Bilateral Dual-Arm Teleoperation Robot System with a Unified Control Architecture},
  booktitle = {2021 30th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}}, {{RO-MAN}} 2021},
  author = {Zhou, C. and Zhao, L. and Wang, H. and Chen, L. and Zheng, Y.},
  date = {2021},
  pages = {495--502},
  doi = {10.1109/RO-MAN50785.2021.9515523},
  abstract = {The teleoperation system can transmit human intention to the remote robot, so that the system combines excellent robot operation performance and human intelligence. In this article, we have established a bilateral teleoperation system with force feedback from the arm and gripper. That is, the slave robot system can provide force feedback on both the wrist and the fingers, while the master robot system can render the slave feedback force and human interaction force, and control the slave robot accordingly. In addition, this paper also proposes the framework of the robot's four-channel bilateral teleoperation control system, which is attributed to two situations: impedance control or admittance control. Finally, single-arm/single-arm, dual-arm/dual-arm bilateral teleoperation experiments prove the effectiveness of the bilateral teleoperation system and the four-channel controller architecture proposed in this paper.},
  isbn = {978-1-66540-492-1}
}

@article{zilbersteinResourceboundedSensingPlanning1996,
  title = {Resource-Bounded Sensing and Planning in Autonomous Systems},
  author = {Zilberstein, S.},
  date = {1996},
  journaltitle = {Autonomous Robots},
  volume = {3},
  number = {1},
  pages = {31--48},
  doi = {10.1007/BF00162466},
  abstract = {This paper is concerned with the implications of limited computational resources and uncertainty on the design of autonomous systems. To address this problem, we redefine the principal role of sensor interpretation and planning processes. Following Agre and Chapman's plan-as-communication approach, sensing and planning are treated as computational processes that provide information to an execution architecture and thus improve the overall performance of the system. We argue that autonomous systems must be able to trade off the quality of this information with the computational resources required to produce it. Anytime algorithms, whose quality of results improves gradually as computation time increases, provide useful performance components for time-critical sensing and planning in robotic systems. In our earlier work, we introduced a compilation scheme for optimal composition of anytime algorithms. This paper demonstrates the applicability of the compilation technique to the construction of autonomous systems. The result is a flexible approach to construct systems that can operate robustly in real-time by exploiting the tradeoff between time and quality in planning, sensing and plan execution. © 1996 Kluwer Academic Publishers.}
}

@article{zilbersteinResourceboundedSensingPlanning1996a,
  title = {Resource-Bounded Sensing and Planning in Autonomous Systems},
  author = {Zilberstein, S.},
  date = {1996},
  journaltitle = {Autonomous Robots},
  volume = {3},
  number = {1},
  pages = {31--48},
  doi = {10.1007/BF00162466},
  abstract = {This paper is concerned with the implications of limited computational resources and uncertainty on the design of autonomous systems. To address this problem, we redefine the principal role of sensor interpretation and planning processes. Following Agre and Chapman's plan-as-communication approach, sensing and planning are treated as computational processes that provide information to an execution architecture and thus improve the overall performance of the system. We argue that autonomous systems must be able to trade off the quality of this information with the computational resources required to produce it. Anytime algorithms, whose quality of results improves gradually as computation time increases, provide useful performance components for time-critical sensing and planning in robotic systems. In our earlier work, we introduced a compilation scheme for optimal composition of anytime algorithms. This paper demonstrates the applicability of the compilation technique to the construction of autonomous systems. The result is a flexible approach to construct systems that can operate robustly in real-time by exploiting the tradeoff between time and quality in planning, sensing and plan execution. © 1996 Kluwer Academic Publishers.}
}

@misc{zotero-1833,
  type = {misc}
}
